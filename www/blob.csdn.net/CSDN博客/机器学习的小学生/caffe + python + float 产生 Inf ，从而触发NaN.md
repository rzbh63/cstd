
# caffe + python + float 产生 Inf ，从而触发NaN - 机器学习的小学生 - CSDN博客


2018年06月13日 11:12:40[机器学习的小学生](https://me.csdn.net/xuluhui123)阅读数：317


损失函数在训练过程中，如果在刚开始的迭代过程中损失函数就发散变为了Inf 或者NaN，那么往往可以通过调节学习率来解决。
另外一种情况是在迭代了数千次，例如我迭代了1800次，忽然出现损失函数为Inf或者NaN的情况，在我的实验情况下是由于caffe的python接口使用的是单精度float类型，在自己用python定义的层中，使用到了指数函数np.exp(a)，当a的 值超过某个数时例如90，使用单精度无法表示，就产生了Inf值。解决方法是在自己定义的python层中将bottom[0].data或者其他都转化为double类型然后再操作。
后续… 对于一些数值（如e^90），虽然能够利用双精度表示了，但是再进一步的迭代过程中出现了更大的数据，例如(e^710) ，即上一层产生的激活值大于710，导致 e^710 会产生溢出。现在问题还未解决….

