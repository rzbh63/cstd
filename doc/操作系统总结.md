# 操作系统总结



# 操作系统概述



　　我觉得学习某样知识的最大原动力在于，当你觉得现有知识不足以解决当前问题的时候的求知欲。为了彻底与系统底层做个了断。今天开始全面复习系统底层知识，从操作系统开始吧，到UNIX，再到虚拟机。我希望自己能把一件事情的本质，用自己的话讲出来。

# 一、操作系统是什么

　　计算机是什么？说白了，硬件加软件的集合。操作系统是什么？是操作最底层硬件的那层软件。有了操作系统，我们就无需外部输入1010这样的二进制信息让计算机处理了，这么说吧，计算机硬件是一组资源，操作系统把这些资源都封装了，让你可以更方便的使用它。

　　对于计算机的资源，可以分为4类，按照教科书上的说法，就是处理器、存储器、I/O设备以及信息（数据和程序），说白了，指的就是CPU、内存、输入输出设备（鼠标、键盘、显示器等等）、硬盘和硬盘上的软件。操作系统封装了计算机硬件系统，并且管理计算机的4种资源，这就是操作系统的功能。很容易理解吧。

 

# 二、操作系统发展历程

　　操作系统的发展历程很重要，它可以让我们意识到，技术改进最重要的作用，就是改变目前最迫切需要改变的东西。

　　这里三言两语介绍一下操作系统的发展历程。

### （1） 人工操作方式。

　　传说中的纸带操作。把程序和数据用最简单的纸带记录下来，然后通过纸带输入（I/O）进计算机（内存），然后计算机运行。这时候我们可以看到，计算机I/O和信息（硬盘程序、数据）都是通过简单的纸带来存储并传送的。速度当然慢。

### （2） 脱机输入/输出方式。

　　这个跟纸带也脱不了关系，不过是将纸带信息预先装进磁带上，然后计算机运行的时候，程序和信息从磁带调入内存。这样的速度当然大大提升了。我们可以看到，这种方式，说白了就是给计算机增加了一个简单的硬盘，程序和数据放在硬盘上，而不是纸带上。

### （3） 单批道处理系统。

　　这是最早的操作系统了。CPU控制“监督程序”将磁带上的一个作业（程序和数据）调入内存，然后运行它，然后调用下一个作业入内存，再运行它。这样依次运行完磁带上的所有作业。系统内存中一个时刻只有一道程序在运行，CPU也只是单线程的处理完IO再处理程序这样循环。

### （4） 多道批处理系统。

　　这是效率非常高的一种操作系统。用户提交的作业在硬盘上并排成一个队列，然后调度程序把若干作业放进内存。某个作业执行的时候，遇到IO请求，不阻塞，不让CPU空闲，而是让CPU去执行内存中的另一个作业。这样各个作业轮流执行，CPU等系统资源尽可能的保持占用。

### （5） 分时系统。

　　这是一种多用户系统，主要特点就是多用户同时使用，每个用户都有自己的终端对计算机进行操作。分时系统采用了非常经典的时间片，即每个用户、每个作业在一个时间片内，都依次运行，并只运行一个很短的时间，这样看上去好像每个用户都独占了整个计算机一样。分时系统主要用于查询系统。

### （6）实时系统。

　　实时系统可以看作是一种面向内部的要求更高更精确的分时系统。不过这种“分时”不一定通过时间片来控制，也可能是通过一个设定的截止时间来控制。系统内部是对多项实时任务的采集和控制。说白了，就是一种精确的多任务系统。

### （7）微机操作系统。

　　这个就很简单啦，分别有单用户单任务操作系统（CP/M、MS-DOS等）、单用户多任务操作系统（Windows95、XP等）、多用户多任务操作系统（UNIX OS等）。

 

# 三、操作系统的结构

### （1）无结构OS（第一代）

　　这是最早期的操作系统，仅仅追求功能和实现，无需深究。

### （2）模块化结构的OS（第二代）

　　将OS划分为若干各自独立的模块，如进程管理模块、存储器管理模块、文件管理模块等，并将各模块划分为各自的子模块，这样不断细分，系统就有比较清晰的模块化结构。不过由于模块化结构设计中，各个模块的设计齐头并进，没有可靠的“决定顺序”，这种设计又被称为“无序模块法”。这一代OS在第一代的基础上加上了模块的划分，便前进了一大步。

### （3）分层式结构的OS（第三代）

　　自底向上的分层设计，最底层只面向硬件，功能单一而正确，此后每层看待下层都是透明的，功能不断丰富、往高层不断抽象，高层只依赖于它的底层。这也是面向对象思想的体现。这种结构与我们熟知的网络协议体系结构非常类似。这种结构在软件设计上是非常常见的。简单说就是按层划分、不断抽象，每层只操作下一层。 　　 　　

### （4）微内核结构的OS（现代结构OS）

 　　微内核结构的OS将系统划分为两大部分：微内核和多个系统服务器。微内核指的是足够小的、能实现现代OS最基本功能的部分。它负责于硬件最基本的联系、与外层系统服务器通信这两大基本功能。外层系统服务器指的是操作系统内部的，将各种系统服务都抽象为一种模块化的服务器结构，用一个进程来表示，如文件服务器、进程服务器等。我们都知道，服务器的本质就是对消息的请求和响应，这十分适用于当今系统所要求的分布式处理。用一个足够简单和高效率的微内核来对各个服务器进行实际的处理，各个服务器是总体而言是模块化的，而服务器本身是建立在分层次的OS上的，这种设计模式不但可靠，而且扩展性和性能都非常优越。这种设计实在是优雅。

 



# 进程（上）



　　上一篇博文复习了操作系统总的概述——[我的操作系统复习——操作系统概述](http://www.cnblogs.com/zrtqsk/p/4064155.html) ，包括对操作系统的定义、发展历程以及操作系统结构。接下来我们就开始详细复习计算机知识，包括进程、处理器、存储器等等。本篇首先对进程这个及其重要的概念进行复习，这是进程系列的上篇。

 

 

# 一、什么是并发

　　并发是什么？很简单，前面介绍的多道批处理系统就是典型的并发执行。这里再次过一遍高性能的多道批处理系统，其本质在于保持对系统资源的占用，CPU运行一个任务，若这个任务中断，如需要IO请求之类的，那么CPU直接去运行其他任务，原任务的IO请求由IO设备自己处理。有一个著名的图——表示并发：

　　![img](https://images0.cnblogs.com/blog/580631/201412/172311308127677.png)

　　如图，假设计算机有输入、计算、输出这三个部件，一组任务顺序执行，并发就是如图流水线一样的各部件配合。某一时刻，只有一个程序在占用CPU（计算设备）。那么什么是并行呢？并行是建立在多核的基础上的，即多个CPU同时运行，那么有几个CPU，同一时刻就有几个程序同时运行。所以电脑只有一个CPU的苦逼程序员只能并发了。

　　现代系统的实际并发比上图要复杂的多，现代计算机系统的并发是以时间片为基础的，即在很短的时间内，每个进程都分别运行一次。这样，宏观上，每个进程都在不断的运行，而实际上每个进程的运行都是间断运行的。那么问题来了，什么是进程呢？

　

------

 

# 二、什么是进程 

　　进程的目的就是为了对并发执行的程序进行控制。进程实体由程序段、数据段、PCB三部分构成。我们知道计算机运行的本质就是对数据的处理的机器。

　　——数据段就是各种数据

　　——程序段就是一系列操作计算机的指令，即操作数据的方法策略

　　——PCB 即进程控制块（Process Control Block），控制运行程序段的时机。

　　书本上是这样定义进程的：**“进程是进程实体的运行过程，是系统进行资源分配和调度的一个独立单位”。**

　　让我们理清楚思绪，进程是什么？进程就是进程实体的运行过程，是一个过程。就是说，进程实体不运行，那就不叫进程。一个没有被调用的进程实体，不叫进程。**所以说，进程有动态的特征**。上面提到，进程的目的就是为了对并发执行的程序进行控制。为了在一个时间片内，运行多个程序才引进进程。**所以说，进程有并发的特征。**进程实体是一个拥有独立的资源（程序段和数据段）、（因为PCB）能独立地接受调度并独立的运行的基本单位。**所以说，进程有独立的特征**。进程运行的过程中，由于涉及到的资源众多、运行环境不一定，也受到其他进程的影响，所以，进程的运行情况是不可具体预知的。所以书本定义，进程按各自独立的、不可预知的速度向前推进。**所以说，进程有异步的特征。**如上文所说，进程是进程实体这一数据结构被调用运行。**所以说，进程有结构的特征。**

　　可以这么说，真正理解了进程的这五个特征，才算理解了进程这个概念。高手跟我们这些菜鸟的最大区别，不就在于对系统的理解吗？ 　　

 

------

 

# 三、进程的状态

　　进程有3种基本状态：

**（1）就绪（Ready）状态**

　　此时的进程拥有完整的进程实体，只要获得CPU，即只要被调用就能马上执行，这种状态被称为就绪状态。处于这种状态的进程都会被放进就绪队列，以便随时接受CPU调用。

**（2）执行状态**

　　此时的进程已经获得CPU，正在执行。

**（3）阻塞状态**

　　执行中的进程，因为某种原因（IO请求）无法继续执行的一种暂停状态，暂停完毕就会变成就绪状态。

　　*除了以上的3种基本状态，有的系统额外还增加了一种状态。*

**（4）挂起状态**

　　为什么需要挂起状态？因为有时候希望某些正在执行的线程暂停下来，持续一段时间后，让它回到之前的状态。

　　挂起状态是一种静止的状态，相当于把某个进程从执行的流水线上拿出来，等到需要的时候再把它放进去继续执行。我们来看前三种基本状态，就绪 ->执行 -> 阻塞，阻塞完毕又回到就绪。由于线程的异步性，阻塞是会在不确定的有限时间内结束的。就是说，三种基本状态是动态的，通常不存在一个线程一直处于某种状态。挂起状态相对于它们来说，是静止的，因为它是被控制的，是对以不可预知的速度前进的线程的一种干扰。

　　*此外，为了管理的需要，通常还有两种比较常见的状态。*

**（5）创建状态**

　　我们知道进程实体包括程序段、数据段和PCB。创建状态指的是PCB已经被创建，因为某些原因（程序段或数据段未放入内存等），进程还未被放入就绪队列的这种状态。

**（6）终止状态**

　　线程的终止也是有个过程的。终止状态指的是线程除了PCB以外的系统资源都被回收后的状态。此时线程真正终止。

 

------

 

# 四、进程的核心PCB

### （1）PCB是什麽？

　　作为进程实体的一部分，PCB是用来控制进程运行的一种数据结构。它包含了进程的状态、优先级、运行的状态、处理机状态、程序数据的内存地址等各种信息，一旦被操作系统调用，操作系统就从PCB中获取的信息，来恢复进程阻塞前的现场，继续执行。PCB一般都保存在CPU的寄存器中。

### （2）PCB包含的信息

　　1）**进程标识符**。用来标识唯一的一个进程。包括方便系统调用的内部标识符和方便用户调用的外部标识符。进程标识符通常还包括父、子进程，以及所属用户等信息。

　　2）**处理机状态信息**。

　　　　处理机状态信息指的是处理机调用线程时的环境信息。处理机处理调用进程时，运行过程中的许多信息都放在处理机的寄存器中。进程阻塞或挂起时，寄存器中的运行信息会保存到PCB中，以便进程下次被调用时恢复之前的运行现场。

　　3）**进程调度信息**。

　　　　进程调度信息指的是本进程调度所需的必要信息。包括，本进程的状态（6种之一）、进程优先级、进程等待时间、进程执行时间（可能决定优先级）、阻塞原因、父子进程关系等。

　　4）**进程控制信息**。

　　　　进程控制信息指的是进程的资源信息和进程切换时的所需信息，包括进程的程序和数据的内存地址、进程同步和通信的机制、进程资源的清单、指向下一个进程PCB的指针（若PCB的组织方式是链接方式）等。

### （3）PCB的具体信息（结构）

 　　这里我们来看一下Unix中，PCB的具体结构，以便对PCB有一个清晰的认识。这玩意其实就这么一回事：

（下面代码摘自http://blog.sina.com.cn/s/blog_65403f9b0100gs3a.html）

![img](https://images.cnblogs.com/OutliningIndicators/ContractedBlock.gif) View Code

###  （4）PCB的组织形式

　　系统中拥有众多PCB，对应着众多进程，那么这些PCB怎么组织的呢？一般有两种组织方式：链接方式和索引方式。这两种方式的共同点在于，正在执行的PCB，都有一个执行指针指向它。不同在于，链接方式的就绪队列、阻塞队列等，通过指针链接的方式组织。进程切换时，直接取就绪队列指针即可，因为它指向的就是当前优先级最高的就绪的PCB，随后就绪队列指针指向其指向的下一个PCB。索引方式的就绪队列、阻塞队列等，通过一个表的形式来组织，就绪队列指针指向这个表的第一条数据。这个表本质是一个指针数组，第一个指针指向的当然是优先级最高的就绪进程。

 

------

 

# 五、进程控制

　　进程控制是什麽？本质就是切换进程状态的控制。 一般由操作系统中的原语实现。原语即具有“原子操作”这种属性的若干指令集合，说白了，就是这些指令集合，要么全部执行，要么全部不执行。不同操作系统的原语也是有区别的。

###  （1）、进程创建

　　进程可能是由系统内核收到请求而创建，也可能由进程本身创建，由进程本身创建的进程一般是子进程，它继承父进程拥有的全部资源。创建进程由**进程创建原语**实现，通常由下面几个步骤：

 

 ![img](https://images0.cnblogs.com/blog/580631/201412/211031230629178.png)

 

 

 

 

 

 

 

###  （2）、进程终止

 　　进程的终止是由操作系统执行的。当一个进程因各种原因结束时，会通知操作系统。操作系统会调用**进程终止原语**来终止对应进程：

 ![img](https://images0.cnblogs.com/blog/580631/201412/211046405156225.png)

 

###  （3）进程阻塞

　　进程的阻塞是由进程自身主动执行的。但进程发现自身无法继续执行时，就主动调用**进程阻塞原语**，把自己阻塞：

 ![img](https://images0.cnblogs.com/blog/580631/201412/211115402651188.png)

###  （4）进程唤醒

　　进程的唤醒通常由其他线程执行。但其他线程由于某些事件希望执行线程执行时，会调用进程唤醒原语将指定进程唤醒：

　　![img](https://images0.cnblogs.com/blog/580631/201412/211121332652411.png)

 　　值得注意的是，进程唤醒和进程阻塞是一对作用刚好相反的原语。阻塞的进程必须由进程唤醒操作才能继续执行。

### （5）进程挂起和激活

　　进程挂起由自身或其他进程执行。进程激活由其他进程执行。过程很简单，就不画图了：

　　1）进程挂起：若进程为活动就绪，就将其改为静止就绪；若进程为活动阻塞，就将其改为静止阻塞；若进程正在执行，则让调度程序重新调度。

　　（PS：由于没有挂起队列，所以需要把进程的PCB复制到指定的内存区域）

　　2）进程激活：若进程为静止就绪，就将其改为活动就绪；若进程为静止阻塞，就将其改为活动阻塞；

 

 



# 进程（下）



　　上一篇博客是复习操作系统进程篇的上篇，包括进程状态、PCB、进程控制等——[我的操作系统复习——进程（上）](http://www.cnblogs.com/zrtqsk/p/4170666.html)，本篇博文是进程篇的下篇，开始复习进程同步、进程通信，以及重要的线程概念。

 

# 一、进程同步

 　　什么是同步？同步就是说一个任务要等另一个执行完毕才能继续执行，而不是同时执行。我们都知道，进程有异步性，这种性质会导致操作系统的混乱。进程同步，指的是进程之间的执行次序的管理，就是为了解决进程异步性的这种混乱。

### 　　（1）直接制约和间接制约。

　　进程之间有两种制约关系。分别是直接制约和间接制约。直接制约指的是进程间的合作，即一个进程需要另一个进程的配合，否则会阻塞。如输出缓冲区为空的时候，输出进程就会阻塞，输出进程依赖输入进程不断的输入。间接制约指的是对于某种资源，同时只能有一个进程占用，你用的时候，别人就不能用。

### 　　（2）同步机制应遵循的规则。

　　这是所有的同步机制所需要遵循的规则：

　　　　1）空闲让进。资源空闲的时候，允许进程访问。

　　　　2）忙则等待。资源被占用的时候，进程必须等待。

　　　　3）有限等待。应保证进程有限时间能访问到资源，不能无限等待。

　　　　4）让权等待。运行中的进程不能访问指定资源时，应释放处理机。

 

# 二、PV操作

　　PV操作的鼎鼎大名，想必很多人都听说过。它就是经典的实现最基本的进程同步机制的一对操作。为什么叫PV操作呢？它是鼎鼎大名的计算机学家狄克斯特拉用荷兰语定义的，在荷兰文中，通过叫passeren，释放叫vrijgeven。P操作又叫Wait(S)，本质是使用资源，V操作又叫Sign(S)，本质是释放资源。PV操作都是原子操作，要么全做，要么全不做，并且PV操作是成对的。我们来详细看看PV操作的原理，是怎么实现进程同步的。PV操作跟信号量是分不开的，先看看什么是信号量。

### （1）什么是信号量？

　　信号量是一种数据结构。包括整形信号量、记录型信号量、AND型信号量和信号量集等。不同的信号量对应不同的数据结构，也对应不同的PV操作。信号量和操作它的PV操作构成了对

应的信号量机制，用来控制进程同步。

### （2）整型信号量。

　　顾名思义，整形信号量的数据结构就是一个简单的整形，一般用整形S来表示。其上的PV操作如下：

（这里的程序代码都是Pascal代码）

```
wait(S):    while S <= 0  do no-op;
            s := s - 1
sinal(S):    s := s + 1
```

　　如上，S代表的是资源数目。对于wait(S)操作，当资源数目小于等于0的时候，就一直等待。若有资源，就跳出循环，使用一个资源。

　　对于sinal(S)操作，每次执行都释放一个资源。

### （3）记录型信号量。　　

　　这个信号量比整形信号量增加了一个标识进程指针的属性，指向所有等待的进程链表。

　　PV操作与整形信号量的区别在于，wait()时，若s<=0,那么阻塞自身，放弃处理机。signal()后，判断若s<=0,就唤醒一个进程。它的好处是当进程请求不到资源的时候，不会无限等待。

### （4）AND型信号量。

　　AND型信号量是针对多个临界资源而言的。即将进程运行中所需要的所有资源一次性分配给进程，进程运行完毕后释放所有资源。相当于把进程所需的所有资源捆绑在一起了。做法就是在wait操作中增加一个AND条件：只有当进程所需的所有资源处于空闲状态时，进程才能继续操作。

### （5）信号量集。

　　信号量集指的是一次性对N个某类资源的请求处理。上面的AND型信号量指的是对多个不同类型资源的处理，而信号量集指的是对同类的多个资源的处理，也相当于AND型信号量的特殊情况。

### （6）管程

　　由于进程对某一个资源进行操作的时候，都需要自带一对PV操作，为了避免这种情况，把某个资源和进程对其进行的操作包装起来，这样的一个模块称为管程。它是操作系统中的一个资源管理模块，供进程调用。可以看到，管程实现了面向对象的思想。

### （7）条件变量

　　在上面的进程同步的实现中都有一个很严重的隐含问题，那就是，如果某个进程一直不释放某个资源，其他进程就只能无止休地等待。条件变量的意义在于，除了原本的资源空闲就让进、处理完就释放这样的逻辑外，还有其他的条件。例如：资源空闲且XX条件，就让进。处理完成或XX条件就释放资源。这些额外的条件，就叫条件变量。

 

# 三、进程通信

 　　上面的通过信号量进行的进程同步，其本质是一种低级的通信机制。进程之间无法大量交换信息。那么两个进程之间想要实现大量的、频繁的信息交换，该怎么做呢？这就是高级通信机制了。高级通信机制有三大类：

### 　　（1）共享存储器系统。

　　　　存储器即内存，共享存储器，顾名思义，就是通信的两个进程通过共享的一块内存区域来通信，一个负责读一个负责写。而实际上面的信号量也是一种共享存储器系统，只不过进程间共享的是一个数据结构，并用PV操作对数据结构进行操作。

### 　　（2）消息传递系统。

　　　　进程间通过指定格式的消息进行通信。消息格式通常就是一个包含地址的头和一个包含内容的body。这种格式也叫做协议。我们常见的网络协议也是这种方式。消息传递系统分为直接通信方式和间接通信方式。直接通信方式即通信的进程双方都知道对方的存在，并在消息头中携带了自身和对方的地址信息。间接通信方式即进程间的消息传递不是直接传递给对方，而是有一个中间实体暂存、并转发，这样避免了进程双方接收、发送数据的速率不统一导致的进程阻塞。

### 　　（3）管道通信。

 　　　　管道是一种连接读进程和写进程的共享文件——pipe文件，其本质是固定大小的缓冲区，这个缓冲区将2个进程连接起来，这两个进程对管道是互斥的访问，且写进程写入数据后便阻塞，直到读进程取走所有数据才被唤醒继续写数据。这种一次性的读操作和写操作，虽然会导致进程堵塞，但是在读写的过程中无须维护读写指针，效率非常高。

 

# 四、线程

　　线程是什么？线程就为了使操作系统能够有更好的并发而创建的，相当于只拥有少量资源的进程——轻型进程。在这种多线程操作系统中，进程是拥有系统资源的基本单位，包含多个线程，为其提供资源，而进程本身不再作为可执行的实体，当进程执行的时候，实际上是其中的某个线程在执行。

### （1）线程执行的本质。

　　理解线程就必须深入理解并发。并发的本质就是单处理机系统永远都是线性执行任务的。而线程的本质就是将原本为实现进程的时间片划分的更细，假设在某个单处理机操作系统中，时间片为20毫秒，即一个进程的单次执行时间为20毫秒，在这个进程内有50个线程在执行，那么划分后，平均每个线程的执行时间肯定小于0.4毫秒。不过对于大部分任务而言，这仍旧是足够的。线程无非就是这样。

### （2）线程的类型和实现。

　　**1）用户级线程（User Level Thread）——ULT。**

　　这种线程的实现非常简单，对于处理器而言，它仍旧是在进行进程切换，并不知道有线程的存在。如果每个进程相当于一个车子，那每个线程都相当于一个司机，线程切换就是不断在换司机。

　　那么在进程内部如何分割出各种多线程的呢？进程中有一个函数集合，专门用来管理和控制线程的执行。这个函数集合被称为运行时系统。进程执行时就是执行它的运行时系统，对其中的线程进行切换管理。线程的运行时信息——线程控制块TCB存放在各自的堆栈中，每次切换的时候，运行时系统就从线程的堆栈中取得对应的运行时信息，设置CPU的寄存器中，之后便可以运行。值得注意的是，线程是不能直接调用系统资源的，线程需要系统资源时，需要由运行时系统来调用分配。

　　**2）内核支持线程（KernelSupported Thread）——KST。**

　　这种线程的创建、撤销、切换就不是依赖进程，是直接像进程调度一样由内核控制，由于线程基本不用有资源，所以这种调度也很快。内核支持线程的线程优先级通常比用户级线程要高很多。

　　那么内核支持线程如何实现的呢？创建一个进程时，系统为之分配一个任务数据区（Per Task Data Area），其中包含若干线程控制块TCB，这些TCB并非存放在进程资源内存中，而是保存在CPU的寄存器中。然后进行跟PCB非常类似的由处理器切换控制。

　　**3）组合方式，由轻型进程（Light weight process）——LWP实现。**

　　内核支持多KST线程的创建，同时支持ULT线程的创建，这种支持是通过轻型进程LWP实现的。轻型进程LWP的本质就是一个KST进程，它的特点就是能够让ULT连接，当ULT连接它的时候，就相当于在调用KST，可以实现KST的所有功能。所以一般LWP都是用线程池来实现的。可以看到LWP的目的就是为了让用户级线程ULT直接能调用系统资源。

 

　　



# [处理机调度](https://www.cnblogs.com/zrtqsk/p/4192091.html)



　　前两篇博客都是在讲操作系统进程，包括进程状态、PCB、进程同步、通信、线程等——[我的操作系统复习——进程（上）](http://www.cnblogs.com/zrtqsk/p/4170666.html) 和 [我的操作系统复习——进程（下](http://www.cnblogs.com/zrtqsk/p/4176879.html)），本篇开始讲处理器调度，包括处理机调度算法、死锁等。 

# 一、处理机调度的类型

处理机调度程序按照某种算法将处理机分配给某个进程，这就叫处理机调度。总体而言，按层次分，有三种类型：

### （1）作业调度（又称高级调度、长程调度）。

　　作业调度的本质就是根据某种算法，把外存上的作业调入内存，并为之创建进程，分配处理机并执行。这里有两个概念：

　　1）作业（Job）

　　在操作系统概述中，我们了解过操作系统的发展历程，在单道批处理系统和多道批处理系统中粗略了解过作业的概念。作业是一个比程序更广泛的概念，可以包含多个程序和数据，还包含一份作业说明书，处理机根据作业说明书来对作业中的程序进行控制。一般而言，批处理系统中才会有高级调度。

　　2）作业步（Job Step）

　　作业步的本质就是程序。作业运行过程中的每一个步骤可以称为一个作业步。典型的作业可分为三个作业步：编译作业步->连续装配作业步->运行作业步。相当于我们的程序代码的整个执行步骤。

 

### （2）进程调度（又称低级调度、短程调度）。

　　进程调度的本质就是根据某种算法，把处理机分配给进程。进程调度首先会保存处理机现场。将程序计数器等指定寄存器中的内容保存到PCB中。然后将按照某种算法从就绪队列中选取进程，把处理机分配给进程。最后，把指定进程的PCB中的处理机现场信息恢复到处理机中，处理机分配给进程执行。这里需要额外的了解一下进程调度中的三个基本机制和两种调度方式：

　　1）进程调度中的三个基本机制

- 排队器。将所有的就绪进程按照一定方式 （如优先级）排成一个队列，以便调度程序找到。
- 分派器。把从就绪队列中取出的进程，处理机上下文切换后，把处理机分配给该进程执行。
- 上下文切换机制。

　　（PS：这里有一个额外的知识：通常每一次上下文切换需要花费几毫秒的时间。有一种简单的方式，通过多组寄存器来减少上下文切换的时间。一组寄存器供处理机在系统态使用，一组供处理机在应用程序状态时使用。这样，上下文切换的时候只需要改变指针，指向当前的寄存器。）

　　（PSS：CPU的系统态就是CPU在执行操作系统，用户态则是CPU在执行普通应用程序。）

　　2）进程调度的两种调度方式

- 非抢占式（Nonpreemptive Mode）。说白了就是一旦把进程分配给某个进程，除非它自愿退出，它将永远运行下去。
- 抢占式（Preemptive Mode）。说白了就是可以根据某种条件，使正在运行的进程暂停，将处理机分配给另一个进程。相当于信号量机制中的条件变量。

 

### （3）中级调度

　　中级调度的本质就是让暂时不能运行的进程挂起，释放内存资源，并把它们调到外存上去等待。什么是外存？外存就是硬盘、磁盘等存储设备。

 

# 二、调度算法

说到调度算法，那么有几个衡量进程运行效率的名词需要了解一下，在做题的时候需要用到：

- 服务时间：进程总共需要占用处理机的时间长度。
- 开始执行时间：进程开始执行的时间点。
- 完成时间：进程执行完毕的时间点。
- 周转时间：完成时间-到达时间。
- 带权周转时间：周转时间/服务时间。
- 到达时间：进程进入就绪队列的时间点

### （1）先来先服务调度算法（FCFS）。

　　顾名思义。就是先来的先进入内存或占用处理机。对于作业调度，就是从后备作业队列中选择一个或多个最先进入队列的作业，将其调入内存。对于进程调度就是从就绪队列选择最新进入的进程，为之分配处理机。

 

### （2）短作业（进程）优先调度算法（SJ(P)F）

　　顾名思义。就是在选择作业或进程的时候，先估算每个作业、进程的服务时间，选择其中最短的优先获得处理机。

 

### （3）高优先权优先调度算法。

　　这种算法给进程加了一个属性，那就是优先权。这个算法的本质就是，高优先权的优先调用。优先权有两种类型，一种是静态的，即每个进程、作业的优先权在它创建的时候就已经确定，此后都不能改变。另一种是动态的，即进程、作业的优先权是可以改变的。最常见的做法就是进程、作业在等待中，优先权以一定速率随时间增长，这样等待时间越长，被调用的可能性就越大。

 

### （4）基于时间片的轮转调度法。

　　这就是分时系统中采用的调度算法。原理就是把所有的就绪队列进程按先来先服务的原则排成队列。每次都把CPU分配给队首，让其执行一个时间片，执行完毕，调度器中断进程，并把该进程移至就绪队列的队尾，然后再取一个队首进程，继续执行下一个时间片。时间片是什么，就是一段很短的CPU时间，几毫秒到几百毫秒不等。

 

### （5）多级反馈队列调度算法。

　　这是当下公认的比较好的，使用最广泛的调度算法。其原理也不难。例如，某计算机采用多级反馈队列调度算法，设置了5个就绪队列。第一个就绪队列优先级最高，时间片为2ms。第二个就绪队列优先级第二，时间片为4ms，其余队列也一样，优先级依次递减，时间片依次增加。如果某个进程进入就绪队列，首先把它放在第一个就绪队列的末尾，轮到它执行就执行2ms，时间片结束，若该进程还没有执行完毕，就把该进程移入第二个就绪队列的末尾。只有当第一个队列的进程都执行完时间片，才会执行第二个队列。如此依次执行，若该进程服务时间很长，将被移到最后一个就绪队列。在最后一个就绪队列，进程将按照时间片轮转调度法执行。处理机执行过程中，只有当优先级高的队列中的线程都执行完毕，才会执行优先级低的队列。如图所示（懒得自己画一遍了，直接从书上拿过来）：

 ![img](https://images0.cnblogs.com/blog/580631/201412/301835054976319.png)

# 三、死锁

何谓死锁？即多个进程在运行过程中因争夺资源造成的一种僵局。

（1）、产生死锁的必要原因：

　　1）互斥条件。即一段时间内，某资源只能由一个进程占用。这段时间，其他的进程只能等待。

　　2）请求和保持条件。进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源又已被其它进程占有，此时请求进程阻塞，但又对自己已获得的其它资源保持不放。

​      3）不剥夺条件。进程已获得的资源，在未使用完之前，不能被剥夺

　　4）环路等待条件。

 

  



# [存储器管理](https://www.cnblogs.com/zrtqsk/p/4195976.html)



　　上篇博客介绍了处理机调度的相关知识——[我的操作系统复习——处理机调度](http://www.cnblogs.com/zrtqsk/p/4192091.html)，本篇开始讲跟处理机打交道最多的计算机部件——存储器。存储器包括常说的内存和外存。存储器管理，一般指的是内存管理。外存也属于存储器，不过应该算作文件管理。

# 一、存储器层次分类

　　存储器按存储层次分可以分为三类，分别是寄存器、主存、辅存。寄存器位于CPU内，主存又称内存，辅存即硬盘。仔细划分的话，主存还可以分为高速缓存、主存、磁盘缓存。如下图所示，层次越往上，存储介质访问速度越快，价格越贵、相对存储容量也越贵。寄存器和主存这里大概说一说，辅存（外存）就留到文件系统的时候再说。

　　![img](https://images0.cnblogs.com/blog/580631/201412/311626000441180.png)

### 　　（1）寄存器

　　寄存器位于CPU内，是CPU的组成部分。它是计算机系统内CPU访问速度最快的存储部件，完全能与CPU协调工作。不过价格太贵，只能做得很小。寄存器是用来存放系统最常访问的数据，如，指令寄存器用来存放从内存读到的正在执行的指令，程序计数器存放下一条指令所在单元的地址。其本质就是用来存放供CPU最频繁访问的一批数据。寄存器就是为了解决CPU访问主存速度过慢的问题。通常，CPU从主存读取数据，放入寄存器内，以便频繁访问。

### 　　（2）主存

　　主存即内存。CPU可以通过指令直接存取主存中的数据，所以CPU对主存的访问速度也很快，不过这个速度也远低于CPU的执行速度。为了解决这个问题，引入了寄存器和高速缓存。高速缓存是什么？高速缓存也是属于内存，不过它与通常的主存的实现形式不同，它一般是由静态存储芯片(SRAM)组成，访问速度比主存高得多， 接近于CPU的速度。而主存通常使用动态MOS随机读写存储器DRAM组成，速度比SRAM快得多。高速缓存的作用就是存放主存中一些经常被访问的信息。磁盘缓存的本质就是主存划分的一个小区域，为了减少CPU透过I/O读取磁盘机的次数，提升磁盘I/O的效率，用一块区域来储存存取较频繁的磁盘内容。

 

# 二、程序的装入和链接

　　程序装入就是把程序和数据放入内存。程序也不是一开始就有的。这里指的程序是最终在内存中运行的模块——装入模块。那么一份源代码是怎么变成可运行的程序的呢？学过C、C++的同学对这个最了解。首先是把源代码用编译程序编译成目标模块，每一份源代码文件对应一个目标模块。然后用链接程序将目标模块和程序所需要的库函数链接起来，变成一个可运行的程序。这个可运行的程序，实质是编译链接后的机器指令，CPU可以运行这些机器指令。程序运行时，装入模块将其放入内存并运行。其中，将这些机器指令何其指向的资源装入内存有3种方式：

### 　　（1）装入：

　　　　**1）绝对装入方式（Absolute Loading Mode）**

　　程序中使用的地址是直接指向内存的绝对地址，那么在把程序装入内存的时候，不需要对程序地址做任何修改，这种装入方式就叫做绝对装入方式。绝对装入方式只能将程序装入到内存中指定的位置，它只适合单道处理环境，这样就不会有内存冲突了。

　　　　**2）可重定位装入方式（Relocation Loading Mode）**

　　可重定位装入方式指的是，将程序装入内存的时候，将程序地址都相对于内存当前地址偏移。这时程序中的地址都是相对地址。值得注意的是，装入时对程序中指令和数据地址的修改过程叫做重定位。

　　　　**3）动态运行时装入方式（Dynamic Run-time Loading）**

　　如果程序在运行时位置需要改变，应该采用动态运行时装入方式。动态运行时装入方式指的是程序中的相对地址并不在装入时就转换成内存中的绝对地址，而是等到真正运行的时候才会转换。

### 　　（2）链接：

　　与程序装入相对应的是程序的链接方式。程序的链接方式也有3种方式，分别是静态链接方式、装入时动态链接和运行时动态链接。分别对应的是程序链接时的3个时间。其中静态链接是程序的目标模块在装入之前就链接好，而装入时动态链接，顾名思义，就是目标模块实在装入内存的时候动态的进行链接，这种方式链接的程序的目标模块是分开存放的，若一个目标模块需要链接给其他多个模块是非常方便的。而在静态链接方式中要实现这个功能，需要其他多个模块都含有该模块的拷贝。

 

# 三、内存分配方式——连续分配方式

　　将内存分配给程序，最典型的方式就是将一个连续的内存空间分配给程序，这就是连续分配方式。这种分配方式细分可以分为单一连续分配、固定分区分配、动态分区分配和动态重定位分区分配。需要了解的是，前面的程序装入内存的过程就是典型的内存分配。就是说，内存的分配通常可能是动态，在程序运行过程中，通常伴随着动态的内存创建和内存回收，其中还涉及到很多缓存、优化之类的策略。在各种内存分配和回收的过程中，会产生很多空余碎片。内存分配就是要尽可能利用内存空间，避免内存浪费。

### 　　（1）单一连续分配

　　这种分配方式就是简单的把内存分为系统区和用户区，系统区给操作系统用，用户区给用户用。这种分配方式非常简单，并未考虑多用户内存冲突和多任务内存冲突的情况，所以只适用于单用户、单任务的OS。值得注意的是，系统区通常是分配在内存的低址部分。

### 　　（2）固定分区分配

　　这种分配方式就是将内存划分为若干固定大小的区域，区域的大小是事先划分好的，每个区域装入一道作业、程序，这样多任务内存冲突的问题就解决了。这种划分方法适用于多道批处理系统——多任务并发的情况。但是，由于每个分区大小固定，存储空间的浪费是必然的。

### 　　（3）动态分区分配

　　这种分配方式就是根据进程的实际需要，动态的分配内存空间。这种分配方式有3个问题需要注意。1、需要有一种数据结构来描述空闲分区和已分配分区的情况。2、需要按照一定的分配算法从空闲分区中选择空间来分配。3、需要有合适的分区分配和内存回收操作：

　　　　**1）描述空闲分区的数据结构：**

　　　　有2种数据结构可以描述空闲分区的数据结构，分别是空闲分区表和空闲分区链。其中，分区表很容易理解，分区链指的是通过在空闲分区的首尾设置2个指向其他空闲分区的指针，形成一个空闲分区的链，用来记录空闲的分区。

　　　　**2）分区分配算法：**

- - 首次适应算法（first fit）：分区链以地址递增的次序链接；分配内存时，从链首开始，查找到一个大小能满足要求的空闲分区就停止。这个算法说白了就先分配内存的低址部分，再分配高址部分。
  - 循环首次适应算法（next fit）：这个分配算法与首次适应算法的区别在于，它分配内存时，不是从链首开始查找，而是从上次找到的空闲分区的下一个分区开始查找。
  - 最佳适应算法（best fit）: 分区链以从小到大的顺序链接；分配内存时，从链首开始，查找到一个能满足要求的空闲分区就停止。
  - 最坏适应算法（worst fit）: 分区链以从大到小的顺序连接；与最佳适应算法相反，每次都挑最大的空闲区来分配。
  - 快速适应算法（quick fit）: 将空闲区根据大小进行分类，每一种类别单独设立一个链表。同时，用一个管理索引表来管理这些链表。那么分配内存的时候只需要查询管理索引表就行了，无需遍历链表，速度非常快。缺点是，这个算法需要一直维护着链表和管理索引表，需要一定系统开销。

　　　　**3）内存分配和回收：**

　　　　在分配空闲分区的时候，值得注意的是，通常空闲分区会有一个“不可再分割的剩余分区大小”的属性，规定了，当空闲分区所剩属性小于它的时候，分区不允许再继续分割，分区也将从空闲分分区链表中移除。

　　　　内存回收的时候，值得注意的是，若回收的内存区与某个空闲分区相邻接，那么需要将它们合并。否则，需要为回收区建立新的空闲分区。 

　　　　**4）伙伴系统：**

　　　　我们知道1G的内存有220个字节，有224个字。那么根据指数，最多分为24个空闲分区链表。假设一个应用程序申请2MB的内存，2MB即215个字的大小，这时候查找大小为215的空闲分区链表，若找不到，那么查找大小为216的空闲分区链表，若216的空闲分区链表存在，那么把它分成2个，一个分配给请求，另一个分配为215的空闲分区链表，若若216的空闲分区链表不存在，那么继续往后查找，以此类推。

### 　　（4）可重定位分区分配

　　　　由于程序、资源间会有很多碎片，浪费了内存空间，可重定位分区分配就是为了解决这个问题，它可以直接移动内存中的程序、资源，使内存变得紧凑，同时也不影响程序的正常运行。可重定位分区分配要求程序的装入方式是动态运行时装入方式。程序装入内存后，所有地址仍旧是相对地址，直到运行时才会转变为绝对地址。程序在寄存器中有一个重定位寄存器，用来存放程序在硬盘中的实际地址的首地址。那么将程序在内存中的绝对地址移动，只需要移动后，改变重定位寄存器的值即可。这我们经常用的“磁盘碎片清理”就是一样的效果。

### 　　（5）对换

　　　　对换是一个需要了解一下的概念。还记得前面我们讲进程调度的时候，有一个特殊的调度类型，叫做中级调度。中级调度就是让暂时不能运行的进程挂起，释放内存资源，并把它们调到外存上去等待，这种操作，在内存看来，就叫对换。以进程为单位的对换叫进程对换。对换的情况下，外存中必须分配一定的区域用来存放对换的内存资源，叫做对换区。这个对换区本质是虚拟存储器，这个后面会讲。

 

# 四、内存分配方式——离散分配方式

　　连续的分配方式会产生很多碎片。离散的分配方式是将进程、资源装入不相邻的多个分区的内存分配方式。这种分配方式按照分配的单位是“页”还是“段”，分为分页存储管理、分段存储管理以及段页式存储管理。

###  （1）分页存储管理

　　分页存储管理是根据程序作业中的“页”为单位离散分配内存的管理。

　　**1）页面（页）。**

　　分页存储管理的内存分配单位是页。什么是页？页就是一段指定大小的内存块。分页存储管理就是按照一定大小把进程的逻辑地址空间分成若干份，每一份就是一个页，把他们编号。然后按照页的大小把内存分为若干物理块，并编号。页的大小通常是512B到8KB之间。

　　**2）页表。**

　　每一个进程都有一张页表，用来记录进程的页号对应的物理块号。进程运行时，CPU会根据程序的逻辑地址和页号大小从页表找到实际的物理块和实际的物理地址。页表是经常被CPU访问的，CPU经常需要先访问页表再根据页表的地址访问内存，所以一般会设置一个“联想寄存器”，又称“块表”，存放最近频繁访问的页表。如果系统的内存特别大，页表中页面的逻辑地址就会特别大，就需要用多层的页表结构来对应物理块号。这种情况下，CPU会根据程序的逻辑地址和页面大小从多层的外部页表找到指定的页表，再从页表中找到实际的物理块和物理地址。

### （2）分段存储管理

　　分段存储管理是根据程序作业中的“段”为单位离散分配内存的管理。

　　**1）段。**

　　段指的是程序、作业中的一组逻辑信息。例如：全局变量可以设为一个段；每个函数的局部变量可以设为一个段；每个函数的代码部分可以设置为一个段。这样做有什么意义呢？相当于将程序中的这种逻辑信息根据大小离散的存储在内存中，而对于逻辑信息本身而言，他们在内存中是连续的，不会被分割的，这样有利于对逻辑信息的处理，如信息共享、信息保护等。

　　**2）段表。**

　　与页表类似的，每个进程都有一张段表，用来记录程序中每个段对应的物理位置。段表中每个记录都记录了段的物理地址和段的长度。同样，由于段表经常需要被访问，有些系统会把段表放在寄存器中。

　　（PS：值得注意的是，运行时动态链接要求内存使用分段存储管理。）

### （3）段页式存储管理

　　段页式存储管理是根据“段”为单位，再将“段”细分为“页”，以这个为单位离散分配内存的管理。原理与分页、分段存储管理类似。　　

 

# 五、虚拟存储器管理

 　　对于内存的连续分配方式，上文有一个“对换”的概念，就是将暂时不用的内存资源从内存中移出，放到外存的对换区中。当需要该内存资源的时候，需要及时能够把该内存资源从外存中移入内存。这里的对换区其实就是虚拟存储器。讲到虚拟存储器有需要了解一下程序执行的局部性原理，总结下来就是：

- 程序的执行过程中，大部分的指令是执行一次或很少执行的，CPU主要是在执行一小部分指令。
- 程序的执行过程中，大部分资源是很少被访问的。

　　所以，程序一次性装入内存，而实际上大部分内存资源是被浪费的。基于这种情况，没必要把所有资源都一次性装入内存。仅需要将程序当前需要的运行的段（页）装入内存即可。如果程序运行时访问到内存中不存在的段（页），这种现象叫“缺段”（却页），这时候需要根据一定算法从外存的虚拟存储区将缺失的资源立即装入内存。

　　这里有一个补充知识，见http://zhidao.baidu.com/question/86215203.html：

> 　 　至于页表的问题是这样的，在系统初始化时，是直接对物理内存进行访问的，不经过页表，这是的工作模式叫实模式，等页表在内存中建立好了，再切换的保护模式，在保护模式就出现了虚拟地址向物理地址转译的过程了。 
>
> 　　CPU有两种工作模式，一个是实模式，就是直接访问物理内存，不分页的。另一个是保护模式，就是分页的，而且存在虚拟地址。保护模式下又有特权模式和用户模式两种。关系是这样子的。
>
> 　　我给你讲，只要发生缺页中断，就会陷入内核，只是就进入了特权模式，控制权交给了操作系统，这一系列过程都是硬件完成的。至于换页使软件完成的，就是操作系统负责调页。MMU只是负责把虚拟地址转译成物理地址，他只能做这个，纯硬件实现的。操作系统有调页算法，就是在空闲的页找出来一个，把需要的内容从磁盘读出来，放到内存里，然后让进程重新运行那条指令。一切继续，就像没有缺页过一样。如果没有空闲的，就把最不经常使用的一页替换掉。

 





# I/O控制和系统调用



　　上篇博客介绍了存储器管理的相关知识——[我的操作系统复习——存储器管理](http://www.cnblogs.com/zrtqsk/p/4195976.html)，本篇讲设备管理中的I/O控制方式和操作系统中的系统调用。

# 一、I/O控制方式

　　I/O就是输入输出，I/O设备指的是输入输出设备和存储设备。I/O控制方式值得就是CPU对内存资源与I/O设备之间输入输出的控制。I/O的控制方式按照发展有下面几种： 

### （1）、程序I/O方式。

　　这个最原始的方式的特点是I/O过程中，CPU全程阻塞。CPU向I/O控制器发送指令，要求读取一个字节，IO控制器取一个字节，存入自身的数据寄存器中，存入完毕后通知CPU。然后CPU把这个字节存入内存。在这个过程中，CPU的大部分时间都在等待操作完成。值得注意的是，这种控制方式必须以字节为单位。

### （2）、中断驱动I/O控制方式。

　　这种控制方式的特点是I/O过程中，CPU跟I/O控制器并行工作，无需阻塞。传输过程跟程序I/O方式没区别。不过由于CPU在I/O过程中无需阻塞，效率比之程序I/O方式提高了百倍。

### （3）、直接存储器访问I/O控制方式——DMA（Direct Memory Access）

　　这是一种非常有效率的I/O控制方式——数据传输的基本单位是数据块；DMA控制器将数据直接送入内存；整个数据块传送开始和结束的一刻CPU才会处理，其他时候CPU与控制器并行工作。值得注意的是DMA控制方式是由DMA控制器实现的，DMA控制器有3部分——主机&控制器接口、控制器&块设备接口和I/O控制逻辑。核心就是主机&控制器接口，这个接口是为了完成主机和块数据的直接交换。DMA控制器为了实现功能有四类寄存器：命令/状态寄存器(CR)，用来存放控制信息和状态；内存地址寄存器(MAR)，存放目标地址；数据寄存器(DR)，相当于缓存，暂存数据；以及数据计数器(DC)，存放本次 CPU 要读或写的字(节)数。数据传送的过程，简单来说就是，传送前在MAR中设置目标地址，在DC中设置数据块大小，然后控制器每从磁盘取数据存入内存或从内存取数据存入磁盘，就把MAR中的目标地址加一，并把DC中数据块大小减一，直到DC中数据块大小为0，数据便传送完毕。可以看到，DMA是由硬件实现数据块移动的。

### （4）、I/O通道控制方式

　　这种控制方式是对DMA方式的改进，把一个数据块的传输改进为一组数据块的传输。通道指的是这整个传输的虚拟含义。I/O通道控制方式是由通道程序和设备控制器共同实现的。可以说，它比DMA方式改进的地方在于用程序增加了对DMA方式的控制，使多个数据块的传输能够合为一个整体。

 　　《计算机操作系统》上这一幅流程图直接拿来用了：

![img](https://images0.cnblogs.com/blog/580631/201501/042057088568418.png)

#  

#  二、系统调用

 　　什么是系统调用？系统调用说白了就是操作系统提供的接口，用以与系统通信，取得系统服务。应用程序需要通过系统调用才能访问操作系统的关键资源。首先来了解一下计算机的两种状态。

### （1）、计算机的两种状态——系统态和用户态

　　系统态和用户态，其本质就是CPU的两种状态。

　　**1）系统态**，又称管态或核心态。处理机运行操作系统的状态。

　　**2）用户态**，又称目态。处理机运行应用程序的状态。

　　应用程序需要调用系统功能时，通过系统调用，CPU转为系统态，取得系统资源，执行系统功能。对应CPU的系统态和用户态，CPU所执行的指令分为特权指令和非特权指令。

### （2）CPU执行的两种指令——特权指令和非特权指令。

　　**1）特权指令**

　　即CPU在系统态所执行的指令。这种指令只允许系统态的CPU运行，即只允许操作系统调用。特权指令可以对操作系统执行能执行的所有操作，不受任何限制。

　　**2）非特权指令**

　　即CPU在用户态所执行的指令。这种指令只能执行一般性的操作任务，不能直接进行访问系统中的硬件和软件，其对内存的访问范围也局限于用户空间。应用程序想要访问系统中的硬件和软件，只能通过系统调用间接进行。

### （3）系统调用的实现

　　那么系统调用是怎么实现的呢？系统调用是通过中断机制实现的，并且是同一个中断入口来实现。具体操作就是系统调用的时候，CPU转换为系统态，请求系统服务，处理完毕后继续执行应用程序。这里有几个概念需要了解一下：

　　**1）中断的本质**：百度百科解释的很好：“CPU执行完每条指令时，都会去检查一个中断标志位”，这句话是所有关于中断长篇大论的开场白，但很容易被人忽略，其实，这就是中断的本质。

　　**2）内中断（陷入、捕获）**：由于系统调用引起的中断

　　**3）陷入指令**：由于系统调用引起中断的指令称为陷入指令。

　　**4）中断标识码（中断类型号）**：由硬件（通常是中断控制器）产生，以标识不同的中断源。

　　**5）中断向量**：中断服务程序的入口地址。在某些计算机中，中断向量的位置存放一条跳转到中断服务程序入口地址的跳转指令。

　　**6）中断向量地址**：存储中断向量的存储单元地址

 

 

 参考：《计算机操作系统(汤子瀛)》

 



