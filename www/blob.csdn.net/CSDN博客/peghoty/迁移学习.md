
# 迁移学习 - peghoty - CSDN博客


2013年11月04日 10:51:56[皮果提](https://me.csdn.net/peghoty)阅读数：3023标签：[迁移学习																](https://so.csdn.net/so/search/s.do?q=迁移学习&t=blog)[transfer learning																](https://so.csdn.net/so/search/s.do?q=transfer learning&t=blog)[薛贵荣																](https://so.csdn.net/so/search/s.do?q=薛贵荣&t=blog)[同构异构																](https://so.csdn.net/so/search/s.do?q=同构异构&t=blog)[翻译学习																](https://so.csdn.net/so/search/s.do?q=翻译学习&t=blog)[
							](https://so.csdn.net/so/search/s.do?q=同构异构&t=blog)[
																					](https://so.csdn.net/so/search/s.do?q=薛贵荣&t=blog)个人分类：[数据挖掘																](https://blog.csdn.net/peghoty/article/category/1451019)
[
																								](https://so.csdn.net/so/search/s.do?q=薛贵荣&t=blog)
[
				](https://so.csdn.net/so/search/s.do?q=transfer learning&t=blog)
[
			](https://so.csdn.net/so/search/s.do?q=transfer learning&t=blog)
[
		](https://so.csdn.net/so/search/s.do?q=迁移学习&t=blog)
作者： 薛贵荣

在传统的机器学习的框架下，学习的任务就是在给定充分训练数据的基础上学习一个分类模型，然后利用这个学习到的模型对测试文档进行分类与预测。然而，机器学习算法在当前互联网应用研究中存在一个关键问题，即一些新出现的领域中大量训练数据非常稀缺。随着互联网的高速发展，Web 应用领域的发展非常快速，大量新的领域不断涌现，从传统的新闻，到网页，到图片，再到博客、播客等。首先，**传统的机器学习需要对每个领域都标定大量训练数据，这将会耗费大量的人力与物力；而没有大量的标注数据，会使很多与学习相关研究与应用无法开展**。其次，传统的机器学习假设训练数据与测试数据服从相同的数据分布。然而，在许多情况下，这种同分布假设并不满足。通常可能发生的情况，如训练数据过期。这往往需要去重新标注大量的训练数据以满足训练的需要，但标注新数据是非常昂贵的，需要大量的人力与物力。从另外一个角度看，如果有了大量的、在不同分布下的训练数据，完全丢弃这些数据也是非常浪费的。如何合理地利用这些数据就是**迁移学习**（transfer
 learning）主要解决的问题。迁移学习可以**从现有的数据中迁移知识，用来帮助将来的学习**。迁移学习的目标是**将从一个应用场景中学到的知识，用来帮助新的应用场景中的学习任务**。因此，迁移学习不会像传统机器学习做同分布假设。
在迁移学习方面的工作目前可以分为三个部分，即同构空间下基于实例的迁移学习、同构空间下基于特征的迁移学习与异构空间下的迁移学习。研究指出，基于实例的迁移学习有更强的知识迁移能力，基于特征的迁移学习具有更广泛的知识迁移能力，而异构空间的迁移具有广泛的学习与扩展能力。这几种方法各有千秋。
1  同构空间下基于实例的迁移学习
基于实例的迁移学习的基本思想是，尽管辅助训练数据和源训练数据或多或少会有不同，但是辅助训练数据中应该还会存在一部分比较适合用来训练一个有效的分类模型，并且适应测试数据。于是，学习的目标就是**从辅助训练数据中找出那些适合测试数据的实例，并将这些实例迁移到源训练数据的学习中**。在基于实例的迁移学习方面，文献 [1] 推广了传统 AdaBoost 算法，提出一种具有迁移能力的 Boosting 算法——Tradaboosting，使之具有迁移学习的能力，从而能够最大限度地利用辅助训练数据来帮助目标的分类。其中关键想法是，利用
 Boosting 的技术过滤辅助数据中那些与源训练数据最不像的数据。其中，Boosting 的作用是建立一种自动调整权重的机制，于是重要的辅助训练数据的权重将会增加，不重要的辅助训练数据的权重将会减小。调整权重之后，这些带权重的辅助训练数据将会作为额外的训练数据，与源训练数据一起提高分类模型的可靠度。
基于实例的迁移学习只能发生在**源数据与辅助数据非常相近**的情况下。但是，当源数据和辅助数据差别比较大时，基于实例的迁移学习算法往往很难找到可以迁移的知识。即便有时源数据与目标数据在实例层面上并没有共享一些公共的知识，它们可能会在特征层面上有一些交集。因此学者们研究了基于特征的迁移学习，讨论的是如何利用特征层面上公共的知识进行学习的问题。
**2  同构空间下基于特征的迁移学习**
在基于特征的迁移学习研究方面，多种学习算法被提出，如 CoCC 算法 [2]、TPLSA 算法 [3]、谱分析算法 [4] 与自学习聚类算法 [5] 等。这些算法的基本思想是**使用互聚类算法同时对源数据与辅助数据进行聚类，得到一个共同的特征表示，这个新的特征表示优于只基于源数据的特征表示。通过把源数据表示在这个新空间里，以实现迁移学习**。基于特征的有监督迁移学习与基于特征的无监督迁移学习都可以应用这个思想解决。
2.1  基于特征的有监督迁移学习
基于特征的有监督迁移学习方面的工作的一个例子是基于互聚类的跨领域分类 [2]，这个工作考虑的问题是：当给定一个新的、不同的领域，标注数据及其稀少时，如何利用原有领域中含有的大量标注数据进行迁移学习的问题。在基于互聚类的跨领域分类这个工作中，跨领域分类问题定义了一个统一的信息论形式化公式，其中基于互聚类的分类问题转化成对目标函数的最优化问题。在文献 [2] 的模型中，目标函数定义为源数据实例、公共特征空间与辅助数据实例间互信息的损失。
2.2  基于特征的无监督迁移学习——自学习聚类
自学习聚类算法 [5] 属于基于特征的无监督迁移学习方面的工作。其考虑的问题是现实中可能有标记的辅助数据都难以得到，在这种情况下如何利用大量无标记数据辅助数据进行迁移学习的问题。自学习聚类的基本思想是通过同时对源数据与辅助数据进行聚类得到一个共同的特征表示，而这个新的特征表示由于基于大量的辅助数据，所以会优于仅基于源数据而产生的特征表示，从而对聚类产生帮助。
上面提出的这两种学习策略解决的都是源数据与辅助数据在同一特征空间内的基于特征的迁移学习问题。当源数据与辅助数据所在的特征空间中不同时，学者们还研究了跨特征空间的基于特征的迁移学习，它也属于基于特征的迁移学习的一种。
3  异构空间下的迁移学习——翻译学习
翻译学习 [6-7] 致力于解决**源数据与测试数据分别属于两个不同特征空间**下的情况。翻译学习的方法基于使用那些有两个视角的数据来构建沟通两个特征空间的桥梁。虽然这些多视角数据可能不一定能作为分类用的训练数据，但是，它们可以构建翻译器。通过这个翻译器，可以结合与扩展各种传统的学习算法，让它们有跨特征领域学习的能力。例如，文献 [6] 使用近邻算法和特征翻译结合在一起用一个统一的语言模型进行学习与分类；文献 [8] 扩展了传统的贝叶斯分类的框架，通过引入由翻译器利用文本领域内的知识进行图像分类；文献
 [9] 将图文特征翻译器与文本数据同时看成对本领域特征的约束，扩展了 PLSA 算法进行聚类。
翻译学习除了在如分类聚类问题的传统机器学习领域中有很多应用之外，在网络数据挖掘中也有广阔的应用前景。使用翻译学习，可以在不同的特征空间之间进行知识的迁移。例如在互联网在线广告领域，文献 [10] 提出了在没有任何辅助文本信息的情况下，对图像依照它的内容进行广告的问题，称为视觉内容关联广告推荐（visual contextual advertising）问题。针对这个问题，文献 [10] 在之前的研究基础上，继续使用互联网上大量存在的共同出现数据作为桥梁，用一个特征映射（feature mapping）建立视觉图像空间与文本空间的关系，然后通过把图片“翻译”到文本空间，同时利用一个统一的生成模型将“翻译”与“推荐广告”两部分合成一体，最后达到文本广告的推送。
4  结束语
迁移学习是一个新兴的机器研究领域，其研究与应用都是处于快速发展阶段。对迁移学习的研究必将大大提高学习算法的普适性，推动机器学习的更广泛应用。
参考文献：
[1]Dai Wenyuan, Yang Qiang, Xue Guirong,et al. Boosting for transfer learning[C]//The Twenty-Fourth International Conference on Machine Learning (ICML 2007).Corvallis, Oregon:[s.n.], 2007:193-200.
[2]Dai Wenyuan, Xue Guirong, Yang Qiang, et al. Co-clustering based classification for out-of-domain documents[C]//The Thirteenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD 2007). San Jose, California:[s.n.], 2007:210-219.
[3]Xue Guirong, Dai Wenyuan, Yang Qiang, et al. Topic-bridged PLSA for cross-domain text classification[C]//The Thirty-first International ACM SIGIR Conference on Research and Development on Information Retrieval (SIGIR 2008). Singapore:[s.n.], 2008:627-634.
[4]Ling Xiao, Dai Wenyuan, Xue Guirong, et al. Spectral domain-transfer learning[C]//The Fourteenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD 2008). Las Vegas, Nevada:[s.n.], 2008:488-496.
[5]Dai Wenyuan, Yang Qiang, Xue Guirong, et al. Self-taught clustering[C]//The Twenty-Fifth International Conference on Machine Learning (ICML 2008). Helsinki:[s.n.], 2008:200-207.
[6]Dai Wenyuan, Chen Yuqiang, Xue Guirong, et al. Translated learning: transfer learning across different feature spaces[C]// Advances in Neural Information Processing Systems 21 (NIPS 2008). Vancouver, British Columbia:[s.n.], 2008.
[7]Ling Xiao, Xue Guirong, Dai Wenyuan, et al . Can Chinese Web pages be classified with English data source?[C]//Seventeenth International World Wide Web Conference (WWW 2008). Beijing:[s.n.], 2008:969-978.
[8]Lin Yuan, Chen Yuqiang, Xue Guirong et al. Text-aided image classication: using labeled text from Web to help image classication[C]//The 12th Asia-Pacific Web Confernence (APWeb 2010). Busan:[s.n.], 2010:267-273.
[9]Yang Qiang, Chen Yuqiang, Xue Guirong, et al. Heterogeneous transfer learning for image clustering via the social Web[C]// The Conference of the 47th Annual Meeting of the ACL (ACL 2009).Suntec:[s.n.], 2009:1-9.
[10]Chen Yuqiang, Jin Ou, Xue Guirong, et al. Visual contextual advertising: bringing textual advertisements to images[C]// Proceedings of The 24th AAAI Conference on Artificial Intelligence (AAAI 2010). Atlanta:[s.n.], 2010.

**作者简介**：薛贵荣，博士，阿里云计算公司资深总监，中国人工智能学会会员；主要研究方向为互联网搜索、机器学习、云计算。E-mail：grxue@aliyun-inc.com



