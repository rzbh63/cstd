
# 拉普拉斯平滑 - simplex - 博客园|[simplex](https://www.cnblogs.com/simplex/)
|
|[博客园](https://www.cnblogs.com/)|::|[首页](https://www.cnblogs.com/simplex/)|::|[新随笔](https://i.cnblogs.com/EditPosts.aspx?opt=1)|::|[联系](https://msg.cnblogs.com/send/simplex)|::|[订阅](https://www.cnblogs.com/simplex/rss)![订阅](//www.cnblogs.com/images/xml.gif)|::|[管理](https://i.cnblogs.com/)|17 				Posts ::				0 Stories				::				5 Comments				::				0 Trackbacks|
|

|公告


|假设我们在做一个抛硬币的实验，硬币出现正面的概率是\(\theta\)。在已知前\(n\)次结果的情况下，如何推断抛下一次硬币出现正面的概率呢？
|当\(n\)很大的时候，我们可以直接统计正面出现的次数，假设为\(n_1\)，然后可以做出推断\(\theta=\frac{n_1}{n}\)。
|但是，如果\(n\)很小，上述公式就不合适了。注意“硬币出现正面的概率是\(\theta\)”这句话的意思是说在实验次数趋近无穷的时候，正面出现的次数除以总抛掷次数近似等于\(\theta\)。而在实验次数很少的情况下这个比值可能偏离\(\theta\)很远。比如只做三次试验，而且全都是反面，如果利用上面的公式来进行计算将得到\(\theta=0\)。这时，我们可以利用贝叶斯定理来做一个更为合理的推断，结果就是Laplace’s rule of succession。
|假设先验概率\(P(\theta)\)是\([0,1]\)上的均匀分布。似然 (likelihood)\(P(D|\theta)=\theta^{n_1}(1-\theta)^{n-n_1}\)，其中\(D\)代表已知的实验结果（即出现\(n_1\)次正面）。这样，利用贝叶斯定理我们可以得到后验概率的计算公式为：
|\(P(\theta|D)=\frac{P(D|\theta)P(\theta)}{\int_0^1 P(D|t)P(t)dt}\)
|根据假设，先验概率\(P(\theta)\)是\([0,1]\)上的均匀分布，所以可以将其从积分中提出来并消去，得到：
|\(P(\theta|D)=\frac{P(D|\theta)}{\int_0^1 P(D|t)t}\)
|再利用公式（Beta函数的性质）：
|\(\int_0^1P(D|\theta)d\theta=\int_0^1\theta^{n_1}(1-\theta)^{n-n_1}d\theta=\frac{n_1!(n-n_1)!}{(n+1)!}\)
|可以得到后验概率\(P(\theta|D)\)的表达式：
|\(P(\theta|D)=\frac{(n+1)!}{n_1!(n-n_1)!}\theta^{n_1}(1-\theta)^{n-n_1}\)
|可见其刚好是Beta分布\(B(n_1+1,n-n_1+1)\)，其期望值为\(\frac{n_1+1}{n+2}\)。
|求出了后验概率\(P(\theta|D)\)的期望值，便可以用它来作为下次出现正面的概率了。可以发现后验概率相当于把出现正面的次数加上了1，然后把总抛掷次数加2。该方法也可以自然地推广到抛掷具有多个面的筛子的情况。
|注意这里的核心思想是利用参数的期望值来做估计以达到平滑的效果，即贝叶斯方法，而不是参数的MAP或MLE估计。





|posted on|2016-08-18 23:09|[simplex](https://www.cnblogs.com/simplex/)|阅读(|...|) 评论(|...|)|[编辑](https://i.cnblogs.com/EditPosts.aspx?postid=5785874)|[收藏](#)


|[刷新评论](javascript:void(0);)|[刷新页面](#)|[返回顶部](#top)






|
Copyright @
	simplex
Powered by:[.Text](http://scottwater.com/blog)and[ASP.NET](http://asp.net)
Theme by:[.NET Monster](http://www.DotNetMonster.com)
