# 图像二值化算法总结





# Otsu算法

Otsu算法又称为最大类间方差法或者大津法，核心就是计算背景和前景的最大类间方差，把类间方差最大的像素值作为全局二值化的阈值。由日本学者大津于1979年提出。该算法是在灰度直方图的基础上采用最小二乘法原理推导出来的，具有统计意义上的最佳分割。它的基本原理是利用最佳阈值将图像的灰度值分割成两个部分，即背景和目标，使背景和目标之间的方差最大，具有最大的分离性。背景和目标之间的方差如果越大，就说明构成图像的两个部分之间的差别越大，当部分目标被错分为背景或者部分背景被错分为目标，都会导致两部分之间的差别变小，当所取阈值的分割使类间方差最大时就意味着错分概率最小。Otsu算法是一种自适应阈值确定的方法，计算简单，效率高，但对于光照不均的图像处理效果不是很好。

      设有一幅灰度图像，大小为M*N。f(x,y)是该图像中点(x,y)处像素的灰度值，灰度级为L，则f(x,y)∈[0, L-1]。若灰度级i的所有像素个数为fi，则第i级灰度出现的概率为：


​                                                             

其中i=0, 1, 2, ..., L-1，并且。

将图像中的像素按灰度级用阈值t划分为两类，即背景C0和目标C1。背景C0的灰度级为0~t-1，目标C1的灰度级为t~L-1。背景C0和目标C1对应的像素分别为{f(x,y)<t}和{f(x,y)≥t}。

背景C0部分出现的概率为：

​                                                        

目标C1部分出现的概率为：

​                                                          

其中w0+w1=1。

背景C0部分的平均灰度值为：

​                                                      

目标C1部分的平均灰度值为：

​                                                       

图像的总平均灰度值为：

​                                                           

图像中背景和目标的类间方差为：

​                                

令k的取值从0~L-1变化，计算不同k值下的类间方差，使得类间方差最大时的那个k值就是所要求的最佳阈值。

      在matlab图像处理工具箱中，函数graythresh()采用Otsu算法获取全局阈值，获取全局阈值后，可以采用函数im2bw()进行图像分割。函数graythresh()的调用格式如下：

level = graythresh(I)：该函数采用Otsu算法获取灰度图像I的最佳阈值，函数的返回值level为获取的阈值，大小介于[0,1]之间。





以下部分为Otsu算法的MATLAB代码实现：

close all; clear; clc; 

I = imread('rice.png'); % 读入图像
level = graythresh(I); % 通过otsu算法获取最佳阈值
BW = im2bw(I, level);  % 图像二值化

figure;      % imshowpair(I, BW, 'montage');可以采用这种方式显示两幅图像
subplot(121), imshow(I); 
subplot(122), imshow(BW); 
实验效果如下：



其中函数graythresh()实现的代码如下：

~~~matlab
function [level, em] = graythresh(I)
% Global image threshold using Otsu's method
% 输入：
%     图像I（can be uint8,uint16,int16,single,double,must be nonsparse）
% 输出：
%     level: 全局阈值，值介于[0,1]之间
%     em: 有效性度量，用于评价level的有效性，值介于[0,1]之间
%
% Example
% -------
%           I = imread('coins.png'); 
%           level = graythresh(I); 
%           BW = imbinarize(I, level); 
%           figure, imshow(BW);
% Reference:
% N. Otsu, "A Threshold Selection Method from Gray-Level Histograms,"
% IEEE Transactions on Systems, Man, and Cybernetics, vol.9, no.1, pp.62-66, 1979

% 输入检查
validateattributes(I, {'uint8', 'uint16', 'double', 'single', 'int16'}, ...
    {'nonsparse'}, mfilename, 'I', 1); 

if ~isempty(I)
   % convert all N-D arrays into a single column. 
   % convert to uint8 for fastest histogram computation
    I = im2uint8(I(:)); % I(:),is all the elements of I, regarded as a single column
    num_bins = 256; 
    counts = imhist(I, num_bins); 
    

```
if nargout <= 1 % 针对当前正在执行的函数，返回该函数输出参数的数目
    level = otsuthresh(counts);
else
    [level, em] = otsuthresh(counts); 
end
```

end
其中函数otsuthresh()实现的代码如下：

function [t,em] = otsuthresh(counts)
% global histogram threshold using Otsu's method

% 输入检查
validateattributes(counts, {'numeric'}, {'real', 'nonsparse', ...
    'vector', 'nonnegative', 'finite'}, mfilename, 'COUNTS');

num_bins = numel(counts); % numel()返回数组元素的数目

% make counts a double column vector
counts = double(counts(:)); 

% variables names are chosen to be similar to the formulas in the Otsu's paper
p = counts / sum(counts); % 这里的p是一个列向量，包含各灰度级出现的概率
omega = cumsum(p); % omega也是一个列向量
mu = cumsum(p .* (1:num_bins)'); 
mu_t = mu(end); 
sigma_b_squared = (mu_t * omega - mu) .^2 ./ (omega .* (1 - omega)); 
% find the location of the maximum value of sigma_b_squared
% the maximum may extend over several bins, so average together the
% locations. if maxval is nan, meaning that sigma_b_squared is all nan,then
% return 0.
maxval = max(sigma_b_squared); 
isfinite_maxval = isfinite(maxval); 
if isfinite_maxval
   idx = mean(find(sigma_b_squared == maxval)); 
   % normalize the threshold to the range [0,1]
   t = (idx - 1) / (num_bins - 1);
else
    t = 0.0; 
end
% compute the em
if nargout > 1
   if isfinite_maxval
       em = maxval / (sum(p .* ((1:num_bins) .^ 2)') - mu_t^2);
   else
        em = 0; 
   end
end

end
~~~



```matlab
%matlab程序
G = imread('IMG_0019.JPG');
I = rgb2gray(G);

[m,n] = size(I);
Hist = zeros(255);%直方图
dHist = zeros(255);
variance = zeros(255);%方差
PXD = 0;

for i = 1:m
    for j = 1:n
        Hist(uint8(I(i,j))) = Hist(uint8(I(i,j))) + 1;
    end
end

for i = 1:255
    dHist(i) = Hist(i)/(m*n);
end

for PXD = 1:255
    w0 = 0;
    w1 = 0;
    g0 = 0;
    g1 = 0;
    for i = 1:PXD
        g0 = g0 + i*dHist(i);
        w0 = w0 + dHist(i);
    end
    for i = PXD+1 : 255
        g1 = g1 + i*dHist(i);
        w1 = w1 + dHist(i);
    end
    variance(PXD) = w0*w1*(g0 - g1)*(g0 - g1);
end

PXD = 1;
for i = 1:255
    if variance(PXD) < variance(i)
        PXD = i;
    end
end

for  i = 1:m
    for j = 1:n
        if I(i,j) > PXD 
            I(i,j) = 255;
        else
            I(i,j) = 0;
        end
    end
end    
imagBW = I;    
```





# Bernsen算法

较原始的Bernsen： 
这个算法的中心思想是：设当前像素为P，计算以P为中心的大小为(2w+1)*(2w+1)窗口内的所有像素的最大值M与最小值N，两者的均值T, 
if(M-N）> S 
　　则当前点P的阈值为T。 
else
　　当前窗口所在区域的灰度级差别较小，那么窗口在目标区或在背景区，若T>T'则当前点灰度值为255，否则，当前点灰度值为0.

end
S作者最初设为15, T'设为（255+0）/2=128。
这种最原始的算法的效果总体来说还行，但一般所用的Bernsen算法都是经过各种改进的。

```matlab
%局部阈值操作Bersen算法
clc
clear

I = imread('card8.bmp');

w = 1;%矩阵大小为2*w+1
T = 0;%阈值大小
max = 0;
min = 0;
[m,n] = size(I);
T = zeros(m - 2*w,n - 2*w);

%根据bersen算法计算每个像素点的阈值
for i = (w + 1):(m - w)
    for j = (w + 1):(n - w)
        max = uint8(I(i,j));
        min = uint8(I(i,j));
        for k = -w:w
            for l = -w:w
                if max < uint8(I(i + k,j + l))
                    max = uint8(I(i + k,j + l));
                end
                if min > uint8(I(i + k,j + l))
                    min = uint8(I(i + k,j + l));
                end
            end
        end
        T(i,j) = 0.5*(max + min);
    end
end
for i = (w + 1):(m - w)
    for j = (w + 1):(n - w)
        if I(i,j) > T(i,j)
            I(i,j) = uint8(255);
        else
            I(i,j) = uint8(0);
        end
    end
end
imshow(I);
```







# Niblack算法



局部阈值NiBlack方法是一种简单有效的动态阈值分割方法，修改得到最佳参数之后的效果比大津法要好，因为大津法是根据整个图像来确定一个阈值，而Niblack则是在不同的R*R区域会有不同的阈值。

*Niblack的基本思想是：对于图像*的每一个像素点，在*rxr*领域空问里，计算该像素点领域方位内其他像素点的均值和方差。然后利用公式（*1*）进行二值化。

阈值的计算公式是$T(x,y) = m(x,y) + k*s(x,y)$，其中m为以该像素点为中心的区域的平均灰度值，s是该区域的标准差，k是一个系数。

使用Niblack法的优点在于：

       对每一个像素点都独立的跟据此像素点的邻域的情况来计算门限，对于和邻域均值m(x，y)相近的像素点判断为背景而反之判断为前景；而具体相近到什么程度由标准差s(X'y)和修正系数k来决定，这保证了这种的方法的灵活性。

使用Niblack法的不足在于：

      由于要利用域r×r模板遍历图像，导致边界区域（r-1）/2的像素范围内无法求取阈值；同时当进行图像遍历时，如果域r×r范围内都是背景，经NIBLACK计算后必有一部分被确定为目标，产生伪噪声。



总之，用Niblack方法进行图像分割时，选择的处理模板窗口R*R大小的选择很关键，选择的空间太小，则噪声抑制的效果不理想，目标主体不够突出，选择的空间太大，则目标的细节会被去除而丢失信息。

代码地址【免费下载】包含otsu，Niblack方法：https://download.csdn.net/download/lovexinxinsensen/10298684这个网页上面有百度网盘链接，可以点击直接下载。

```cpp
/** @brief 计算单通道灰度图像的平均值

@param src 单通道灰度图
*/
static double GetMatAverage(const cv::Mat& src)
{
    CV_Assert(src.type() == CV_8UC1);
    double sum = 0.0;
    for (int y = 0; y < src.rows; ++y)
    {
        for (int x = 0; x < src.cols; ++x)
        {
            int value = src.at<uchar>(y, x);
            sum += value;
        }
    }

    return sum / (src.rows * src.cols);
}

/** @brief 计算单通道灰度图像的标准差

@param src 单通道灰度图
*/
static double GetMatStdDev(const cv::Mat& src, double meanValue)
{
    CV_Assert(src.type() == CV_8UC1);
    double sum = 0.0;
    for (int y = 0; y < src.rows; ++y)
    {
        for (int x = 0; x < src.cols; ++x)
        {
            int value = src.at<uchar>(y, x);
            double var = (value - meanValue)*(value - meanValue);
            sum += var;
        }
    }

    double stdDev = std::sqrt(double(sum) / double(src.rows * src.cols));
    return stdDev;
}

void Niblack(const cv::Mat & src, cv::Mat & dst, cv::Size wndSize)
{
    CV_Assert(src.type() == CV_8UC1);
    CV_Assert((wndSize.width % 2 == 1) && (wndSize.height % 2 == 1));
    CV_Assert((wndSize.width <= src.cols) && (wndSize.height <= src.rows));

    cv::Mat flag = cv::Mat::zeros(src.rows, src.cols, CV_64FC1);
    for (int y = wndSize.height / 2; y <= src.rows - wndSize.height / 2 - 1; ++y)
    {
        for (int x = wndSize.width / 2; x <= src.cols - wndSize.width / 2 - 1; ++x)
        {
            int value = src.at<uchar>(y, x);
            cv::Point center = cv::Point(x, y);
            cv::Point topLeftPoint = cv::Point(x - wndSize.width / 2, y - wndSize.height / 2);
            cv::Rect wnd = cv::Rect(topLeftPoint.x, topLeftPoint.y, wndSize.width, wndSize.height);
            cv::Mat roiMat = src(wnd);
            double avgValue = GetMatAverage(roiMat);
            double dev = GetMatStdDev(roiMat, avgValue);

            // 这里是0.2
            double flagValue = avgValue + 0.2 * dev;
            flag.at<double>(y, x) = flagValue;
        }
    }

    dst = cv::Mat::zeros(src.rows, src.cols, CV_8UC1);
    for (int y = 0; y < src.rows; ++y)
    {
        for (int x = 0; x < src.cols; ++x)
        {
            double flagValue = flag.at<double>(y, x);
            int value = src.at<uchar>(y, x);
            if (value > flagValue)
            {
                dst.at<uchar>(y, x) = 255;
            }
            else
            {
                dst.at<uchar>(y, x) = 0;
            }
        }
    }
}
```



```matlab
function imagBW = niblack(imag)
% Reference:
%   Wayne Niblack. An Introduction to Digital Image Processing. pp: 115.
%   1986. Prentice/Hall International. ISBN: 013 480674 3
tic;

k = -0.2;  
b = 80;   % R*R的大小
choice = 1; % 1 for pixel-to-pixel computation, 2 for pixel averaging within the square neighborhood for fast computation.

imag = imag( :, :, 1);
[Hei, Wid] = size(imag);

imag = padarray(imag, [b b], 'symmetric', 'both');  % Pad image array 
Hei_pad = Hei + 2 * b;
Wid_pad = Wid + 2 * b;
imagBW = false(Hei_pad, Wid_pad);
switch choice
    case 1
        for i = 1+b : Hei+b
            for j = 1+b : Wid+b
                upR = i-floor(b/2-1/2);
                dnR = i+floor(b/2);
                lfC = j-floor(b/2-1/2);
                rtC = j+floor(b/2);
                m_ij = mean(mean(imag(upR : dnR, lfC : rtC)));
                sigma_squared = double(imag(upR : dnR, lfC : rtC)) - m_ij;
                sigma_squared = mean(mean(sigma_squared .^2));
                sigma = sqrt(sigma_squared);
                th_ij = m_ij + k * sigma;
                if double(imag(i,j)) > th_ij
                   imagBW(i,j) = 1;
                end
            end
        end
    case 2
        for i = 1+b : b : Hei+b
            for j = 1+b : b : Wid+b
                upR =  i-floor(b/2-1/2);
                dnR =  i+floor(b/2);
                lfC =  j-floor(b/2-1/2);
                rtC =  j+floor(b/2);
                m_ij = mean(mean(imag(upR : dnR, lfC : rtC)));
                sigma_squared = double(imag(upR : dnR, lfC : rtC)) - repmat(m_ij, (dnR-upR+1), (rtC-lfC+1));
                sigma_squared = sigma_squared .^ 2;
                sigma_squared = mean(mean(sigma_squared));
                sigma = sqrt(sigma_squared);
                th_ij = m_ij + k * sigma;
                imagBW(upR : dnR, lfC : rtC) = double(imag(upR : dnR, lfC : rtC)) > th_ij;
            end
        end   
    otherwise
        display('Wrong Choice!');
end
imagBW = imagBW(1+b : Hei+b, 1+b : Wid+b);

toc;
```



```
I = imread('card3.bmp');
I = rgb2gray(I);

w =  2;%   
max = 0;   
min = 0;   
[m,n] = size(I);   
T = zeros(m ,n );   
  
%
for i = (w + 1):(m - w)   
    for j = (w + 1):(n - w)      
        sum = 0;
        for k = -w:w   
            for l = -w:w   
                sum = sum + uint32(I(i + k,j + l));
            end   
        end   
        average = double(sum) /((2*w+1)*(2*w+1));
        s = 0;
        for k = -w:w   
            for l = -w:w   
                s = s +   (uint32(I(i + k,j + l)) - average)*(uint32(I(i + k,j + l)) - average);
            end   
        end   
        s= sqrt(double(s)/((2*w+1)*(2*w+1)));
        
        T(i,j) = average + 0.2*s;
    end   
end   
for i =  1:m 
    for j = 1:n 
        if I(i,j) > T(i,j)   
            I(i,j) = uint8(255);   
        else  
            I(i,j) = uint8(0);   
        end   
    end   
end   
imshow(I);  
```





# 基于块分析的二值化算法





​       前几个月的时候曾经看了一篇论文"Binarization Localization of Text Images Captured on a Mobile Phone Camera" 印度人写的。在这片论文中按循序渐进的思路提出了四种二值化的方法，Block Analysis是在第三阶段，大体思想是基于Niblack算法的，只不过把图像进行分块，然后对每一块计算阈值，T = m + k*v，其中m为这一块的平均灰度值，v是这一块的标准差。当时写的Niblack算法有问题，最近才改正了一下，然后就想到了本文所涉及的算法。matlab程序如下所示：

```matlab
I = imread('100_1243.JPG');

I = rgb2gray(I);
[m,n] = size(I);

block = 10;
ver = floor(m/block);
hor = floor(n/block);
T = zeros(m,n);
for b_ver = 1:block
    for b_hor = 1: block
%        T((ver * (b_ver - 1)+1) : (ver *b_ver),(hor *(b_hor - 1) + 1):(hor*b_hor)) = otsu(I((ver * (b_ver - 1)+1) : (ver *b_ver),(hor *(b_hor - 1) + 1):(hor*b_hor)));
        t = 0;
        for i = (ver * (b_ver - 1)+1) : (ver * b_ver)
            for j = (hor * (b_hor - 1) + 1):(hor * b_hor)
                t = t + uint32(I(i,j));
            end
        end
        t =  double(t)/(ver * hor);
        std_deviation = 0;
        for i = (ver * (b_ver - 1)+1) : (ver * b_ver)
            for j = (hor * (b_hor - 1) + 1):(hor * b_hor)
                std_deviation = std_deviation + (uint32(I(i,j)) - t)*(uint32(I(i,j)) - t);
            end
        end
        std_deviation = sqrt(double(std_deviation)/(ver*hor));
        
        thr = t + 0.2*std_deviation;
        
        for i = (ver * (b_ver - 1)+1) : (ver * b_ver)
            for j = (hor * (b_hor - 1) + 1):(hor * b_hor)
                if I(i,j) > uint8(floor(thr))
                    T(i,j) = 255;
                else
                    T(i,j) = 0;
                end
            end
        end
    end
end
imshow(T);

```





# sauvola算法实现



实现了sauvola算法，原论文去google一下就有了~

参数是：k, windowSize，自己调调看效果

```cpp
void sauvola(unsigned char * grayImage,unsigned char * biImage,int w,int h,int k,int windowSize)
{	
	int whalf = windowSize >> 1;
	
	int i,j;
	int IMAGE_WIDTH = w;
	int IMAGE_HEIGHT = h;
	// create the integral image
	unsigned long * integralImg = (unsigned long*)malloc(IMAGE_WIDTH*IMAGE_HEIGHT*sizeof(unsigned long*));
	unsigned long * integralImgSqrt = (unsigned long*)malloc(IMAGE_WIDTH*IMAGE_HEIGHT*sizeof(unsigned long*));
	int sum = 0;
	int sqrtsum = 0;
	int index;
	for (i=0; i<IMAGE_HEIGHT; i++)
	{
		// reset this column sum
		sum = 0;
		sqrtsum = 0;
 
		for (j=0; j<IMAGE_WIDTH; j++)
		{
			index = i*IMAGE_WIDTH+j;
 
			sum += grayImage[index];
			sqrtsum += grayImage[index] * grayImage[index];
 
			if (i==0)
			{
				integralImg[index] = sum;
				integralImgSqrt[index] = sqrtsum;
			}
			else
			{
				integralImgSqrt[index] = integralImgSqrt[(i-1)*IMAGE_WIDTH+j] + sqrtsum;
				integralImg[index] = integralImg[(i-1)*IMAGE_WIDTH+j] + sum;
			}
		}
	}
	
	//Calculate the mean and standard deviation using the integral image
	int xmin,ymin,xmax,ymax;
	double mean,std,threshold;
	double diagsum,idiagsum,diff,sqdiagsum,sqidiagsum,sqdiff,area;
 
	for (i=0; i<IMAGE_WIDTH; i++){
		for (j=0; j<IMAGE_HEIGHT; j++){
			xmin = max(0,i - whalf);
			ymin = max(0,j - whalf);
			xmax = min(IMAGE_WIDTH-1,i+whalf);
			ymax = min(IMAGE_HEIGHT-1,j+whalf);
			
			area = (xmax - xmin + 1) * (ymax - ymin + 1);
			if(area <= 0)
			{
				biImage[i * IMAGE_WIDTH + j] = 255;
				continue;
			}
			
			if(xmin == 0 && ymin == 0){
				diff = integralImg[ymax * IMAGE_WIDTH + xmax];
				sqdiff = integralImgSqrt[ymax * IMAGE_WIDTH + xmax];
			}else if(xmin > 0 && ymin == 0){
				diff = integralImg[ymax * IMAGE_WIDTH + xmax] - integralImg[ymax * IMAGE_WIDTH + xmin - 1];
				sqdiff = integralImgSqrt[ymax * IMAGE_WIDTH + xmax] - integralImgSqrt[ymax * IMAGE_WIDTH + xmin - 1];	
			}else if(xmin == 0 && ymin > 0){
				diff = integralImg[ymax * IMAGE_WIDTH + xmax] - integralImg[(ymin - 1) * IMAGE_WIDTH + xmax];
				sqdiff = integralImgSqrt[ymax * IMAGE_WIDTH + xmax] - integralImgSqrt[(ymin - 1) * IMAGE_WIDTH + xmax];;
			}else{
				diagsum = integralImg[ymax * IMAGE_WIDTH + xmax] + integralImg[(ymin - 1) * IMAGE_WIDTH + xmin - 1];
				idiagsum = integralImg[(ymin - 1) * IMAGE_WIDTH + xmax] + integralImg[ymax * IMAGE_WIDTH + xmin - 1];
				diff = diagsum - idiagsum;
 
				sqdiagsum = integralImgSqrt[ymax * IMAGE_WIDTH + xmax] + integralImgSqrt[(ymin - 1) * IMAGE_WIDTH + xmin - 1];
				sqidiagsum = integralImgSqrt[(ymin - 1) * IMAGE_WIDTH + xmax] + integralImgSqrt[ymax * IMAGE_WIDTH + xmin - 1];
				sqdiff = sqdiagsum - sqidiagsum;
			}
 
			mean = diff/area;
			std  = sqrt((sqdiff - diff*diff/area)/(area-1));
			threshold = mean*(1+k*((std/128)-1));
			if(grayImage[j*IMAGE_WIDTH + i] < threshold)
				biImage[j*IMAGE_WIDTH + i] = 0;
			else
				biImage[j*IMAGE_WIDTH + i] = 255;	
		}
	}
	
	free(integralImg);
	free(integralImgSqrt);
}
```



```cpp
#include "opencv2/opencv.hpp"

static int CalcMaxValue(int a, int b)
{
    return (a > b) ? a : b;
}

static double CalcMaxValue(double a, double b)
{
    return (a > b) ? a : b;
}

static int CalcMinValue(int a, int b)
{
    return (a < b) ? a : b;
}

static double CalcMinValue(double a, double b)
{
    return (a < b) ? a : b;
}


/** @brief SauvolaThresh二值算法

此代码不适用与分辨率较大的图像, 此bug准备有空再处理

@param src 单通道灰度图
@param dst 单通道处理后的图
@param k  threshold = mean*(1 + k*((std / 128) - 1))
@param wndSize 处理区域宽高, 一定是奇数

*/
void SauvolaThresh(const cv::Mat& src, cv::Mat& dst, const int k, const cv::Size wndSize)
{
    CV_Assert(src.type() == CV_8UC1);
    CV_Assert((wndSize.width % 2 == 1) && (wndSize.height % 2 == 1));
    CV_Assert((wndSize.width <= src.cols) && (wndSize.height <= src.rows));

    dst = cv::Mat::zeros(src.rows, src.cols, CV_8UC1);

    // 产生标志位图像
    unsigned long* integralImg = new unsigned long[src.rows * src.cols];
    unsigned long* integralImgSqrt = new unsigned long[src.rows * src.cols];
    std::memset(integralImg, 0, src.rows *src.cols*sizeof(unsigned long));
    std::memset(integralImgSqrt, 0, src.rows *src.cols*sizeof(unsigned long));

    // 计算直方图和图像值平方的和
    for (int y = 0; y < src.rows; ++y)
    {
        unsigned long sum = 0;
        unsigned long sqrtSum = 0;
        for (int x = 0; x < src.cols; ++x)
        {
            int index = y * src.cols + x;
            sum += src.at<uchar>(y, x);
            sqrtSum += src.at<uchar>(y, x)*src.at<uchar>(y, x);
            if (y == 0)
            {
                integralImg[index] = sum;
                integralImgSqrt[index] = sqrtSum;
            }
            else
            {
                integralImgSqrt[index] = integralImgSqrt[(y - 1)*src.cols + x] + sqrtSum;
                integralImg[index] = integralImg[(y - 1)*src.cols + x] + sum;
            }
        }
    }

    double diff         = 0.0;
    double sqDiff       = 0.0;
    double diagSum      = 0.0;
    double iDiagSum     = 0.0;
    double sqDiagSum    = 0.0;
    double sqIDiagSum   = 0.0;
    for (int x = 0; x < src.cols; ++x)
    {
        for (int y = 0; y < src.rows; ++y)
        {
            int xMin = CalcMaxValue(0, x - wndSize.width / 2);
            int yMin = CalcMaxValue(0, y - wndSize.height / 2);
            int xMax = CalcMinValue(src.cols - 1, x + wndSize.width / 2);
            int yMax = CalcMinValue(src.rows - 1, y + wndSize.height / 2);
            double area = (xMax - xMin + 1)*(yMax - yMin + 1);
            if (area <= 0)
            {
                // blog提供源码是biImage[i * IMAGE_WIDTH + j] = 255;但是i表示的是列, j是行
                dst.at<uchar>(y, x) = 255;
                continue;
            }

            if (xMin == 0 && yMin == 0)
            {
                diff = integralImg[yMax*src.cols + xMax];
                sqDiff = integralImgSqrt[yMax*src.cols + xMax];
            }
            else if (xMin > 0 && yMin == 0)
            {
                diff = integralImg[yMax*src.cols + xMax] - integralImg[yMax*src.cols + xMin - 1];
                sqDiff = integralImgSqrt[yMax * src.cols + xMax] - integralImgSqrt[yMax * src.cols + xMin - 1];
            }
            else if (xMin == 0 && yMin > 0)
            {
                diff = integralImg[yMax * src.cols + xMax] - integralImg[(yMin - 1) * src.cols + xMax];
                sqDiff = integralImgSqrt[yMax * src.cols + xMax] - integralImgSqrt[(yMin - 1) * src.cols + xMax];;
            }
            else
            {
                diagSum = integralImg[yMax * src.cols + xMax] + integralImg[(yMin - 1) * src.cols + xMin - 1];
                iDiagSum = integralImg[(yMin - 1) * src.cols + xMax] + integralImg[yMax * src.cols + xMin - 1];
                diff = diagSum - iDiagSum;
                sqDiagSum = integralImgSqrt[yMax * src.cols + xMax] + integralImgSqrt[(yMin - 1) * src.cols + xMin - 1];
                sqIDiagSum = integralImgSqrt[(yMin - 1) * src.cols + xMax] + integralImgSqrt[yMax * src.cols + xMin - 1];
                sqDiff = sqDiagSum - sqIDiagSum;
            }
            double mean = diff / area;
            double stdValue = sqrt((sqDiff - diff*diff / area) / (area - 1));
            double threshold = mean*(1 + k*((stdValue / 128) - 1));
            if (src.at<uchar>(y, x) < threshold)
            {
                dst.at<uchar>(y, x) = 0;
            }
            else
            {
                dst.at<uchar>(y, x) = 255;
            }

        }
    }

    delete[] integralImg;
    delete[] integralImgSqrt;
}
```





# 循环阈值算法

```matlab
clc
clear
G = imread('img.jpg');
I = rgb2gray(G);
%l = rgb2gray(h);%转换成灰度图像，得到灰度值
%imhist(img);%得到灰度直方图
%disp(img);%显示各像素的灰度值

%循环阈值选择方法
gray1 = 0;%一部分图像的灰度值之和
gray2 = 0;%另一部分图像的灰度值之和
u1 = 0;%一部分图像的平均灰度值
u2 = 0;%另一部分的平均灰度值
k = 0;%一部分图像的像素个数
r = 0;%另一部分图像的像素个数
x = 0;%阈值和
T = 0;%图像的阈值
[m,n] = size(I)%获取图像大小

%获取平均阈值
for i = 1:m
    for j = 1:n
        x = x + uint32(I(i,j));
    end
end
T = x/(m*n);%初始阈值

T1 = 0;
while T ~= T1 
    T1 = T;
    for i = 1:m
        for j = 1:n
            if I(i,j) < T
                gray1 = gray1 + uint32(I(i,j));
                k = k + 1;
            else 
                gray2 = gray2 + uint32(I(i,j));
                r = r + 1;
            end
        end
    end
    u1 = gray1/k;
    u2 = gray2/r;    
    T = (u1 + u2)/2;%新的阈值
end
%BW = im2bw(g,T);%转换成二值图像
T %输出最后选择的阈值
%显示区域，把不在阈值范围内的点的灰度值置为255
for i = 1:m
    for j = 1:n
        if I(i,j) > T 
            I(i,j) = uint32(255);
        else
            I(i,j) = uint32(0);
        end
    end
end
%se = strel('disk',1);
%h = imclose(I,se);
%h = imdilate(I,se);
%y = imerode(h,se);

%h = medfilt2(I,[3,3];
%imshow(y);
imshow(I);
```





# wallner

我们用P(n)来表示第n个点的灰度值. T(n)来表示二值化后的值。用f­ s  (n) 来表示第n个点之前s个点的灰度值的和,就是



用这个s和另一个变量t就可以简单的说明P(n)应该是0还是1了, 这个公式就是



根据经验值来看, 这里的s和t最佳的取值范围是s= image.width/8, 而t=15的时候效果最好.且1为黑（背景），0为白（前景））

但是有个问题，现在定义T(n)的时候,用的是平均值,也就是说之前扫描过的若干点对于当前点的影响或者说权重是一样的。

所以这里改进成离当前点越近的像素对当前点的影响越大,越远则越小。用g(n)代替T(n)。公式如下：



还有一个问题存在, 就是现在的颜色计算依赖于我的扫描顺序,(一般都是水平扫描的). 这样的话, 我的像素值实际上取决于我水平位置上的邻接点的灰度值, 可是竖直方向的像素如何关联起来呢? 这里也有一个说明, 我们可以维护前面依次水平扫描产生的g_prev(n)序列, 在某个g(n)被使用之前, 我们可以让他和前一个g_prev(n)取一个平均值, 这样的话, 这个最终的值就更有说服力了.

另外由于需要给定一个初始的迭代值，这里取g(n) = 127 *s，127是灰度0~255的中间值

```cpp
#include<opencv2\opencv.hpp>
#include<iostream>
using namespace std;
using namespace cv;
 
void wallner(Mat & src, Mat & dst)
{
	/*
	* pn = 当前点的灰度值
	* s = 图片宽度/n （n = 8时效果最好）
	* t = 比例阈值
	* 公式：g(n) = g(n-1) * (1-1/s) + p(n)
	*/
	int t = 15;
	int s = src.cols >> 3;
	const int S = 9;
	const int power2S = 1 << S;//加速因子
	int factor = power2S * (100 - t) / (100 * s);
	/*使用初始值127*s *s是因为 原先算法采用均值也就是fn 是前n个像素之和 
	这次算法优化为与当前点越相邻对其影响越大的思路*/
	int gn = 127 * s;
	int q = power2S - power2S / s;
	int pn, hn;
	int *prev_gn = NULL;//前一行各点像素值
	//Mat dst = Mat::zeros(src.size(), CV_8UC1);
	prev_gn = new int[src.cols];
	for (int i = 0; i < src.cols; i++)
		prev_gn[i] = gn;
	uchar * scanline = NULL;
	for (int i = 0; i < src.rows; i++)
	{
		scanline = src.ptr<uchar>(i);
		for (int j = 0; j < src.cols; j++)//从左向右遍历
		{
			pn = scanline[j];
			gn = ((gn * q) >> S) + pn;
			hn = (gn + prev_gn[j]) >> 1;
			prev_gn[j] = gn;
			pn < (hn * factor) >> S ? dst.at<uchar>(i, j) = 0 : dst.at<uchar>(i, j) = 255;
		}
		i++;
		if (i == src.rows)
			break;
		scanline = src.ptr<uchar>(i);
		for (int j = src.cols - 1; j >= 0; j--)//从右向左遍历
		{
			pn = scanline[j];
			gn = ((gn * q) >> S) + pn;
			hn = (gn + prev_gn[j]) >> 1;
			prev_gn[j] = gn;
			pn < (hn * factor) >> S ? dst.at<uchar>(i, j) = 0 : dst.at<uchar>(i, j) = 255;
		}
	}
}
 
void main()
{
	Mat src = imread("Checkerboard.jpg", IMREAD_GRAYSCALE);
	Mat cmp = src.clone();
	Mat dst = Mat::zeros(src.size(), CV_8UC1);
	threshold(cmp, cmp, 0, 255, THRESH_OTSU);
	wallner(src, dst);
	imshow("src", src);
	imshow("dst", dst);
	imshow("cmp", cmp);
	waitKey();
}
```



# Wolf Jolion

```cpp

// *************************************************************
// glide a window across the image and
// *************************************************************
// create two maps: mean and standard deviation.
//
// Version patched by Thibault Yohan (using opencv integral images)


double calcLocalStats (Mat &im, Mat &map_m, Mat &map_s, int winx, int winy) {
    Mat im_sum, im_sum_sq;
    cv::integral(im,im_sum,im_sum_sq,CV_64F);

	double m,s,max_s,sum,sum_sq;
	int wxh	= winx/2;
	int wyh	= winy/2;
	int x_firstth= wxh;
    int y_firstth= wyh;
	int y_lastth = im.rows-wyh-1;
	double winarea = winx*winy;

	max_s = 0;
	for	(int j = y_firstth ; j<=y_lastth; j++){
		sum = sum_sq = 0;

		// for sum array iterator pointer
		double *sum_top_left = im_sum.ptr<double>(j - wyh);
		double *sum_top_right = sum_top_left + winx;
		double *sum_bottom_left = im_sum.ptr<double>(j - wyh + winy);
		double *sum_bottom_right = sum_bottom_left + winx;

		// for sum_sq array iterator pointer
		double *sum_eq_top_left = im_sum_sq.ptr<double>(j - wyh);
		double *sum_eq_top_right = sum_eq_top_left + winx;
		double *sum_eq_bottom_left = im_sum_sq.ptr<double>(j - wyh + winy);
		double *sum_eq_bottom_right = sum_eq_bottom_left + winx;

		sum = (*sum_bottom_right + *sum_top_left) - (*sum_top_right + *sum_bottom_left);
		sum_sq = (*sum_eq_bottom_right + *sum_eq_top_left) - (*sum_eq_top_right + *sum_eq_bottom_left);

		m  = sum / winarea;
		s  = sqrt ((sum_sq - m*sum)/winarea);
		if (s > max_s) max_s = s;

		float *map_m_data = map_m.ptr<float>(j) + x_firstth;
		float *map_s_data = map_s.ptr<float>(j) + x_firstth;
		*map_m_data++ = m;
		*map_s_data++ = s;

		// Shift the window, add and remove	new/old values to the histogram
		for	(int i=1 ; i <= im.cols-winx; i++) {
			sum_top_left++, sum_top_right++, sum_bottom_left++, sum_bottom_right++;

			sum_eq_top_left++, sum_eq_top_right++, sum_eq_bottom_left++, sum_eq_bottom_right++;

			sum = (*sum_bottom_right + *sum_top_left) - (*sum_top_right + *sum_bottom_left);
			sum_sq = (*sum_eq_bottom_right + *sum_eq_top_left) - (*sum_eq_top_right + *sum_eq_bottom_left);

			m  = sum / winarea;
			s  = sqrt ((sum_sq - m*sum)/winarea);
			if (s > max_s) max_s = s;

			*map_m_data++ = m;
			*map_s_data++ = s;
		}
	}

	return max_s;
}



/**********************************************************
 * The binarization routine
 **********************************************************/


void NiblackSauvolaWolfJolion (Mat im, Mat output, NiblackVersion version,
	int winx, int winy, double k, double dR) {


	double m, s, max_s;
	double th=0;
	double min_I, max_I;
	int wxh	= winx/2;
	int wyh	= winy/2;
	int x_firstth= wxh;
	int x_lastth = im.cols-wxh-1;
	int y_lastth = im.rows-wyh-1;
	int y_firstth= wyh;
	// int mx, my;

	// Create local statistics and store them in a double matrices
	Mat map_m = Mat::zeros (im.rows, im.cols, CV_32F);
	Mat map_s = Mat::zeros (im.rows, im.cols, CV_32F);
	max_s = calcLocalStats (im, map_m, map_s, winx, winy);

	minMaxLoc(im, &min_I, &max_I);

	Mat thsurf (im.rows, im.cols, CV_32F);

	// Create the threshold surface, including border processing
	// ----------------------------------------------------
	for	(int j = y_firstth ; j<=y_lastth; j++) {

		float *th_surf_data = thsurf.ptr<float>(j) + wxh;
		float *map_m_data = map_m.ptr<float>(j) + wxh;
		float *map_s_data = map_s.ptr<float>(j) + wxh;

		// NORMAL, NON-BORDER AREA IN THE MIDDLE OF THE WINDOW:
		for	(int i=0 ; i <= im.cols-winx; i++) {
			m = *map_m_data++;
			s = *map_s_data++;

    		// Calculate the threshold
    		switch (version) {

    			case NIBLACK:
    				th = m + k*s;
    				break;

    			case SAUVOLA:
	    			th = m * (1 + k*(s/dR-1));
	    			break;

    			case WOLFJOLION:
    				th = m + k * (s/max_s-1) * (m-min_I);
    				break;

    			default:
    				cerr << "Unknown threshold type in ImageThresholder::surfaceNiblackImproved()\n";
    				exit (1);
    		}

    		// thsurf.fset(i+wxh,j,th);
			*th_surf_data++ = th;


    		if (i==0) {
        		// LEFT BORDER
				float *th_surf_ptr = thsurf.ptr<float>(j);
        		for (int i=0; i<=x_firstth; ++i)
					*th_surf_ptr++ = th;

        		// LEFT-UPPER CORNER
        		if (j==y_firstth)
				{
        			for (int u=0; u<y_firstth; ++u)
					{
						float *th_surf_ptr = thsurf.ptr<float>(u);
						for (int i=0; i<=x_firstth; ++i)
        					*th_surf_ptr++ = th;
					}

				}

        		// LEFT-LOWER CORNER
        		if (j==y_lastth)
				{
        			for (int u=y_lastth+1; u<im.rows; ++u)
					{
						float *th_surf_ptr = thsurf.ptr<float>(u);
        				for (int i=0; i<=x_firstth; ++i)
        					*th_surf_ptr++ = th;
					}
				}
    		}

			// UPPER BORDER
			if (j==y_firstth)
				for (int u=0; u<y_firstth; ++u)
					thsurf.fset(i+wxh,u,th);

			// LOWER BORDER
			if (j==y_lastth)
				for (int u=y_lastth+1; u<im.rows; ++u)
					thsurf.fset(i+wxh,u,th);
		}

		// RIGHT BORDER
		float *th_surf_ptr = thsurf.ptr<float>(j) + x_lastth;
		for (int i=x_lastth; i<im.cols; ++i)
        	// thsurf.fset(i,j,th);
			*th_surf_ptr++ = th;

  		// RIGHT-UPPER CORNER
		if (j==y_firstth)
		{
			for (int u=0; u<y_firstth; ++u)
			{
				float *th_surf_ptr = thsurf.ptr<float>(u) + x_lastth;
				for (int i=x_lastth; i<im.cols; ++i)
					*th_surf_ptr++ = th;
			}
		}

		// RIGHT-LOWER CORNER
		if (j==y_lastth)
		{
			for (int u=y_lastth+1; u<im.rows; ++u)
			{
				float *th_surf_ptr = thsurf.ptr<float>(u) + x_lastth;
				for (int i=x_lastth; i<im.cols; ++i)
					*th_surf_ptr++ = th;
			}
		}
	}
	cerr << "surface created" << endl;

	for	(int y=0; y<im.rows; ++y)
	{
		unsigned char *im_data = im.ptr<unsigned char>(y);
		float *th_surf_data = thsurf.ptr<float>(y);
		unsigned char *output_data = output.ptr<unsigned char>(y);
		for	(int x=0; x<im.cols; ++x)
		{
			*output_data = *im_data >= *th_surf_data ? 255 : 0;
			im_data++;
			th_surf_data++;
			output_data++;
		}
	}
}

```



参考：

[1] An Adaptive Binarization Method for Camera based Document Image

[2] Survey over image thresholding techniques and quantitative performance evaluation



