
# 漫步最优化八——梯度信息 - 蜗牛 - CSDN博客


2017年07月06日 18:54:33[会敲键盘的猩猩](https://me.csdn.net/u010182633)阅读数：472



$\textbf{不见你会想你，}$
$\textbf{想随时献殷勤，希望你像蜜桃般甜美；}$
$\textbf{想阅读更多书，期待你我能赌书泼茶。}$
$\textbf{我想我们已互相知道对方的心意，}$
$\textbf{即便相隔万里也能感受到远方心中的牵挂。}$
$\textbf{希望我们互相是对的人，}$
$\textbf{一直彼此宠爱。}$
$\qquad\qquad\qquad\qquad\textbf{——畅宝宝的傻逼哥哥}$
在许多优化方法中，需要目标函数的梯度信息，这个信息由$f(\textbf{x})$对$n$个变量的一阶与二阶导组成的。
如果$f(\textbf{x})\in C^1$，即$f(\textbf{x})$有连续的一阶偏导，$f(\textbf{x})$的梯度定义为：

$$
\begin{align*}
\textbf{g(x)}
&=[\frac{\partial f}{\partial x_1}\ \frac{\partial f}{\partial x_2}\ \cdots\ \frac{\partial f}{\partial x_n}]^T\\
&=\nabla f(\textbf{x})
\end{align*}
$$
其中

$$
\nabla=[\frac{\partial}{\partial x_1}\ \frac{\partial}{\partial x_2}\ \cdots\ \frac{\partial}{\partial x_n}]^T
$$
如果$f(\textbf{x})\in C^2$，即$f(\textbf{x})$有连续的二阶偏导，$f(\textbf{x})$的海森矩阵定义为：

$$
\textbf{H(x)}=\nabla\textbf{g}^T=\nabla\{\nabla^Tf(\textbf{x})\}
$$
因此海森矩阵可以写为：

$$
\textbf{H(x)}=
\begin{bmatrix}
\frac{\partial^2f}{\partial x_1^2}&\frac{\partial^2f}{\partial x_1\partial x_2}&\cdots&\frac{\partial^2f}{\partial x_1\partial x_n}\\
\frac{\partial^2f}{\partial x_2\partial x_1}&\frac{\partial^2f}{\partial x_2^2}&\cdots&\frac{\partial^2f}{\partial x_2\partial x_n}\\
\vdots&\vdots&&\vdots\\
\frac{\partial^2f}{\partial x_n\partial x_1}&\frac{\partial^2f}{\partial x_n\partial x_2}&\cdots&\frac{\partial^2f}{\partial x_n^2}
\end{bmatrix}
$$
对函数$f(\textbf{x})\in C^2$

$$
\frac{\partial^2f}{\partial x_i\partial x_j}=\frac{\partial^2f}{\partial x_j\partial x_i}
$$
这是因为求导是线性运算，由此可得$\textbf{H(x)}$是$n\times n$对称方阵。
点$\textbf{x}=\textbf{x}_k$处的梯度与海森矩阵用$\textbf{g}(\textbf{x}_k),\textbf{H}(\textbf{x}_k)$表示，或者用简化的符号$\textbf{g}_k,\textbf{H}_k$表示。有时候在不至于混淆的前提下，$\textbf{g}(\textbf{x}),\textbf{H}(\textbf{x})$简化成$\textbf{g,H}$。
梯度与海森矩阵简化了优化过程，但是在某些应用中求解他们非常耗时且代价比较大，或者$f(\textbf{x})$无法求偏导，对于这种应用，最好用不需要求梯度的方法。
梯度方法，即基于梯度信息的方法可能只需要$\textbf{g}(\textbf{x})$或者$\textbf{g}(\textbf{x}),\textbf{H(\textbf{x})}$都需要，对于后者，可能需要求解矩阵$\textbf{H}(\textbf{x})$的逆，这会带来数值精确性问题且很耗时，一般我们会避免这种方法。

