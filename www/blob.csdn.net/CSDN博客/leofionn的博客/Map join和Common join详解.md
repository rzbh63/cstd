
# Map join和Common join详解 - leofionn的博客 - CSDN博客


2018年05月28日 22:11:39[leofionn](https://me.csdn.net/qq_36142114)阅读数：80


利用hive进行join连接操作，相较于MR有两种执行方案，一种为common join，另一种为map join ，map join是相对于common join的一种优化，省去shullfe和reduce的过程，大大的降低的作业运行的时间。
一.先决条件
emp表
```python
hive
```
```python
>
```
```python
select
```
```python
*
```
```python
from
```
```python
emp
```
```python
;
```
```python
OK
```
```python
369
```
```python
SMITH
```
```python
CLERK
```
```python
7902    1980
```
```python
-12-17
```
```python
00
```
```python
:00
```
```python
:00
```
```python
800
```
```python
.0
```
```python
NULL
```
```python
20
7499
```
```python
ALLEN
```
```python
SALESMAN
```
```python
7698    1981
```
```python
-02-20
```
```python
00
```
```python
:00
```
```python
:00
```
```python
1600
```
```python
.0
```
```python
300
```
```python
.0
```
```python
30
7521
```
```python
WARD
```
```python
SALESMAN
```
```python
7698    1981
```
```python
-02-22
```
```python
00
```
```python
:00
```
```python
:00
```
```python
1250
```
```python
.0
```
```python
500
```
```python
.0
```
```python
30
7566
```
```python
JONES
```
```python
MANAGER
```
```python
7839    1981
```
```python
-04-02
```
```python
00
```
```python
:00
```
```python
:00
```
```python
2975
```
```python
.0
```
```python
NULL
```
```python
20
7654
```
```python
MARTIN
```
```python
SALESMAN
```
```python
7698    1981
```
```python
-09-28
```
```python
00
```
```python
:00
```
```python
:00
```
```python
1250
```
```python
.0
```
```python
1400
```
```python
.0
```
```python
30
7698
```
```python
BLAKE
```
```python
MANAGER
```
```python
7839    1981
```
```python
-05-01
```
```python
00
```
```python
:00
```
```python
:00
```
```python
2850
```
```python
.0
```
```python
NULL
```
```python
30
7782
```
```python
CLARK
```
```python
MANAGER
```
```python
7839    1981
```
```python
-06-09
```
```python
00
```
```python
:00
```
```python
:00
```
```python
2450
```
```python
.0
```
```python
NULL
```
```python
10
7788
```
```python
SCOTT
```
```python
ANALYST
```
```python
7566    1982
```
```python
-12-09
```
```python
00
```
```python
:00
```
```python
:00
```
```python
3000
```
```python
.0
```
```python
NULL
```
```python
20
7839
```
```python
KING
```
```python
PRESIDENT
```
```python
NULL
```
```python
1981
```
```python
-11-17
```
```python
00
```
```python
:00
```
```python
:00
```
```python
5000
```
```python
.0
```
```python
NULL
```
```python
10
7844
```
```python
TURNER
```
```python
SALESMAN
```
```python
7698    1981
```
```python
-09-08
```
```python
00
```
```python
:00
```
```python
:00
```
```python
1500
```
```python
.0
```
```python
0
```
```python
.0
```
```python
30
7876
```
```python
ADAMS
```
```python
CLERK
```
```python
7788    1983
```
```python
-01-12
```
```python
00
```
```python
:00
```
```python
:00
```
```python
1100
```
```python
.0
```
```python
NULL
```
```python
20
7900
```
```python
JAMES
```
```python
CLERK
```
```python
7698    1981
```
```python
-12-03
```
```python
00
```
```python
:00
```
```python
:00
```
```python
950
```
```python
.0
```
```python
NULL
```
```python
30
7902
```
```python
FORD
```
```python
ANALYST
```
```python
7566    1981
```
```python
-12-03
```
```python
00
```
```python
:00
```
```python
:00
```
```python
3000
```
```python
.0
```
```python
NULL
```
```python
20
7934
```
```python
MILLER
```
```python
CLERK
```
```python
7782    1982
```
```python
-01-23
```
```python
00
```
```python
:00
```
```python
:00
```
```python
1300
```
```python
.0
```
```python
NULL
```
```python
10
```
```python
Time
```
```python
taken
```
```python
: 0
```
```python
.161
```
```python
seconds
```
```python
,
```
```python
Fetched
```
```python
: 14
```
```python
row
```
```python
(
```
```python
s
```
```python
)
```
dept表
```python
hive>
```
```python
select
```
```python
*
```
```python
from
```
```python
dept;
OK
```
```python
10
```
```python
ACCOUNTING
```
```python
NEW
```
```python
YORK
```
```python
20
```
```python
RESEARCH    DALLAS
```
```python
30
```
```python
SALES   CHICAGO
```
```python
40
```
```python
OPERATIONS  BOSTON
Time taken:
```
```python
0.185
```
```python
seconds, Fetched:
```
```python
4
```
```python
row(s)
```
二.具体实现
1.common join
架构图
![这里写图片描述](https://img-blog.csdn.net/20180112130427860?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VpeGluXzM5MjE2Mzgz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
两个map作业读取两张表，归并为emp:
> deptno, (e.empno, e.ename)

> dept: deptno, (d.dname)
的格式，然后经由reducer合并。最后能获取到join的连接结果。
执行计划
```python
STAGE DEPENDENCIES:
  Stage
```
```python
-
```
```python
1
```
```python
is a root stage
  Stage
```
```python
-
```
```python
0
```
```python
depends
```
```python
on
```
```python
stages: Stage
```
```python
-
```
```python
1
```
```python
STAGE PLANS:
  Stage: Stage
```
```python
-
```
```python
1
```
```python
Map
```
```python
Reduce
```
```python
Map
```
```python
Operator Tree:
          TableScan
            alias: e
            Statistics: Num
```
```python
rows
```
```python
:
```
```python
7
```
```python
Data
```
```python
size:
```
```python
820
```
```python
Basic stats: COMPLETE Column stats:
```
```python
NONE
```
```python
Filter Operator
              predicate: deptno is
```
```python
not
```
```python
null
```
```python
(
```
```python
type
```
```python
: boolean)
              Statistics: Num
```
```python
rows
```
```python
:
```
```python
4
```
```python
Data
```
```python
size:
```
```python
468
```
```python
Basic stats: COMPLETE Column stats:
```
```python
NONE
```
```python
Reduce Output Operator
                key expressions: deptno (
```
```python
type
```
```python
: int)
                sort
```
```python
order
```
```python
:
```
```python
+
```
```python
Map
```
```python
-reduce
```
```python
partition columns: deptno (
```
```python
type
```
```python
: int)
                Statistics: Num
```
```python
rows
```
```python
:
```
```python
4
```
```python
Data
```
```python
size:
```
```python
468
```
```python
Basic stats: COMPLETE Column stats:
```
```python
NONE
```
```python
value expressions: empno (
```
```python
type
```
```python
: int), ename (
```
```python
type
```
```python
:
```
```python
string
```
```python
)
          TableScan
            alias: d
            Statistics: Num
```
```python
rows
```
```python
:
```
```python
1
```
```python
Data
```
```python
size:
```
```python
80
```
```python
Basic stats: COMPLETE Column stats:
```
```python
NONE
```
```python
Filter Operator
              predicate: deptno is
```
```python
not
```
```python
null
```
```python
(
```
```python
type
```
```python
: boolean)
              Statistics: Num
```
```python
rows
```
```python
:
```
```python
1
```
```python
Data
```
```python
size:
```
```python
80
```
```python
Basic stats: COMPLETE Column stats:
```
```python
NONE
```
```python
Reduce Output Operator
                key expressions: deptno (
```
```python
type
```
```python
: int)
                sort
```
```python
order
```
```python
:
```
```python
+
```
```python
Map
```
```python
-reduce
```
```python
partition columns: deptno (
```
```python
type
```
```python
: int)
                Statistics: Num
```
```python
rows
```
```python
:
```
```python
1
```
```python
Data
```
```python
size:
```
```python
80
```
```python
Basic stats: COMPLETE Column stats:
```
```python
NONE
```
```python
value expressions: dname (
```
```python
type
```
```python
:
```
```python
string
```
```python
)
      Reduce Operator Tree:
```
```python
Join
```
```python
Operator
          condition
```
```python
map
```
```python
:
               Inner
```
```python
Join
```
```python
0
```
```python
to
```
```python
1
```
```python
keys:
```
```python
0
```
```python
deptno (
```
```python
type
```
```python
: int)
```
```python
1
```
```python
deptno (
```
```python
type
```
```python
: int)
          outputColumnNames: _col0, _col1, _col7, _col12
          Statistics: Num
```
```python
rows
```
```python
:
```
```python
4
```
```python
Data
```
```python
size:
```
```python
514
```
```python
Basic stats: COMPLETE Column stats:
```
```python
NONE
```
```python
Select
```
```python
Operator
            expressions: _col0 (
```
```python
type
```
```python
: int), _col1 (
```
```python
type
```
```python
:
```
```python
string
```
```python
), _col7 (
```
```python
type
```
```python
: int), _col12 (
```
```python
type
```
```python
:
```
```python
string
```
```python
)
            outputColumnNames: _col0, _col1, _col2, _col3
            Statistics: Num
```
```python
rows
```
```python
:
```
```python
4
```
```python
Data
```
```python
size:
```
```python
514
```
```python
Basic stats: COMPLETE Column stats:
```
```python
NONE
```
```python
File Output Operator
              compressed:
```
```python
false
```
```python
Statistics: Num
```
```python
rows
```
```python
:
```
```python
4
```
```python
Data
```
```python
size:
```
```python
514
```
```python
Basic stats: COMPLETE Column stats:
```
```python
NONE
```
```python
table:
                  input format: org
```
```python
.
```
```python
apache
```
```python
.
```
```python
hadoop
```
```python
.
```
```python
mapred
```
```python
.
```
```python
TextInputFormat
                  output format: org
```
```python
.
```
```python
apache
```
```python
.
```
```python
hadoop
```
```python
.
```
```python
hive
```
```python
.
```
```python
ql
```
```python
.
```
```python
io
```
```python
.
```
```python
HiveIgnoreKeyTextOutputFormat
                  serde: org
```
```python
.
```
```python
apache
```
```python
.
```
```python
hadoop
```
```python
.
```
```python
hive
```
```python
.
```
```python
serde2
```
```python
.
```
```python
lazy
```
```python
.
```
```python
LazySimpleSerDe
  Stage: Stage
```
```python
-
```
```python
0
```
```python
Fetch Operator
      limit:
```
```python
-
```
```python
1
```
```python
Processor Tree:
        ListSink
```
详解
读取一张emp表的过程，另一张表以此类推

```python
TableScan
            alias: e
            Statistics: Num
```
```python
rows
```
```python
:
```
```python
7
```
```python
Data
```
```python
size:
```
```python
820
```
```python
Basic stats: COMPLETE Column stats:
```
```python
NONE
```
```python
Filter Operator
              predicate: deptno is
```
```python
not
```
```python
null
```
```python
(
```
```python
type
```
```python
: boolean)
              Statistics: Num
```
```python
rows
```
```python
:
```
```python
4
```
```python
Data
```
```python
size:
```
```python
468
```
```python
Basic stats: COMPLETE Column stats:
```
```python
NONE
```
```python
Reduce Output Operator
                key expressions: deptno (
```
```python
type
```
```python
: int)
```
```python
//键值对的键
```
```python
sort
```
```python
order
```
```python
:
```
```python
+
```
```python
Map
```
```python
-reduce
```
```python
partition columns: deptno (
```
```python
type
```
```python
: int)
                Statistics: Num
```
```python
rows
```
```python
:
```
```python
4
```
```python
Data
```
```python
size:
```
```python
468
```
```python
Basic stats: COMPLETE Column stats:
```
```python
NONE
```
```python
value expressions: empno (
```
```python
type
```
```python
: int), ename (
```
```python
type
```
```python
:
```
```python
string
```
```python
)
```
```python
//键值对中的值
```
```python
2.reduce端join
```
```python
Reduce Operator Tree:
```
```python
Join
```
```python
Operator
          condition
```
```python
map
```
```python
:
               Inner
```
```python
Join
```
```python
0
```
```python
to
```
```python
1
```
```python
keys:
```
```python
0
```
```python
deptno (
```
```python
type
```
```python
: int)
```
```python
//连接条件，两个字段
```
```python
1
```
```python
deptno (
```
```python
type
```
```python
: int)
          outputColumnNames: _col0, _col1, _col7, _col12
```
```python
//输出位置号
```
```python
Statistics: Num
```
```python
rows
```
```python
:
```
```python
4
```
```python
Data
```
```python
size:
```
```python
514
```
```python
Basic stats: COMPLETE Column stats:
```
```python
NONE
```
```python
Select
```
```python
Operator
            expressions: _col0 (
```
```python
type
```
```python
: int), _col1 (
```
```python
type
```
```python
:
```
```python
string
```
```python
), _col7 (
```
```python
type
```
```python
: int), _col12 (
```
```python
type
```
```python
:
```
```python
string
```
```python
)
```
```python
//输出类型
```
```python
outputColumnNames: _col0, _col1, _col2, _col3
            Statistics: Num
```
```python
rows
```
```python
:
```
```python
4
```
```python
Data
```
```python
size:
```
```python
514
```
```python
Basic stats: COMPLETE Column stats:
```
```python
NONE
```
```python
File Output Operator
              compressed:
```
```python
false
```
```python
Statistics: Num
```
```python
rows
```
```python
:
```
```python
4
```
```python
Data
```
```python
size:
```
```python
514
```
```python
Basic stats: COMPLETE Column stats:
```
```python
NONE
```
```python
table:
                  input format: org
```
```python
.
```
```python
apache
```
```python
.
```
```python
hadoop
```
```python
.
```
```python
mapred
```
```python
.
```
```python
TextInputFormat
                  output format: org
```
```python
.
```
```python
apache
```
```python
.
```
```python
hadoop
```
```python
.
```
```python
hive
```
```python
.
```
```python
ql
```
```python
.
```
```python
io
```
```python
.
```
```python
HiveIgnoreKeyTextOutputFormat
                  serde: org
```
```python
.
```
```python
apache
```
```python
.
```
```python
hadoop
```
```python
.
```
```python
hive
```
```python
.
```
```python
serde2
```
```python
.
```
```python
lazy
```
```python
.
```
```python
LazySimpleSerDe
```
3.结束
```python
Stage: Stage-
```
```python
0
```
```python
Fetch
```
```python
Operator
```
```python
limit: -
```
```python
1
```
```python
Processor Tree:
        ListSink
```
2.map join
架构图
![这里写图片描述](https://img-blog.csdn.net/20180112133215670?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VpeGluXzM5MjE2Mzgz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
首先在本地生成一个local task 读取比较小的表dept，然后将表写入Hash Table Files ，上传到HDFS的缓存中，然后启动一个map作业，每读取一条数据，就与缓存中的小表进行join操作，直至整个大表读取结束。
执行计划
```python
STAGE DEPENDENCIES:
  Stage
```
```python
-
```
```python
4
```
```python
is a root stage
  Stage
```
```python
-
```
```python
3
```
```python
depends
```
```python
on
```
```python
stages: Stage
```
```python
-
```
```python
4
```
```python
Stage
```
```python
-
```
```python
0
```
```python
depends
```
```python
on
```
```python
stages: Stage
```
```python
-
```
```python
3
```
```python
STAGE PLANS:
  Stage: Stage
```
```python
-
```
```python
4
```
```python
Map
```
```python
Reduce
```
```python
Local
```
```python
Work
      Alias
```
```python
->
```
```python
Map
```
```python
Local
```
```python
Tables:
        d 
          Fetch Operator
            limit:
```
```python
-
```
```python
1
```
```python
Alias
```
```python
->
```
```python
Map
```
```python
Local
```
```python
Operator Tree:
        d 
          TableScan
            alias: d
            Statistics: Num
```
```python
rows
```
```python
:
```
```python
1
```
```python
Data
```
```python
size:
```
```python
80
```
```python
Basic stats: COMPLETE Column stats:
```
```python
NONE
```
```python
Filter Operator
              predicate: deptno is
```
```python
not
```
```python
null
```
```python
(
```
```python
type
```
```python
: boolean)
              Statistics: Num
```
```python
rows
```
```python
:
```
```python
1
```
```python
Data
```
```python
size:
```
```python
80
```
```python
Basic stats: COMPLETE Column stats:
```
```python
NONE
```
```python
HashTable Sink Operator
                keys:
```
```python
0
```
```python
deptno (
```
```python
type
```
```python
: int)
```
```python
1
```
```python
deptno (
```
```python
type
```
```python
: int)
  Stage: Stage
```
```python
-
```
```python
3
```
```python
Map
```
```python
Reduce
```
```python
Map
```
```python
Operator Tree:
          TableScan
            alias: e
            Statistics: Num
```
```python
rows
```
```python
:
```
```python
7
```
```python
Data
```
```python
size:
```
```python
820
```
```python
Basic stats: COMPLETE Column stats:
```
```python
NONE
```
```python
Filter Operator
              predicate: deptno is
```
```python
not
```
```python
null
```
```python
(
```
```python
type
```
```python
: boolean)
              Statistics: Num
```
```python
rows
```
```python
:
```
```python
4
```
```python
Data
```
```python
size:
```
```python
468
```
```python
Basic stats: COMPLETE Column stats:
```
```python
NONE
```
```python
Map
```
```python
Join
```
```python
Operator
                condition
```
```python
map
```
```python
:
                     Inner
```
```python
Join
```
```python
0
```
```python
to
```
```python
1
```
```python
keys:
```
```python
0
```
```python
deptno (
```
```python
type
```
```python
: int)
```
```python
1
```
```python
deptno (
```
```python
type
```
```python
: int)
                outputColumnNames: _col0, _col1, _col7, _col12
                Statistics: Num
```
```python
rows
```
```python
:
```
```python
4
```
```python
Data
```
```python
size:
```
```python
514
```
```python
Basic stats: COMPLETE Column stats:
```
```python
NONE
```
```python
Select
```
```python
Operator
                  expressions: _col0 (
```
```python
type
```
```python
: int), _col1 (
```
```python
type
```
```python
:
```
```python
string
```
```python
), _col7 (
```
```python
type
```
```python
: int), _col12 (
```
```python
type
```
```python
:
```
```python
string
```
```python
)
                  outputColumnNames: _col0, _col1, _col2, _col3
                  Statistics: Num
```
```python
rows
```
```python
:
```
```python
4
```
```python
Data
```
```python
size:
```
```python
514
```
```python
Basic stats: COMPLETE Column stats:
```
```python
NONE
```
```python
File Output Operator
                    compressed:
```
```python
false
```
```python
Statistics: Num
```
```python
rows
```
```python
:
```
```python
4
```
```python
Data
```
```python
size:
```
```python
514
```
```python
Basic stats: COMPLETE Column stats:
```
```python
NONE
```
```python
table:
                        input format: org
```
```python
.
```
```python
apache
```
```python
.
```
```python
hadoop
```
```python
.
```
```python
mapred
```
```python
.
```
```python
TextInputFormat
                        output format: org
```
```python
.
```
```python
apache
```
```python
.
```
```python
hadoop
```
```python
.
```
```python
hive
```
```python
.
```
```python
ql
```
```python
.
```
```python
io
```
```python
.
```
```python
HiveIgnoreKeyTextOutputFormat
                        serde: org
```
```python
.
```
```python
apache
```
```python
.
```
```python
hadoop
```
```python
.
```
```python
hive
```
```python
.
```
```python
serde2
```
```python
.
```
```python
lazy
```
```python
.
```
```python
LazySimpleSerDe
```
```python
Local
```
```python
Work:
```
```python
Map
```
```python
Reduce
```
```python
Local
```
```python
Work
  Stage: Stage
```
```python
-
```
```python
0
```
```python
Fetch Operator
      limit:
```
```python
-
```
```python
1
```
```python
Processor Tree:
        ListSink
Time taken:
```
```python
0.191
```
```python
seconds, Fetched:
```
```python
62
```
```python
row(s)
```
详解
1.将启用本地MR读取小表
```python
Map
```
```python
Reduce
```
```python
Local
```
```python
Work
      Alias
```
```python
->
```
```python
Map
```
```python
Local
```
```python
Tables:
        d 
          Fetch Operator
            limit:
```
```python
-
```
```python
1
```
```python
Alias
```
```python
->
```
```python
Map
```
```python
Local
```
```python
Operator Tree:
        d 
          TableScan
            alias: d
            Statistics: Num
```
```python
rows
```
```python
:
```
```python
1
```
```python
Data
```
```python
size:
```
```python
80
```
```python
Basic stats: COMPLETE Column stats:
```
```python
NONE
```
```python
Filter Operator
              predicate: deptno is
```
```python
not
```
```python
null
```
```python
(
```
```python
type
```
```python
: boolean)
              Statistics: Num
```
```python
rows
```
```python
:
```
```python
1
```
```python
Data
```
```python
size:
```
```python
80
```
```python
Basic stats: COMPLETE Column stats:
```
```python
NONE
```
2.写入哈希表文件
```python
HashTable Sink Operator
                keys:
```
```python
0
```
```python
deptno (
```
```python
type
```
```python
:
```
```python
int
```
```python
)
```
```python
1
```
```python
deptno (
```
```python
type
```
```python
:
```
```python
int
```
```python
)
```
3.上传到Hadoop缓存中（执行计划不可见该步骤，可由日志看见）
```python
2018
```
```python
-
```
```python
01
```
```python
-
```
```python
11
```
```python
10
```
```python
:
```
```python
30
```
```python
:
```
```python
28
```
```python
Uploaded
```
```python
1
```
```python
File
```
```python
to
```
```python
: file:/tmp/hadoop/aedaa8e1
```
```python
-
```
```python
17
```
```python
a9
```
```python
-
```
```python
4211
```
```python
-
```
```python
86
```
```python
b1
```
```python
-
```
```python
79
```
```python
debe362aba/hive_2018
```
```python
-
```
```python
01
```
```python
-
```
```python
11
```
```python
_22
```
```python
-
```
```python
30
```
```python
-
```
```python
12
```
```python
_222_6099353227386611286
```
```python
-
```
```python
1
```
```python
/
```
```python
-local
```
```python
-
```
```python
10004
```
```python
/HashTable
```
```python
-Stage
```
```python
-
```
```python
4
```
```python
/MapJoin
```
```python
-mapfile32
```
```python
--
```
```python
.
```
```python
hashtable (
```
```python
373
```
```python
bytes
```
```python
)
```
4.执行一个map作业，读取大表，并与缓存中的小表连接操作
```python
Stage: Stage
```
```python
-
```
```python
3
```
```python
Map
```
```python
Reduce
```
```python
Map
```
```python
Operator Tree:
          TableScan
            alias: e
            Statistics: Num
```
```python
rows
```
```python
:
```
```python
7
```
```python
Data
```
```python
size:
```
```python
820
```
```python
Basic stats: COMPLETE Column stats:
```
```python
NONE
```
```python
Filter Operator
              predicate: deptno is
```
```python
not
```
```python
null
```
```python
(
```
```python
type
```
```python
: boolean)
              Statistics: Num
```
```python
rows
```
```python
:
```
```python
4
```
```python
Data
```
```python
size:
```
```python
468
```
```python
Basic stats: COMPLETE Column stats:
```
```python
NONE
```
```python
Map
```
```python
Join
```
```python
Operator
                condition
```
```python
map
```
```python
:
                     Inner
```
```python
Join
```
```python
0
```
```python
to
```
```python
1
```
```python
keys:
```
```python
0
```
```python
deptno (
```
```python
type
```
```python
: int)
```
```python
1
```
```python
deptno (
```
```python
type
```
```python
: int)
                outputColumnNames: _col0, _col1, _col7, _col12
                Statistics: Num
```
```python
rows
```
```python
:
```
```python
4
```
```python
Data
```
```python
size:
```
```python
514
```
```python
Basic stats: COMPLETE Column stats:
```
```python
NONE
```
```python
Select
```
```python
Operator
                  expressions: _col0 (
```
```python
type
```
```python
: int), _col1 (
```
```python
type
```
```python
:
```
```python
string
```
```python
), _col7 (
```
```python
type
```
```python
: int), _col12 (
```
```python
type
```
```python
:
```
```python
string
```
```python
)
                  outputColumnNames: _col0, _col1, _col2, _col3
                  Statistics: Num
```
```python
rows
```
```python
:
```
```python
4
```
```python
Data
```
```python
size:
```
```python
514
```
```python
Basic stats: COMPLETE Column stats:
```
```python
NONE
```
```python
File Output Operator
                    compressed:
```
```python
false
```
```python
Statistics: Num
```
```python
rows
```
```python
:
```
```python
4
```
```python
Data
```
```python
size:
```
```python
514
```
```python
Basic stats: COMPLETE Column stats:
```
```python
NONE
```
```python
table:
                        input format: org
```
```python
.
```
```python
apache
```
```python
.
```
```python
hadoop
```
```python
.
```
```python
mapred
```
```python
.
```
```python
TextInputFormat
                        output format: org
```
```python
.
```
```python
apache
```
```python
.
```
```python
hadoop
```
```python
.
```
```python
hive
```
```python
.
```
```python
ql
```
```python
.
```
```python
io
```
```python
.
```
```python
HiveIgnoreKeyTextOutputFormat
                        serde: org
```
```python
.
```
```python
apache
```
```python
.
```
```python
hadoop
```
```python
.
```
```python
hive
```
```python
.
```
```python
serde2
```
```python
.
```
```python
lazy
```
```python
.
```
```python
LazySimpleSerDe
```
```python
Local
```
```python
Work:
```
```python
Map
```
```python
Reduce
```
```python
Local
```
```python
Work
```
5.结束
```python
Stage: Stage-
```
```python
0
```
```python
Fetch
```
```python
Operator
```
```python
limit: -
```
```python
1
```
```python
Processor Tree:
        ListSink
```
三.实验结果
```python
hive>
```
```python
select
```
```python
e.empno,e.ename,e.deptno, d.dname
    > from emp e join dept d
```
```python
on
```
```python
e.deptno=d.deptno;
Query ID = hadoop_20180111202424_2a1594f6-ef46-
```
```python
4
```
```python
a99-a85d-
```
```python
4
```
```python
a4cc82e1b9c
Total jobs =
```
```python
1
```
```python
18
```
```python
/
```
```python
01
```
```python
/
```
```python
12
```
```python
00
```
```python
:
```
```python
08
```
```python
:
```
```python
18
```
```python
WARN util.NativeCodeLoader: Unable
```
```python
to
```
```python
load native-hadoop
```
```python
library
```
```python
for
```
```python
your platform... using builtin-java classes where applicable
Execution log at: /tmp/hadoop/hadoop_20180111202424_2a1594f6-ef46-
```
```python
4
```
```python
a99-a85d-
```
```python
4
```
```python
a4cc82e1b9c.log
```
```python
2018
```
```python
-
```
```python
01
```
```python
-
```
```python
12
```
```python
12
```
```python
:
```
```python
08
```
```python
:
```
```python
21
```
```python
Starting
```
```python
to
```
```python
launch local task
```
```python
to
```
```python
process
```
```python
map
```
```python
join;  maximum memory =
```
```python
518979584
```
```python
2018
```
```python
-
```
```python
01
```
```python
-
```
```python
12
```
```python
12
```
```python
:
```
```python
08
```
```python
:
```
```python
24
```
```python
Dump the side-table
```
```python
for
```
```python
tag:
```
```python
1
```
```python
with
```
```python
group
```
```python
count:
```
```python
4
```
```python
into
```
```python
file
```
```python
:
```
```python
file
```
```python
:/tmp/hadoop/aedaa8e1-
```
```python
17
```
```python
a9-
```
```python
4211
```
```python
-
```
```python
86
```
```python
b1-
```
```python
79
```
```python
debe362aba/hive_2018-
```
```python
01
```
```python
-
```
```python
12
```
```python
_00-
```
```python
08
```
```python
-
```
```python
10
```
```python
_896_8719990077853360918-
```
```python
1
```
```python
/-local-
```
```python
10003
```
```python
/HashTable-Stage-
```
```python
3
```
```python
/MapJoin-mapfile51
```
```python
--.hashtable
```
```python
2018
```
```python
-
```
```python
01
```
```python
-
```
```python
12
```
```python
12
```
```python
:
```
```python
08
```
```python
:
```
```python
24
```
```python
Uploaded
```
```python
1
```
```python
File
```
```python
to
```
```python
:
```
```python
file
```
```python
:/tmp/hadoop/aedaa8e1-
```
```python
17
```
```python
a9-
```
```python
4211
```
```python
-
```
```python
86
```
```python
b1-
```
```python
79
```
```python
debe362aba/hive_2018-
```
```python
01
```
```python
-
```
```python
12
```
```python
_00-
```
```python
08
```
```python
-
```
```python
10
```
```python
_896_8719990077853360918-
```
```python
1
```
```python
/-local-
```
```python
10003
```
```python
/HashTable-Stage-
```
```python
3
```
```python
/MapJoin-mapfile51
```
```python
--.hashtable (373 bytes)
```
```python
2018
```
```python
-
```
```python
01
```
```python
-
```
```python
12
```
```python
12
```
```python
:
```
```python
08
```
```python
:
```
```python
24
```
```python
End
```
```python
of
```
```python
local task;
```
```python
Time
```
```python
Taken:
```
```python
2.59
```
```python
sec.
Execution completed successfully
MapredLocal task succeeded
Launching Job
```
```python
1
```
```python
out
```
```python
of
```
```python
1
```
```python
Number
```
```python
of
```
```python
reduce tasks
```
```python
is
```
```python
set
```
```python
to
```
```python
0
```
```python
since there
```
```python
's
```
```python
no reduce operator
Starting Job = job_1515720212312_0005, Tracking URL = http://hadoop:
```
```python
8088
```
```python
/proxy/application_1515720212312_0005/
Kill Command = /home/hadoop/app/hadoop-
```
```python
2.6
```
```python
.0
```
```python
-cdh5
```
```python
.7
```
```python
.0
```
```python
/bin/hadoop job  -kill job_1515720212312_0005
Hadoop job information
```
```python
for
```
```python
Stage-
```
```python
3
```
```python
: number
```
```python
of
```
```python
mappers:
```
```python
1
```
```python
; number
```
```python
of
```
```python
reducers:
```
```python
0
```
```python
2018
```
```python
-
```
```python
01
```
```python
-
```
```python
12
```
```python
00
```
```python
:
```
```python
08
```
```python
:
```
```python
39
```
```python
,
```
```python
954
```
```python
Stage-
```
```python
3
```
```python
map
```
```python
=
```
```python
0
```
```python
%,  reduce =
```
```python
0
```
```python
%
```
```python
2018
```
```python
-
```
```python
01
```
```python
-
```
```python
12
```
```python
00
```
```python
:
```
```python
08
```
```python
:
```
```python
53
```
```python
,
```
```python
406
```
```python
Stage-
```
```python
3
```
```python
map
```
```python
=
```
```python
100
```
```python
%,  reduce =
```
```python
0
```
```python
%, Cumulative CPU
```
```python
2.59
```
```python
sec
MapReduce Total cumulative CPU
```
```python
time
```
```python
:
```
```python
2
```
```python
seconds
```
```python
590
```
```python
msec
Ended Job = job_1515720212312_0005
MapReduce Jobs Launched: 
Stage-Stage-
```
```python
3
```
```python
:
```
```python
Map
```
```python
:
```
```python
1
```
```python
Cumulative CPU:
```
```python
2.59
```
```python
sec   HDFS Read:
```
```python
6800
```
```python
HDFS Write:
```
```python
309
```
```python
SUCCESS
Total MapReduce CPU
```
```python
Time
```
```python
Spent:
```
```python
2
```
```python
seconds
```
```python
590
```
```python
msec
OK
```
```python
369
```
```python
SMITH
```
```python
20
```
```python
RESEARCH
```
```python
7499
```
```python
ALLEN
```
```python
30
```
```python
SALES
```
```python
7521
```
```python
WARD
```
```python
30
```
```python
SALES
```
```python
7566
```
```python
JONES
```
```python
20
```
```python
RESEARCH
```
```python
7654
```
```python
MARTIN
```
```python
30
```
```python
SALES
```
```python
7698
```
```python
BLAKE
```
```python
30
```
```python
SALES
```
```python
7782
```
```python
CLARK
```
```python
10
```
```python
ACCOUNTING
```
```python
7788
```
```python
SCOTT
```
```python
20
```
```python
RESEARCH
```
```python
7839
```
```python
KING
```
```python
10
```
```python
ACCOUNTING
```
```python
7844
```
```python
TURNER
```
```python
30
```
```python
SALES
```
```python
7876
```
```python
ADAMS
```
```python
20
```
```python
RESEARCH
```
```python
7900
```
```python
JAMES
```
```python
30
```
```python
SALES
```
```python
7902
```
```python
FORD
```
```python
20
```
```python
RESEARCH
```
```python
7934
```
```python
MILLER
```
```python
10
```
```python
ACCOUNTING
```
```python
Time
```
```python
taken:
```
```python
43.697
```
```python
seconds, Fetched:
```
```python
14
```
```python
row(s)
```
之所以会出现两种方式，就是一个hive的调优参数
set hive.auto.convert.join = true;
若为false，则为common join
若为true，则为map join

