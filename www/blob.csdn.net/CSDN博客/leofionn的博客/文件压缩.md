
# 文件压缩 - leofionn的博客 - CSDN博客


2018年03月23日 09:42:27[leofionn](https://me.csdn.net/qq_36142114)阅读数：52


#### 源数据在云上（hdfs）压缩存储
Hadoop默认支持Gzip和BZip2的解压缩方式，可直接读取（hadoop fs -text命令），但hive只能用TEXTFILE格式的表加载，然后再insertoverwrite 到其他格式的表（比如SEQUENCEFILE表），如果hive其他格式的表想要直接加载压缩格式数据，需要重写INPUTFORMAT和OUTPUTFORMAT文件类

#### 压缩格式文件的切分(不支持则hadoop不能并行的进行map操作)
BZip2和LZO（提供block级的压缩）支持文件切分
Gzip和Snappy则不支持。

#### hadoop中支持的压缩格式
DEFLATEorg.apache.hadoop.io.compress.DefaultCodec
gzip org.apache.hadoop.io.compress.GzipCodec
bzip org.apache.hadoop.io.compress.BZip2Codec
Snappy org.apache.hadoop.io.compress.SnappyCodec
LZO:
org.apache.hadoop.io.compress.LzopCodec或者com.hadoop.compression.lzo.LzopCodec;
org.apache.hadoop.io.compress.LzoCodec或者com.hadoop.compression.lzo.LzoCodec;

注意：（引自http://ju.outofmemory.cn/entry/63512）
(1)org.apache.hadoop.io.compress.LzoCodec和com.hadoop.compression.lzo.LzoCodec功能一样，都是源码包中带的，返回都是lzo_deflate文件
(2)有两种压缩编码可用，即LzoCodec和LzopCodec，区别是：
1)LzoCodec比LzopCodec更快， LzopCodec为了兼容LZOP程序添加了如 bytes signature, header等信息
2)LzoCodec作为Reduce输出，结果文件扩展名为”.lzo_deflate”，无法被lzop读取；
而使用LzopCodec作为Reduce输出，生成扩展名为”.lzo”的文件，可被lzop读取
3)LzoCodec结果（.lzo_deflate文件)不能由lzo index job的"DistributedLzoIndexer"创建index；且“.lzo_deflate”文件不能作为MapReduce输入（不识别，除非自编inputformat）。而所有这些“.LZO”文件都支持
综上所述，应该map输出的中间结果使用LzoCodec，reduce输出用 LzopCodec


#### hive压缩的编解码器（压缩格式）
执行set io.compression.codecs 可以查看目前hive已加载的所以编解码器（逗号分隔）
也就是说，参数io.compression.codecs是hadoop的MR读写支持的所有格式支持，如果设置，就必须设置所有支持格式。默认支持，没有必要的话，最好别加。设置多个语法为：
setio.compression.codecs=org.apache.hadoop.io.compress.DefaultCodec,com.hadoop.compression.lzo.LzoCodec,com.hadoop.compression.lzo.LzopCodec,org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.BZip2Codec;
当然，
set mapred.output.compression.codec=com.hadoop.compression.lzo.LzopCodec;
和
set mapred.output.compression.codec=org.apache.hadoop.io.compress.LzopCodec
两者一样，是LzopCodec的两个不同开源包。用哪个都行。

#### hive压缩设置
##### 1）中间结果压缩
中间结果是map产生的。格式设置语句
set hive.exec.compress.intermediate=true;
set hive.intermediate.compression.codec=org.apache.Hadoop.io.compress.LzoCodec;

map结果压缩最好使用snappy的，因为压缩的前提是map输出非常大，影响io，如果中间结果数据集比较小反而会拖慢速度
另外，中间结果的压缩格式设置还可以直接设置map输出结果压缩实现，如
set mapred.map.output.compression.codec=org.apache.Hadoop.io.compress.SnappyCodec
来代替set hive.intermediate.compression.codec这个语句实现

##### 2）最终输出结果压缩
配置参数为hive.exec.compress.output
选择编解码器（压缩格式）参数mapred.output.compression.code（
命令格式
set hive.exec.compress.output=true;
set mapred.output.compression.codec=org.apache.hadoop.io.compress.GzipCodec;
（也可以用org.apache.hadoop.io.compress.SnappyCodec）
或者
set mapred.output.compress=true
setmapred.output.compression.codec=org.apache.hadoop.io.compress.LzopCodec
两种方式功能一样，之所以两个方式，是因为作用不同的参数文件

hive.exec.compress.output和mapred.output.compression.codec是hive-site.xml中的配置参数
而mapred.output.compress 和mapred.output.compression.codec是hdfs-site.xml的配置参数
都可以配置实现。可以查看各个文件中的配置参数，如
hive-site.xml中有
<property>
<name>hive.exec.compress.output</name>
<value>true</value>
</property>
<property>
<name>mapred.output.compression.codec</name>
<value>org.apache.hadoop.io.compress.GzipCodec</value>
</property>

mapred-site.xml中有
<property>
<name>mapred.compress.map.output</name>
<value>true</value>
</property>
<property>
<name>mapred.map.output.compression.codec</name>
<value>com.hadoop.compression.lzo.LzoCodec</value>
</property>

core-site.xml中有
<property>
<name>io.compression.codecs</name>
<value>org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.BZip2Codec,com.hadoop.compression.lzo.LzoCodec,com.hadoop.compression.lzo.LzopCodec</value>
</property>
<property>
<name>io.compression.codec.lzo.class</name>
<value>com.hadoop.compression.lzo.LzopCodec</value>
</property>
hadoop-site.xml中有
<property>
<name>io.compression.codecs</name>
<value>org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.BZip2Codec,org.apache.hadoop.io.compress.LzoCodec</value>
<description>A listof the compression codec classes that can be used
for compression/decompression.</description>
</property>
<property>
<name>mapred.output.compress</name>
<value>true</value>
<description>Shouldthe job outputs be compressed?
</description>
</property>
<property>
<name>mapred.output.compression.codec</name>
<value>org.apache.hadoop.io.compress.LzoCodec</value>
<description>If thejob outputs are compressed, how should they be compressed?
</description>
</property>


##### 设置的另外方式：
hive
–hiveconfhive.exec.compress.output=true
–hiveconfmapred.output.compression.codec=com.hadoop.compression.lzo.LzopCodec


#### 重要的辅助工作，添加索引
添加index是为让.lzo文件子在hdfs上按照block大小来切分块（速度加快，但多消耗cpu时间。map数大量增加）
如果不建立lzo索引则不会按照block来切分块
为每个lzo块添加index的命令：
hadoop jar $HADOOP_HOME/lib/hadoop-lzo-0.4.15.jarcom.hadoop.compression.lzo.DistributedLzoIndexer  path/xxx.lzo
注意（只设置mapred.output.compress=true默认的reduce输出格式为.lzo_deflate）

### Hadoop上三种压缩格式的存储方案对比（LZO，gz，orc,）
#### Lzo的使用
drop table tmp_tb_test_lzo;
CREATE EXTERNAL TABLE tmp_tb_test_lzo( allstring)
stored as
INPUTFORMAT'com.hadoop.mapred.DeprecatedLzoTextInputFormat'
OUTPUTFORMAT'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
location '/user/pmp_bi/test/testlog/'
---------------------------------------------
select
split(split(all,'\\|~\\|')[5],'/')[1]as media,
split(all,'\\|~\\|')[21] as device,
split(all,'\\|~\\|')[22] as network,
split(all,'\\|~\\|')[25] as id_code,
split(all,'\\|~\\|')[26] ascode_method,
split(all,'\\|~\\|')[30] as os,
split(all,'\\|~\\|')[34] as channel,
split(all,'\\|~\\|')[42] as adtype,
split(all,'\\|~\\|')[43] as rtbtype,
count(1) as cnt
from tmp_tb_test_lzo
group bysplit(split(all,'\\|~\\|')[5],'/')[1],split(all,'\\|~\\|')[21],split(all,'\\|~\\|')[22],split(all,'\\|~\\|')[25],split(all,'\\|~\\|')[26],split(all,'\\|~\\|')[30],split(all,'\\|~\\|')[34],split(all,'\\|~\\|')[42],split(all,'\\|~\\|')[43]
lzo加索引
hadoop
jar/usr/local/hadoop-0.20.2/lib/hadoop-lzo0.4.15.jarcom.hadoop.compression.lzo.LzoIndexer/user/pmp_bi/test/testlog/access_bid_20160414_22.log.lzo







