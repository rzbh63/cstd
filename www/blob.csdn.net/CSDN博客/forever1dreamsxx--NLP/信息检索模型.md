
# 信息检索模型 - forever1dreamsxx--NLP - CSDN博客


2013年05月27日 15:39:19[forever1dreamsxx](https://me.csdn.net/forever1dreamsxx)阅读数：1821


转载地址：[http://blog.sina.com.cn/s/blog_7155aa130100v8fe.html](http://blog.sina.com.cn/s/blog_7155aa130100v8fe.html)

模型是采用数学工具，对现实世界某种事物或某种运动的抽象描述。面对相同的输入，模型的输出应能够无限地逼近现实世界的输出。若将World分为Real
World、Virtual
World、Computer
World，那么模型将属于Virtual
World。
信息检索模型是表示文档，用户查询以及查询与文档的关系的框架。信息检索模型是一个四元组[D,
Q, F, R(qi, dj)]
D:文档集的机内表示
Q:用户需求的机内表示
F:文档表示、查询表示和它们之间的关系的模型框架(Frame)
R(qi, dj):排序函数，给query
qi和document
dj评分
信息检索模型取决于：（1）从什么样的视角去看待查询式和文档（2）基于什么样的理论去看待查询式和文档的关系（3）如何计算查询式和文档之间的相似度
![信息检索模型](http://s15.sinaimg.cn/bmiddle/7155aa13xa6236ff354de&690)
1.布尔模型(Boolean Model)
最早的IR模型，也是应用最广泛的模型；目前仍然应用于商业系统中；Lucene是基于布尔（Boolean）模型的。
布尔模型描述
文档D表示
一个文档被表示为关键词的集合
查询式Q表示
查询式(Queries)被表示为关键词的布尔组合，用“与、或、非”连接起来，并用括弧指示优先次序
匹配F
一个文档当且仅当它能够满足布尔查询式时，才将其检索出来
检索策略基于二值判定标准
算法R
根据匹配框架F判定相关
查询表示
在布尔模型中， 所有索引项的权值变量和文档dj与查询q的相关度都是二值的
查询q被表述成一个常规的布尔表达式，为方便计算查询q和文档d的相关度，一般将查询q的布尔表达式转换成析取范式qDNF。
示例
文档集包含两个文档：
文档1：a
b c f g h
文档2：a
f b x y z
用户查询：文档中出现a或者b，但一定要出现z。
将查询表示为布尔表达式![信息检索模型](http://s7.sinaimg.cn/small/7155aa13xa623a87eb1c6&690),并转换成析取范式
文档1和文档2的三元组对应值分别为(1,1,0)和(1,1,1)
经过匹配,将文档2返回
优点
到目前为止，布尔模型是最常用的检索模型，因为：
由于查询简单，因此容易理解
通过使用复杂的布尔表达式，可以很方便地控制查询结果
相当有效的实现方法
相当于识别包含了一个某个特定term的文档
经过某种训练的用户可以容易地写出布尔查询式
布尔模型可以通过扩展来包含排序的功能，即“扩展的布尔模型”
问题
布尔模型被认为是功能最弱的方式，其主要问题在于不支持部分匹配，而完全匹配会导致太多或者太少的结果文档被返回
非常刚性:“与”意味着全部;“或”意味着任何一个
很难控制被检索的文档数量
原则上讲，所有被匹配的文档都将被返回
很难对输出进行排序
不考虑索引词的权重，所有文档都以相同的方式和查询相匹配
很难进行自动的相关反馈
如果一篇文档被用户确认为相关或者不相关，怎样相应地修改查询式呢？
2.向量空间模型（Vector space model）
Salton在上世纪60年代提出的向量空间模型进行特征表达；成功应用于SMART（System for the 
Manipulation and Retrieval of Text）文本检索系统；这一系统理论框架到现在仍然是信息检索技术研究的基础。
模型的描述
文档D(Document)：泛指文档或文档中的一个片段（如文档中的标题、摘要、正文等）。
索引项t（Term）：指出现在文档中能够代表文档性质的基本语言单位（如字、词等），也就是通常所指的检索词，这样一个文档D就可以表示为D(t1,t2,…,tn)，其中n就代表了检索字的数量。
特征项权重Wk（Term
Weight）：指特征项tn能够代表文档D能力的大小，体现了特征项在文档中的重要程度。
相似度S（Similarity）：指两个文档内容相关程度的大小
模型的特点
基于关键词(一个文本由一个关键词列表组成)
根据关键词的出现频率计算相似度
例如：文档的统计特性
用户规定一个词项(term)集合，可以给每个词项附加权重
未加权的词项: Q =<database;
text; information >
加权的词项: Q = <database
0.5; text 0.8; information 0.2>
查询式中没有布尔条件
根据相似度对输出结果进行排序
支持自动的相关反馈
有用的词项被添加到原始的查询式中
例如：Q=> <database;
text; information; document>
模型中的问题
怎样确定文档中哪些词是重要的词？（索引项）
怎样确定一个词在某个文档中或在整个文档集中的重要程度？（权重）
怎样确定一个文档和一个查询式之间的相似度？（内积、余弦值）
索引项的选择
若干独立的词项被选作索引项(index terms) 
or词表vocabulary
索引项代表了一个应用中的重要词项
这些索引项是不相关的(或者说是正交的)，形成一个向量空间vector
space
实际上，这些词项是相互关联的
当你在一个文档中看到 “计算机”,非常有可能同时看到“科学”
当你在一个文档中看到 “电子”,有中等的可能性同时看到
“商务”
当你在一个文档中看到“商务”，只有很少的机会同时看到“科学”
词项的权重
根据词项在文档(tf)和文档集(idf)中的频率(frequency)计算词项的权重
tfij =词项j在文档i中的频率
df j =词项j的文档频率=包含词项j的文档数量
idfj =词项j的反文档频率=
log2 (N/ df j)
N:文档集中文档总数
反文档频率用词项区别文档
![信息检索模型](http://s5.sinaimg.cn/bmiddle/7155aa13xa623760e67b4&690)
查询式的词项权重
如果词项出现在查询式中，则该词项在查询式中的权重为1，否则为0
也可以用用户指定查询式中词项的权重
一个自然语言查询式可以被看成一个文档
查询式：“有没有周杰伦的歌？” 会被转换为:
<周杰伦,歌>
查询式： “请帮我找关于俄罗斯和车臣之间的战争以及车臣恐怖主义首脑的资料” 会被转换为:
<俄罗斯2,车臣2,战争1,恐怖主义1,首脑1>
过滤掉了：“请帮我找”，“和”，“之间的”，“以及”，“的资料”
两个文档之间的相似度可以同理计算
由索引项构成向量空间
2个索引项构成一个二维空间，一个文档可能包含0,
1或2个索引项
di =<0,
0>(一个索引项也不包含)
dj =<0,
0.7 >(包含其中一个索引项)
dk = <1,
2>(包含两个索引项)
类似的，3个索引项构成一个三维空间，n个索引项构成n维空间
一个文档或查询式可以表示为n个元素的线性组合
文档集 – 一般表示
向量空间中的N个文档可以用一个矩阵表示
矩阵中的一个元素对应于文档中一个词项的权重。“0”意味着该词项在文档中没有意义，或该词项不在文档中出现。
![信息检索模型](http://s13.sinaimg.cn/bmiddle/7155aa13xa6238d709ebc&690)
![信息检索模型](http://s16.sinaimg.cn/bmiddle/7155aa13xa623862eca5f&690)
相似度计算
相似度是一个函数，它给出两个向量之间的相似程度，查询式和文档都是向量，各类相似度存在于：
两个文档之间（文本分类，聚类）
两个查询式之间（常问问题集）
一个查询式和一个文档之间（检索）
人们曾提出大量的相似度计算方法，因为最佳的相似度计算方法并不存在。
通过计算查询式和文档之间的相似度
可以根据预定的重要程度对检索出来的文档进行排序
可以通过强制设定某个阈值，控制被检索出来的文档的数量
检索结果可以被用于相关反馈中，以便对原始的查询式进行修正。(例如：将文档向量和查询式向量进行结合)
相似度度量 – 内积(Inner Product)
文档D和查询式Q可以通过内积进行计算:
![信息检索模型](http://s8.sinaimg.cn/bmiddle/7155aa13x77038d8e9567&690)
对于二值向量,内积是查询式中的词项和文档中的词项相互匹配的数量
对于加权向量,内积是查询式和文档中相互匹配的词项的权重乘积之和
![信息检索模型](http://s2.sinaimg.cn/bmiddle/7155aa13xa62388dff971&690)
内积的特点
内积值没有界限
不象概率值，要在(0,1)之间
对长文档有利
内积用于衡量有多少词项匹配成功，而不计算有多少词项匹配失败
长文档包含大量独立词项，每个词项均多次出现，因此一般而言，和查询式中的词项匹配成功的可能性就会比短文档大。
![信息检索模型](http://s14.sinaimg.cn/bmiddle/7155aa13xa623925a0c2d&690)
![信息检索模型](http://s10.sinaimg.cn/bmiddle/7155aa13xe7d63addf1b9&690)
向量空间优点
术语权重的算法提高了检索的性能
部分匹配的策略使得检索的结果文档集更接近用户的检索需求
可以根据结果文档对于查询串的相关度通过Cosine Ranking等公式对结果文档进行排序
不足
标引词之间被认为是相互独立
随着Web页面信息量的增大、Web格式的多样化，这种方法查询的结果往往会与用户真实的需求相差甚远，而且产生的无用信息量会非常大
隐含语义索引模型是向量空间模型的延伸
3.扩展的布尔模型
![信息检索模型](http://s9.sinaimg.cn/bmiddle/7155aa13xa62393aad4f8&690)
4.概率模型
![信息检索模型](http://s6.sinaimg.cn/bmiddle/7155aa13xa623941e8385&690)
5.基于统计语言模型的信息检索模型
![信息检索模型](http://s15.sinaimg.cn/bmiddle/7155aa13xa62394982c1e&690)
和传统概率模型的比较
基本思想完全不同
传统的信息检索概率模型
文档d与检索q的相关度排序函数定义为事件R(文档是否满足检索要求)的概率，即：f(q,d)=P(R|d)；
相关度排序函数定义虽然比较直观，但相关性是一个抽象的概念，该定义本身没有也无法具体给出R的定义，所以该模型在理论上存在很大的模糊性。
基于语言模型的检索模型
相关度排序函数则定义为由文档的语言模型生成检索的概率，即f(q,d)=p(q|d)。
建立在统计语言模型理论基础上，定义明确，便于操作。
具体实施方法不同
传统的概率模型
由于没有也无法对相关性做出明确定义，因此一般需要在检索中，首先给定带有相关性标记的文档作为建立模型的基础。
在实际中，要针对每个检索给定学习数据，几乎不可能。该问题是传统信息检索模型存在的一个主要问题。
基于语言模型的信息检索模型
可以基于每个文档直接计算出相关度排序函数，从而有效地避免这个问题
还可以用该模型为传统概率模型形成初始检索。
6.基于本体论的信息检索模型
基于本体的检索过程
用户向信息检索系统提出检索申请。
信息检索系统产生一个界面与用户交互。界面接收用户提出的查询关键字后，系统查询本体库，从中找出出现该关键字的各个领域，然后将其领域以及在该领域下的关键字的含义罗列给用户。
用户此时可根据自己的意图，在界面上确定所需查找的领域及含义。
系统将经过本体规范后的请求交给全文搜索引擎进行检索。
全文搜索引擎检索后返回给用户检索信息。
7.隐含语义索引(LSI)
略


