
# 贝叶斯相关（整理） - 郭云飞的专栏 - CSDN博客


2017年09月18日 16:22:14[guoyunfei20](https://me.csdn.net/guoyunfei20)阅读数：305个人分类：[机器学习																](https://blog.csdn.net/guoyunfei20/article/category/7178819)


**----贝叶斯理论----**
在古代，人们对一件事情发生或不发生的概率，只有固定的0和1，即要么发生，要么不发生，从来不会去考虑某件事情发生的概率有多大，不发生的概率又是多大。比如如果问那时的人们一个问题：“有一个袋子，里面装着若干个白球和黑球，请问从袋子中取得白球的概率是多少？”他们会想都不用想，会立马告诉你，取出白球的概率就是1/2，要么取到白球，要么取不到白球，即θ只能有一个值，不是1/2，就是0，而且不论你取了多少次，取得白球的概率θ始终都是1/2，即不随观察结果X的变化而变化。这种频率派的观点长期统治着人们的观念，直到后来一个名叫Thomas
 Bayes的人物出现。
贝叶斯认为取得白球的概率是个不确定的值，因为其中含有机遇的成分。
举个例子来理解这种机遇的成分：一个朋友创业，你明明知道创业的结果就两种，即要么成功要么失败，但你依然会忍不住去估计他创业成功的几率有多大？你如果对他为人比较了解，而且有方法、思路清晰、有毅力、且能团结周围的人，你会不由自主的估计他创业成功的几率可能在80%以上。这种不同于最开始的“非黑即白非0即1”的思考方式，便是贝叶斯式的思考方式。贝叶斯及贝叶斯派提出了一个思考问题的固定模式：
```python
先验概率 + 样本信息 = 后验概率
```
上述思考模式意味着，新观察到的样本信息将修正人们以前对事物的认知。换言之，在得到新的样本信息之前，人们对样本*a*的认知是先验分布*p(a)*，在得到新的样本信息**b**后，人们对的认知为*p(a|b)*。其中，先验信息一般来源于经验跟历史资料。而后验分布*p(a|b)*一般也认为是在给定样本**b**的情况下的条件分布，而使*p(a|b)*达到最大的值*maxarg(p(b|a))*称为最大后验估计，类似于经典统计学中的极大似然估计。综合起来看，则好比是人类刚开始时对大自然只有少得可怜的先验知识，但随着不断是观察、实验获得更多的样本、结果，使得人们对自然界的规律摸得越来越透彻。所以，贝叶斯方法既符合人们日常生活的思考方式，也符合人们认识自然的规律，经过不断的发展，最终占据统计学领域的半壁江山，与经典统计学分庭抗礼。
**----贝叶斯定理----**
>>**条件概率**就是事件*A*在另外一个事件*B*已经发生条件下的发生概率。条件概率表示为**P(A|B)**，读作“在**B**条件下**A**的概率”。
>>**联合概率**表示两个事件共同发生的概率。**A**与*B*的联合概率表示为**p(A∩B)**。
>>**边缘概率**（又称先验概率）是某个事件发生的概率。
接下来，考虑：
>>  事件**B**发生之前，我们对事件*A*的发生有一个基本的概率判断，称为*A*的先验概率，用*P(A)*表示
>>  事件*B*发生之后，我们对事件*A*的发生概率重新评估，称为*A*的后验概率，用*P(A|B)*表示
类似的：
>>  事件**A**发生之前，我们对事件*B*的发生有一个基本的概率判断，称为*B*的先验概率，用*P(B)*表示
>>  事件*A*发生之后，我们对事件*B*的发生概率重新评估，称为*B*的后验概率，用*P(B|A)*表示
则贝叶斯公式为：
![](https://img-blog.csdn.net/20141110213025473)
举个例子来说明贝叶斯定理的用途：经常在网上搜索东西的朋友知道，当你不小心输入一个不存在的单词时，搜索引擎会提示你是不是要输入某一个正确的单词，比如当你输入“Julw”时，系统会提示你是不是要搜索“July”。这叫做拼写检查。根据谷歌一员工写的文章显示，Google的拼写检查基于贝叶斯方法。下面我们就来看看，怎么利用贝叶斯方法，实现"拼写检查"的功能。
用户输入一个单词时，可能拼写正确，也可能拼写错误。如果把拼写正确的情况记做c（correct），拼写错误的情况记做w（wrong），那么"拼写检查"要做的事情就是：在发生w的情况下，试图推断出c。换言之：已知w，然后在若干个备选方案中，找出**可能性最大**的那个c，也就是求的最大值。而根据贝叶斯定理，有：
![](https://img-blog.csdn.net/20141112230845578)
由于对于所有备选的c来说，对应的都是同一个w，所以它们的**P(w)**是相同的，因此我们只要最大化*P(w|c)*P(c)*即可。
>>**P(c)**表示某个正确的词的出现"概率"，它可以用"频率"代替。如果我们有一个足够大的文本库，那么这个文本库中每个单词的出现频率，就相当于它的发生概率。某个词的出现频率越高，*P(c)*就越大。
>>*P(w|c)*表示在试图拼写**c**的情况下，出现拼写错误w的概率。为了简化问题，假定两个单词在字形上越接近，就有越可能拼错，P(w|c)就越大。举例来说，相差一个字母的拼法，就比相差两个字母的拼法，发生概率更高。你想拼写单词July，那么错误拼成Julw（相差一个字母）的可能性，就比拼成Jullw高（相差两个字母）
所以，我们只要找到与输入单词在字形上最相近的那些词，再在其中挑出出现频率最高的一个，就能实现的最大值。
**----贝叶斯网络----**
贝叶斯网络(Bayesian network)，又称信念网络(Belief Network)，或有向无环图模型(directed acyclic graphical model)，是一种概率图模型，于1985年由Judea Pearl首先提出。它是一种模拟人类推理过程中因果关系的不确定性处理模型，其网络拓朴结构是一个有向无环图(DAG)。
贝叶斯网络的有向无环图中的**节点表示随机变量**，它们可以是可观察到的变量，或隐变量、未知参数等。认为**有因果关系（或非条件独立）的变量或命题则用箭头来连接**（换言之，连接两个节点的箭头代表此两个随机变量是具有因果关系，或非条件独立）。若两个节点间以一个单箭头连接在一起，表示其中一个节点是“因(parents)”，另一个是“果(children)”，两节点就会产生一个条件概率值。
例如，假设节点E直接影响到节点H，即E→H，则用从E指向H的箭头建立结点E到结点H的有向弧(E,H)，权值(即连接强度)用条件概率P(H|E)来表示，如下图所示：
![](https://img-blog.csdn.net/20141111180200463)
**贝叶斯网络定义**：令G = (I,E)表示一个有向无环图(DAG)，其中I代表图形中所有的节点的集合，而E代表有向连接线段的集合，且令X = (Xi)i ∈ I为其有向无环图中的某一节点i所代表的随机变量，若节点X的联合概率可以表示成：
![](https://img-blog.csdn.net/20141110222518593)
则称X为相对于一有向无环图G 的贝叶斯网络。
举例1：
![](https://img-blog.csdn.net/20141110221319352)
因为a导致b，a和b导致c，所以有：
![](https://img-blog.csdn.net/20141110222147578)
举例2：
![](https://img-blog.csdn.net/20141111213550845)
>> smoking表示吸烟，其概率用P(S)表示，lung Cancer表示的肺癌，一个人在吸烟的情况下得肺癌的概率用P(C|S)表示
>> X-ray表示需要照医学上的X光，肺癌可能会导致需要照X光，吸烟也有可能会导致需要照X光（所以smoking也是X-ray的一个因），所以，因吸烟且得肺癌而需要照X光的概率用P(X|C,S)表示。
>> Bronchitis表示支气管炎，一个人在吸烟的情况下得支气管炎的概率用P(B|S)，dyspnoea表示呼吸困难，支气管炎可能会导致呼吸困难，肺癌也有可能会导致呼吸困难（所以lung Cancer也是dyspnoea的一个因），因吸烟且得了支气管炎导致呼吸困难的概率用P(D|C,B)表示。
lung Cancer简记为C，Bronchitis简记为B，dyspnoea简记为D，且C = 0表示lung Cancer不发生的概率，C = 1表示lung Cancer发生的概率，B等于0（B不发生）或1（B发生）也类似于C，同样的，D=1表示D发生的概率，D=0表示D不发生的概率，便可得到dyspnoea的一张概率表，如上图的最右下角所示。















