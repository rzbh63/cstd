# 机器学习——低秩矩阵分解中低秩的意义、矩阵填补、交叉验证

2018年06月04日 12:28:58 [Manduner_TJU](https://me.csdn.net/manduner) 阅读数：9623



​        在研读论文《Matrix completion by deep matrix factorization》时，遇到了一些不明白的知识点，花费了大量时间在网上查阅相关资料，终于找到了能够让自己一看就一目了然的博文，下面的内容是我对所看到博文的一些修正总结。

​       **注：** 我写的这篇文章一部分是转自[zouxy09](https://blog.csdn.net/zouxy09)的文章，在参考资料中也给出了原文章的链接地址。由于原文章涉及知识点比较多，所以总结后再写来的目的主要是为了以后能够按照自己的理解、自己的需求、自己的思路来查阅知识点，也给予了自己要向所参考博文博主学习的希冀以及动力。当然，如果也能给大家带来方便，那就更好了。(*￣︶￣)



# 一、低秩矩阵中低秩（Low-rank）的意义



## 1，问题的引出——对低秩矩阵分解中低秩的误解

​        论文《Privileged Matrix Factorization for Collaborative Filtering》是我在推荐系统研究方向上所读的第一篇论文（针对该篇论文，请看总结[点击打开链接](https://blog.csdn.net/manduner/article/details/80470992)），当时对矩阵分解的理解是：评分矩阵X分解成两个隐特征矩阵U和V，U代表用户隐特征矩阵，V代表商品隐特征矩阵。U和V的隐因子向量的长度为k，其中k<<min{m,n}，自己也就理解成了分解后的两个矩阵的秩是比原来的评分矩阵X的秩低很多，所以就把该方法称为低秩矩阵分解法。

​        在我查阅了大量资料后，事实证明我对低秩矩阵分解中的低秩的意义理解是错误的。那么低秩（Low-rank）的意义到底代表什么呢，请看下面的解释



## 2，低秩矩阵分解中低秩的意义

​        我们先来回忆下线性代数里面“秩”到底是啥？举个简单的例子吧：

![img](https://img-blog.csdn.net/2018060411140644)

​         对上面的线性方程组，第一个方程和第二个方程有不同的解，而第2个方程和第3个方程的解完全相同。从这个意义上说，第3个方程是“多余”的，因为它没有带来任何的信息量，把它去掉，所得的方程组与原来的方程组同解。为了从方程组中去掉多余的方程，自然就导出了“矩阵的秩”这一概念。



​        还记得我们怎么手工求矩阵的秩吗？为了求矩阵A的秩，我们是通过矩阵初等变换把A化为阶梯型矩阵，若该阶梯型矩阵有r个非零行，那A的秩rank(A)就等于r。从物理意义上讲，矩阵的秩度量的就是矩阵的行列之间的相关性。如果矩阵的各行或列是线性无关的，矩阵就是满秩的，也就是秩等于行数。回到上面线性方程组来说吧，因为线性方程组可以用矩阵描述嘛。秩就表示了有多少个有用的方程了。上面的方程组有3个方程，实际上只有2个是有用的，一个是多余的，所以对应的矩阵的秩就是2了。

​       OK。既然秩可以度量相关性，而矩阵的相关性实际上就表示了矩阵的结构信息。如果矩阵之间各行的相关性很强，那么就表示这个矩阵实际可以投影到更低维的线性子空间，也就是用几个向量就可以完全表达了，它就是低秩的。所以我们总结的一点就是：如果矩阵表达的是结构性信息，例如图像、用户-商品推荐表等等，那么这个矩阵各行之间存在这一定的相关性，那这个矩阵一般就是低秩的。

​       如果X是一个m行n列的数值矩阵，rank(X)是X的秩，假如rank (X)远小于m和n，则我们称X是低秩矩阵。低秩矩阵每行或每列都可以用其他的行或列线性表出，可见它包含大量的冗余信息。利用这种冗余信息，可以对缺失数据进行恢复，也可以对数据进行特征提取。



# 二、矩阵填补（Matrix Completion）

​        矩阵填补的应用很广泛，论文《Matrix completion by deep matrix factorization》就给出了矩阵填补的两个应用：图像修复（image inpainting）、协同过滤（Collaborative filtering）。

​        **图像修复**：简单来说就是通过矩阵填补模型将“打码”的图片修复成原来的图片，如下图所示：

![img](https://img-blog.csdn.net/20180604112847920)

![img](https://img-blog.csdn.net/20180604112858433)

​        **协同过滤**：是推荐系统的一种模型，该方法通过分析用户的历史记录（主要是用户-商品评分矩阵）来给用户做出推荐。例如我们在看一部电影的时候，如果喜欢看，就会给它打个分，例如3颗星。然后系统，例如Netflix等知名网站就会分析这些数据，看看到底每部影片的题材到底是怎样的？针对每个人，喜欢怎样的电影，然后会给对应的用户推荐相似题材的电影。但有一个问题是：我们的网站上面有非常多的用户，也有非常多的影片，不是所有的用户都看过说有的电影，不是所有看过某电影的用户都会给它评分。假设我们用一个“用户-影片”的矩阵来描述这些记录，例如下图，可以看到，会有很多空白的地方。如果这些空白的地方存在，我们是很难对这个矩阵进行分析的，所以在分析之前，一般需要先对其进行补全。也叫矩阵填充。

![img](https://img-blog.csdn.net/20180604121250646)

​        那到底怎么填呢？如何才能无中生有呢？每个为0的地方的信息是否蕴含在其他已有的信息之上了呢？如果有，怎么提取出来呢？Yeah，这就是低秩生效的地方了。这叫低秩矩阵重构问题，它可以用如下的模型表述：已知数据是一个给定的m*n矩阵A，如果其中一些元素因为某种原因丢失了，我们能否根据其他行和列的元素，将这些元素恢复？当然，如果没有其他的参考条件，想要确定这些数据很困难。但如果我们已知A的秩rank(A)<<m且rank(A)<<n，那么我们可以通过矩阵各行(列)之间的线性相关将丢失的元素求出。你会问，这种假定我们要恢复的矩阵是低秩的，合理吗？实际上是十分合理的，比如一个用户对某电影评分是其他用户对这部电影评分的线性组合。所以，通过低秩重构就可以预测用户对其未评价过的视频的喜好程度。从而对矩阵进行填充。



# 三、交叉验证（Cross Validation）

​        论文的实验部分会经常用到交叉验证，它是评价模型性能的一种指标，也是选择合适超参的一种方法。

​        交叉验证：把在某种意义下将原始数据(dataset)进行分组,一部分做为训练集(train set),另一部分做为验证集(validation set or test set),首先用训练集对分类器进行训练,再利用验证集来测试训练得到的模型(model),以此来做为评价分类器的性能指标。



# 四、参考资料

[1] [机器学习中的规则化范数（L0，L1，L2，核范数）](https://blog.csdn.net/zouxy09/article/details/24971995)

[2] [核范数与规则项参数选择](https://blog.csdn.net/zouxy09/article/details/24972869)

[3] Du Y, Xu C, Tao D. Privileged matrix factorization for collaborative filtering[C]//Proceedings of the 26th International Joint Conference on Artificial Intelligence. AAAI Press, 2017: 1610-1616.

[4] Fan J, Cheng J. Matrix completion by deep matrix factorization[J]. Neural Networks, 2018, 98: 34-41.