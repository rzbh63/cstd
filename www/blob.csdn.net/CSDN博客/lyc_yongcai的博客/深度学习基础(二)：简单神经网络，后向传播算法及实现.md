
# 深度学习基础(二)：简单神经网络，后向传播算法及实现 - lyc_yongcai的博客 - CSDN博客


2017年06月14日 09:56:23[刷街兜风](https://me.csdn.net/lyc_yongcai)阅读数：219



在之前的[深度学习笔记(一):logistic分类](http://blog.csdn.net/u014595019/article/details/52554582)中，已经描述了普通logistic回归以及如何将logistic回归用于多类分类。在这一节，我们再进一步，往其中加入隐藏层，构建出最简单的神经网络

# 2.简单神经网络及后向传播算法

## 2.1 大概描述和公式表达
神经网络的大概结构如图所示，
![这里写图片描述](https://img-blog.csdn.net/20160916202938313)
从左往右，分别是输入层，隐藏层，输出层，分别记为,,.
 从输入层到隐藏层的矩阵记为,
 偏置向量;
 从隐藏层到输出层的矩阵记为,
 偏置向量为.
 那么根据之前logistic分类的公式稍作扩展，不难得到

其实就是两层logistic分类的堆叠，将前一个分类器的输出作为后一个的输入。得到输出以后的判断方法也比较类似，哪项最高就判定属于哪一类。真正值得写一下的是神经网络中的后向算法。按照传统的logistic分类，只能做到根据误差来更新和那么如何来更新从输入层到隐藏层的参数和呢？这就要用到后向算法了。所谓后向算法，就是指误差由输出层逐层往前传递，进而逐层更新参数矩阵和偏执向量。后向算法的核心其实就4个字：链式法则。首先来看和的更新

其实在上面的公式中，已经用到了链式法则。 类似的，可以得到

可以看到，在和的计算中都用到了这可以看成由输出层传递到中间层的误差。那么在获得了各参数的偏导数以后，就可以对参数进行修正了


## 2.2 神经网络的简单实现
为了加深印象，我自己实现了一个神经网络分类器，分类效果如下图所示
![这里写图片描述](https://img-blog.csdn.net/20160916222448503)
上图中，左上角显示的是实际的分类，右上角显示的是分类器判断出的各点分类。靠下的图显示的是分类器的判断准确率随迭代次数的变化情况。可以看到，经过训练以后，分类器的判断准确率还是可以的。
下面是代码部分
```python
import
```
```python
numpy
```
```python
as
```
```python
np
```
```python
import
```
```python
matplotlib.pyplot
```
```python
as
```
```python
plt
```
```python
import
```
```python
random
```
```python
import
```
```python
math
```
```python
# 构造各个分类
```
```python
def
```
```python
gen_sample
```
```python
()
```
```python
:
```
```python
data = []
    radius = [
```
```python
0
```
```python
,
```
```python
50
```
```python
]
```
```python
for
```
```python
i
```
```python
in
```
```python
range(
```
```python
1000
```
```python
):
```
```python
# 生成10k个点
```
```python
catg = random.randint(
```
```python
0
```
```python
,
```
```python
1
```
```python
)
```
```python
# 决定分类
```
```python
r = random.random()*
```
```python
10
```
```python
arg = random.random()*
```
```python
360
```
```python
len = r + radius[catg]
        x_c = math.cos(math.radians(arg))*len
        y_c = math.sin(math.radians(arg))*len
        x = random.random()*
```
```python
30
```
```python
+ x_c
        y = random.random()*
```
```python
30
```
```python
+ y_c
        data.append((x,y,catg))
```
```python
return
```
```python
data
```
```python
def
```
```python
plot_dots
```
```python
(data)
```
```python
:
```
```python
data_asclass = [[]
```
```python
for
```
```python
i
```
```python
in
```
```python
range(
```
```python
2
```
```python
)]
```
```python
for
```
```python
d
```
```python
in
```
```python
data:
        data_asclass[int(d[
```
```python
2
```
```python
])].append((d[
```
```python
0
```
```python
],d[
```
```python
1
```
```python
]))
    colors = [
```
```python
'r.'
```
```python
,
```
```python
'b.'
```
```python
,
```
```python
'r.'
```
```python
,
```
```python
'b.'
```
```python
]
```
```python
for
```
```python
i,d
```
```python
in
```
```python
enumerate(data_asclass):
```
```python
# print(d)
```
```python
nd = np.array(d)
        plt.plot(nd[:,
```
```python
0
```
```python
],nd[:,
```
```python
1
```
```python
],colors[i])
    plt.draw()
```
```python
def
```
```python
train
```
```python
(input, output, Whx, Wyh, bh, by)
```
```python
:
```
```python
"""
    完成神经网络的训练过程
    :param input:   输入列向量， 例如 [x,y].T
    :param output:  输出列向量, 例如[0,1,0,0].T
    :param Whx:     x->h 的参数矩阵
    :param Wyh:     h->y 的参数矩阵
    :param bh:      x->h 的偏置向量
    :param by:      h->y 的偏置向量
    :return:
    """
```
```python
h_z = np.dot(Whx, input) + bh
```
```python
# 线性求和
```
```python
h_a =
```
```python
1
```
```python
/(
```
```python
1
```
```python
+np.exp(-
```
```python
1
```
```python
*h_z))
```
```python
# 经过sigmoid激活函数
```
```python
y_z = np.dot(Wyh, h_a) + by
    y_a =
```
```python
1
```
```python
/(
```
```python
1
```
```python
+np.exp(-
```
```python
1
```
```python
*y_z))
    c_y = (y_a-output)*y_a*(
```
```python
1
```
```python
-y_a)
    dWyh = np.dot(c_y, h_a.T)
    dby = c_y
    c_h = np.dot(Wyh.T, c_y)*h_a*(
```
```python
1
```
```python
-h_a)
    dWhx = np.dot(c_h,input.T)
    dbh = c_h
```
```python
return
```
```python
dWhx,dWyh,dbh,dby,c_y
```
```python
def
```
```python
test
```
```python
(train_set, test_set, Whx, Wyh, bh, by)
```
```python
:
```
```python
train_tag = [int(x)
```
```python
for
```
```python
x
```
```python
in
```
```python
train_set[:,
```
```python
2
```
```python
]]
    test_tag = [int(x)
```
```python
for
```
```python
x
```
```python
in
```
```python
test_set[:,
```
```python
2
```
```python
]]
    train_pred = []
    test_pred = []
```
```python
for
```
```python
i,d
```
```python
in
```
```python
enumerate(train_set):
        input = train_set[i:i+
```
```python
1
```
```python
,
```
```python
0
```
```python
:
```
```python
2
```
```python
].T
        tag = predict(input,Whx,Wyh,bh,by)
        train_pred.append(tag)
```
```python
for
```
```python
i,d
```
```python
in
```
```python
enumerate(test_set):
        input = test_set[i:i+
```
```python
1
```
```python
,
```
```python
0
```
```python
:
```
```python
2
```
```python
].T
        tag = predict(input,Whx,Wyh,bh,by)
        test_pred.append(tag)
```
```python
# print(train_tag)
```
```python
# print(train_pred)
```
```python
train_err =
```
```python
0
```
```python
test_err =
```
```python
0
```
```python
for
```
```python
i
```
```python
in
```
```python
range(train_pred.__len__()):
```
```python
if
```
```python
train_pred[i]!=int(train_tag[i]):
            train_err +=
```
```python
1
```
```python
for
```
```python
i
```
```python
in
```
```python
range(test_pred.__len__()):
```
```python
if
```
```python
test_pred[i]!=int(test_tag[i]):
            test_err +=
```
```python
1
```
```python
# print(test_tag)
```
```python
# print(test_pred)
```
```python
train_ratio = train_err / train_pred.__len__()
    test_ratio = test_err / test_pred.__len__()
```
```python
return
```
```python
train_err,train_ratio,test_err,test_ratio
```
```python
def
```
```python
predict
```
```python
(input,Whx,Wyh,bh,by)
```
```python
:
```
```python
# print('-----------------')
```
```python
# print(input)
```
```python
h_z = np.dot(Whx, input) + bh
```
```python
# 线性求和
```
```python
h_a =
```
```python
1
```
```python
/(
```
```python
1
```
```python
+np.exp(-
```
```python
1
```
```python
*h_z))
```
```python
# 经过sigmoid激活函数
```
```python
y_z = np.dot(Wyh, h_a) + by
    y_a =
```
```python
1
```
```python
/(
```
```python
1
```
```python
+np.exp(-
```
```python
1
```
```python
*y_z))
```
```python
# print(y_a)
```
```python
tag = np.argmax(y_a)
```
```python
return
```
```python
tag
```
```python
if
```
```python
__name__==
```
```python
'__main__'
```
```python
:
    input_dim   =
```
```python
2
```
```python
output_dim  =
```
```python
2
```
```python
hidden_size =
```
```python
200
```
```python
Whx = np.random.randn(hidden_size, input_dim)*
```
```python
0.01
```
```python
Wyh = np.random.randn(output_dim, hidden_size)*
```
```python
0.01
```
```python
bh  = np.zeros((hidden_size,
```
```python
1
```
```python
))
    by  = np.zeros((output_dim,
```
```python
1
```
```python
))
    data = gen_sample()
    plt.subplot(
```
```python
221
```
```python
)
    plot_dots(data)
    ndata = np.array(data)
    train_set = ndata[
```
```python
0
```
```python
:
```
```python
800
```
```python
,:]
    test_set = ndata[
```
```python
800
```
```python
:
```
```python
1000
```
```python
,:]
    train_ratio_list = []
    test_ratio_list = []
```
```python
for
```
```python
times
```
```python
in
```
```python
range(
```
```python
10000
```
```python
):
        i = times%train_set.__len__()
        input = train_set[i:i+
```
```python
1
```
```python
,
```
```python
0
```
```python
:
```
```python
2
```
```python
].T
        tag = int(train_set[i,
```
```python
2
```
```python
])
        output = np.zeros((
```
```python
2
```
```python
,
```
```python
1
```
```python
))
        output[tag,
```
```python
0
```
```python
] =
```
```python
1
```
```python
dWhx,dWyh,dbh,dby,c_y = train(input,output,Whx,Wyh,bh,by)
```
```python
if
```
```python
times%
```
```python
100
```
```python
==
```
```python
0
```
```python
:
            train_err,train_ratio,test_err,test_ratio = test(train_set,test_set,Whx,Wyh,bh,by)
            print(
```
```python
'times:{t}\t train ratio:{tar}\t test ratio: {ter}'
```
```python
.format(tar=train_ratio,ter=test_ratio,t=times))
            train_ratio_list.append(train_ratio)
            test_ratio_list.append(test_ratio)
```
```python
for
```
```python
param, dparam
```
```python
in
```
```python
zip([Whx, Wyh, bh, by],
                                 [dWhx,dWyh,dbh,dby]):
            param -=
```
```python
0.01
```
```python
*dparam
```
```python
for
```
```python
i,d
```
```python
in
```
```python
enumerate(ndata):
        input = ndata[i:i+
```
```python
1
```
```python
,
```
```python
0
```
```python
:
```
```python
2
```
```python
].T
        tag = predict(input,Whx,Wyh,bh,by)
        ndata[i,
```
```python
2
```
```python
] = tag
    plt.subplot(
```
```python
222
```
```python
)
    plot_dots(ndata)
```
```python
# plt.figure()
```
```python
plt.subplot(
```
```python
212
```
```python
)
    plt.plot(train_ratio_list)
    plt.plot(test_ratio_list)
    plt.show()
```
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
![](http://static.blog.csdn.net/images/save_snippets.png)
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144


