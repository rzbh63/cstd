
# 吴恩达机器学习笔记 —— 10 神经网络参数的反向传播算法 - 喜欢打酱油的老鸟 - CSDN博客


2018年08月05日 08:45:29[喜欢打酱油的老鸟](https://me.csdn.net/weixin_42137700)阅读数：191


[http://www.cnblogs.com/xing901022/p/9350271.html](http://www.cnblogs.com/xing901022/p/9350271.html)
本篇讲述了神经网络的误差反向传播以及训练一个神经网络模型的流程
更多内容参考机器学习&深度学习
神经网络可以理解为两个过程：信号的正向传播和误差的反向传播。在正向的传播过程中，计算方法为Sj=wij*xi+bj，其中i是样本、j是层数。然后xj=f(Sj)，f为激活函数。引入激活函数的原因是可以带来一定的非线性特性。由于样本的y是在最后一层输出的，因此在计算误差的时候，需要从最后一层开始计算、针对与之关联的参数进行求梯度，获得参数的更新。然后再计算前一层的误差，前一层的误差等于权值*误差值，继续计算每个参数的梯度变化。在神经网络中很容易形成局部最优解，因此需要初始的随机性比较好。
神经网络中的每一层可以用下面的表达式来表示：
![](https://images.cnblogs.com/cnblogs_com/xing901022/1187174/o_%E5%90%B4%E6%81%A9%E8%BE%BE10_1.png)
通过最后一层的误差，就能推出来每一层的误差值。
![](https://images.cnblogs.com/cnblogs_com/xing901022/1187174/o_%E5%90%B4%E6%81%A9%E8%BE%BE10_2.png)
通过误差值计算梯度，然后修改权值
![](https://images.cnblogs.com/cnblogs_com/xing901022/1187174/o_%E5%90%B4%E6%81%A9%E8%BE%BE10_3.png)
![](https://images.cnblogs.com/cnblogs_com/xing901022/1187174/o_%E5%90%B4%E6%81%A9%E8%BE%BE10_4.png)
![](https://images.cnblogs.com/cnblogs_com/xing901022/1187174/o_%E5%90%B4%E6%81%A9%E8%BE%BE10_5.png)
# 神经网络的流程
![](https://images.cnblogs.com/cnblogs_com/xing901022/1187174/o_%E5%90%B4%E6%81%A9%E8%BE%BE10_6.png)
![](https://images.cnblogs.com/cnblogs_com/xing901022/1187174/o_%E5%90%B4%E6%81%A9%E8%BE%BE10_7.png)
有时候误差传播代码是有问题，可以通过梯度检测，判断是否有问题。
![](https://images.cnblogs.com/cnblogs_com/xing901022/1187174/o_%E5%90%B4%E6%81%A9%E8%BE%BE10_8.png)

