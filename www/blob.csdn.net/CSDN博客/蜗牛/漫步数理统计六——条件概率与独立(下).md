
# 漫步数理统计六——条件概率与独立(下) - 蜗牛 - CSDN博客


2017年03月12日 23:18:09[会敲键盘的猩猩](https://me.csdn.net/u010182633)阅读数：400


\$\$\textbf{例5：}\$瓶\$C_1\$中有\$3\$个红球，\$7\$个白球，瓶\$C_2\$中有\$8\$个红球，\$2\$个白球，这些球大小与形状都是一样的，现在假设选择瓶\$C_1\$的概率为\$P(C_1)=\frac{2}{6}\$，而选\$C_2\$的概率为\$P(C_2)=\frac{4}{6}\$。选完瓶子后我们随机抽一个球，抽到红球的事件用\$C\$表示，显然条件概率\$P(C|C_1)=\frac{3}{10},P(C|C_2)=\frac{8}{10}\$，那么在抽到红球的条件下，是瓶\$C_1\$的条件概率为
\begin{align*}
P(C_1|C)
&=\frac{P(C_1)P(C|C_1)}{P(C_1)P(C|C_1)+P(C_2)P(C|C_2)}\
&=\frac{(\frac{2}{6})(\frac{3}{10})}{(\frac{2}{6})(\frac{3}{10})+(\frac{4}{6})(\frac{8}{10})}=\frac{3}{19}
\end{align*}
同样得我们可得$P(C_2|C)=\frac{16}{19}$。
在例$5$中，概率$P(C_1)=\frac{2}{6},P(C_2)=\frac{4}{6}$称为$C_1,C_2$的先验概率，因为他们是已知的。观察到是红球以后，条件概率$P(C_1|C)=\frac{3}{19},P(C_2|C)=\frac{16}{19}$称为后验概率。因为$C_2$中红球的比例比$C_1$中大，所以直觉上我们认为$P(C_2|C)$应该比$P(C_1|C)$大，并且$P(C_1|C)$应该比$P(C_1)$要小。贝叶斯定理提供了精确算出他们概率是多少的方法。
$\textbf{例6：}$三个工厂$C_1,C_2,C_3$分别占公司百分之$10,50,40$的产出，虽然$C_1$产出规模小，但是其产品质量很高，只有百分之$1$的残品率，其他两个工厂$C_2,C_3$的残品率分别是百分之$3$和$4$，所有产品最终会送到同一个仓库，现在我们随机抽一个产品，其是残品的事件记为$C$，接下来我们来计算该产品来自$C_1$的条件概率。我们很自然会得到$P(C_1)=0.1,P(C_2)=0.5,P(C_3)=0.4$，残品的条件概率为$P(C|C_1)=0.01,P(C|C_2)=0.03,P(C|C_3)=0.04$，那么给定一个次品，$C_1$的后验概率是

$$
P(C_1|C)=\frac{P(C_1\cap C)}{P(C)}=\frac{(0.1)(0.01)}{(0.1)(0.01)+(0.5)(0.03)+(0.4)(0.04)}
$$
等于$\frac{1}{32}$；这比先验概率$P(C_1)=\frac{1}{16}$要小。这是因为产品为残品的事实降低了其来自高质量$C_1$的机会。
$\textbf{例7：}$假设我们想调查某个人群中受虐儿童的比例，我们感兴趣的事件是：受虐$(A)$与它的补，即不受虐$(N=A^c)$。为了我们假设$P(A)=0.01$，那么$P(N)=0.99$，当然是否受虐是基于医生的鉴定，因为医生不一定就能做出完美的结论，他们时候会把受虐的儿童$(A)$判定成未受虐的$(N_D)$，另一方面，也可能把为未受虐的$(N)$分为受虐的$A_D$。假设误分的错误率为$P(N_D|A)=0.04,P(A_D|N)=0.05$；那么正确分类的概率是$P(N_D|A)=0.96,P(A_D|N)=0.95$，现在我们计算随机选一个孩子，他被医生分成受虐儿童的概率。因为会有两种情况$A\cap A_D,N\cap A_D$，所以我们有$P(A_D)=P(A_D|A)P(A)+P(A_D|N)P(N)=(0.96)(0.01)+(0.05)(0.99)=0.0591$，它比受虐儿童的概率0.01要高。进一步，当一个儿童被医生判定为受虐待，而实际就是受虐待的概率为

$$
P(A|A_D)=\frac{P(A\cap A_D)}{P(A_D)}=\frac{(0.96)(0.01)}{0.0591}=0.1624
$$
同样的我们可以计算一个儿童被医生判定为受虐待而实际没有受虐嗲的概率为$0.8376$。这些概率相对真实概率比较不靠谱，原因在于医生的误差率比受虐儿童的$0.01$还高。
有时事件$C_1$的发生不会影响$C_2$的概率，这里$P(C_1)>0$，即

$$
P(C_2|C_1)=P(C_2)
$$
这时候我们称事件$C_1,C_2$是独立的，而且乘法法则变成

$$
P(C_1\cap C_2)=P(C_1)P(C_2|C_1)=P(C_1)P(C_2)
$$
反过来当$P(C_2)>0$时有

$$
P(C_1|C_2)=\frac{P(C_1\cap C_2)}{P(C_2)}=\frac{P(C_1)P(C_2)}{P(C_2)}=P(C_1)
$$
注意，如果$P(C_1)>0,P(C_2)>0$，那么根据上面的讨论，独立等价于

$$
\begin{equation}
P(C_1\cap C_2)=P(C_1)P(C_2)\tag1
\end{equation}
$$
那么$P(C_1)=0$或者$P(C_2)=0$会怎样呢？这时候，等式$1$的右边是$0$，左边也是$0$，因为$C_1\cap C_2\subset C_1,C_1\cap C_2\subset C_2$。因此我们取等式1作为独立的正式定义；即
$\textbf{定义1：}$令$C_1,C_2$是两个事件，如果等式1成立，我们就说$C_1,C_2$是独立的。
假设$C_1,C_2$是独立事件，那么下面三个事件是独立的：$C_1,C_2^c$与$C_1^c,C_2$与$C_1^c,C_2^c$。
$\textbf{注1：}$独立的事件有时候称为统计独立，随机独立或者依概率独立，多数情况下，如果不引起误解我们一般用独立。
$\textbf{例8：}$红白双方分别掷骰子，如果$C_1$表示红方掷出$4$，$C_2$表示白方掷出$3$，$P(C_1)=\frac{1}{6},P(C_2)=\frac{1}{6}$，那么根据独立性，有序数对$(4,3)$的概率是

$$
P[(4,3)]=(\frac{1}{6})(\frac{1}{6})=\frac{1}{36}
$$
数对和等于7的概率是

$$
\begin{align*}
P[(1,&6),(2,5),(3,4),(4,3),(5,2),(6,1)]\\
&=(\frac{1}{6})(\frac{1}{6})+(\frac{1}{6})(\frac{1}{6})+(\frac{1}{6})(\frac{1}{6})+(\frac{1}{6})(\frac{1}{6})+(\frac{1}{6})(\frac{1}{6})+(\frac{1}{6})(\frac{1}{6})=\frac{6}{36}
\end{align*}
$$
同样得，我们可以算出和为$2,3,4,5,6,7,8,9,10,11,12$的概率分别为

$$
\frac{1}{36},\frac{2}{36},\frac{3}{36},\frac{4}{36},\frac{5}{36},\frac{6}{36},\frac{5}{36},\frac{4}{36},\frac{3}{36},\frac{2}{36},\frac{1}{36},
$$
假设有三个事件$C_1,C_2,C_3$，当且仅当他们每对独立即

$$
\begin{align*}
&P(C_1\cap C_3)=P(C_1)P(C_3),P(C_1\cap C_2)=P(C_1)P(C_2),\\
&P(C_2\cap C_3)=P(C_2)P(C_3),
\end{align*}
$$
且

$$
P(C_1\cap C_2\cap C_3)=P(C_1)P(C_2)P(C_3)
$$
时，我们称他们互相独立。对于$n$个事件$C_1,C_2,\ldots,C_n$，当且仅当对每$k$个集合，$2\leq k\leq n$，下面事实为真：
$d_1,d_2,\ldots,d_k$是$1,2,\ldots,n$中不同的整数；那么

$$
P(C_{d_1}\cap C_{d_2}\cap\cdots \cap C_{d_k})=P(C_{d_1})P(C_{d_2})\cdots P(C_{d_k})
$$
另外对任意两个由这些事件以及他们的补构成的组合也是独立的，例如
事件C_1^c与C_2\cup C_3^c\cup C_4是独立的；
事件C_1\cup C_2^c,C_3^c与C_4\cap C_5^c是互相独立的。
在不引起误解的情况下，在考虑多于两个事件时我们依然用独立，而不是互相独立。
我们经常会执行一些随机试验，这些事件互相是独立的。为了简便我们将这些事件称为独立试验，也就是说各个事件是独立的，因此我们经常独立的抛硬币或独立的掷骰子。
$\textbf{例9：}$独立地掷几次硬币，令事件$C_i$表示第$i$次头$(H)$朝上；那么$C_i^c$表示尾$(T)$朝上。假设$C_i$与$C_i^c$是等可能的；即$P(C_i)=P(C_i^c)=\frac{1}{2}$，所以像$HHTH$这样有序数列的概率是

$$
P(C_1\cap C_2\cap C_3^c\cap C_4)=P(C_1)P(C_2)P(C_3^c)P(C_4)=(\frac{1}{2})^4=\frac{1}{16}
$$
同样得，第三次头朝上的概率是

$$
P(C_1^c\cap C_2^c\cap C_3)=P(C_1^c)P(C_2^c)P(C_3)=(\frac{1}{2})^3=\frac{1}{8}
$$
另外四次中至少有一次头朝上的概率为

$$
\begin{align*}
P(C_1\cup C_2\cup C_3\cup C_4)
&=1-P[(C_1\cup C_2\cup C_3\cup C_4)^c]\\
&=1-P(C_1^c\cup C_2^c\cup C_3^c\cup C_4^c)\\
&=1-\frac{1}{2}^4=\frac{15}{16}
\end{align*}
$$
$\textbf{例10：}$有一个计算系统，如果组件$K_1$发生故障，那么使用$K_2$，如果$K_2$发生故障，那么使用$K_3$。 假设$k_1$发生故障的概率是$0.01$，$K_2$发生故障的概率是$0.03$，$K_3$发生故障的概率是$0.08$。 而且我们假设这三个组件发生故障是互相独立的，那么这系统发生故障的概率是

$$
(0.01)(0.03)(0.08)=0.000024
$$
因此系统不发生故障的概率是$1-0.000024=0.999975$。

