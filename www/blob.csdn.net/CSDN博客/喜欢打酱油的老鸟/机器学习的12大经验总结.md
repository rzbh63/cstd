
# 机器学习的12大经验总结 - 喜欢打酱油的老鸟 - CSDN博客


2019年01月01日 20:47:19[喜欢打酱油的老鸟](https://me.csdn.net/weixin_42137700)阅读数：98


机器学习的12大经验总结
[https://www.toutiao.com/a6640235431042482695/](https://www.toutiao.com/a6640235431042482695/)
2018-12-29 10:24:49
机器学习难吗？有些小伙伴们会说，难！真的难！不知道怎么去应用实践？弯路陷阱太多不知如何避免？不知道如何更好的学习机器学习？这些问题相信大部分人都有过疑虑。
本文整理了关于机器学习研究者和从业者的12个宝贵经验，包括需要避免的陷阱、需要关注的重点问题、常见问题的答案。希望这些经验对机器学习爱好者有一些帮助。
**01、“表征+评估+优化”构成机器的主要内容**
构成机器学习算法的 3 部分：
表征（Representation）：分类器必须用计算机可以处理的形式化语言来表示。相反地，为训练模型选择一个表征就等同于选择可训练分类器的集合。这个集合称为训练模型的「假设空间」。如果分类器不在「假设空间」中，那么它就不能由训练所得到。一个相关的问题是如何表征输入，即使用哪些特征。
评估（Evaluation）：需要一个评估函数来区分分类器的好坏。算法内部使用的评估函数可能与分类器优化的外部评估函数不同，这是为了便于优化，并且是由我们下一节所要讨论的问题导致的。
优化（Optimization）：我们要用一种方法搜索得分最高的分类器。优化方法的选择对于提升模型的效率非常关键。另外，如果评估函数具有一个以上的最优值，则优化方法有助于确定最后产生的分类器。新的训练模型一开始常常使用现有的优化器，后来常会转而使用自定义的优化器。
**02、“泛化能力”很关键，“测试数据”验证至关重要**
机器学习的主要目标是对训练集之外的样本进行泛化。因为无论有多少数据，都不太可能在测试中再次看到完全相同的例子。在训练集上具有良好表现很容易。机器学习初学者最常犯的错误是把模型放在训练数据中进行测试，从而产生成功的错觉。
如果被选择的分类器在新的数据上进行测试，一般情况，结果往往和随机猜测相差无几。所以，如果你雇佣他人建立分类器，一定要留一些数据给你自己，以便在他们给你的分类器中进行测试。相反，如果有人雇佣你建立一个分类器，请保留一部分数据对你的分类器进行最终测试。
![国匠智能制造培训｜机器学习的12大经验总结](https://img-blog.csdnimg.cn/20181229131554167)
**03、仅有数据是不够的，知识相结合效果更好**
把泛化能力作为目标，会又另一个后果：只有数据是不够的，无论你拥有多少数据。这是否让人沮丧。那么，我们怎么能奢求它学到东西呢？
不过，现实世界中我们想学习的函数并不都是从数学上可能的函数中提取出来的！实际上，使用一般假设——例如平滑性、相似样本有相似分类、有限的依赖性或有限复杂度——往往能做得足够好，这也正是机器学习能如此成功的大部分原因。
正如演绎一样，归纳（训练模型所做的）是一个知识杠杆——它将少量知识输入转化为大量知识输出。归纳是一个比演绎更为强大的杠杆，仅需更少的知识就能产出有用的结果。不过，它仍然需要大于零的知识输入才能工作。正如任何一个杠杆一样，输入得越多，得到的也越多。
这样回想起来，训练过程中对知识的需求没什么好惊讶的。机器学习并非魔术，它无法做到无中生有，它所做的是举一反三。如同所有的工程一样，编程需要做大量的工作：我们必须从头开始构建所有的东西。训练的过程更像是耕种，其中大部分工作是自然完成的。农民将种子与营养物质结合起来，种植作物。训练模型将知识与数据结合起来，编写程序。
![国匠智能制造培训｜机器学习的12大经验总结](https://img-blog.csdnimg.cn/20181229131554210)
**04、“过拟合”让机器学习效果产生错觉**
如果我们所拥有的知识和数据不足以完全确定正确的分类器，分类器（或其中的一部分）就可能产生「错觉」。所获得的分类器并不是基于现实，只是对数据的随机性进行编码。这个问题被称为过拟合，是机器学习中棘手的难题。如果你的训练模型所输出的分类器在训练数据上准确率是 100％，但在测试数据上准确率只有 50％，那么实际上，该分类器在两个集合上的输出准确率总体可能约为 75％，它发生了过拟合现象。
在机器学习领域，人人都知道过拟合。但是过拟合有多种形式，人们往往不能立刻意识到。理解过拟合的一种方法是将泛化的误差进行分解，分为偏差和方差。偏差是模型不断学习相同错误的倾向。而方差指的是不管真实信号如何，模型学习随机信号的倾向。线性模型有很高的偏差，因为当两个类之间的边界不是一个超平面时，模型无法做出调整。决策树不存在这个问题，因为它们可以表征任何布尔函数。但是另一方面，决策树可能方差很大：如果在不同训练集上训练，生成的决策树通常差异很大，但事实上它们应该是相同的。
交叉验证可以帮助对抗过拟合，例如，通过使用交叉验证来选择决策树的最佳规模用于训练。但这不是万能的，因为如果我们用交叉验证生成太多的参数选择，它本身就会开始产生过拟合现象。
除交叉验证之外，还有很多方法可以解决过拟合问题。最流行的是在评估函数中增加一个正则化项。举个例子，这样一来就能惩罚含更多项的分类器，从而有利于生成参数结构更简单的分类器，并减少过拟合的空间。另一种方法是在添加新的结构之前，进行类似卡方检验的统计显著性检验，在添加新结构前后确定类的分布是否真的具有差异。当数据非常少时，这些技术特别有用。
尽管如此，你应该对某种方法完美解决了过拟合问题的说法持怀疑态度。减少过拟合（方差）很容易让分类器陷入与之相对的欠拟合误差（偏差）中去。如果要同时避免这两种情况，需要训练一个完美的分类器。在没有先验信息的情况下，没有任何一种方法总能做到最好（天下没有免费的午餐）。
![国匠智能制造培训｜机器学习的12大经验总结](https://img-blog.csdnimg.cn/20181229131554258)
**05、机器学习中最大的问题就是“维度灾难”**
除了过拟合，机器学习中最大的问题就是维度灾难。这一名词是由 Bellman 在 1961 年提出的，指的是当输入维度很高时，许多在低维工作正常的算法将无法正常工作。但是在机器学习中，它的意义更广。随着样本维度（特征数量）的增加，进行正确泛化变得越来越难，因为固定大小的训练集对输入空间的覆盖逐渐缩减。
高维的一般问题是，来自三维世界的人类直觉通常不适用于高维空间。在高维度当中，多元高斯分布的大部分数据并不接近平均值，而是在其周围越来越远的「壳」中；此外，高维分布的大部分体积分布在表面，而不是体内。如果恒定数量的样本在高维超立方体中均匀分布，那么在超越某个维数的情况下，大多数样本将更接近于超立方体的一个面，而不是它们的最近邻。
此外，如果我们通过嵌入超立方体的方式逼近一个超球面，那么在高维度下，超立方体几乎所有的体积都在超球面之外。这对于机器学习来说是个坏消息，因为一种类型的形状常常可以被另一种形状所逼近，但在高维空间中却失效了。
建立二维或三维分类器容易；我们可以仅通过视觉检查找出不同类别样本之间的合理边界。但是在高维中，我们很难理解数据的分布结构。这又反过来使设计一个好的分类器变得困难。简而言之，人们可能会认为收集更多的特征一定不产生负面作用，因为它们最多只是不提供有关分类的新信息而已。但事实上，维度灾难的影响可能大于添加特征所带来的利益。
**06、“理论保证”与“实际出入”的相互关系**
机器学习论文中充斥着理论保证。最常见的保证就是关于保持模型良好泛化能力的训练样本数量约束问题。首先，该问题显然是可证的。归纳通常与演绎相对：通过演绎，你可以确保结论是正确的; 在归纳中，所有臆想都被摒弃。或许这就是传世的古老智慧。近十年的主要突破就是认识到归纳的结果是可证的这一事实，尤其在我们愿意给出概率保证时。
必须斟酌这类约束意味着什么。这并不意味着，如果你的网络返回与某个特定训练集一致的假设，那么这个假设就可能具有很好的泛化能力。而是，给定一个足够大的训练集，你的网络很可能会返回一个泛化能力好的假设或无法得到一致的假设。这类约束也没有教我们如何选择一个好的假设空间。它只告诉我们，如果假设空间包含好的分类器，那么随着训练集的增大，网络训练出一个弱分类器的概率会减小。如果缩小假设空间，约束条件作用会增强，但是训练出一个强分类器的概率也会下降。
另一种常见的理论保证是渐进性：假如输入的数据规模是无穷大的，那么网络肯定会输出一个强分类器。听起来靠谱，但是由于要保证渐近性，选择某个网络而非另一个就显得过于轻率。在实践中，我们很少处于渐近状态。由上面讨论的偏差 - 方差权衡可知，如果网络 A 在具有海量数据时比网络 B 好，则在有限数据情况下，B 往往比 A 好。
理论保证在机器学习中存在的意义不仅仅是作为评判实际决策的标准，而且是理解的方法及设计算法的动力。鉴于此，它十分有用。事实上，这么多年以来，正是理论联系实际促进了机器学习的飞跃式进步。注意：学习是一个复杂的现象，它在理论上说得通，在实际工作中可行，也并不表示前者是导致后者的原因。
![国匠智能制造培训｜机器学习的12大经验总结](https://img-blog.csdnimg.cn/20181229131554295)
**07、“特征工程”是机器学习的关键**
最后，有些机器学习项目大获成功，有些却失败了。这是什么造成的？最重要的影响因素就是使用的特征。如果你获取到很多独立的且与所属类别相关的特征，那么学习过程就很容易。相反，若某一个类是特征的极其复杂的函数，你的模型可能无法学习到该函数。通常来说，原始数据格式很不适合学习，但是可以基于它来构建特征。这正是机器学习项目最重要的部分，通常也是最有趣的部分，直觉、创造力、「魔术」和技术同样重要。
初学者常常会惊讶于机器学习项目实际上花在机器学习上的时间很少。但是当你将收集、整合、清洗和预处理数据以及将数据重构成特征过程中解决错误等琐事所消耗的时间考虑在内就不奇怪了。而且，机器学习并不只是构建数据集跑一次模型就没事了，它通常是一个跑模型、分析结果、修改数据集/模型的迭代式过程。学习是其中最快的部分，但这取决于我们已经可以熟练运用它！特征工程因为针对特定的领域，所以很难做，而模型架构的适用范围更广泛。但是，这二者之间并没有清晰的界线，这通常可以解释那些整合了领域知识的模型具有更好的性能。
**08、记住：数据量比算法还重要**
在计算机科学的大多数领域，时间和内存是两大紧缺资源。但在机器学习中，数据集俨然是第三个紧缺资源。随着时间的推移，瓶颈之争也在不断改变。在 20 世纪 80 年代，数据通常是瓶颈。而如今时间更为宝贵。我们今天有海量的数据可用，但是却没有充足的时间去处理它，这些数据因此被搁置。
这就产生了一个悖论：即使在原则上讲，大量的数据意味着可以学习到更复杂的分类器，但在实践中，我们往往采用更简单的分类器，因为复杂的分类器意味着更长的训练时间。部分解决方案是提出可以快速学习到复杂分类器的方法，且今天在这一方向上确实取得了显著的进展。
使用更智能的算法的收益不如期望的部分原因是，第一次取近似值时，它跟其它算法无异。当你认为表征方式之间的区别与规则、神经网络之间的区别类似时，这会让你惊讶。但事实是，命题规则可以轻易地编码进神经网络，并且其它的表征方式之间也有类似的关系。模型本质上都是通过将近邻样本分到相同的类别而实现的，关键差异在于「近邻」的含义。
对于非均匀分布的数据，模型可以产生广泛不同的边界，同时在重要的区域（具有大量训练样例的区域，因此也是大多数文本样例可能出现的区域）中产生相同的预测。这也能解释为什么强大的模型可能是不稳定的但仍然很准确。
一般来说，我们首先要考虑最简单的模型（例如，先考虑朴素贝叶斯而非 logistic 回归，先考虑 K-近邻而非支持向量机）。模型越复杂越诱人，但是它们通常很难使用，因为你需要调整很多的节点以获得好的结果，同时，它们的内部构造极其不透明。
模型可以分为两种主要类型：一种是规模固定的模型，例如线性分类器，另一种是表征能力随数据集增强的模型，例如决策树。固定规模的模型只能利用有限的数据。规模可变的模型理论上可以拟合任何函数，只要有足够大的数据集，但是现实很骨感，总存在算法的局限性或计算成本。而且，由于维度灾难，现有的数据集可能不够。鉴于这些原因，更智能的算法—那些充分利用数据和计算资源的算法--如果你愿意努力去调试，最终会得到好的结果。
在设计模型与学习分类器之间并没有十分清晰的界线；但是，任何给定的知识点都可以编码进模型或从数据中学习到。因此，模型设计往往是机器学习项目中的重要组成部分，设计者最好拥有相关专业背景。
**09、“单模型”很难实现最优，“多模型集成”才是出路**
在机器学习发展的早期，大家都有各自喜爱的模型，用一些先验的理由说明它的优越性。研究员对模型开发了大量的变体并从中挑选一个最优的模型。随后，系统的经验比较表明，最好的模型随应用的改变而改变，开始出现了包含许多不同模型的系统。
现在的研究开始尝试调试多个模型的不同变体，然后挑选表现最好的那一个。但研究人员开始注意到，不选择找到的最佳变体，而是结合多个变体，却得到了更好的结果（通常会好很多），而且这没有增加工作量。
现在，模型集成已经是标准方法。其中最简单的技术叫 bagging 算法，我们仅通过重采样来生成训练数据集的随机变体，再基于这些变体分别学习分类器，并通过投票整合这些分类器的结果。此法的可行性在于它大幅减少了方差，且只微微提升了一点偏差。
在 boosting 算法中，训练样例有权重，而且这些权重各不相同，因此每个新分类器都把重点放在前面的模型会出错的样例上。在 stacking 算法中，每个单独的分类器的输出作为「高层」模型的输入，这些高层模型会以最佳方式组合这些模型。
还有很多其它的方法，就不一一列举了，但是总的趋势是规模越来越大的集成学习。在 Netflix 的奖金激励下，全世界的团队致力于构建最佳视频推荐系统。随着竞赛的推进，竞赛团队发现通过结合其它团队的模型可以获得最佳结果，同时这也促进团队的合并。冠军和亚军模型都是由 100 多个小模型组成的集成模型，两个集成模型相结合可进一步提高成绩。毫无疑问，将来还会出现更大的集成模型。
![国匠智能制造培训｜机器学习的12大经验总结](https://img-blog.csdnimg.cn/20181229131554336)
**10、“简单”不能代表是“准确”**
奥卡姆剃刀原理指出，如无必要，勿增实体。在机器学习中，这通常意味着，给定两个具有相同训练误差的分类器，两者中较简单的分类器可能具有最低的评估误差。关于这一说法的佐证在文献中随处可见，但实际上有很多反例用来反驳它，「没有免费午餐」定理质疑它的真实性。
我们在前文中也看到了一个反例：集成模型。即使训练误差已经达到零，通过增加分类器，增强集成模型的泛化误差仍然可以继续减少。因此，与直觉相悖，模型的参数数量与其过拟合趋势并没有必然的联系。
一个巧妙的观点是将模型复杂性等同于假设空间的大小，因为较小的空间允许用较短的编码表征假设。类似理论保证部分中的界限可能被理解成较短的假设编码有更好的泛化能力。通过在有先验偏好的空间中对假设进行较短的编码，我们可以进一步细化这一点。
但是把这看作准确率和简单性之间的权衡的证明则是循环论证：我们通过设计使偏爱的假设更简单，如果它们准确率不错，那是因为偏爱假设的正确，而不是因为在特定表征下假设的「简单」。
**11、“可表征”并不代表“可学习”**
所有运用于非固定规模的模型表征实际上都有「任意函数都可以使用该表征来表示或无限逼近」之类的相关定理。这使得某表征方法的偏好者常常会忽略其它要素。然而，仅凭可表征性并不意味着模型可以学习。例如，叶节点多于训练样本的决策树模型就不会学习。在连续的空间中，通常使用一组固定的原语表征很简单的函数都需要无限的分量。
进一步讲，如果评估函数在假设空间有很多局部最优点（这很常见），模型可能就找不到最优的函数，即使它是可表征的。给定有限的数据、时间及存储空间，标准的模型只能学到所有可能函数集的一个很小的子集，且这个子集随所选的表征方法的不同而不同。因此，关键问题不在「模型是否可表示」，而「模型是否可学习」以及尝试不同的模型（甚至是集成模型）是很重要的。
![国匠智能制造培训｜机器学习的12大经验总结](https://img-blog.csdnimg.cn/20181229131554374)
**12、“相关性”并非就是“因果关系”**
相关性并不意味着因果关系这一点被频繁提起，以至于都不值得再批评。但是，我们讨论的某类模型可能只学习相关性，但是它们的结果通常被看作是表征因果关系。有问题吗？如果有，那么大家为何还这么做？
通常是不对的，预测模型学习的目标是用它们作为行动的指南。当发现人们在买啤酒的时候也会买纸尿布，那么把啤酒放在纸尿布旁边或许会提高销量。


