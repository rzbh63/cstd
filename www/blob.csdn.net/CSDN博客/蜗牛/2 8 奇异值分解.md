
# 2.8 奇异值分解 - 蜗牛 - CSDN博客


2015年10月20日 17:30:03[会敲键盘的猩猩](https://me.csdn.net/u010182633)阅读数：871


**声明：该文章翻译自MIT出版的《DEEP LEARNING》，博主会定期更新文章内容。由于博主能力有限，中间有过错之处希望大家给予批评指正，一起学习交流。**
在2.7节中，我们看到如何将矩阵分解为特征向量和特征值。奇异值分解（SVD）提供了另一种因式分解矩阵方法，即分解为奇异向量和奇异值。 SVD让我们发现了一些和特征分解相同的信息。然而，SVD却更加适用。因为每个实矩阵具有奇异值分解，但不一定有特征值分解。例如，如果矩阵不是方阵，那么特征分解就未定义，这样的话，我们必须用奇异值分解代替。
回想一下，特征分解涉及分析一个矩阵$\boldsymbol{A}$，来发现特征向量的矩阵$\boldsymbol{V}$和特征值$\lambda$的向量，使得我们可以将$\boldsymbol{A}$重写为:
$$
\boldsymbol{A=V{\rm diag}{(\lambda)}V^{-1}}
$$
奇异值分解类似，这里我们将$\boldsymbol{A}$写作三个矩阵相乘：
$$
\boldsymbol{A=UDV^{\rm T}}
$$
假设$\boldsymbol{A}$是一个$m\times n$矩阵，那么$\boldsymbol{U}$就是一个$m\times m$矩阵，$\boldsymbol{D}$是$m\times n$矩阵，$\boldsymbol{V}$是$n\times n$矩阵。
这些矩阵都被定义成特定的结构。矩阵$\boldsymbol{U}$和$\boldsymbol{V}$都是正交矩阵，矩阵$\boldsymbol{D}$是对角矩阵，注意，$\boldsymbol{D}$没必要是方阵。
沿着$\boldsymbol{D}$对角线的元素叫做矩阵$\boldsymbol{A}$的奇异值。$\boldsymbol{U}$的列叫做左奇异向量，$\boldsymbol{V}$的列叫做右奇异向量。
事实上，我们可以将$\boldsymbol{A}$的奇异值分解解释为$\boldsymbol{A}$函数的特征分解。$\boldsymbol{A}$的左奇异向量是$\boldsymbol{A A^{\rm T}}$的特征向量 ，而$\boldsymbol{A}$的右奇异向量是$\boldsymbol{A^{\rm T}A}$的特征向量，$\boldsymbol{A}$的非零奇异值是$\boldsymbol{A^{\rm T}A}$特征值的平方根。$\boldsymbol{AA^{\rm T}}$同样如此。
SVD最有用的功能可能是部分地概括了非方阵的矩阵求逆，我们将在下一节中看到。

