
# 漫步数理统计三十三——采样与统计量 - 蜗牛 - CSDN博客


2017年06月21日 22:03:37[会敲键盘的猩猩](https://me.csdn.net/u010182633)阅读数：471


本篇博文介绍一些有用的推断工具：置信区间与假设检验。
在典型的统计问题中，我们对随机变量$X$感兴趣，但是对其pdf$f(x)$与pmf$p(x)$不知道，对此大致有两个类别：
f(x)或p(x)完全未知
f(x)或p(x)的形式已知，包含参数\theta，其中\theta可能是向量
目前考虑第二类问题，考虑几个这样的例子：
X满足指数分布，\exp(\theta)，其中\theta未知。
X满足二项分布b(n,p)，其中n已知但p未知。
X满足伽玛分布\Gamma(\alpha,\beta)，其中\alpha,\beta未知。
我们经常这样描述这样的问题，随机变量$X$满足形式为$f(x;\theta),p(x;\theta)$的密度或质量，其中$\theta\in\Omega$属于某个集合$\Omega$。例如上面的(1)，$\Omega=\{\theta|\theta>0\}$，我们称$\theta$为分布的参数，因为$\theta$是未知的，所以我们想估计它。我们首先讨论一些估计量的性质，随后再给出估计的常用方法。因为估计是基于样本的，故我们会形式化采样过程。
为了理解这个想法，考虑一个盒子中有$m$个球，出了标号为$1,\ldots,m$不同外其它都一样，我们随机选择一个球然后记下数字，令$X$表示该数字，那么$X$的分布为

$$
P(X=x)=\frac{1}{m},\ for\ x=1,\ldots,m
$$
考虑这种情况，盒子里有许多球但是我们不知道有多少，也就是$m$未知，那么那种情况下$\theta=m,\Omega$是正整数集合，为了得到$m$的信息，我们从球中取$n$个样本，表示为$\mathbf{X}=(X_1,\ldots,X_n)^\prime$，其中$X_i$表示第$i$个球的数字。
接下里我们介绍两种采样方法，分别为：
\textbf{有放回的采样}：我们随机选一个球记下数字后放回去，然后继续随机抽，得到的X_1,\ldots,X_n是互相独立的随机变量且分布相同，我们定义为随机样本。
\textbf{无放回的采样}：随意选n个球，如果一次选一个的话，每次选完后不放回。得到的X_1,\ldots,X_n不是独立的且每个X_i有相同的分布，这种采样类型常称为随机采样。
如果$m$远大于$n$，那么两种方法实际一样。
$\textbf{定义1：}$(随机样本)随机变量$X_1,\ldots,X_n$如果互相独立且有相同的分布，那么他们构成了随机变量$X$的随机样本，我们简述为$X_1,\ldots,X_n$是$\textbf{iid}$；即独立同分布。
令$F(x),f(x)$分别表示$X$的cdf与pdf，那么$X_1,\ldots,X_n$的联合cdf为

$$
F_{X_1,\ldots,X_n}(x_1,\ldots,x_n)=\prod_{i=1}^nF(x_i)
$$
而联合pdf为

$$
f_{X_1,\ldots,X_n}(x_1,\ldots,x_n)=\prod_{i=1}^nf(x_i)
$$
同样的方式可定义离散随机变量$X$，我们常使用向量符号来表示样本$\textbf{X}=(X_1,\ldots,X_n)^\prime$，接下来定义统计量。
$\textbf{定义2：}$(统计量)假设n$n$个随机变量$X_1,X_2,X_3,\ldots,X_n$是随机变量$X$分布中的一个样本，那么任何样本函数$T=T(X_1,\ldots,X_n)$称为统计量。
在高等课程中，我们将需要函数是博莱尔度量。
因为统计量是样本的函数，所以它也是随机变量，统计量经常是数据的总结，像统计量$T=T(X_1,\ldots,X_n)$可能包含未知参数$\theta$的信息，这时候我们称统计量是$\theta$的点估计量，回忆一下之前说过，如果$E(T)=\theta$，那么$T$是$\theta$的无偏估计，如果依概率$T\to\theta$，那么$T$是$\theta$的一致估计。一旦得到的随机样本，$X_1,\ldots,X_n$的观测为$x_1,\ldots,x_n$，那么值$T(x_1,\ldots,x_n)$称为$\theta$的点估计。那么什么是好的点估计呢？接下来我们讨论一些估计的性质，下面的实例给出了一些问题。
$\textbf{例1：}$还是考虑取球的例子，$m$个球标记为$1,\ldots,m$，假设$m$未知，为了估计$m$我们需要有放回的得到随机样本，每个$X_i$的分布为$P(X=x)=1/m,x=1,\ldots,m$，$m$的直观点估计量为$T=\max\{X_1,\ldots,X_n\}$，这就是$m$好的估计量，但是$T$与$m$有多远呢？一种方式是考虑$T$的分布，$T$的支撑为$\{1,\ldots,m\}$，为了确定$T$的cdf，注意因为$T$是$X$观测的最大时，所以事件$T\leq t$可以表示为

$$
\{T\leq t\}=\{X_1\leq t,\ldots,X_n\leq t\}=\cap_{i=1}^n\{X_i\leq t\}
$$
其中$1\leq t\leq m$，因此根据$X_1,\ldots,X_n$是独立同分布的，$T$的iid为

$$
P[T\leq t]=\prod_{i=1}^nP[X_i\leq t]=[P(X_1\leq t)]^n=\left(\frac{[t]}{m}\right)^n
$$
其中$[t]$表示小于等于$t$的最大整数，因此对于$0\leq t\leq m$

$$
P[T_n\leq t]=\left(\frac{[t]}{m}\right)^n\to\begin{cases}
0&t<m\\
1&t=m
\end{cases}
$$
因此$T_n\overset{D}\to m$，根据前面的定理可知$T_n\overset{P}\to m$，所以$T_n$是$m$的一致估计。
注意在这个问题中，$E(\bar{X})=(m+1)/2$，因此$E(2\bar{X}-1)=m$，其中$\bar{X}=n^{-1}\sum_{i=1}^nX_i$表示样本均值，也许$2\bar{X}-1$也是$m$的一个好的无偏估计量，如果这个满足的话，我们后面会说明$T$是更好的估计量。
$\textbf{例2：}$假设$X$是随机变量，未知参数为$\theta$，$X_1,\ldots,X_n$是$X$分布中得到随机样本，令$\bar{X}=n^{-1}\sum_{i=1}^nX_i$是样本均值，那么因为$E(\bar{X})=\theta$,所以统计量$\bar{X}$是$\theta$的无偏估计量，但是$\bar{X}$与$\theta$有多远呢？之后我们会介绍一般情况下的结论，目前先考虑特殊情况，假设$X$满足正态分布$N(\theta,\sigma^2)$且$\sigma^2$已知，那么$\bar{X}$的分布为$N(\theta,\sigma^2/n)$，然后就可以用$\bar{X}$分布的知识会到问题。因为$(\bar{X}-\theta)/(\sigma/\sqrt{n})$满足标准正态分布，$N(0,1)$，所以我们有

$$
\begin{align*}
0.954
&=P\left(-2<\frac{\bar{X}-\theta}{\sigma/\sqrt{\theta}}<2\right)\\
&=P\left(\bar{X}-2\frac{\sigma}{\sqrt{n}}<\theta<\bar{X}+2\frac{\sigma}{\sqrt{n}}\right)
\end{align*}
$$
上式表明，在采样以前，$\theta$落在随机区间$(\bar{X}-2\frac{\sigma}{\sqrt{n}},\bar{X}+2\frac{\sigma}{\sqrt{n}})$的概率为0.954，采完样之后，$\theta$可能落在实际区间

$$
\left(\bar{x}-2\frac{\sigma}{\sqrt{n}},\bar{x}+2\frac{\sigma}{\sqrt{n}}\right)
$$
也可能不在，但是因为有很高的概率落在区间内即0.954，所以区间为$\theta$的95.4\%置信区间，0.954=95.4\%称为置信系数。注意随着置信的增加，置信区间的长度也会增加，即增加置信意味着降低准确度，另一方面对于任意的置信系数，样本增加也会缩短置信区间。

