
# 配置hiveserver2访问hive - Magician的博客 - CSDN博客


2018年08月30日 10:03:19[春雨里de太阳](https://me.csdn.net/qq_16633405)阅读数：378标签：[配置																](https://so.csdn.net/so/search/s.do?q=配置&t=blog)[hiveserver2																](https://so.csdn.net/so/search/s.do?q=hiveserver2&t=blog)[hive																](https://so.csdn.net/so/search/s.do?q=hive&t=blog)[访问																](https://so.csdn.net/so/search/s.do?q=访问&t=blog)[beeline																](https://so.csdn.net/so/search/s.do?q=beeline&t=blog)[
							](https://so.csdn.net/so/search/s.do?q=访问&t=blog)[
																					](https://so.csdn.net/so/search/s.do?q=hive&t=blog)个人分类：[Hive																](https://blog.csdn.net/qq_16633405/article/category/7234365)
[
																								](https://so.csdn.net/so/search/s.do?q=hive&t=blog)
[
				](https://so.csdn.net/so/search/s.do?q=hiveserver2&t=blog)
[
			](https://so.csdn.net/so/search/s.do?q=hiveserver2&t=blog)
[
		](https://so.csdn.net/so/search/s.do?q=配置&t=blog)
[目录：](#目录)[1、前言](#1前言)
[2、beeline相关的Server.Thrift配置](#2beeline相关的serverthrift配置)
[3、启动beeline并访问Hive](#3启动beeline并访问hive)
[4、期间遇到的问题和解决方法](#4期间遇到的问题和解决方法)


# 目录：
## 1、前言
作为数据仓库的工具，hive提供了两种ETL运行方式，分别是通过Hive 命令行和beeline客户端；
命令行方式即通过hive进入命令模式后通过执行不同的HQL命令得到对应的结果；相当于胖客户端模式，即客户机中需要安装JRE环境和Hive程序。
beeline客户端方式相当于瘦客户端模式，采用JDBC方式借助于Hive Thrift服务访问Hive数据仓库。
HiveThrift(HiveServer)是Hive中的组件之一，设计目的是为了实现跨语言轻量级访问Hive数据仓库，有Hiveserver和 Hiveserver2两个版本，两者不兼容，使用中要注意区分。体现在启动HiveServer的参数和jdbc:hiveX的参数上。
## 2、beeline相关的Server.Thrift配置
主要是hive/conf/hive-site.xml中hive.server2.thrift相关的一些配置项，但要注意一致性。
```python
<
```
```python
property
```
```python
>
```
```python
<
```
```python
name
```
```python
>
```
```python
hive.server2.thrift.bind.host
```
```python
</
```
```python
name
```
```python
>
```
```python
<
```
```python
value
```
```python
>
```
```python
ha1
```
```python
</
```
```python
value
```
```python
>
```
```python
<
```
```python
description
```
```python
>
```
```python
Bind host on which to run the HiveServer2 Thrift service.
```
```python
</
```
```python
description
```
```python
>
```
```python
</
```
```python
property
```
```python
>
```
```python
<
```
```python
property
```
```python
>
```
```python
<
```
```python
name
```
```python
>
```
```python
hive.server2.thrift.port
```
```python
</
```
```python
name
```
```python
>
```
```python
<
```
```python
value
```
```python
>
```
```python
10000
```
```python
</
```
```python
value
```
```python
>
```
```python
<
```
```python
description
```
```python
>
```
```python
Port number of HiveServer2 Thrift interface when hive.server2.transport.mode is 'binary'.
```
```python
</
```
```python
description
```
```python
>
```
```python
</
```
```python
property
```
```python
>
```
进入beeline连接数据库后，因为要访问的文件在HDFS上，对应的路径有访问权限限制，所以，这里要设成hadoop中的用户名，实例中用户名即为’root’(看你用什么用户来启动hadoop的)。如果使用其它用户名，可能会报权限拒绝的错误。或通过修改hadoop中的配置项hadoop.proxyuser.ＸＸ为“*”　来放宽用户名和权限，如示例。
hadoop/etc/hadoop/core-site.xml
```python
<
```
```python
property
```
```python
>
```
```python
<
```
```python
name
```
```python
>
```
```python
hadoop.proxyuser.hadoop.hosts
```
```python
</
```
```python
name
```
```python
>
```
```python
<!--value>master</value-->
```
```python
<
```
```python
value
```
```python
>
```
```python
*
```
```python
</
```
```python
value
```
```python
>
```
```python
</
```
```python
property
```
```python
>
```
```python
<
```
```python
property
```
```python
>
```
```python
<
```
```python
name
```
```python
>
```
```python
hadoop.proxyuser.hadoop.groups
```
```python
</
```
```python
name
```
```python
>
```
```python
<!--value>hadoop</value-->
```
```python
<
```
```python
value
```
```python
>
```
```python
*
```
```python
</
```
```python
value
```
```python
>
```
```python
</
```
```python
property
```
```python
>
```
## 3、启动beeline并访问Hive
slave01上启动hiveserver2,
```python
nohup hive --service hiveserver2 & 
nohup hiveserver2
```
```python
1
```
```python
>
```
```python
/root/apps
```
```python
/hive-2.1.1/logs
```
```python
/hiveserver.log 2>/root
```
```python
/apps/hive
```
```python
-
```
```python
2.1
```
```python
.
```
```python
1
```
```python
/logs/hiveserver.err &（将hivesever的日志导入对应的目录）
```
```python
ps -ef
```
```python
| grep Hive
```
能看到Hiveserver2已启动
master机器上执行beeline并访问hive
```python
root@master:~/bigdata/hive$ beeline
Beeline version
```
```python
1.2
```
```python
.1
```
```python
.
```
```python
spark2
```
```python
by
```
```python
Apache Hive
beeline
```
```python
>
```
```python
beeline
```
```python
>
```
```python
!
```
```python
connect jdbc:hive2:
```
```python
//ha1:10000       // 2中配置项的host:port ，因为启动的是hiveserver2，所以参数中是hive2
```
```python
Connecting
```
```python
to
```
```python
jdbc:hive2:
```
```python
//ndh-ha1:10000
```
```python
Enter username for jdbc:hive2:
```
```python
//ndh-ha1:10000: root
```
```python
Enter password for jdbc:hive2:
```
```python
//ndh-ha1:10000: ****        //2中配置项的user/password
```
```python
17
```
```python
/
```
```python
09
```
```python
/
```
```python
08
```
```python
14
```
```python
:
```
```python
39
```
```python
:
```
```python
27
```
```python
INFO jdbc
```
```python
.
```
```python
Utils: Supplied authorities: ndh
```
```python
-slave01
```
```python
:
```
```python
10000
```
```python
17
```
```python
/
```
```python
09
```
```python
/
```
```python
08
```
```python
14
```
```python
:
```
```python
39
```
```python
:
```
```python
27
```
```python
INFO jdbc
```
```python
.
```
```python
Utils: Resolved authority: ndh
```
```python
-slave01
```
```python
:
```
```python
10000
```
```python
17
```
```python
/
```
```python
09
```
```python
/
```
```python
08
```
```python
14
```
```python
:
```
```python
39
```
```python
:
```
```python
27
```
```python
INFO jdbc
```
```python
.
```
```python
HiveConnection: Will try
```
```python
to
```
```python
open client transport
```
```python
with
```
```python
JDBC Uri: jdbc:hive2:
```
```python
//ha1:10000
```
```python
Connected
```
```python
to
```
```python
: Apache Hive (version
```
```python
2.1
```
```python
.1
```
```python
)
Driver: Hive JDBC (version
```
```python
1.2
```
```python
.1
```
```python
.
```
```python
spark2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
```
```python
0
```
```python
: jdbc:hive2:
```
```python
//ha1:10000>
```
```python
0
```
```python
: jdbc:hive2:
```
```python
//slave01:10000> show databases;
```
```python
+----------------+--+
```
```python
|
```
```python
database_name
```
```python
|
```
```python
+----------------+--+
```
```python
|
```
```python
default
```
```python
|
```
```python
|
```
```python
feigu3
```
```python
|
```
```python
|
```
```python
wordcount
```
```python
|
```
```python
+----------------+--+
```
```python
3
```
```python
rows
```
```python
selected (
```
```python
0.379
```
```python
seconds)
```
```python
0
```
```python
: jdbc:hive2:
```
```python
//slave01:10000> select * from wordcount order by count desc limit 50;
```
```python
...
```
```python
...
```
```python
...
```
```python
...
```
```python
...
```
```python
...
```
```python
...
```
```python
...
```
```python
...
```
```python
...
```
```python
...
```
```python
...
```
```python
...
```
```python
...
```
```python
..
```
```python
...
```
```python
...
```
```python
...
```
```python
...
```
```python
...
```
```python
...
```
```python
...
```
```python
...
```
```python
...
```
```python
...
```
```python
...
```
```python
...
```
```python
...
```
```python
...
```
```python
...
```
```python
看到结果后，进入hadoop yarn
http:
```
```python
//master:8088/cluster/apps/FINISHED　可看到刚执行的任务。
```
```python
0
```
```python
: jdbc:hive2:
```
```python
//slave01:10000> !q　　　　//// 退出beeline
```
## 4、期间遇到的问题和解决方法
4.1    hadoop is not allowed to impersonate hive // hadoop是hadoop中配置的用户名，解决方法见２中说明；
具体的原因见：[https://blog.csdn.net/qq_16633405/article/details/82190440](https://blog.csdn.net/qq_16633405/article/details/82190440)
转自：[https://blog.csdn.net/wqhlmark64/article/details/77894026](https://blog.csdn.net/wqhlmark64/article/details/77894026)

