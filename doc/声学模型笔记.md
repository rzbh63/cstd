# 声学模型笔记



# （一） HMM

2016年10月08日 19:45:48 [xmucas](https://me.csdn.net/xmdxcsj) 阅读数：2944



**“声学模型学习笔记”是《automatic speech recognition a deep learning approach》这本书的读书笔记，会有少量的个人理解和公式详细推导，声学入门狗一枚，不具有指导意义，具体以原书和列出的参考文献为准，欢迎指导和讨论。**

## HMM含义

### Markov Chains

[马尔科夫链](https://en.wikipedia.org/wiki/Markov_chain)，表示一个状态到另一个状态转换的随机过程。该过程要求具备“无记忆”的性质：下一状态的概率分布只能由当前状态决定，在时间序列中它前面的事件均与之无关。这种特定类型的“无记忆性”称作**马尔可夫性质**。 
假设状态空间$q_t\in{s^{(j)}, j=1,2,...,N}$，马尔科夫性质可以表示如下： 
$$
P(q_{t+1}=s^{({t+1})}|q_{0}=s^{0},...,q_t=s^t)=P(q_{t+1}=s^{({t+1})}|q_t=s^t)
$$
转移概率可以定义如下：
$$
P(q_t=s^{j}|q_{t-1}=s^i)=a_{ij}(t), i,j=1,2,...,N
$$
如果转移概率跟t无关，只由i和j决定，那么说马尔科夫链是齐次（homogeneous）的，转移概率矩阵可以写成一下形式：
$$
A=[a_{ij}], where a_{ij}\ge 0, \forall i,j;and \sum_{j=1}^{N}a_{ij}=1, \forall i
$$

### Hidden Markov Sequences

马尔科夫链关注的状态转移概率。比如天气的三个状态分别是{sun, cloud, rain}，状态转移概率矩阵如下： 
$$
\begin{matrix}
     & sun & cloud & rain\\
  sun & 0.50 & 0.375 & 0.125 \\
  cloud & 0.25 & 0.125 & 0.625 \\
  rain & 0.25 & 0.375 & 0.375
 \end{matrix}
$$
马尔科夫链求解的问题是：如果今天晴天(sun)，后天下雨(rain)的概率。

 马尔科夫链的观察序列和状态序列是一一对应的，具有确定性（比如今天是sun，那么sun的概率将会是1，不可能为cloud或者rain），从而导致马尔科夫链很难去拟合有些现实问题。

 为了增加马尔科夫链的随机性，对每一个状态，增加一个观察值的生成概率函数，即为隐马尔科夫序列。使用隐马尔科夫序列去建模解决实际问题，称为Hidden Markov model（HMM）。

 同样以上面的例子来讲，比如在封闭的小黑屋里面，无法观察到天气状况，但是小黑屋里面有种的水藻，水藻的状态和天气的存在一定的概率关系，如下：
$$
\begin{matrix}
     & dry & dryish & damp & soggy \\
  sun & 0.60 & 0.20 & 0.15 & 0.05 \\
  cloud & 0.25 & 0.25 & 0.25 & 0.25 \\
  rain & 0.05 & 0.10 & 0.35 & 0.50
 \end{matrix}
$$
此时，我们可以把天气状况当成隐状态，把水藻的状况当成观察值，通过观察值来预测隐状态（天气状态）的序列，马尔科夫链转变成为隐马尔科夫模型。

 不难隐马尔科夫模型有两方面的随机性：底层隐藏的随时间改变的马尔科夫过程（天气状态的变化过程）；与隐藏状态存在某种映射关系的可观察状态集合（天气状态和水藻状态的关系）。



## HMM公式

假设状态序列$q_{1}^{T}=(q_1,...,q_T)$，观察序列$o_1^T=(o_1,...,o_T)$，hmm的三要素$\lambda=(A,B,\pi)$： 
\- 转移概率$A=[a_{ij}]$ 
\- 初始状态概率分布$\pi = [\pi_{i}]$ 
\- 观察概率$B=[b_i(k)]$:状态i生成观察值$v_k$的概率

hmm需要解决的三个问题 
\- 概率计算问题：已知λ和$o_1^T$，求解$P(o_1^T|\lambda)$ 
\- 学习问题：已知$o_1^T$和$q_{1}^{T}$，求解λ 
\- 预测问题：已知λ和$o_1^T$，求解概率最大的$(q_{1}^{T})​$

### 问题一：为问题二的求解打基础

观察概率用混合高斯建模，可以表示如下： 
$$
b_i(o_t)=\sum_{m=1}^{M}\frac{c_{i,m}}{(2\pi)^{D/2}|\sum_{i,m}|^{1/2}}exp[-\frac{1}{2}(o_t-\mu_{i,m})^T\sum_{i,m}^{-1}(o_t-\mu_{i,m})]
$$
其中i表示状态下标，m表示高斯分量的下标。 
1.似然概率： 
$$
P(o_1^T|q_1^T)=\prod_{t=1}^{T}\sum_{m=1}^{M}\frac{c_{i,m}}{(2\pi)^{D/2}|\sum_{i,m}|^{1/2}}exp[-\frac{1}{2}(o_t-\mu_{i,m})^T\sum_{i,m}^{-1}(o_t-\mu_{i,m})]
$$
2.状态概率 
$$
P(q_1^T)=\pi_{q_1}\prod_{t=1}^{T-1}a_{q_tq_{t+1}}
$$
3.联合概率 
$$
P(o_1^T, q_1^T)=P(o_1^T|q_1^T)P(q_1^T)
$$
4.观察概率 
$$
P(o_1^T)=\sum_{q_1^T}P(o_1^T,q_1^T)
$$
随着T的增大，穷举状态序列$q_1^T$将会指数增加，$P(o_1^T)$求解的复杂度也会指数增加，考虑引入前后向算法解决$P(o_1^T)$的求解问题。

#### 1.前向变量

前向概率定义为从开始到t时刻状态i的所有路径的概率和，定义如下： 
$$
\alpha_t(i)=P(q_t=i,o_1^t),t=1,...,T
$$
初值：$\alpha_1(i)=\pi_ib_i(o_1)​$
递推关系：$\alpha_t(j)=\sum_{i=1}^{N}\alpha_{t-1}(i)a_{ij}b_j(o_t), t=2,3,...,T​$
终止：$P(o_1^T)=\sum_{i=1}^N\alpha_T(i)​$

#### 2.后向变量

后向概率定义为从t时刻状态i点出发到结尾的所有路径概率和，定义如下： 
$$
\beta_t(i)=P(o_{t+1}^T|q_t=i),t=1,...,T-1
$$
初值：$\beta_T(i)=1​$
递推关系：$\beta_t(i)=\sum_{j=1}^{N}\beta_{t+1}(i)a_{ij}b_j(o_{t+1}), t=1,2,...,T-1​$
终止：$P(o_1^T)=\sum_{i=1}^N\pi_ib_i(o_1)\beta_1(i)​$

参考[3]，不难得出以上关系。 
t时刻处在状态i的概率可以用前后向变量表示如下： 
$$
P(q_t=i, o_1^T)=\alpha_t(i)\beta_t(i)
$$
从而可以达到我们的终极目标，求解： 
$$
P(O_1^T)=\sum_{i=1}^{N}\alpha_t(i)\beta_t(i)
$$
**前后向算法的基本原理是利用递推关系，复用了中间的变量，减少了重复计算。不需要穷举所有的路径就可以完成P(OT1)P(O1T)的求解。**

#### 3.中间变量

两个变量（后面的EM会用到）定义如下： 
t时刻处于状态$q_i$的概率：$\gamma_t(i)=\frac{\alpha_t(i)\beta_t(i)}{\sum_{j=1}^N \alpha_t(j)\beta_t(j)}$
t时刻处在状态$q_i$并且t+1时刻处在qjqj的概率：$\xi_t(i,j)=\frac{\alpha_t(i)a_{ij}b_j(o_{t+1})\beta_{t+1}(j)}{\sum_{i=1}^N \sum_{j=1}^N\alpha_t(i)a_{ij}b_j(o_{t+1})\beta_t(j)}$

### 问题二：求解hmm的参数

首先参考[3]，简单介绍EM算法： 
EM是expectation-maximization的简称，是一种最优化问题的迭代算法，1977年由Dempster等人总结提出，简介参考[之前的博文](http://blog.csdn.net/xmdxcsj/article/details/48809537) 
目标函数采用极大似然估计，极大化观测数据YY关于参数θθ的对数似然函数 
$$
L_{max}(\theta)=log P(Y|\theta)=log \sum_Z P(Y,Z|\theta)=log(\sum_Z P(Y|Z,\theta)P(Z|\theta))
$$
由于含有隐变量$Z$，所以没有解析解，只能通过迭代的方式求解。假设第i次迭代以后模型参数为$θ_i$，我们希望满足$L(θ)>L(θ_i)$，即每一次迭代都使得似然函数变大，慢慢逼近极大值点，即：

$$
L(\theta)- L(\theta^i) \gt 0\\
L(\theta)- L(\theta^i)=log(\sum_Z P(Y|Z,\theta)P(Z|\theta))-logP(Y|\theta^i)\\
=log(\sum_Z P(Z|Y,\theta^i) \frac{P(Y|Z,\theta)P(Z|\theta)} {P(Z|Y,\theta^i)})-logP(Y|\theta^i)
$$
Jenssen不等式

满足：

$$
log\sum_j \lambda_j y_j \ge \sum_j \lambda_j log y_i,其中\lambda_i\ge 0, \sum_j \lambda_j=1
$$
所以
$$
L(\theta)- L(\theta^i)\ge \sum_Z P(Z|Y,\theta^i) log\frac{P(Y|Z,\theta)P(Z|\theta)} {P(Z|Y,\theta^i)}-logP(Y|\theta^i)\\
=\sum_Z P(Z|Y,\theta^i) log\frac{P(Y|Z,\theta)P(Z|\theta)} {P(Z|Y,\theta^i)P(Y|\theta^i)}
$$
定义$L(θ)$的下限

$$
B(\theta, \theta^i)=L(\theta^i) + \sum_Z P(Z|Y,\theta^i) log\frac{P(Y|Z,\theta)P(Z|\theta)} {P(Z|Y,\theta^i)P(Y|\theta^i)}
$$
满足

$$
L(\theta) \ge  B(\theta, \theta^i)\\
L(\theta^i)=B(\theta^i, \theta^i)
$$
在$θ^i​$点，$L(θ)​$和$B(θ,θ^i)​$两个曲线相交，其他点$L(θ)​$曲线在$B(θ,θ^i)​$曲线的上方，如下图：

 ![这里写图片描述](https://img-blog.csdn.net/20161008194713110)



为了获得更接近L(θ)的极大值点，使用$B(θ,θ^i)$对应的极大值点作为$θ^{i+1}$，当然不能保证此时的$θ^{i+1}$是$L(θ)$的极大值点，如上图所示。

$$
\theta^{i+1}=argmax_{\theta}(B(\theta, \theta^i))
$$
忽略一些不含θ的项，可得 

$$
\theta^{i+1}=argmax_{\theta}Q(\theta, \theta^i)
$$
其中Q函数：

$$
Q(\theta, \theta^i)=\sum_Z P(Z|Y,\theta^i) log{P(Y,Z|\theta)}
$$
Q函数的数学意义其实就是$log{P(Y,Z|\theta)}$在已知Y和$θ^i$条件下关于隐变量$Z$的均值，即 

$$
Q(\theta, \theta^i)=\sum_Z P(Z|Y,\theta^i) log{P(Y,Z|\theta)}=E_Z[ log{P(Y,Z|\theta)} | Y,\theta^i])
$$
**E步的含义是构造$log{P(Y,Z|\theta)}$在已知Y和$θ^i$条件下关于隐变量ZZ的均值函数（物理意义是找出L(θ)的下限函数），即为Q函数。M步的含义是对E步构造出的均值函数求极大值，以期望最大程度上逼近L(θ)函数的极大值。**

 考虑到HMM求解的时候涉及到隐变量$q_t$即某一帧特征属于哪个状态是位置的，所以采用Baum-Welch(EM算法)来进行求解。

 完全数据集定义为$y=[o_1^T,q_1^T]$，由观测变量$o_1^T$和隐变量$q_1^T$状态序列共同构成，单高斯的HMM的模型参数$\theta=[a_{ij}, \sum_i, \mu_i]$，由状态的转移概率、高斯均值和方差组成。

 E步：首先构造Q函数

$$
Q(\theta, \theta_0)=\sum_{q_1^T}P(q_1^T|o_1^T,\theta_0)logP(o_1^T,q_1^T|\theta)
$$
M步：然后Q函数分别构造拉格朗日函数，对模型参数$\theta=[a_{ij}, \sum_i, \mu_i]$求导等于0，可得最后的参数（自己没有推导出来，直接上结果吧）

 \- 转移概率

$$
\hat{a}_{ij}=\frac{\sum_{t=1}^{T-1}\xi_t(i,j)}{\sum_{t=1}^{T-1}\gamma_t(i)}
$$
\- 方差

$$
\hat{\sum}_i=\frac{\sum_{t=1}^T \gamma_t(i)(o_t-\hat{\mu}_i)(o_t-\hat{\mu}_i)^T }{\sum_{t=1}^T \gamma_t(i)}
$$
\- 均值

$$
\hat{\mu}_i=\frac{\sum_{t=1}^T \gamma_t(i)o_t}{\sum_{t=1}^T \gamma_t(i)}
$$


### 问题三：求解最优状态序列

对应于解码，动态规划的思想，比较简单。

## HMM局限性

- the temporal independence of speech data conditioned on each HMM state 
  HMM观察独立性假设，任意时刻的观察只依赖于该时刻的马尔科夫链的状态，与其他观测和状态无关
- lack of lawful correlation between the acoustic features 
  高斯的方差是用的对角阵，假设特征维度之间是相互独立的

## 参考文献

[1]《automatic speech recognition a deep learning approach》 chapter2-3 
[2][HMM理解例子](http://www.52nlp.cn/hmm-learn-best-practices-one-introduction) 
[3]《统计学习方法》 李航 第10章







# （二） DNN





## training

![这里写图片描述](https://img-blog.csdn.net/20161008195041504)

### training criteria

1.MSE 
对于回归任务，可以使用MSE（mean square error）准则: 
$$
J_{MSE}(W,b;o,y)=\frac{1}{2}(v^L-y)^T(v^L-y)
$$
y表示标注结果，v表示预测结果 

2.CE

 对于分类任务，可以使用CE（cross-entropy）准则:
$$
J_{CE}(W,b;o,y)=-\sum_{i=1}^Cy_ilogv_i^L
$$
3.NLL

 对于输出概率只有对应标注的为1，其他的概率都是0，所以CE可以简化为NLL(negative log-likilihood)准则：
$$
J_{NLL}(W,b;o,y)=-logv_c^L
$$
其中c表示标注的类别。



### bp training

假设使用CE准则，层数为$l=1,2,...,L$，每一层线性转化以后的输出为$z_t^l=W_t^l*v_t^{l-1}+b_t^l$，非线性转化以后的输出为$v_t^l$，误差为$e_t^l$. 
BP推导比较简单，直接结果如下： 
1.对于L层（最后一层） 
$$
\Delta _{W_t^L}J_{CE}(W,b;o,y)=\Delta _{z_t^L}J_{CE}(W,b;o,y)\frac{\partial z_t^L}{\partial W_t^L}=(v_t^L-y)(v_t^{L-1})^T\\
\Delta _{b_t^L}J_{CE}(W,b;o,y)=(v_t^L-y)
$$
2.其他层
$$
\Delta _{W_t^l}J_{CE}(W,b;o,y)=[f'(z_t^l) \bullet e_t^l](v_t^{l-1})^T\\
\Delta _{b_t^l}J_{CE}(W,b;o,y)=f'(z_t^l) \bullet e_t^l
$$
其中误差$e_t^l$如下：
$$
e_t^{L-1}=(W_t^L)^Te_t^L\\
e_t^{l-1}=(W_t^l)^T[f'(z_t^l) \bullet e_t^l]
$$

## tricks

### data preprocessing

对于训练集$(o^m,y^m) ,0\le m \lt M$，首先根据训练集计算均值和方差： 
$$
\mu_i=\frac{1}{M}\sum_{m=1}^Mo_i^m\\
\delta_i=\sqrt{\frac{1}{M}\sum_{m=1}^M(o_i^m-\mu_i)^2}
$$
然后训练集和测试集进行归一化：
$$
\tilde{o}_i^m=\frac{o_i^m-\mu_i}{\delta_i}
$$
当特征的各个维度在同样的数值范围值归一化以后，可以进行更好的训练。



### initialization

可以使用均值为0、方差为$\delta_{W^{l+1}=\frac{1}{\sqrt{N_l}}}$的高斯分布，其中$N_l$表示连接到这个节点的入边个数。 
也可以使用RBM、DBM、autodecoder等高级方法进行模型初始化。

### weight decay

为了解决过拟合问题引入[正则化](http://blog.csdn.net/xmdxcsj/article/details/50286705)

### dropout

[dropout](http://blog.csdn.net/xmdxcsj/article/details/50286673)也是为了解决过拟合问题引入。

### batch size

使用梯度下降的训练方法包括BGD/SGD/MBGD三种形式，三者的关系[这片博客](http://www.cnblogs.com/maybe2030/p/5089753.html)写的比较清楚。 
BGD：更新一次参数使用全部训练集；目标函数是整体风险最小，收敛于全局最优；但是训练集较大的时候存在训练速度慢的问题。 
[SGD](https://en.wikipedia.org/wiki/Stochastic_gradient_descent)：更新一次参数使用一个训练数据；目标函数是单个样本风险最小（容易引入noise，反而有利于跳出局部最优），收敛于局部最优，当满足一定条件，可以接近全局最优；训练速度快(参数更新快)；不容易并行，而且会在最小值附近震荡。 
MBGH：更新一次参数使用minibatch的数据；介于BGD和SGD之间，方便并行；开始使用较小的batch size，后面使用较大的batch size

### sample randomization

BGD不受影响，SGD和MBGD需要使用，如果训练数据的随机采样做的不好的话（比如都是同一个人的语音），会导致模型训练沿着特定的方向严重走偏。

### momentum

如果当前模型参数的更新，不仅使用当前的梯度，还包含里之前梯度的信息（具备了全局的视角），那么收敛速度将会加快。引入了动量技术，梯度表示为： 
$$
\Delta W_t^l=\rho \Delta b_{t-1}^l+(1-\rho)\frac{1}{M_b}\sum_{m=1}^{M_b}\nabla_{W_t^l}J(W,b;o^m,y^m)
$$
其中$ρ$成为动量因子，使用SGD或者MBGD的时候，一般取值0.9-0.99。



### learning rate

开始较大，后面减小

### reproducibility and restartability

使用同样的random seed保证可以复现 
使用check-point，可以中断以后接着上次的结果继续训练

## 参考文献

《automatic speech recognition a deep learning approach》 chapter 4





# （三） DNN-HMM hybrid system





## architecture

![这里写图片描述](https://img-blog.csdn.net/20161008195355115) 
声学信号使用HMM框架建模，每个状态的生成概率使用DNN替换原来的GMM进行估计，DNN每个单元的输出表示状态的后验概率。

## decoding

实际的语音识别解码的时候使用的是似然概率： 
$$
\hat{w}=argmax_{w}p(w|x)=argmax_{w}p(x|w)p(w)/p(x)=argmax_wp(x|w)p(w)
$$
其中声学部分概率为$p(x|w)$，使用的是似然概率。

所以需要将DNN输出的后验概率转化为似然概率：
$$
p(x_t|q_t=s)=p(q_t=s|x_t)*p(x_t)/p(s)
$$
$p(x_t)$表示观察值的概率，跟词序列无关可以忽略。

$p(s)$表示状态的先验概率，可以使用训练语料的频率统计近似。实际使用时的先验概率有时无关紧要，但是可以缓解训练语料的标注偏移问题（比如训练语料包含大量的silience，从而导致silience的后验概率偏大）。

 最终的声学概率表示如下：
$$
p(x|w)=\sum_{q}p(x|q,w)p(q|w)\approx max\pi(q_0)\prod_{t=1}^Ta_{q_{t-1}q_{t}}\prod_{t=0}^Tp(q_t|x_t)/p(q_t)
$$

## training

流程如下： 
\- 训练CD-GMM-HMM 
\- 使用CD-GMM-HMM对训练语料进行维特比解码，强制对齐特征和状态 
\- dnn训练

dnn训练使用的准则是基于后验概率，而hmm训练的准则是基于似然概率。

## tricks

### 1.隐层个数 

隐层越多（具有更强的函数拟合能力），效果越好，超过9层基本饱和。 

### 2.contextual window 

一般使用左右相邻的特征拼接起来作为dnn的输入，一般9-13帧。 
在HMM中，有观察独立性假设（任意时刻的观测至于该时刻的状态有关，与其他观测和状态无关）： 
$$
logp(o_{t_n},...,o_{t_{n+1}-1}|s_n)\approx \sum_{t=t_n}^{t_{n+1}-1}[log(p(o_t|s_n)]
$$
实际上相邻帧是存在一定关系的，并不是完全独立的：
$$
logp(o_{t_n},...,o_{t_{n+1}-1}|s_n)=\sum_{t=t_n}^{t_{n+1}-1}[log(p(o_t|s_n,o_{t_n},...,o_{t-1})]
$$
DNN的拼帧方法在一定程度上减弱了HMM的独立性假设，更符合实际关系。

### 3.对senones建模

使用cd-phone的状态比使用monophone的state建模效果更好。

### 4.pretraining

层数小于5的时候pretraining比较重要；当层数增加以后，pretraining收益变小，但是pretraining可以保证训练的鲁棒性，避免比较糟糕的参数初始化。

### 5.better alignment

更好的模型可以获得更准确的alignment，除了使用GMM-HMM的模型进行对齐，还可以使用DNN-HMM模型对训练数据进行对齐。



## 参考文献

《automatic speech recognition a deep learning approach》 chapter 6







# （四） dnn speedup





## training

### minibatch

一般设为256-1024.太小会导致更新参数频繁，降低GPU的计算效率；太大会导致训练需要更多的训练迭代数。

### piplined bp

将模型按层分割，然后分配到不同的GPU机器上面，实现训练的并行。例如下图 
![这里写图片描述](https://img-blog.csdn.net/20161008195535481)
一帧数据依次经过三个GPU的前向计算，然后在依次进行后向传播。图中的时刻： 
\- GPU1处理n的前向计算和n-5的bp计算 
\- GPU2处理n-1的前向计算和n-4的bp计算 
\- GPU3处理n-2的前向计算和n-3的bp计算

考虑到参数更新的时延性，GPU上面先进行后向更新，在进行前向计算。参数更新越在lower layer，时延越长，最后一层没有时延。 
如果GPU的数量少于层数，可以将多层分到一个GPU，此时需要考虑到计算量的balance问题，因为一般最后一层（输出维度较高）计算量比其它层要大。

### Asynchronous SGD

首先在CPU集群上面提出的 
\- parameter server pool（多个机器，每个机器有一部分的模型参数）作为master，master将模型参数发送给slaves 
\- 多个slave，每个slave包含多个机器（每个机器有一部分的模型参数，一个slave包含完整的模型数据），每个slave对应训练集的一个subset，计算minibatch的梯度然后发送给master

ASGD也可以用在GPU机器上面，主机上的CPU作为master，GPU作为slave。由于GPU的使用以及GPU和CPU之间通信（PCIe bus）的优势，这种训练方式比CPU集群高效。同时GPU和CPU之间的通信也会成为瓶颈，所以GPU上面可以累计多个minibatch和CPU通信一次，此时需要降低学习率。

### ALMs

对于多GPU（大于4）的情况，由于延时更新的问题，ASGD或者pipelined BP都有一定的局限性，可以考虑使用ALMs方法（Augmented Lagrangian Methods）。

### reduce model size

使用low-rank factorization降低模型参数，例如SVD。

## decoding

### parallel computation

- CPU支持SIMD指令级并行，SSE2/SSSE3/SSE4
- batch处理，一次输入多帧特征，向量*矩阵可以转化为矩阵*矩阵，获得更好的优化
- lazy evaluation，每一帧数据的25%-35%的输出会有用，所以可以lazy计算最后一层的输出。

### sparse network

实际DNN的参数中，有很大一部分的数值很小，比如有人统计70%的权重小于0.1。所以可以将这些权重小的边砍掉，获得一个稀疏网络。 
网络被稀疏以后还需要重新进行训练

### low-rank approximation

对于lower layer，使用low-rank对结果影响比较大。同样，参数矩阵做过SVD以后，还需要重新训练。 
实验表示，保留30%的模型大小，基本对性能没有影响。

### teach small DNN with large DNN

使用large DNN的输出作为标注，训练small DNN，以期望small DNN和large DNN的输出一致，达到同样的性能。

### multiframe DNN

解码的时候计算dnn得分可以复制使用上一帧的得分，以减少计算，称为frame-asynchronous DNN。 
还有一种方式称为MFDNN（multiframe DNN），不再是简单的复制得分，而是一个DNN对应多个输出的softmax输出层，这样就可以减少隐层的计算，一帧的输入，一次前向就能得到多帧的输出结果。 
MFDNN的性能比asynchronous DNN好。

## 参考

《automatic speech recognition a deep learning approach》 chapter 7









# （五） SDT(MMI/BMMI/MPE/sMBR)

DNN训练使用的CE准则是基于每一帧进行分类的优化，最小化帧错误率，但是实际上语音识别是一个序列分类的问题，更关心的是序列的准确性。所以引入SDT(sequence-discriminative training)，训练准则更符合实际，有利于提升识别率。常用的准则包括MMI/BMMI、MPE、MBR等。

| 准则     | 目标函数    |
| -------- | ----------- |
| CE       | 帧错误率    |
| MMI/BMMI | 句子正确率  |
| MPE      | phone错误率 |
| sMBR     | 状态错误率  |

## MMI

MMI(maximum mutual information)准则最大化观察序列分布和word序列分布之间的互信息，减小句子错误率。 
假设观察序列$o^m=o_1^m,...,o_{T_m}^m$，word序列$w^m=w_1^m,...,w_{N_m}^m$，其中m表示utterance，$T_m$表示帧数，$N_m$表示word个数。训练集为$S=\{(o^m,w^m)|0\le m\le M\}$，MMI准则可以表示如下: 
$$
J_{MMI}(\theta;S)=\sum_{m=1}^MJ_{MMI}(\theta;o^m,w^m)=\sum_{m=1}^MlogP(w^m|o^m;\theta)\\
=\sum_{m=1}^Mlog\frac{p(o^m|s^m;\theta)^kP(w^m)}{\sum_w p(o^m|s^w;\theta)^k P(w)}
$$
其中k表示acoustic scale，θ表示模型参数，$s^m$表示状态序列。物理意义可以理解为：分子表示准确结果对应路径的总得分（声学和语言），分母表示所有路径对应的得分总和（为了计算上的可操作性，实际用lattice简化表示）。模型参数的梯度可以表示如下：
$$
\nabla{J_{MMI}(\theta;o^m,w^m)}=\sum_m\sum_t \nabla_{z_{mt}^L}{J_{MMI}(\theta;o^m,w^m)} \frac{\partial z_{mt}^L}{\partial \theta}=\sum_m\sum_t \ddot{e}_{mt}^L\frac{\partial z_{mt}^L}{\partial \theta}
$$
其中$z_{mt}^L$表示softmax层的输入（没有做softmax运算），跟CE准则的不同体现在$\ddot{e}_{mt}^L$，进一步计算如下:
$$
\ddot{e}_{mt}^L(i)=\nabla_{z_{mt}^L(i)}{J_{MMI}(\theta;o^m,w^m)}\\
=\sum_r \frac{\partial J_{MMI}(\theta;o^m,w^m)}{\partial logp(o_t^m|r)}\frac{\partial logp(o_t^m|r)}{\partial z_{mt}^L(i)}
$$


### 第一部分

$$
\frac{\partial J_{MMI}(\theta;o^m,w^m)}{\partial logp(o_t^m|r)}\\
=\frac{\partial log\frac{p(o^m|s^m)^kP(w^m)}{\sum_w p(o^m|s^w)^k P(w)}}{\partial logp(o_t^m|r)}\\
=k\frac{\partial log p(o^m|s^m)}{\partial log p(o_t^m|r)}-\frac{\partial log\sum_w p(o^m|s^w)^k P(w)}{\partial logp(o_t^m|r)}
$$

考虑到$p(o^m|s^m)=p(o_1^m|s_1^m)p(o_2^m|s_2^m)...p(o_{T_m}^m|s_{T_m}^m)$，所以上式第一项可以简化为： $k\frac{\partial p(o^m|s^m)}{\partial logp(o_t^m|r)}=k(\delta(r=s_t^m))$

 

第二项可以进一步求导：
$$
\frac{\partial log\sum_w p(o^m|s^w)^k P(w)}{\partial logp(o_t^m|r)}\\
=\frac{\partial log\sum_w e^{logp(o^m|s^w)^k P(w)}}{\partial logp(o_t^m|r)}\\
=\frac{1}{\sum_w e^{logp(o^m|s^w)^k P(w)}}\frac{\partial \sum_w e^{log p(o^m|s^w)^k P(w)}}{\partial logp(o_t^m|r)}\\
=\frac{1}{\sum_w p(o^m|s^w)^k P(w)}*\sum_w e^{logp(o^m|s^w)^k P(w)}*\frac{\partial log p(o^m|s^w)^k P(w)}{\partial logp(o_t^m|r)}\\
=\frac{1}{\sum_w p(o^m|s^w)^k P(w)}*\sum_w p(o^m|s^w)^k P(w)*\delta (s_t^m=r)\\
=\frac{\sum_{w:s_t=r} p(o^m|s^w)^k P(w)}{\sum_w p(o^m|s^w)^k P(w)}
$$
综合前面的第一项和第二项，可得：
$$
\frac{\partial J_{MMI}(\theta;o^m,w^m)}{\partial logp(o_t^m|r)}=k(\delta(r=s_t^m)-\frac{\sum_{w:s_t=r} p(o^m|s^m)^k P(w)}{\sum_w p(o^m|s^m)^k P(w)})
$$


### 第二部分

考虑到$p(x|y)*p(y)=p(y|x)*p(x)$，第二部分可以表示如下： 
$$
\frac{\partial logp(o_t^m|r)}{\partial z_{mt}^L(i)}\\
=\frac{\partial log p(r|o_t^m)-logp(r)+logp(o_t^m)}{\partial z_{mt}^L(i)}\\
=\frac{\partial log p(r|o_t^m)}{\partial z_{mt}^L(i)}
$$
其中$p(r|o_t^m)$表示DNN的第r个输出， 
$$
p(r|o_t^m)=softmax_r(z_{mt}^L)=\frac{e^{z_{mt}^L(r)}}{\sum_j e^{z_{mt}^L(j)}}
$$
所以，
$$
\frac{\partial logp(o_t^m|r)}{\partial z_{mt}^L(i)}=\delta(r=i)
$$
按照文章的推导应该得到这个结果，但是实际上分母还包含$z_{mt}^L(i)$，是不是做了近似认为分母是常量，这一步有疑问？？？？

综合上面两部分，可以得到最终的公式: 
$$
\ddot{e}_{mt}^L(i)=k(\delta(i=s_t^m)-\frac{\sum_{w:s_t=i} p(o^m|s^m)^k P(w)}{\sum_w p(o^m|s^m)^k P(w)})
$$


## Boosted MMI

$$
J_{BMMI}(\theta;S)=\sum_{m=1}^MJ_{BMMI}(\theta;o^m,w^m)=\sum_{m=1}^Mlog \frac{P(w^m|o^m)}{\sum_w P(w|o^m)e^{-bA(w,w^m)}}\\
=\sum_{m=1}^Mlog \frac{P(o^m|w^m)^kP(w^m)}{\sum_w P(o^m|w^m)^k P(w)e^{-bA(w,w^m)}}
$$

相比于MMI，BMMI在分母上面增加了一个权重系数$e^{-bA(w,w^m)}$，一般b=0.5,$A(w,w^m)$是w和$w^m$之间准确率的度量，可以是word/phoneme/state级别的准确率。

 

物理意义：

 

参考[3]给出的解释，We boost the likelihood of the sentences that have more errors, thus generating more confusable data. Boosted MMI can viewed as trying to enforce a soft margin that is proportional to the number of errors in a hypothesised sentence。

 

结合参数理解，就是w和$w^m$越接近(错误的word越少)，$e^{-bA(w,w^m)}$这个权重越小，相反，权重会越大，增加了数据的困惑度。

 

通过可以推导出误差信号：
$$
\ddot{e}_{mt}^L(i)=k(\delta(i=s_t^m)-\frac{\sum_{w:s_t=i} p(o^m|s^w)^k P(w) e^{-bA(w,w^m)}}{\sum_w p(o^m|s^w)^k P(w) e^{-bA(w,w^m)}})
$$


## MPE/sMBR

MBR(minimum Bayes risk)的目标函数是最小化各种粒度指标的错误，比如MPE是最小化phone级别的错误，sMBR最小化状态的错误。目标函数如下： 
$$
J_{MBR}(\theta;S)=\sum_{m=1}^MJ_{MBR}(\theta;o^m,w^m)=\sum_{m=1}^M \sum_w P(w|o^m) A(w,w^m)\\
=\sum_{m=1}^M \frac{\sum_w P(o^m|s^w)^kP(w) A(w,w^m)}{\sum_{w'} P(o^m|s^{w'})^k P(w')}
$$
其中$A(w,w^m)$表示两个序列之间的差异，MPE就是正确的phone的个数，sMBR是指正确的state的个数。求导可得：
$$
\ddot{e}_{mt}^L(i)=\nabla_{z_{mt}^L(i)}{J_{MBR}(\theta;o^m,w^m)}\\
=\sum_r \frac{\partial J_{MBR}(\theta;o^m,w^m)}{\partial logp(o_t^m|r)}\frac{\partial logp(o_t^m|r)}{\partial z_{mt}^L(i)}
$$


### 第一部分

对于MPE，参考文献[4]： 
首先将$J_{MBR}(\theta;o^m,s^m)$分子分母求和部分分为两块，$r\in s^w$和$r\notin s^w$
$$
J_{MBR}(\theta;o^m,s^m)=\frac{\sum_s P(o^m|s)^kP(s) A(s, s^m)}{\sum_{s'} P(o^m|s')^k P(s')}\\
= \frac{\sum_{s:r\in s} P(o^m|s)^kP(s) A(s, s^m)+\sum_{s:r\notin s} P(o^m|s)^kP(s) A(s, s^m)}{\sum_{s':r\in s'} P(o^m|s')^k P(s')+\sum_{s':r\notin s'} P(o^m|s')^k P(s')}
$$
\- 如果满足r∈s，那么导数满足以下关系：
$$
\frac{\partial P(o^m|s)^k}{\partial log p(o_t^m|r)}=\frac{\partial e^{k*logP(o^m|s)}}{\partial log p(o_t^m|r)}=k*P(o^m|s)^k
$$
\- 如果不满足r∈s，那么导数将为0：
$$
\frac{\partial P(o^m|s)^k}{\partial log p(o_t^m|r)}=0
$$
不难推出： 
$$
\frac{\partial J_{MBR}(\theta;o^m,s^m)}{\partial logp(o_t^m|r)}\\

=k*\frac{\sum_{s:r\in s} P(o^m|s)^kP(s) A(s, s^m)}{\sum_{s'} P(o^m|s')^k P(s')}-k*\frac{\sum_s P(o^m|s)^kP(s) A(s, s^m)}{\sum_{s'} P(o^m|s')^k P(s')}*\frac{\sum_{s:r\in s} P(o^m|s)^kP(s)}{\sum_{s'} P(o^m|s')^k P(s')}
$$
上面的等式可以简化为以下形式：
$$
\frac{\partial J_{MBR}(\theta;o^m,s^m)}{\partial logp(o_t^m|r)}=k*\ddot{\gamma}_{mt}^{DEN}(r)(\bar{A}^m(r=s_t^m)-\bar{A}^m)
$$
各个部分的定义如下：
$$
\ddot{\gamma}_{mt}^{DEN}(r)=\frac{\sum_{s:r\in s} P(o^m|s)^kP(s)}{\sum_{s'} P(o^m|s')^k P(s')}\\
\bar{A}^m=\frac{\sum_s P(o^m|s)^kP(s) A(s, s^m)}{\sum_{s'} P(o^m|s')^k P(s')}\\
\bar{A}^m(r=s_t^m)=\mathbb E(A(s, s^m))=\frac{\sum_{s:r\in s} P(o^m|s)^kP(s)A(s,s^m)}{\sum_{s':r\in s'} P(o^m|s')^k P(s')}
$$
第一项表示occupancy statistics

第二项表示lattice中所有路径的平均准确率 

第三项表示lattice中所有经过r的路径的平均准确率，是$A(s,s^m)$

的均值，可以将三个三项合并起来进行还原就很容易里面均值的含义。



### 第二部分

第二部分和MMI的一致

## tricks

### lattice generation

区分性训练时生成高质量的lattice很重要，需要使用最好的模型来生成对应的lattice，并且作为seed model。

### lattice compensation

如果lattice产生的不合理的话，会导致计算出来的梯度异常，比如分子的标注路径没有在分母中的lattice出现，这种情况对于silience帧尤其常见，因为silience经常出现在分子的lattice，但是很容易被分母的lattice忽略。有一些方法可以解决这种问题： 
\- fame rejection，直接删除这些帧 
\- 根据reference hypothesis修正lattice，比如在lattice中人为地添加一下silience边

### frame smoothing

SDT很容易出现overfitting，两方面原因 
\- sparse lattice 
\- sdt的squence相比于frame增加了建模的维度，导致训练集的后验概率分布更容易跟测试集出现差异

可以修改训练准则来减弱overfitting，通过结合squence criteria和frame criteria来实现： 
$$
J_{FS-SEQ}(\theta;S)=(1-H)J_{CE}(\theta;S)+HJ_{SEQ}(\theta;S)
$$
H成为smoothing factor，经验值设为4/5到10/11



### learning rate

SDT的学习率相比于CE要下，因为 
\- SDT的起点一般基于CE训练出来的model 
\- SDT训练容易出现overfitting

### criterion selection

sMBR效果相比其他会好一点，MMI比较容易理解和实现。

### noise contrastIve estimation

NCE可以用于加速训练

## 参考

[1]《automatic speech recognition a deep learning approach》 chapter8 
[2]Sequence-discriminative training of deep neural networks 
[3]Boosted MMI for model and feature-space discriminative training 
[4]discriminative training for large vocabulary speech recognition {daniel povey的博士论文chapter6}









# （六） representation learning

2016年10月08日 20:07:23 [xmucas](https://me.csdn.net/xmdxcsj) 阅读数：2190



## feature representation

### 特征抽象

![这里写图片描述](https://img-blog.csdn.net/20161008200522902)
DNN的前L-1层可以认为是特征提取部分，最后一层认为是简单的分类层。 
相比于人工设计的特征（比如MFCC），多层（每一层sigmoid都是一种非线性变换）连接起来具有很强的特征抽象能力。 
靠近输入层的表示low-level特征；靠近输出层的表示high-level的特征，high-level的特征更为抽象。 
![这里写图片描述](https://img-blog.csdn.net/20161008200552807)
如上图，一个特点是high-level的层包含有更多的饱和神经元（activation value>0.99或者<0.01），意味着越靠近输出层，对应的特征输出更为稀疏（因为最后的输出层是0和1的分类，本身就是稀疏的）。 
另外一个特点是high-level的层产生的特征具有更好的鲁棒性和区分度。 
GMM为了简化计算，方差使用的是对角矩阵，即假设输入的特征的各个维度之间是相互独立的，所以使用的是[MFCC特征](http://blog.csdn.net/xmdxcsj/article/details/51228791)，利用DCT运算去相关；相比之下，DNN没有这方面的限制，可以直接使用高维度的fbank特征直接计算。

### 特征鲁棒性

体现在两方面：说话人和环境。

#### speaker variations

为了解决说话人不同的问题，GMM-HMM引入了VTLN和fMLLR。当这种技术用在DNN-HMM模型上面的时候，收益相对小，说明了DNN-HMM对说话人信息具有更强的鲁棒性。

#### environment variations

GMM使用VTS和MLLR技术来归一化输入特征，减弱环境噪声的影响。DNN具有更好的健壮性。 
在不同的信噪比和语速下，DNN都会优于GMM。但是在畸变比较大的情况下（比如强噪声），DNN的性能也会很差。

## fuse DNN and GMM

### DNN提取特征训练GMM-HMM

![这里写图片描述](https://img-blog.csdn.net/20161008200638557)

### fuse recognition result

GMM-HMM和DNN-HMM的识别结果进行融合提升识别效果，包括： 
\- ROVER(recognizer output voting error reduction) 
\- SCARF(segmental conditional random field) 
\- MBR(minimum bayesian risk)

### fuse frame-level acoustic scores

多个系统的声学得分线性插值作为最后的得分。

### multistream speech recognition

有三种架构： 
\- early integration: 特征结合（比如拼接） 
\- intermediate integration: 每个stream的特征单独处理（不同的DNN模型），然后进行结合 
\- late integration: 每个stream使用不同的DNN-HMM，在最后的识别结果进行结合

stream的划分可以有多种形式，比如不同的频带，不同的特征PLP/MFCC等。

## adaptation of DNN

三种adaption方式

### linear transformation

可以针对不同层增加线性转化层 
\- input feature 
\- softmax layer 
\- hidden layer

### conservative training

linear transformation是针对一层做的adaption，如果对所有层做adaption可以达到更好的效果，但是这样会引入一个问题：因为adaption的数据量相比比较小，如果对整个模型进行调整的话，可能会破坏模型的信息。 
为了避免上面问题的发生，引入了conservative training。通过增加regularization来避免模型被adaption数据训练跑偏了。 
典型的两种正则方法： 
\- l2 正则，通过限制模型参数不要偏离原始模型太多来实现 
\- KLD(Kullback-Leibler divergence)正则，通过限制输出概率不要偏离原来模型的输出概率太多来实现

如果每个人的模型都要单独保存的话，存储空间将会是个问题。有两种方法解决这个问题： 
\- 保留si-model和sa-model转化的delta矩阵，并对delta矩阵进行svd简化 
\- 通过将矩阵Wm∗nWm∗n分解为Wm∗rWm∗r和Wr∗nWr∗n，并在中间增加矩阵Wr∗rWr∗r，每个speaker只需要单独存放Wr∗rWr∗r即可

### subspace methods

1.PCA 
线性变换矩阵可以转化为向量$a=vec(W^AADP)$，向量构成说话人的空间，然后经过PCA可以获得eigenvectors。 
$$
a\approx \overline{a}+\tilde{U}\tilde{g_a}
$$
其中$\overline{a}$是自适应参数的均值，$\tilde{U}$是简化的eigenvector矩阵，$\tilde{g_a}$是需要估计的从自适应参数向量到主成方向的映射。

 

2.Speaker-Aware

 



 

如上图，通过扩展特征输入，让模型拥有根据speaker信息自动调整的能力。

 

可以使用i-vector特征作为增加的speaker info。



## 参考

《automatic speech recognition a deep learning approach》 chapter 9-11







# （七） advanced deep models





## multitask and transfer learning

multitask learning：不同的任务网络，可以共享一部分网络结构（比如说某个隐层） 
transfer learning：迁移学习

### SHL-MDNN

![这里写图片描述](https://img-blog.csdn.net/20161008200838495)
shared-hidden-layer multilingual DNN，用于训练不同语言的模型，所有的模型共享同一个隐层，输出层跟语言有关。 
共用的隐层可以认为是一个特征提取器，最后的输出层为分类器。 
SHL-MDNN需要多个语言同时进行训练，一个mini-batch包括多个语言的训练语料。 
试验表明多语言训练出来的SHL-MDNN相比单语言训练出来的DNN性能有提升，共享的隐层训练在一定程度上面减弱了overfitting问题。 
隐层作为特征提取器，可以把它对音素的区分性迁移到其他语言上面。 
\- 如果需要增加一种语言，只需要增加一个输出层，还是复用前面训练好的隐层，训练是固定隐层，只需要训练最后一层的参数即可 
\- 如果新增语言的训练数据比较充足，整体重新训练效果更好。 
\- 可以由英语迁移到中文，依然有效

## RNN

[RNN](http://blog.csdn.net/xmdxcsj/article/category/5855803) 
[LSTM](http://blog.csdn.net/xmdxcsj/article/details/52526843)

## 参考

《automatic speech recognition a deep learning approach》 chapter 12-15



