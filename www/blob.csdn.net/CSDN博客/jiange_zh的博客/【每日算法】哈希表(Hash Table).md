
# 【每日算法】哈希表(Hash Table) - jiange_zh的博客 - CSDN博客


2016年02月25日 23:16:42[jiange_zh](https://me.csdn.net/jiange_zh)阅读数：1981所属专栏：[每日算法](https://blog.csdn.net/column/details/algorithmeveryday.html)



## 概述
哈希表又称散列表，它用于快速查找。
查找，如果能够不经过比较，直接就能得到待查记录的存储位置，那效率必定很高。
通过在记录的存储位置和它的关键码之间建立一个确定的对应关系H，使得每个关键码key跟唯一的存储位置H(key)对应，那么当我们想查找关键码为k的记录时，直接到H(k)处取即可。这种查找技术叫做**散列技术**。
采用散列技术将记录存储在一块连续的存储空间中，这块连续的存储空间称为**散列表**，将关键码映射为散列表中适当存储位置的函数称为**散列函数**。
散列主要是面向查找的数据结构，它不适用于范围查找（如找最大最小值、某一个范围内的值等等）。它最适合回答的问题是：如果有的话，哪个记录的关键码等于待查值。
散列表有一个问题：对于两个不同的关键码k1 != k2，有H(k1) = H(k2)，即两个不同的记录需要存放在同一个存储空间中，这种现象称为**冲突**。
散列技术需要考虑的两个主要问题：
散列函数的设计（力求简单、均匀、存储利用率高）；
冲突的处理。
## 散列函数
设计原则：
计算简单（否则影响查找效率）；
函数值，即散列地址均匀分布（充分利用存储空间，减少冲突）。
### 直接定址
散列函数为关键码的线性函数：
```python
H(key) =
```
```python
a
```
```python
* key + b （
```
```python
a
```
```python
、b为常数）
```
特点：单调、均匀，不会产生冲突；
适用于事先知道关键码的分布，且关键码集合不是很大而连续性号的情况。
实际不常用。
### 除留取余
```python
H(
```
```python
key
```
```python
) =
```
```python
key
```
```python
mod
```
```python
p （p为正整数）
```
关键在于p的选取，一般情况下，若表长为m，通常选p为小于等于表长（最好接近m）的最小素数或与2的整数幂不太接近的质数或不包含小于20质因子的合数。
### 平方取中
平方取中法将关键码平方后，按散列表的大小，取中间的若干位作为散列地址。因为一个数平方后，中间几位分布较均匀，从而冲突发生的概率较小。
### 折叠法
折叠法将关键码从左到右分割成位数相等的几步分，最后一部分位数可以短些，然后将几部分折叠求和，并按散列表长度，取后几位作为散列地址。
以key=25346358705为例，散列表长为3位。
**移位叠加**：
```python
253
```
```python
463
```
```python
587
```
```python
+
```
```python
05
```
```python
————
```
```python
1308
```
```python
H(key) =
```
```python
308
```
**间界叠加**：
```python
253
```
```python
364
```
```python
587
```
```python
+
```
```python
50
```
```python
————
```
```python
1254
```
```python
H(key) =
```
```python
254
```
适用于：关键码位数多，每一位分布都不均匀。
### 全域散列
全域散列保证了较好的平均性态。
它从预先设计好的一组函数中随机选择一个作为散列函数，随机化保证了没有哪一种输入会**始终导致**最坏情况形态。
关于散列函数还有很多，散列函数是不通用的，需要针对具体的应用场景来设计，这里作为入门，不一一介绍了。
## 冲突处理
### 开放定址法
用开放定址法处理冲突得到的散列表称为**闭散列表**，其做法是：一旦产生冲突，就去寻找下一个空的散列地址，只有散列表足够大，就能找到空的散列地址并将记录存入。
找下一个空的散列地址有多种方法，这里介绍三种：
**线性探测法**
设散列表长度为m，线性探测法从冲突位置的下一个位置起，依次寻找空的散列地址：
```python
Hi = (H(key) + di) % m (di =
```
```python
1
```
```python
,
```
```python
2
```
```python
,
```
```python
...
```
```python
,m-
```
```python
1
```
```python
)
```
这个方法将引入一个问题：不是同义词（即散列值不同的记录）可能争抢同一个散列地址，这称为**堆积**。
闭散列表查找算法：
```python
int
```
```python
HashSearch(
```
```python
int
```
```python
ht[],
```
```python
int
```
```python
m,
```
```python
int
```
```python
k)
{
    j = H(k);
```
```python
//计算散列地址
```
```python
if
```
```python
(ht[j] == k)
```
```python
//没有冲突，一次查找成功
```
```python
return
```
```python
j;
```
```python
else
```
```python
if
```
```python
(ht[j] == empty)
    {
        ht[j] = k;
```
```python
//查找不成功，插入
```
```python
return
```
```python
0
```
```python
;
```
```python
//退出
```
```python
}
```
```python
//ht[j]不为空，且ht[j] != k，说明有冲突
```
```python
i = (j+
```
```python
1
```
```python
) % m;
```
```python
//探测的起始下标
```
```python
while
```
```python
(ht[i] != empty && i != j)
    {
```
```python
if
```
```python
(ht[j] == k)
```
```python
//有冲突，但是查找若干次后成功了
```
```python
return
```
```python
i;
```
```python
else
```
```python
i = (i+
```
```python
1
```
```python
) % m;
```
```python
//往后探测
```
```python
}
```
```python
if
```
```python
(i == j)
```
```python
//找不到合适的地方插入了
```
```python
throw
```
```python
"溢出"
```
```python
;
```
```python
else
```
```python
{
        ht[i] = k;
```
```python
return
```
```python
0
```
```python
;
    }
}
```
**删除**
当从闭散列表中删除一个记录时，需要考虑以下两点：
删除一个记录一定不能影响以后的查找；
删除记录后的存储单元应该能够为将来的插入使用。
假如有H(11)=H(22)=0，则将11删除后，22将查找不到，因此不能简单地将被删除的单元清空。
解决方法：在被删除记录的位置上放一个特殊标记，标记一个记录曾经占用该单元，于是查找22的时候将不会在11曾经占用的地方停止，而是继续查找下去。当插入遇到一个标记时，则该单元可以存储新记录。但是为了避免重复，查找过程仍然要继续探测下去，比如在删除11后，要插入22，因为后面已经有22了，所以22不应该插入到11的位置。
**二次探测法**
寻找下一个散列地址的公式：
```python
Hi = (H(key) + di) % m (di =
```
```python
1
```
```python
^
```
```python
2
```
```python
,-
```
```python
1
```
```python
^
```
```python
2
```
```python
,
```
```python
2
```
```python
^
```
```python
2
```
```python
,-
```
```python
2
```
```python
^
```
```python
2
```
```python
,
```
```python
...
```
```python
,q^
```
```python
2
```
```python
,-q^
```
```python
2
```
```python
且q<=sqrt(m))
```
**随机探测法**
```python
Hi = (H(key) + di) % m (di为一个随机序列，i=
```
```python
1
```
```python
,
```
```python
2
```
```python
,
```
```python
...
```
```python
,m-
```
```python
1
```
```python
)
```
**双重散列**
双重散列是用于开放寻址法的最好方法之一：
```python
Hi = (H1(
```
```python
key
```
```python
) + i*H2(
```
```python
key
```
```python
)) % m
```
### 拉链法
用拉链法(chaining)处理冲突构造的散列表叫做开散列表。
其基本思想是：将所有散列地址相同的记录存储在一个单链表中，散列表中存储的是链表的头指针。设n个记录存储在长度为m的开散列表中，则链表平均长度为n/m。
开散列表查找算法：
```python
Node<
```
```python
int
```
```python
> *HashSearch(Node<
```
```python
int
```
```python
> *ht[],
```
```python
int
```
```python
m,
```
```python
int
```
```python
k)
{
    j = H(k);
```
```python
//计算散列地址
```
```python
p = ht[j];
```
```python
//工作指针p指向第j个链表头部
```
```python
while
```
```python
(p && p->data !=k)
        p = p->next;
```
```python
if
```
```python
(p->data == k)
```
```python
//查找成功
```
```python
return
```
```python
p;
```
```python
else
```
```python
{
        q =
```
```python
new
```
```python
Node<
```
```python
int
```
```python
>;
```
```python
//查找失败则插入
```
```python
q->data = k;
```
```python
//头插法
```
```python
q->next = ht[j];
        ht[j] = q;
    }
}
```
另外还有**再哈希**等方法来解决冲突问题，此处不详述。
## 平均查找长度
已知一个线性表(38，25，74，63，52，48)，采用的散列函数为H(Key)=Key%7，将元素散列到表长为7的哈希表中存储。若采用线性探测的开放定址法解决冲突，则在该散列表上进行等概率成功查找的平均查找长度为多少？
解答：
38 25 74 63 52 48 mod 7分别是 3 4 4 0 3 6
所以采用线性探测的开放定址法解决冲突，表为:
63,48, ,38,25,74,52
找38，1次
找25，1次
找74，2次
找63，1次
找52，4次
找48，3次
所以成功查找的平均长度为(1+1+2+1+4+3)/6=2
## 复杂度
建表复杂度O(n)；
查找复杂度O(1)。
**最后补充的一个问题**
为什么一般hashtable的桶数会取一个素数？
如果不取素数的话是会有一定危险的，危险出现在当假设所选非素数m=x*y，如果需要hash的key正好跟这个约数x存在关系就惨了，最坏情况假设都为x的倍数，那么可以想象hash的结果为：1~y，而不是1~m。但是如果选桶的大小为素数是不会有这个问题。
## 结语
关于哈希，暂时介绍到这里，哈希表的设计看似简单，实际上在实际应用中要设计的好还是挺复杂的。
刚刚查资料看到一个利用哈希进行攻击的事情：不断添加散列地址相同的记录，于是在拉链法中，哈希表将退化为链表，导致访问速度极慢，形成拒绝服务攻击。所以实际中需要考虑的问题还有很多。
接下来如果有空，我将开始阅读STL源码，看一看它的哈希表是如何实现的，有兴趣的读者也可以深入了解一下。
---每天进步一点点，Come on！

---(●’◡’●)

---本人水平有限，如文章内容有错漏之处，敬请各位读者指出，谢谢！


