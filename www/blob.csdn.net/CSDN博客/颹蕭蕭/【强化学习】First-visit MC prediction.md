
# 【强化学习】First-visit MC prediction - 颹蕭蕭 - CSDN博客


2019年04月02日 19:55:27[颹蕭蕭](https://me.csdn.net/itnerd)阅读数：53


在未知环境的条件下，通过反复模拟获得样本数据，近似估计给定策略下的价值函数$v_{\pi}$
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190402195225211.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2l0bmVyZA==,size_16,color_FFFFFF,t_70)
```python
import
```
```python
gym
```
```python
import
```
```python
numpy
```
```python
as
```
```python
np
```
```python
from
```
```python
matplotlib
```
```python
import
```
```python
pyplot
```
```python
import
```
```python
matplotlib
```
```python
.
```
```python
pyplot
```
```python
as
```
```python
plt
```
```python
from
```
```python
mpl_toolkits
```
```python
.
```
```python
mplot3d
```
```python
import
```
```python
Axes3D
```
```python
from
```
```python
collections
```
```python
import
```
```python
defaultdict
```
```python
from
```
```python
functools
```
```python
import
```
```python
partial
plt
```
```python
.
```
```python
style
```
```python
.
```
```python
use
```
```python
(
```
```python
'ggplot'
```
```python
)
```
```python
env
```
```python
=
```
```python
gym
```
```python
.
```
```python
make
```
```python
(
```
```python
'Blackjack-v0'
```
```python
)
```
```python
def
```
```python
sample_policy
```
```python
(
```
```python
observation
```
```python
)
```
```python
:
```
```python
score
```
```python
,
```
```python
dealer_score
```
```python
,
```
```python
usable_ace
```
```python
=
```
```python
observation
```
```python
return
```
```python
0
```
```python
if
```
```python
score
```
```python
>=
```
```python
20
```
```python
else
```
```python
1
```
```python
def
```
```python
generate_episode
```
```python
(
```
```python
policy
```
```python
,
```
```python
env
```
```python
)
```
```python
:
```
```python
# we initialize the list for storing states, actions, and rewards
```
```python
states
```
```python
,
```
```python
actions
```
```python
,
```
```python
rewards
```
```python
=
```
```python
[
```
```python
]
```
```python
,
```
```python
[
```
```python
]
```
```python
,
```
```python
[
```
```python
]
```
```python
# Initialize the gym environment
```
```python
observation
```
```python
=
```
```python
env
```
```python
.
```
```python
reset
```
```python
(
```
```python
)
```
```python
while
```
```python
True
```
```python
:
```
```python
# append the states to the states list
```
```python
states
```
```python
.
```
```python
append
```
```python
(
```
```python
observation
```
```python
)
```
```python
# now, we select an action using our sample_policy function and append the action to actions list
```
```python
action
```
```python
=
```
```python
sample_policy
```
```python
(
```
```python
observation
```
```python
)
```
```python
actions
```
```python
.
```
```python
append
```
```python
(
```
```python
action
```
```python
)
```
```python
# We perform the action in the environment according to our sample_policy, move to the next state
```
```python
# and receive reward
```
```python
observation
```
```python
,
```
```python
reward
```
```python
,
```
```python
done
```
```python
,
```
```python
info
```
```python
=
```
```python
env
```
```python
.
```
```python
step
```
```python
(
```
```python
action
```
```python
)
```
```python
rewards
```
```python
.
```
```python
append
```
```python
(
```
```python
reward
```
```python
)
```
```python
# Break if the state is a terminal state
```
```python
if
```
```python
done
```
```python
:
```
```python
break
```
```python
return
```
```python
states
```
```python
,
```
```python
actions
```
```python
,
```
```python
rewards
```
```python
def
```
```python
first_visit_mc_prediction
```
```python
(
```
```python
policy
```
```python
,
```
```python
env
```
```python
,
```
```python
n_episodes
```
```python
)
```
```python
:
```
```python
# First, we initialize the empty value table as a dictionary for storing the values of each state
```
```python
value_table
```
```python
=
```
```python
defaultdict
```
```python
(
```
```python
float
```
```python
)
```
```python
N
```
```python
=
```
```python
defaultdict
```
```python
(
```
```python
int
```
```python
)
```
```python
for
```
```python
_
```
```python
in
```
```python
range
```
```python
(
```
```python
n_episodes
```
```python
)
```
```python
:
```
```python
# Next, we generate the epsiode and store the states and rewards
```
```python
states
```
```python
,
```
```python
_
```
```python
,
```
```python
rewards
```
```python
=
```
```python
generate_episode
```
```python
(
```
```python
policy
```
```python
,
```
```python
env
```
```python
)
```
```python
returns
```
```python
=
```
```python
0
```
```python
# Then for each step, we store the rewards to a variable R and states to S, and we calculate
```
```python
# returns as a sum of rewards
```
```python
for
```
```python
t
```
```python
in
```
```python
range
```
```python
(
```
```python
len
```
```python
(
```
```python
states
```
```python
)
```
```python
-
```
```python
1
```
```python
,
```
```python
-
```
```python
1
```
```python
,
```
```python
-
```
```python
1
```
```python
)
```
```python
:
```
```python
R
```
```python
=
```
```python
rewards
```
```python
[
```
```python
t
```
```python
]
```
```python
S
```
```python
=
```
```python
states
```
```python
[
```
```python
t
```
```python
]
```
```python
returns
```
```python
+=
```
```python
R
```
```python
# Now to perform first visit MC, we check if the episode is visited for the first time, if yes,
```
```python
# we simply take the average of returns and assign the value of the state as an average of returns
```
```python
if
```
```python
S
```
```python
not
```
```python
in
```
```python
states
```
```python
[
```
```python
:
```
```python
t
```
```python
]
```
```python
:
```
```python
N
```
```python
[
```
```python
S
```
```python
]
```
```python
+=
```
```python
1
```
```python
value_table
```
```python
[
```
```python
S
```
```python
]
```
```python
+=
```
```python
(
```
```python
returns
```
```python
-
```
```python
value_table
```
```python
[
```
```python
S
```
```python
]
```
```python
)
```
```python
/
```
```python
N
```
```python
[
```
```python
S
```
```python
]
```
```python
return
```
```python
value_table
value
```
```python
=
```
```python
first_visit_mc_prediction
```
```python
(
```
```python
sample_policy
```
```python
,
```
```python
env
```
```python
,
```
```python
n_episodes
```
```python
=
```
```python
500000
```
```python
)
```
```python
for
```
```python
i
```
```python
in
```
```python
range
```
```python
(
```
```python
10
```
```python
)
```
```python
:
```
```python
print
```
```python
(
```
```python
value
```
```python
.
```
```python
popitem
```
```python
(
```
```python
)
```
```python
)
```
`((4, 1, False), -0.5786802030456852)
((14, 1, True), -0.43960396039603966)
((4, 9, False), -0.42211055276381915)
((13, 3, True), -0.22764227642276424)
((7, 3, False), -0.5780911062906736)
((12, 1, True), -0.4090909090909092)
((15, 8, True), -0.2540983606557379)
((4, 3, False), -0.534246575342466)
((4, 2, False), -0.48458149779735665)
((4, 8, False), -0.4603174603174603)`
```python
def
```
```python
plot_blackjack
```
```python
(
```
```python
V
```
```python
,
```
```python
ax1
```
```python
,
```
```python
ax2
```
```python
)
```
```python
:
```
```python
player_sum
```
```python
=
```
```python
np
```
```python
.
```
```python
arange
```
```python
(
```
```python
12
```
```python
,
```
```python
21
```
```python
+
```
```python
1
```
```python
)
```
```python
dealer_show
```
```python
=
```
```python
np
```
```python
.
```
```python
arange
```
```python
(
```
```python
1
```
```python
,
```
```python
10
```
```python
+
```
```python
1
```
```python
)
```
```python
usable_ace
```
```python
=
```
```python
np
```
```python
.
```
```python
array
```
```python
(
```
```python
[
```
```python
False
```
```python
,
```
```python
True
```
```python
]
```
```python
)
```
```python
state_values
```
```python
=
```
```python
np
```
```python
.
```
```python
zeros
```
```python
(
```
```python
(
```
```python
len
```
```python
(
```
```python
player_sum
```
```python
)
```
```python
,
```
```python
len
```
```python
(
```
```python
dealer_show
```
```python
)
```
```python
,
```
```python
len
```
```python
(
```
```python
usable_ace
```
```python
)
```
```python
)
```
```python
)
```
```python
for
```
```python
i
```
```python
,
```
```python
player
```
```python
in
```
```python
enumerate
```
```python
(
```
```python
player_sum
```
```python
)
```
```python
:
```
```python
for
```
```python
j
```
```python
,
```
```python
dealer
```
```python
in
```
```python
enumerate
```
```python
(
```
```python
dealer_show
```
```python
)
```
```python
:
```
```python
for
```
```python
k
```
```python
,
```
```python
ace
```
```python
in
```
```python
enumerate
```
```python
(
```
```python
usable_ace
```
```python
)
```
```python
:
```
```python
state_values
```
```python
[
```
```python
i
```
```python
,
```
```python
j
```
```python
,
```
```python
k
```
```python
]
```
```python
=
```
```python
V
```
```python
[
```
```python
player
```
```python
,
```
```python
dealer
```
```python
,
```
```python
ace
```
```python
]
```
```python
X
```
```python
,
```
```python
Y
```
```python
=
```
```python
np
```
```python
.
```
```python
meshgrid
```
```python
(
```
```python
player_sum
```
```python
,
```
```python
dealer_show
```
```python
)
```
```python
ax1
```
```python
.
```
```python
plot_wireframe
```
```python
(
```
```python
X
```
```python
,
```
```python
Y
```
```python
,
```
```python
state_values
```
```python
[
```
```python
:
```
```python
,
```
```python
:
```
```python
,
```
```python
0
```
```python
]
```
```python
)
```
```python
ax2
```
```python
.
```
```python
plot_wireframe
```
```python
(
```
```python
X
```
```python
,
```
```python
Y
```
```python
,
```
```python
state_values
```
```python
[
```
```python
:
```
```python
,
```
```python
:
```
```python
,
```
```python
1
```
```python
]
```
```python
)
```
```python
for
```
```python
ax
```
```python
in
```
```python
ax1
```
```python
,
```
```python
ax2
```
```python
:
```
```python
ax
```
```python
.
```
```python
set_zlim
```
```python
(
```
```python
-
```
```python
1
```
```python
,
```
```python
1
```
```python
)
```
```python
ax
```
```python
.
```
```python
set_ylabel
```
```python
(
```
```python
'player sum'
```
```python
)
```
```python
ax
```
```python
.
```
```python
set_xlabel
```
```python
(
```
```python
'dealer showing'
```
```python
)
```
```python
ax
```
```python
.
```
```python
set_zlabel
```
```python
(
```
```python
'state-value'
```
```python
)
```
```python
fig
```
```python
,
```
```python
axes
```
```python
=
```
```python
pyplot
```
```python
.
```
```python
subplots
```
```python
(
```
```python
nrows
```
```python
=
```
```python
2
```
```python
,
```
```python
figsize
```
```python
=
```
```python
(
```
```python
5
```
```python
,
```
```python
8
```
```python
)
```
```python
,
```
```python
subplot_kw
```
```python
=
```
```python
{
```
```python
'projection'
```
```python
:
```
```python
'3d'
```
```python
}
```
```python
)
```
```python
axes
```
```python
[
```
```python
0
```
```python
]
```
```python
.
```
```python
set_title
```
```python
(
```
```python
'value function without usable ace'
```
```python
)
```
```python
axes
```
```python
[
```
```python
1
```
```python
]
```
```python
.
```
```python
set_title
```
```python
(
```
```python
'value function with usable ace'
```
```python
)
```
```python
plot_blackjack
```
```python
(
```
```python
value
```
```python
,
```
```python
axes
```
```python
[
```
```python
0
```
```python
]
```
```python
,
```
```python
axes
```
```python
[
```
```python
1
```
```python
]
```
```python
)
```
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190402195823857.png)

