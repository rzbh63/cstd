
# K-means聚类算法原理分析与实际应用案例分析（案例分析另起一篇博客） - OraYang的博客 - CSDN博客

2017年11月02日 16:05:28[OraYang](https://me.csdn.net/u010665216)阅读数：1624所属专栏：[机器学习](https://blog.csdn.net/column/details/16605.html)



## 引言
在数据分析中，我们常常想将看上去相似或者行为形似的数据聚合在一起。例如，对一个营销组织来说，将不同客户根据他们的特点进行分组，从而有针对性地定制营销活动，这很重要。又比如，对学校老师来说，将学生分组同样能够有所侧重的进行教育活动。分类与聚类是数据挖掘领域两大基础方法，分类被用于监督学习中而聚类算法属于无监督的。聚类算法主要是将相似的数据聚合在一起形成不同的组别，但是组与组之间相差很大。
在本次分享中，我将给大家介绍一种无监督算法K-means算法，为什么介绍这种算法呢？因为这种算法概念简单，实现容易，而且好用！
## K-means聚类算法的介绍
### 相似性度量
K-means算法是一种无监督学习算法，可以被应用到无标签的数据中。这个算法的目的就是要找到数据的分组，分组的数目由K指定。这个算法基于提供的特征，迭代地将数据分配个K个组别的其中一个。数据是基于数据相似性被聚类的。K-means聚类算法的结果就是：
> K个聚类中心，可以用来标注新的数据

> 数据标签，每个数据都被分配给一个簇
基本K-means算法的相似性度量是基于距离计算的，最典型的就是欧几里得距离。欧几里得距离计算给定两点之间的距离，公式如下：

$$
dist_ed(x_i,x_j) = ||x_i-x_j||_2=\sqrt{\sum_{u=1}^n|x_{iu}-x_{ju}|^2}
$$

### 算法流程
K-means算法的流程很简单，具体如下：
> 首先，随机确定k个初始点作为质心。

> 然后将数据集中的每个点分配到一个簇中，具体来讲，为每个点找距其最近的质心，并将其分配给该质心所对应的簇。

> 将每个簇的质心更新为该簇所有点的平均值

> 如果质心不再变化或者说变化很小，退出循环，否则返回到第二步
K-means的伪代码如下：
![k-means](https://img-blog.csdn.net/20171102153242236?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMDY2NTIxNg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
## K-means的实现
因为在前面一次博文分享中，有讲到K-means算法的实际应用场景，大家可以直接调转到那里去：[基于改进的K-means算法在共享交通行业客户细分中的应用](http://blog.csdn.net/u010665216/article/details/78165340)那篇博文使用的K-means算法是sklearn中的K-means++算法。
## K-means不足
### 初始点的选取
K-means算法在实际使用中存在一些不足。在实际使用中，我们发现K-means对初始点的选取很敏感，这种敏感就会导致K-means算法很可能收敛到局部最优。于是有人提出了两种方法，一种是K-means++，一种是二分K-means算法来尽量使K-means达到全局最优。
#### K-means++
k-means++算法选择初始聚类中心的基本原则是：初始的聚类中心之间的相互距离要尽可能的远。它选择初始聚类中心的步骤是：
> （1）从输入的数据点集合中随机选择一个点作为第一个聚类中心；

> （2）对于数据集中的每一个点x，计算它与最近聚类中心(指已选择的聚类中心)的距离D(x)，并根据以下概率选择新的聚类中心。

> （3）重复过程（2）直到找到k个聚类中心。

> 二分K-means

> 二分K-means使用一种度量聚类效果的指标是SSE(Sum of Squared Error，误差平方和)。SSE越小表示数据点越接近它们的质心，聚类效果也是最好。二分K-means算法的工作流程是：

> （1）首先将所有点作为一个簇，然后将簇一分为二

> （2）之后选择其中一个簇继续进行划分，选择哪一个簇进行划分取决于对其划分是否可以最大程度地降低SSE的值

> （3）上述基于SSE的划分过程不断重复，直到得到用户指定的簇数目为止。

> k的确定

> 这个k值选择的问题，讲真目前还真没有什么太好的方法解决，一般都是实际业务场景，靠工程经验去判定k的取值。

> 距离计算

> 上面K-means的实现我们是基于欧几里得距离的，但是实际业务场景中有很多的距离计算方式，有个叫”distance metric learning”的实现方法可以用来做这件事情。本博文就不做介绍了。


