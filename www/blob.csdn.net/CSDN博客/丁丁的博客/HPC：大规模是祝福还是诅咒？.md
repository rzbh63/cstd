
# HPC：大规模是祝福还是诅咒？ - 丁丁的博客 - CSDN博客


2012年07月29日 04:42:12[MoussaTintin](https://me.csdn.net/JackyTintin)阅读数：2022


By Gary M. Johnson: Too Big to FLOP? From[
HPCWire](http://www.hpcwire.com/hpcwire/2012-07-19/too_big_to_flop_.html?page=1)
在高性能计算（HPC）的领域前沿，我们一般认为计算机系统的规模越大越好，用户也需要规模更大的计算机。不过，在我们着手开发计算速度超过petaflops（10的15次方浮点运算每秒）量级的计算机，并向着exaflops量级的目标努力之时，我们的这些观点依然正确吗？计算机是否已经变得过于庞大，从而不再能有效的发挥其巨大的浮点运算能力呢？应用端的用户真的需要更大规模的计算机吗？如果我们的这些前提不再成立了，那么或许我们应该重新规划一下HPC领域的发展蓝图。
## 公共采购前提
新一代的高端计算机的早期产品，几乎都由公共开支买单购买。采购这些最先进的计算设备不仅仅是为了推动计算机产业的创新，最主要的目的是满足研究者和应用开发人员的需求。他们为科学和工程计算所编写的代码，超过了现有计算机的运算能力，因而需要更加强大的机器以保证运行。
其理由大致如下：
• X领域的进步对科学的进步、经济竞争力的提升、国防（或随便哪个你能想到的方面）而言非常之重要。
• X领域的应用端用户声称，没有更好的模型和仿真，他们不可能达到既定的目标。
• 更好的模型和仿真需要如下部分或全部的条件得到满足：更有弹性的代码、更快的执行速度、更大的内存、更多的运行次数，以及更长的运行时间。
• 满足这些起模型和仿真目标，意味着更大规模和更加快速的计算机。
在过去的几十年里，这个理由为我们带来了很大的益处。不到半个世纪的时间，我们所拥有的最高端的计算机的性能已经从megaflops数量级发展到了几十petaflops的量级，增长了超过100亿倍！
## 巨额资金
准确的估计TOP500中位居前列的计算机的成本是非常困难的。有些情况下，引用的数字可能包含了研发成本，而有些情况则没有。有些字数基本上只是硬件成本，而非作为可售商品的”市场价格“。有时，数字则是处于两个极端之间，代表出售给客户和/或研发伙伴的折扣价。尽管估算的成本很不准确，但是有一点是十分确定的：这些机器全都有赖于巨额资金的支持。几个月前，Dan Olds在[The
 Register](http://www.theregister.co.uk/2012/03/08/supercomputing_vs_home_usage/)写了一篇文章，试图估算那些率先突破各个运算速度量级的机器的”早期价格“。他所得的结果如下表示：

![](https://img-my.csdn.net/uploads/201207/29/1343508317_7300.jpg)

注意到上表引用的K Computer的成本，包括了它的研发开销。在最新的[TOP500](http://www.top500.org/)列表中，I一个IBM Blue Gene/Q 系统——位于劳伦斯•利弗莫尔国家实验室的Sequosia，位列榜首。它的Linpack测试性能刚刚超过16 petaflops。Sequosi的成本目前还没有公布，但是根据已有信息，2.1~2.3亿美元是一个比较合理的推测。
![](https://img-my.csdn.net/uploads/201207/29/1343508328_7445.jpg)

我们在上图给出了这些顶级计算机（包括Sequoia）的成本。我们在图上添加了两条趋势线。红线是根据所有的数据拟合而得，而蓝线是将CDC和K Computer作为离群点排除后得出的。根据图示的趋势，一个看上去非常合理的推测是，到2020年，不计研发成本，顶级计算机的造价将在3~4亿美元之间。到2030年，这个数字将升至超过5亿美元。
考虑到当前和在可预计的未来全球财政的限制，不难想象，我们会比以往更加审慎的检查，花费巨额公共开支用以采购顶级计算机的合理性。这些前提还会成立吗？
## 越大越好？
拥护并出资顶赞助级机器研发的人，通常将它们视作是取得突破的工具。他们认为，没有这些机器，或者没有这么多机器，这些突破便无从谈起。因此便诞生了”霸王跑“（hero run）的想法：一个单独的应用团队占用了整个计算机，来做一些惊人之事。
但现实却远非如此。公共资金支持的高端计算机（包括顶尖的设备）通常是被多个用户所共享。根据实际情况的不同，它们可能会被成百甚至上千的用户共同使用。而且，这些计算机的资源很少被某个单独的应用全部使用。例外的情况可能是，在它们上运行[Linpack](http://www.top500.org/project/linpack)标准测试，以便确定它们在TOP500中的位次。
因此，详细想来，没有人真正见识过顶尖计算机完全的计算能力。用户只利用了机器运算能力的一部分；而一个发挥全部性能的非常低端有机器（相比于TOP500列表的神器），可能完全能够提供这些计算能力，而且也会便宜很多。
## 失败是常道
对于超过petaflop计算能力的机器而言，失败（或者说，”系统故障“，如果你愿意的话）不只是可能，而且十分普遍。有关机器运行的平均无故障时间（MTBI）的数据通常并不会公开，但是通过其他途径推测到的情况是：故障间隔足够短，以致于构成了严重的问题。
在最近举办的国际超级计算大会（International Supercomputing Conference，ISC'12）上，Jack Dongarra发表了题为”[Reduced Linpack
 to Keep the Run Time Manageable for Future TOP500 Lists](http://www.isc-events.com/isc12_ap/contributiondetails.php?t=contribution&o=1606&a=select&ra=eventdetails)“的演讲。演讲中，他讨论了修改Linpack测试集，以缩短运行时间的问题。作这样的修改的必要性在他的图示中展现得一清二楚。下表给出了过去TOP500列表中顶尖计算机的Linpack执行时间：
![](https://img-my.csdn.net/uploads/201207/29/1343508334_1446.jpg)
注意到，近几年的顶级机器需要花费20到30小时以完成Linpack测试。Dongarra给出的Linpack运行时间的趋势，如下：
![](https://img-my.csdn.net/uploads/201207/29/1343508340_2350.jpg)

如果这个趋势持续下去，那么exaflops量级的机器将不得不花费将近6天来完成Linpack测试。大家通常不愿直说，但事实是，20到30小时可能已经在顶端计算机的平均无故障时间（MTBI）之内了。因此，为了能在系统遇到故障之前完成测试，可能需要将测试集运行若干次。在目前情况下，想要将现有Linpack测试集跑上6天，显然是天方夜谭。
这与现实中的科学和工程应用又有什么关系呢？回想一下关于Linpack的魔咒：如果你不能运行Linpack，那么运行实际应用则更是痴人说梦。因此，由于MTBI的原因，如果运行Linpack测试都成问题，那么运行其他程序的可行性有多大？
系统故障因素虽然还没有被广泛地讨论，但是由于它的存在，更大规模的机器可能并不会更快的完整运行完成实际的应用程序。
支持顶尖计算机公共采购的最基本的前提是，应用程序端用户对顶尖计算机很在意。无论这些机器多么难以使用，总有人需要它们。没有它们，科学和工程无法取得突破。但是，以下几事例给出的提示可能有违于用户的这种观点了：
在考虑开发exaflops规模的计算机的初期，美国能源部的科学办公室同来自不同学科的应用端用户举行了一系列深入的研讨会。来自这个”[
Scientific Grand Challenges Workshop Series](http://extremecomputing.labworks.org/index.stm)“的报告和其他文档表明，结果是不能一概而论。
最根本的问题被提出：你所在领域的学科进步在多大程度上需要exaflops规模的计算？各个用户小组大体上都l回避了这个问题，转而回应到，如果有一台这样的计算机他们将如何利用它。两种回答的差别可能很细微，但是它暗示了，对于exaflops规模的计算，应用端用户并没有的普遍的显著需要。如果给他们提供一台，他们将使用它吗？当然！
尽管不太正式，但一个更明直白的提示来自于ISC’12的一个专家小组分会。专家们考虑的主题是，20年后，终端用户会对TOP500列表持何种看法。三位杰出的HPC经理为我们显现了这种观点，他们分别来自德国、日本和美国，照片从左到右依次是：
• Michael Resch – Director, High Performance Computing Center, University of Stuttgart
• Satoshi Matsuoka – Professor, Global Scientific Information and Computing Center & Department of Mathematical and Computing Sciences, Tokyo Institute of Technology
• Dona Crawford – Associate Director for Computation at Lawrence Livermore National Laboratory
最右边那位则是我，Gary Johnson，我负责缓和讨论会的氛围。就我所知，讨论会没有文字记录，但是你可以从[ISC Events Channel on YouTube](https://www.youtube.com/watch?v=z2GBN5DIcrM)上找到当时的录像。
![](https://img-my.csdn.net/uploads/201207/29/1343508345_4763.jpg)
在对中间的一位经理关于TOP500列表的观点进行了一番讨论之后，我询问专家们，对于此，他们的应用端用户又是怎么觉得的（问题大约出现在15:50处）。你可以亲自查看他们的回答，而我听到的是：除了因为在顶级计算机上运用自己的程序所引起的可能的自豪感外，终端用户并不关心他们的计算机排在第几。显然，TOP500的位次对终端用户的行为几乎毫无影响。但是我们又怎样来解释用户需要顶级计算机以推进他们的工作的愿望呢？似乎他们中大部分人都对”自家“中心的计算机和使用它所提供的计算资源感到满意，而不会去追求最大、最好的计算机。
## ”大铁”（Big Iron）何去何从？
我们对于大型计算机以及建造大型计算机的军备竞赛的观念已经根深蒂固。因此，文章中的作出评论和提出的问题并不是要质疑exaflosp以及更高速度的机器的到来。相反，评论和问题的目的，是对我们的”标准的理由“提出建设性的批评；依据这种理由，我们提倡高端计算并说服政府赤巨资购买相关设备。尽管Big Iron深入人心——当前根植这些机器的”越大越靠谱“的观念，显然受到了挑战。
反复质疑我们所持有的前提假设，是一种谨慎的作法。如果他们不再有效，那么由此推出的结论的正确性便值得怀疑。现在，支持公共采购顶级计算机的前提似乎在很大程度上不再有效。或许我们——HPC社区，应该未雨绸缪，为HPC的发展寻找一个更加坚实的基础。

