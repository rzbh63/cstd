
# 维特比算法 - lpty的博客 - CSDN博客

2017年12月21日 19:42:14[lpty](https://me.csdn.net/sinat_33741547)阅读数：813标签：[动态规划																](https://so.csdn.net/so/search/s.do?q=动态规划&t=blog)[隐马尔科夫																](https://so.csdn.net/so/search/s.do?q=隐马尔科夫&t=blog)[维特比																](https://so.csdn.net/so/search/s.do?q=维特比&t=blog)[
							](https://so.csdn.net/so/search/s.do?q=隐马尔科夫&t=blog)[
																					](https://so.csdn.net/so/search/s.do?q=动态规划&t=blog)个人分类：[机器学习																](https://blog.csdn.net/sinat_33741547/article/category/6482345)
[
																								](https://so.csdn.net/so/search/s.do?q=动态规划&t=blog)



## 一、前言
之前介绍过马尔科夫模型（[参考](http://blog.csdn.net/sinat_33741547/article/details/78690440)），提到马尔科夫的三个基本问题：
1、概率计算问题
2、学习问题
3、预测问题
这三个问题里面，比较常见是预测问题，也称为解码。在上面链接的文章里谈到有关这个问题的中文分词模型，下面给出一些解法。
## 二、基本介绍
### 1、概率模型
我们知道隐马尔科夫模型是一个概率模型，概率模型的基本思想可以参考：[语言模型](http://blog.csdn.net/sinat_33741547/article/details/78744723)。
传统的概率统计模型自由参数数目随着序列长度的增加指数级增长，这种复杂度是无法接受的，所以针对传统统计概率模型已经提出许多方法：n-gram，神经概率等。

### 2、隐马尔科夫
与n-gram等方法相似，隐马尔科夫也是针对自由参数过多进行了优化。
假设观测序列为s，传统概率模型中P（s）是一个基于所有历史信息，即s序列的条件概率，随着序列长度增加而复杂度指数级增长。隐马尔科夫模型则提出一个隐藏的马尔科夫链的概念，它认为观测序列s是由隐藏的马尔科夫链随机生成观测序列的过程。而这个马尔科夫链序列可取值的范围是有限的，且相对s的可取值范围非常小。
同时，认为隐藏马尔科夫链的状态只与前一个状态有关，观测序列的取值只由马尔科夫链的状态决定。
所以，给定隐马尔科夫模型的参数及相应的观察序列，我们常常希望能够找到生成观察序列的最可能的隐藏状态序列。
## 三、解法
假设有观测序列={dry，damp，soggy}，隐藏状态={Sunny，Cloudy，Rainy}，HMM模型参数={pi，A，B}。
### 1、穷举搜索
![](https://img-blog.csdn.net/20171221202006988)
如上图所示，穷举搜索就是列举出所有可能的隐藏状态序列，计算在每一种隐藏状态序列的情况下，观测序列出现的概率，选取最大概率的隐藏序列。但是这种办法复杂度非常的高。
### 2、维特比算法
与穷举法不同，维特比算法是基于动态规划思想的隐马尔科夫模型解法。动态规划原理提到，假设存在一条最优路径，那么将该路径切分成N段，那么这N段小路径都分别是该环境下的最优路径，否则就存在着其他未知小路径，能组成一个比最优路径还更好的路径，这显然不成立。
基于上述原理，我们只需要从时刻t=1开始，递归的计算子安时刻t状态为i的各条部分路径的最大概率，直至得到时刻t=T的状态为i的各条路径的最大概率，便可以得到最优路径。
#### （1）计算t=1时刻的概率
这里可以直接使用初始概率pi及发射概率B计算得到,
![](https://img-blog.csdn.net/20171225203027934)

#### （2）计算t>1时刻的概率
对于t时刻的每一个状态i，它的概率均可以由t-1时刻的局部概率δ，状态转移概率A，及发射概率B得到，
![](https://img-blog.csdn.net/20171225203041169)
上面公式得到局部最大概率，第一项是t-1时刻的局部概率，第二项是状态转移矩阵，第三项是发射概率。
## 四、实战
假设HMM模型，隐藏状态={1,2,3}，观测序列={红，白，红}，模型参数如下，求解最大概率隐藏状态序列。
![](https://img-blog.csdn.net/20171221205411451)

### 1、计算t=1时刻的概率
已知t=1时刻，观测为红，分别计算在在状态1,2,3的条件下得到观测的概率：
![](https://img-blog.csdn.net/20171221205750201)
由上图，此时取状态=3时，得到最大局部概率，但是，这个节点并不一定会是最优路径的节点。
### 2、计算t>1时刻的概率
在t=2时刻观测到白，t=3时刻观测到红，分别计算观测概率如下：
![](https://img-blog.csdn.net/20171221210028600)
如上图，在t=2时，对于状态s=1，分别计算由t-1时刻的状态s={1,2,3}的局部概率计算得到的t时刻的局部概率，得到最大的t时刻概率，以此类推。
### 3、递归结束
在t=3时刻，可以得到最大概率p=0.0147，此时可以得到最优路径的终点是i_3 = 3.
### 4、回溯最优路径
由最优路径的终点3开始，向前找到之前时刻的最优点：
（1）在t=2时刻，因为i_3 = 3，状态3的最大概率来源于状态3（上图没有显示出来，但可以参考状态1的计算过程）
（2）在t=1时刻，因为i_2 = 3，也可以得到最大概率来源于状态3
最后得到最优路径为（3,3,3）
## 五、参考
1、《统计学习方法》  李航
2、http://www.52nlp.cn/hmm-learn-best-practices-six-viterbi-algorithm-1
3、http://blog.csdn.net/ch1209498273/article/details/53864036

