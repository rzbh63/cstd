
# 漫步线性代数二十七——矩阵对角化 - 蜗牛 - CSDN博客


2016年11月29日 22:03:24[会敲键盘的猩猩](https://me.csdn.net/u010182633)阅读数：1474


现在我们开始实质性的计算，它非常简单并且在随后的几篇文章里都会用到。特征向量对角化一个矩阵：
**3、假设****n\times n****矩阵有****n****个线性无关的特征向量，如果这些向量是矩阵****S****的列，那么****S^{-1}AS****是一个对角矩阵****\Lambda****，****A****的特征值在****\Lambda****的对角线上：**

$$
\begin{equation}
S^{-1}AS=\Lambda=\begin{bmatrix}
\lambda_1&&&\\
&\lambda_2&&\\
&&\ddots&\\
&&&\lambda_n
\end{bmatrix}\tag1
\end{equation}
$$
我们将$S$称作特征向量矩阵，$\Lambda$是特征值矩阵——这里使用大写的表示，因为小写的表示对角线上的特征值。
证明：将特征向量$x_i$放在$S$的列上，按列计算$AS$的：

$$
AS=A\begin{bmatrix}
|&|&&|\\
x_1&x_2&\cdots&x_n\\
|&|&&|
\end{bmatrix}
\begin{bmatrix}
|&|&&|\\
\lambda_1x_1&\lambda_2x_2&\cdots&\lambda_nx_n\\
|&|&&|
\end{bmatrix}
$$
然后技巧就是将最后一个矩阵分成两个矩阵的乘积$S\Lambda$：

$$
\begin{bmatrix}
&&&\\
\lambda_1x_1&\lambda_2x_2&\cdots&\lambda_nx_n\\
&&&
\end{bmatrix}=
\begin{bmatrix}
&&&\\
x_1&x_2&\cdots&x_n\\
&&&
\end{bmatrix}
\begin{bmatrix}
\lambda_1&&&\\
&\lambda_2&&\\
&&\ddots&\\
&&&\lambda_n
\end{bmatrix}
$$
这里关键的一点是矩阵要写在右侧，如果$\Lambda$写在$S$前面，那么$\lambda_1$将和第一行进行乘积，但我们想$\lambda_1$出现在第一列，鉴于此，$S\Lambda$是正确的，所以

$$
\begin{equation}
AS=S\Lambda,\quad or\quad S^{-1}AS=\Lambda,\quad or\quad A=S\Lambda S^{-1}\tag2
\end{equation}
$$
其中$S$是可逆的，因为假设它的列(特征向量)是无关的。
在给出实例和应用之前，我们给出四点说明。
**注解1**：如果矩阵$A$没有虫多特征值-$\lambda_1,\ldots,\lambda_n$是不同的，那么它的$n$个特征值自然是无关的，因此任何特征值不同的矩阵可以被对角化。
**注解2**：对角化矩阵$S$不是唯一的。因为特征向量$x$乘以一个常数后依然是特征向量，于是用任何非零常数乘以$S$的列的到一个新的对角化矩阵$S$，多重特征值有更大的自由度。对于平凡的例子$A=I$，任何可逆矩阵$S$都能是$S^{-1}IS$是对角矩阵($\lambda$就是$I$)，所有向量就是单位矩阵的特征向量。
**注解3**：其他矩阵$S$不会得出对角矩阵$\Lambda$。假设$S$的第一列是$y$，那么$S\Lambda$的第一列是$\lambda_1y$，如果它和$AS$的第一列相同，根据矩阵乘法它的第一列是$Ay$，那么$y$一定是特征向量，$Ay=\lambda_1y$。$S$中特征向量的顺序和$\Lambda$中特征值的顺序自然是一样的。
**注解4**：并非所有的矩阵都有$n$个线性无关的特征向量，所以并非所有的矩阵都可以对角化。考虑病态矩阵的一个标准例子

$$
A=\begin{bmatrix}
0&1\\
0&0
\end{bmatrix}
$$
特的特征值是$\lambda_1=\lambda_2=0$，因为它是三角矩阵，并且对角元素为零：

$$
\det(A-\lambda I)=\det\begin{bmatrix}
-\lambda&1\\
0&-\lambda
\end{bmatrix}
=\lambda^2
$$
$A$的所有特征向量是向量$(1,0)$的倍数：

$$
\begin{bmatrix}
0&1\\
0&0
\end{bmatrix}x=
\begin{bmatrix}
0\\
0
\end{bmatrix},\quad or\quad
x=\begin{bmatrix}
c\\
0
\end{bmatrix}
$$
$\lambda=0$是二重特征值——它的代数重数是2，但是几何重数是1——只有一个无关的特征向量，所以我们不能构建$S$。
对于$A$不能对角化，这里还有一个更直接的证明。因为$\lambda_1=\lambda_2=0$，$\Lambda$肯定是一个零矩阵，但是如果$S^{-1}AS=0$，那么我们左乘$S$，右乘$S^{-1}$，便得到$A=0$。但是$A$不等于0，所以$S$不可逆。
无法对角化的原因不是因为$\lambda=0$，而是$\lambda_1=\lambda_2$：

$$
A=\begin{bmatrix}
3&1\\
0&3
\end{bmatrix}
\quad and\quad
A=\begin{bmatrix}
2&-1\\
1&0
\end{bmatrix}
$$
他们的特征值是3,3和1,1，但是是奇异的！问题在于特征向量不完备，这里再强调一下：
$A$的对角化依赖于充分的特征向量。
$A$的逆依赖于非零特征值。
对角化和逆没有联系，由特征值给出的唯一信息是：只有在特征值重复的时候，对角化才会失败。但是不总是会失败，$A=I$的特征值就是重复的1,1,$\ldots$,1，但是它已经是对角矩阵！这时候特征向量是完备的。
在特征值出现$p$次重复的时候，需要检验是否有$p$个无关的特征向量——也就是说，检验$A-\lambda I$的秩为$n-p$，为了完成所有的想法，我们必须说明特征值不同的情况。
**4、如果特征向量****x_1,\ldots,x_k****对应不同的特征值****\lambda_1,\ldots,\lambda_k****，那么这些特征向量就是线性无关的。**
首先假设$k=2$，并且$x_1,x_2$的组合是零：$c_1x_1+c_2x_2=0$，用$A$进行相乘，可以得到$c_1\lambda_1x_1+c_2\lambda_2x_2=0$，用此方程减去前面方程的$\lambda_2$倍，可以消去向量$x_2$：

$$
c_1(\lambda_1-\lambda_2)x_1=0
$$
因为$\lambda_1\neq\lambda_2$并且$x_1\neq 0$，我们得出$c_1=0$，同样我们可以得到$c_2=0$，所以两个向量是无关的；因为只有平凡组合才能得出零。
这个论证可以扩展到任意个特征向量的情况：如果某个组合产生零，那么用$A$去乘然后减去原组合的$\lambda_k$倍，$x_k$消失了，只留下$x_1,\ldots,x_{k-1}$为零的组合。重复相同的步骤(这就是数学归纳法)，最终我们会得到$x_1$的倍数等于零，所以$c_1=0$，从而每个$c_i=0$，于是来自不同特征值的特征向量自然线性无关。
有$n$个不同特征值的矩阵可以被对角化，下面给出一个典型的例子。
## 对角化实例
这部分主要是$S^{-1}AS=A$，特征向量矩阵$S$将$A$变成特征值矩阵$\Lambda$(对角的)，现在我们来看一下投影和旋转矩阵。
**例1**：投影矩阵

$$
\begin{bmatrix}
\frac{1}{2}&\frac{1}{2}\\
\frac{1}{2}&\frac{1}{2}
\end{bmatrix}
$$
特征值矩阵为

$$
\Lambda=\begin{bmatrix}
1&0\\
0&0
\end{bmatrix}
$$
将特征向量放入$S$的列中得：

$$
S=
\begin{bmatrix}
1&1\\
1&-1
\end{bmatrix}\quad\text{and}\quad
AS=S\Lambda=
\begin{bmatrix}
1&0\\
1&0
\end{bmatrix}
$$
因此$S^{-1}AS=\Lambda$。
**例2**：对于旋转而言，特征值不是很明显：

$$
90^{\circ}\text{旋转}\quad K=
\begin{bmatrix}
0&-1\\
1&0
\end{bmatrix}
$$
可以得出$\det(K-\lambda I)=\lambda^2+1$。一个向量旋转后怎样才会保持方向不变呢？很显然，除了零向量外(然而它是没用的)不可能有向量如此，但是必须由特征值，我们必须求解$du/dt=Ku$，特征多项式$\lambda^2+1$依然有两个根—— 但是这些根不是实值而已。
基于上面的提示，我们找到了出路，$K$的特征值是虚数，$\lambda_1=i,\lambda_2=-i$，从而看出特征值可以是非实的。这似乎很神奇，旋转九十度后他们乘以$i$或者$-i$：

$$
\begin{align*}
&(K-\lambda_1I)x_1=\begin{bmatrix}
-i&-1\\
1&-i
\end{bmatrix}
\begin{bmatrix}
y\\
z
\end{bmatrix}=
\begin{bmatrix}
0\\
0
\end{bmatrix}
\quad\text{and}\quad
x_1=\begin{bmatrix}
1\\
-i
\end{bmatrix}\\
&(K-\lambda_2I)x_2=\begin{bmatrix}
i&-1\\
1&i
\end{bmatrix}
\begin{bmatrix}
y\\
z
\end{bmatrix}=
\begin{bmatrix}
0\\
0
\end{bmatrix}
\quad\text{and}\quad
x_1=\begin{bmatrix}
1\\
i
\end{bmatrix}\\
\end{align*}
$$
即便特征值是虚数，但他们是不同的并且特征值是无关的。将他们放到$S$中：

$$
S=\begin{bmatrix}
1&1\\
-i&i
\end{bmatrix}\quad\text{and}\quad
S^{-1}KS=\begin{bmatrix}
i&0\\
0&-i
\end{bmatrix}
$$
我们面临着一个不可避免的事实，即使是实数矩阵，依然需要复数。如果实特征值很少，那么总是存在$n$个复特征值。(当虚部为零时，复数包括实数)如果$R^3,R^n$中实特征向量很少时，我们就考虑$C^3,C^n$，$C^n$空间包含有复元素的所有列向量并且长度，内积与正交有新的定义，但是确比$R^n$简单。
## 幂和乘  :
## A^k,AB
这里将解一个计算比较简单的情况。$A^2$的特征值是$\lambda_1^2,\ldots,\lambda_n^2$，并且$A$的特征向量也是$A^2$的特征向量，我们先从$Ax=\lambda x$开始，然后乘以$A$：

$$
\begin{equation}
A^2x=A\lambda x=\lambda Ax=\lambda^2x\tag3
\end{equation}
$$
因此$\lambda^2$是$A^2$的特征值，并且有相同的特征向量$x$。如果第一次乘以$A$后留下的$x$方向未变，那么第二次同样如此。
利用对角化可以得到相同的结论，将$S^{-1}AS=\Lambda$平方:

$$
(S^{-1}AS)(S^{-1}AS)=\Lambda^2\quad or\quad S^{-1}A^2S=\Lambda^2
$$
矩阵$A^2$被相同的$S$对角化，所以特征向量不变。特征值是原来的进行平方，这个结论对任意$A$的幂次都成立：
**5、****A^k****的特征值是****\lambda_1^k,\ldots,\lambda_n^k****并且****A****的每个特征向量依然是****A^k****的特征向量。当****S****对角化****A****时，它也对角化****A^k****：**

$$
\begin{equation}
\lambda_k=(S^{-1}AS)(S^{-1}AS)\cdots(S^{-1}AS)=S^{-1}A^kS\tag4
\end{equation}
$$
**除了第一个****S^{-1}****和最后一个****S****外，每一个****S^{-1}****都消掉一个****S****。**
如果$A$是可逆的，这个规则也可以应用到它的逆上(幂$k=-1$)，$A^{-1}$的特征值是$1/\lambda_i$，这个结果即使未对角化也能看出来：

$$
\text{如果}Ax=\lambda x\text{那么}x=\lambda A^{-1}x\text{并且}\frac{1}{\lambda}x=A^{-1}x
$$
**例3**：如果$K$表示旋转$90^{\circ}$，那么$K^2$表示旋转$180^{\circ}$(也就是$-I$)并且$K^{-1}$表示旋转$-90^{\circ}$：

$$
K=\begin{bmatrix}
0&-1\\
1&0
\end{bmatrix},\quad
K^2=\begin{bmatrix}
-1&0\\
0&-1
\end{bmatrix},\quad
K^{-1}=\begin{bmatrix}
0&1\\
-1&0
\end{bmatrix}
$$
$K$的特征值是$i,-i$；他们的平方是-1和-1；他们的倒数是$1/i=-i,1/(-i)=i$，那么$K^4$就是旋转$360^{\circ}$:

$$
K^4=\begin{bmatrix}
1&0\\
0&1
\end{bmatrix},\quad
\Lambda^4=\begin{bmatrix}
i^4&0\\
0&(-i)^4
\end{bmatrix}=
\begin{bmatrix}
1&0\\
0&1
\end{bmatrix}
$$
对于两个矩阵的乘积，我们可能希望它与$AB$的特征值有关—— 但是事与愿违，尝试用同样的推理似乎非常诱人，可是一般情况下这不是真的。如果$\lambda$是$A$的特征值，$\mu$是$B$的特征值，这里给出一个$AB$等于$\mu\lambda$的错误证明：

$$
ABx=A\mu x=\mu Ax=\mu\lambda x
$$
错误的原因在于认为$A,B$有相同的特征向量$x$，一般情况下，他们是不相等的，这里我们给出两个特征值为0的矩阵：

$$
AB=\begin{bmatrix}
0&1\\
0&0
\end{bmatrix}
\begin{bmatrix}
0&0\\
1&0
\end{bmatrix}
=\begin{bmatrix}
1&0\\
0&0
\end{bmatrix}
$$
$A,B$的特征向量完全不同。同理，$A+B$的特征值和$\lambda+\mu$也没有关系。
上面错误的表明了哪些是对的，如果$A,B$的特征向量一样，那么特征值就是他们的乘积$\mu\lambda$。但是还有更重要的，这提供了一种识别$A,B$是否共享同一特征向量集合的方法，这在量子力学中是非常关键的问题。
**6、当且仅当****AB=BA****时，对角化矩阵有相同的特征向量矩阵****S****。**
证明：如果同样的$S$对角化得$A=S\Lambda_1S^{-1},B=S\Lambda_2S^{-1}$，那么我们用两种顺序相乘得：

$$
AB=S\Lambda_1S^{-1}S\Lambda_2S^{-1}=S\Lambda_1\Lambda_2S^{-1},\
BA=S\Lambda_2S^{-1}S\Lambda_1S^{-1}=S\Lambda_2\Lambda_1S^{-1}
$$
因为$\Lambda_1\Lambda_2=\Lambda_2\Lambda_1$(对角矩阵满足交换律)，所以我们有$AB=BA$。
反过来，假设$AB=BA$，从$Ax=\lambda x$开始，我们有

$$
ABx=BAx=B\lambda x=\lambda Bx
$$
所以$x,Bx$都是$A$的特征向量，他们共享$\lambda$。为了方便如果我们假设$A$的特征值是不同的——特征空间总是一维的——那么$Bx$肯定是$x$的倍数，换句或说$x$是$B,A$的特征向量。对于有相同特征值得证明有点长，这里从略。
海森伯格不确定性原则来非交换矩阵，像位置$P$和动量$Q$。 位置是对称的，动量是斜对称的并且他们都满足$QP-PQ=I$，不确定性原则直接来此施瓦兹不等式$(Qx)^{T}(Px)\leq\Vert Qx\Vert\Vert Px\Vert$:

$$
\Vert x\Vert^2=x^{T}x=x^{T}(QP-PQ)x\leq2\Vert Qx\Vert\Vert Px\Vert
$$
$\Vert Qx\Vert/\Vert x\Vert$与$\Vert Px\Vert/\Vert x\Vert$的乘积——动量和位置误差(当波函数是$x$时)——最小是$\frac{1}{2}$，我们无法让两者误差都变小，因为当我们试着度量粒子的位置时我们已经改变了它的动量。
最后我们回到$A=S\Lambda S^{-1}$，这个分解非常适合取$A$的幂，我们用最简单的例子$A^2$进行说明，在平方的情况下$LU$分解完全没办法，但是$S\Lambda S^{-1}$确非常完美，它的平方是$S\Lambda^2S^{-1}$并且特征向量不变。利用这些特征向量，我们将解决微分方程与差分方程。

