
# 大数据之SparkSQL简介及DataFrame的使用 - Magician的博客 - CSDN博客


2018年04月07日 20:25:41[春雨里de太阳](https://me.csdn.net/qq_16633405)阅读数：155所属专栏：[自学大数据之路](https://blog.csdn.net/column/details/18514.html)



[目录](#目录)
[前言：](#前言)
[1、Spark SQL](#1spark-sql)[1.1、Spark SQL概述](#11spark-sql概述)
[1.2、DataFrames](#12dataframes)
[1.3、DataFrame常用操作](#13dataframe常用操作)
[总结：](#总结)

# 目录
# 前言：
本文主要介绍下SparkSQL以及SparkSQL的简单使用。这里只是做了一个非常简单的介绍，后续工作中如果有用到相关的知识，我会再总结。
# 1、Spark SQL
## 1.1、Spark SQL概述
**1.1.1、什么是Spark SQL**
Spark SQL是Spark用来处理结构化数据的一个模块，它**提供了一个编程抽象叫做DataFrame并且作为分布式SQL查询引擎的作用。**
![这里写图片描述](https://img-blog.csdn.net/20180407200425609?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzE2NjMzNDA1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
**1.1.2、为什么要学习Spark SQL**
我们已经学习了Hive，它是将**Hive SQL转换成MapReduce然后提交到集群上执行**，大大简化了编写MapReduce的程序的复杂性，由于MapReduce这种计算模型执行效率比较慢。所有Spark SQL的应运而生，它是**将Spark SQL转换成RDD，然后提交到集群执行，执行效率非常快！**
1.易整合
![这里写图片描述](https://img-blog.csdn.net/20180407200551994?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzE2NjMzNDA1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)[ ](https://img-blog.csdn.net/20180407200551994?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzE2NjMzNDA1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
2.统一的数据访问方式
![这里写图片描述](https://img-blog.csdn.net/20180407200600225?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzE2NjMzNDA1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)[ ](https://img-blog.csdn.net/20180407200600225?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzE2NjMzNDA1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
3.兼容Hive
![这里写图片描述](https://img-blog.csdn.net/20180407200607851?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzE2NjMzNDA1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)[ ](https://img-blog.csdn.net/20180407200607851?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzE2NjMzNDA1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
4.标准的数据连接
![这里写图片描述](https://img-blog.csdn.net/20180407200614461?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzE2NjMzNDA1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
## 1.2、DataFrames
**1.2.1、什么是DataFrames**
**与RDD类似，DataFrame也是一个分布式数据容器。**然而**DataFrame更像传统数据库的二维表格，除了数据以外，还记录数据的结构信息**，**即schema**。同时，与Hive类似，DataFrame也支持嵌套数据类型（struct、array和map）。从API易用性的角度上 看，DataFrame API提供的是一套高层的关系操作，比函数式的RDD API要更加友好，门槛更低。由于与R和Pandas的DataFrame类似，Spark DataFrame很好地继承了传统单机数据分析的开发体验。
![这里写图片描述](https://img-blog.csdn.net/20180407200751148?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzE2NjMzNDA1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)[ ](https://img-blog.csdn.net/20180407200751148?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzE2NjMzNDA1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
**1.2.2、创建DataFrames**
在Spark SQL中SQLContext是创建DataFrames和执行SQL的入口，在spark-1.5.2中已经内置了一个sqlContext。
1.在本地创建一个文件，有三列，分别是id、name、age，用空格分隔，然后上传到hdfs上
```python
hdfs dfs -
```
```python
put
```
```python
person.txt /
```
2.在spark shell执行下面命令，读取数据，将每一行的数据使用列分隔符分割
```python
val lineRDD=sc
```
```python
.textFile
```
```python
(
```
```python
"hdfs://node1.itcast.cn:9000/person.txt"
```
```python
)
```
```python
.map
```
```python
(_
```
```python
.split
```
```python
(
```
```python
" "
```
```python
))
```
3.定义case class（相当于表的schema）
```python
case
```
```python
class
```
```python
Person(id:
```
```python
Int
```
```python
, name:
```
```python
String
```
```python
, age:
```
```python
Int
```
```python
)
```
4.将RDD和case class关联
```python
val personRDD = lineRDD
```
```python
.map
```
```python
(
```
```python
x
```
```python
=> Person(
```
```python
x
```
```python
(
```
```python
0
```
```python
)
```
```python
.toInt
```
```python
,
```
```python
x
```
```python
(
```
```python
1
```
```python
),
```
```python
x
```
```python
(
```
```python
2
```
```python
)
```
```python
.toInt
```
```python
))
```
5.将RDD转换成DataFrame
```python
val personDF
```
```python
=
```
```python
personRDD.toDF
```
6.对DataFrame进行处理
```python
personDF.
```
```python
show
```
![这里写图片描述](https://img-blog.csdn.net/20180407201103786?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzE2NjMzNDA1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
## 1.3、DataFrame常用操作
**1.3.1、DSL风格语法**
```python
//查看DataFrame中的内容
personDF
```
```python
.show
```
```python
//查看DataFrame部分列中的内容
personDF
```
```python
.select
```
```python
(personDF
```
```python
.col
```
```python
(
```
```python
"name"
```
```python
))
```
```python
.show
```
```python
personDF
```
```python
.select
```
```python
(col(
```
```python
"name"
```
```python
), col(
```
```python
"age"
```
```python
))
```
```python
.show
```
```python
personDF
```
```python
.select
```
```python
(
```
```python
"name"
```
```python
)
```
```python
.show
```
```python
//打印DataFrame的Schema信息
personDF
```
```python
.printSchema
```
```python
//查询所有的name和age，并将age+1
```
```python
personDF
```
```python
.select
```
```python
(
```
```python
col(
```
```python
"id"
```
```python
)
```
```python
,
```
```python
col(
```
```python
"name"
```
```python
)
```
```python
,
```
```python
col(
```
```python
"age"
```
```python
)
```
```python
+ 1)
```
```python
.show
```
```python
personDF
```
```python
.select
```
```python
(
```
```python
personDF(
```
```python
"id"
```
```python
)
```
```python
,
```
```python
personDF(
```
```python
"name"
```
```python
)
```
```python
,
```
```python
personDF(
```
```python
"age"
```
```python
)
```
```python
+ 1)
```
```python
.show
```
![这里写图片描述](https://img-blog.csdn.net/20180407201520155?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzE2NjMzNDA1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
```python
//过滤age大于等于
```
```python
18
```
```python
的
personDF
```
```python
.filter
```
```python
(col(
```
```python
"age"
```
```python
) >=
```
```python
18
```
```python
)
```
```python
.show
```
![这里写图片描述](https://img-blog.csdn.net/20180407201530718?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzE2NjMzNDA1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
```python
//按年龄进行分组并统计相同年龄的人数
personDF
```
```python
.groupBy
```
```python
(
```
```python
"age"
```
```python
)
```
```python
.count
```
```python
()
```
```python
.show
```
```python
()
```
![这里写图片描述](https://img-blog.csdn.net/20180407201544419?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzE2NjMzNDA1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
**1.3.2、SQL风格语法**
如果想使用SQL风格的语法，需要将DataFrame注册成表
```python
personDF
```
```python
.registerTempTable
```
```python
(
```
```python
"t_person"
```
```python
)
```
```python
//查询年龄最大的前两名
sqlContext.sql("
```
```python
select
```
```python
*
```
```python
from
```
```python
t_person
```
```python
order
```
```python
by
```
```python
age
```
```python
desc
```
```python
limit
```
```python
2
```
```python
").show
```
![这里写图片描述](https://img-blog.csdn.net/20180407201634546?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzE2NjMzNDA1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
```python
//显示表的Schema信息
sqlContext
```
```python
.sql
```
```python
(
```
```python
"desc t_person"
```
```python
)
```
```python
.show
```
![这里写图片描述](https://img-blog.csdn.net/2018040720165266?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzE2NjMzNDA1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
# 总结：
对于SparkSQL来说，目前博主也只是做了一个简单的了解。希望各位通过该文章能学到以下几点：
1、知道SparkSQL内部是将对应的SQL转换为RDD来处理的。
2、知道SparkSQL是什么以及有什么优缺点。
3、最重要的一点是知道SparkSQL一些常用的操作。

