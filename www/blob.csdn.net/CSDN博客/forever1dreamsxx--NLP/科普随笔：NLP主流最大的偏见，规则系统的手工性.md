
# 科普随笔：NLP主流最大的偏见，规则系统的手工性 - forever1dreamsxx--NLP - CSDN博客


2013年07月04日 09:31:15[forever1dreamsxx](https://me.csdn.net/forever1dreamsxx)阅读数：1160


转载地址：[http://blog.sciencenet.cn/blog-362400-701815.html](http://blog.sciencenet.cn/blog-362400-701815.html)
原文下面的评论也很不错！
NLP（Natural Language Processing）主流对规则系统和语言学家大小偏见积久成堆，这一条可以算是万偏之源。随便翻开计算语言学顶级会议的论文，无论讨论什么语言现象，为了论证机器学习某算法的优越，在对比批评其他学习算法的同时，规则系统大多是随时抓上来陪斗的攻击对象，而攻击的理由往往只有这么一句话，规则系统的手工性决定了
 blah blah（“其难以开发”, “其不能 scale up”，“其效率低下”，“其不鲁棒”，等等），或者干脆不给具体理由，直接说“文献【1】【2】【3】尝试了这个问题的不同方面，但这些系统都是手工编制的”，一句话判处死刑，甚至不用讨论它们的效果和质量。手工性几乎成了规则系统的“原罪”，编制这些系统的人因此成为学术共同体背负原罪的二等公民。

手工编制（hand-crafted）怎么了？在日常消费品领域，这是道地的褒义词，是特别的嘉奖，是批量机械化生产和千篇一律的反动，是独特和匠心的代表，是高价格理直气壮的理由。怎么到了NLP领域，突然就成了带有原罪的贬义词了呢。这是因为在NLP领域，代表主流的精算师们由于他们在NLP某些任务上的非凡成功，使得他们居功自傲，把成功无限推广和夸大，给这个community
 施行了集体催眠术，让人相信机器学习是万能的。换句话说，批判手工编制的劣根性，其隐含的前提是机器学习是万能的，有效的，首选的。而实际情况是，面对自然语言的复杂性，机器学习只是划过了语言学的冰山一角，远远没有到主流们自觉和不自觉吹嘘的如入无人之地的万能境界。催眠的结果是不独不少语言学家以及NLP相关利益方（stake
 holders，如投资人和用户）被他们洗脑了，连他们自己也逐渐相信了自己编制的神话。

真实世界中，NLP 是应用学科，最终结果体现在应用软件（applications）上，属于语言软件工程。作为一个产业，软件工程领域吸引了无数软件工程师，虽然他们自嘲为“码工”，社会共同体给予他们的尊重和待遇是很高的（Bill
 Gates 自封了一个 Chief Engineer，说明了这位软件大王对工匠大师的高度重视）。古有鲁班，现有码师（coding master）。这些码工谁不靠手工编制代码作为立足之本呢？没听说一位明星工程师因为编制代码的手工性质而被贬损。同是软件工程，为什么计算语言学家手工编制NLP代码与其他工程师手工编制软件代码遭遇如此不同的对待。难道NLP应用比其他应用简单？恰恰相反，自然语言的很多应用比起大多数应用（譬如图形软件、字处理软件等等）更加复杂和艰难。解释这种不同遭遇的唯一理由就是，作为大环境的软件领域没有NLP主流的小环境里面那么多的傲慢和偏见。软件领域的大牛们还没有狂妄到以为可以靠自动编程取代手工编程。他们在手工编程的基础建设（编程架构和开发环境）上下功夫，而不是把希望寄托在自动编程的万能上。也许在未来的某一天，一些简单的应用可以用代码自动化来实现，但是复杂任务的全自动化从目前来看是遥遥无期的。不管从什么标准来看，非浅层的自然语言分析和理解都是复杂任务的一种。因此，机器学习作为自动编程的一个体现是几乎不可能取代手工代码的。规则系统的NLP应用价值会长期存在。

自动是一个动听的词汇。如果一切人工智能都是自动学习的，前景该有多么美妙。机器学习因为与自动连接在一起，显得那么高高在上，让人仰视。它承载着人类对未来世界的幻想。这一切理应激励自动学习专家不断创新，而绝不该成为其傲慢和偏见的理由。

在下面具体论述所谓规则系统的知识瓶颈软肋之前，值得一提的是，所谓自动是指系统的开发，不要混淆为系统的应用。在应用层面，无论是机器学习出来的系统，还是手工编制的系统，都是全自动地服务用户的，这是软件应用的性质决定的。这虽然是显而易见的事实，可确实有人被误导，一听说手工编制，就引申为基于规则系统的应用也是手工的，或者半自动的。

手工编制NLP系统是不是规则系统的知识瓶颈？毋庸讳言，确实如此。这个瓶颈体现在系统开发的周期上。但是，这个瓶颈是几乎所有大型软件工程项目所共有的，是理所当然的资源costs，不独为
 NLP “专美”。从这个意义上看，以知识瓶颈诟病规则系统是可笑的，除非可以证明对所有NLP项目，用机器学习开发系统比编制规则系统，周期短而且质量高（个别的项目可能是这样，但一般而言绝非如此，下面还要详谈）。大体说来，对于NLP的浅层应用（譬如中文切词，专名识别，等等），没有三个月到半年的开发，没有至少一位计算语言学家手工编制和调试规则和至少半个工程师的平台层面的支持，是出不来系统的。对于NLP的深层应用（如句法分析，舆情抽取等），没有至少一年的开发，涉及至少一位计算语言学家的手工编制规则，至少半个质量检测员的协助和半个工程师的平台支持，外加软件工程项目普遍具有的应用层面的用户接口开发以及把开发出来的NLP引擎deploy到大数据上去的
 operations 的投入，也是出不来 real life 的软件产品的。当然需要多少开发资源在很大程度上决定于开发人员（包括作为知识工程师的计算语言学家）的经验和质量。譬如让立委来开发中文系统（或英文、法文系统），就比找年轻语言学家快得多，以一当十绝不是自夸。其实，即便是10个新手，也未见得能做出立委的系统来，因为自然语言里面所牵涉到问题的复杂度不是拼时间就可以完成的。

计算语言学家编制规则系统与软件工程师编写程序没有本质不同。不过是所用的语言、形式框架和开发平台（language，formalism
 & development platform）不同而已，系统设计和开发的测重点不同而已。这就好比现代的工程师用所谓高级语言 Java 或者 C，与30年前的工程师使用汇编语言的对比一样，本质是一样的编程，只是层次不同罢了。在为NLP特制的“高级”语言和平台上，计算语言学家可以不用为
 memory allocation 等非语言学的工程细节所羁绊，一般也不用为代码的优化和效率而烦扰，他们的注意力更多地放在面对自然语言的种种复杂现象，怎样设计语言处理的架构和流程，怎样突破规则系统的框架与其他语言处理包括机器学习进行协调，怎样平衡语言条件的宽窄，怎样与QA（质量检测）协调确保系统开发的健康，怎样保证语言学家团队编制规则的操作规范以确保系统的可持续性（data
 driven，unit testing，regression testing，code review，maintenability，baselines，等等等等），怎样根据语言开发需求对于现有形式框架的限制提出扩展要求，以及怎样保证复杂系统的鲁棒性等等。一个领头的计算语言学家就是一个系统的架构师，系统的成败绝不仅仅在于语言规则的编制及其堆积，更多的决定于系统架构的合理性。不要把村干部不当干部，也不要把知识工程师（计算语言学家）不当工程师。很多人由于根深蒂固的偏见，把计算语言学家一律当作资料员，殊不知能够在NLP规则系统中统领项目的计算语言学家，绝不是只要知道某个语言的syntax这些皮毛就可以胜任的。明星工程师是软件企业的灵魂，NLP
 规则系统的大规模成功也一样召唤语言工程大师。

关于知识瓶颈的偏见，必须在对比中评估。规则系统需要语言学家手工开发的资源投入，机器学习也同样需要资源的投入，不过是资源方式不同而已。真实的情况是这样的：自然语言处理需要语言学知识，把这些知识形式化是每个NLP系统的题中应有之义，机器学习绝不会自动免疫，无需知识的形式化。具体说，机器学习的知识瓶颈在于data，大量的大量的data。排除研究性强实用性弱的无监督学习（unsupervised
 learning），机器学习中可资开发系统的方法是有监督的学习（supervised learning）。有监督的学习能开发知识系统成为应用的前提是必须有大量的手工标注的数据，作为学习的源泉。机器学习的算法是自动的（算法的创新、调试和实现当然还是手工的，可这种手工被认为是最高级劳动，=），而语言学家的手工规则甚至系统架构则被认为是资料员的低端工作，损人与自夸，无出其右），但是大量的数据标注则是手工的（本来就有现成标注的不算，那是例外）。因此，机器学习同样面临知识瓶颈，不过是知识瓶颈的表现从需要少量的知识工程师变成需要大量的低端劳动者（懂得语言及其任务的大学生或中学生即可胜任）。马克思说金钱是一般等价物，知识瓶颈的问题于是转化为高级劳动低级劳动的开销和转换问题：雇佣一个知识工程师的代价大，还是雇佣10个大学生的代价大？虽然这个问题根据不同项目不同地区等因素答案会有不同，但所谓机器学习没有知识瓶颈的神话可以休矣。

另外，知识瓶颈的对比问题不仅仅是针对一个应用而言，而应该放在多应用的可移植性上来考察。我们知道绝大多数NLP应用的技术支持都源于从自然语言做特定的信息抽取。由于机器学习把信息抽取看成一个直接对应输入和输出的黑匣子，所以一旦改变信息抽取目标和应用方向，以前的人工标注就废弃了，作为知识瓶颈的标注工作必须完全重来。可是规则系统不同，它可以设计成一个规则层级体系，独立于领域和应用方向的语言学规则组件（parsers）以及在语言学之上的针对领域和应用的信息抽取规则子系统。结果是，在转移应用目标时候，底层的语言学组件基本保持不变，而只需要重新编写不同的信息抽取规则而已。实践证明，对于规则系统，真正的知识瓶颈在语言学组件的构建上，而信息抽取本身花费不多。这是因为前者需要应对自然语言变化多端的表达方式，把它逻辑化，而后者是建立在逻辑形式（logical
 form）上的规则，一条等价于底层规则的几百上千条。因此，从多应用的角度看，机器学习的知识成本最终会远远大于规则系统。


