
# PRML-系列一之1.2.2~1.2.3 - 蜗牛 - CSDN博客


2015年05月10日 02:02:37[会敲键盘的猩猩](https://me.csdn.net/u010182633)阅读数：552标签：[期望和方差																](https://so.csdn.net/so/search/s.do?q=期望和方差&t=blog)[贝叶斯概率																](https://so.csdn.net/so/search/s.do?q=贝叶斯概率&t=blog)[
							](https://so.csdn.net/so/search/s.do?q=期望和方差&t=blog)个人分类：[PRML																](https://blog.csdn.net/u010182633/article/category/3186993)



## 期望和方差
涉及概率最重要的操作是找到函数的加权平均值。在概率分布p（x）情况下函数f（x）的平均值称为f（x）的期望，并用E [f]表示。对于一个离散分布，它由下式给出：
![这里写图片描述](https://img-blog.csdn.net/20150509210539215)[ ](https://img-blog.csdn.net/20150509210539215)
使得平均值加权到不同x值的相应概率上。连续变量的情况下，期望用相应概率密度的积分表达：
![这里写图片描述](https://img-blog.csdn.net/20150509211123555)[ ](https://img-blog.csdn.net/20150509211123555)
对任意一种情况，如果我们给定一个有限的N个点，他们从概率分布或概率密度中得到，则期望可以近似为这些点上的有限和：
![这里写图片描述](https://img-blog.csdn.net/20150509211327011)[ ](https://img-blog.csdn.net/20150509211327011)
当我们在第11章中讨论抽样方法时，将广泛使用这个结果。（1.35）中的近似值在N→∞时变得精确。
有时候，我们会考虑多个变量函数的期望，在这种情况下，我们可以用一个下标来表示被平均过的变量，例如：
![这里写图片描述](https://img-blog.csdn.net/20150509212037683)[ ](https://img-blog.csdn.net/20150509212037683)
表示函数f（x，y）对于x分布的平均值。注意（1.36）将是y的一个函数。
我们也可以考虑条件分布的条件期望：
![这里写图片描述](https://img-blog.csdn.net/20150509212458547)[ ](https://img-blog.csdn.net/20150509212458547)
f（x）的方差定义如下：
![这里写图片描述](https://img-blog.csdn.net/20150509212638574)[ ](https://img-blog.csdn.net/20150509212638574)
它提供了函数f（x）与平均值E[f（x）]有多少差异的度量。扩大到平方，我们看到方差也可以写成函数f（x）和f（x）^2期望的形式:
![这里写图片描述](https://img-blog.csdn.net/20150509212916085)[ ](https://img-blog.csdn.net/20150509212916085)
特别的，我们可以考虑x本身的方差，形式如下:
![这里写图片描述](https://img-blog.csdn.net/20150509213248170)[ ](https://img-blog.csdn.net/20150509213248170)
对于两个随机变量x和y，他们的协方差定义如下：
![这里写图片描述](https://img-blog.csdn.net/20150509213209011)[ ](https://img-blog.csdn.net/20150509213209011)
它表达了x和y一起变化的范围。如果x和y是独立的，那么协方差变成零。
当随机变量x和y是两个向量时，协方差是一个矩阵：
![这里写图片描述](https://img-blog.csdn.net/20150509214115312)[ ](https://img-blog.csdn.net/20150509214115312)
如果我们考虑向量x与自身的协方差，那么我们有一个更简单的符号表示：cov[x] ≡ cov[x, x]。
[

](https://img-blog.csdn.net/20150509214115312)
## 贝叶斯概率
[
](https://img-blog.csdn.net/20150509214115312)到目前为止，我们一直从随机、重复事件的频率方面来观察概率。我们将把它当做古典或频率论的概率解释。现在我们转向更一般的贝叶斯观点，其中概率提供了不确定性的量化。
考虑不确定事件，例如月亮是否曾经在其自己的轨道绕太阳转，或者北极冰盖是否会在本世纪底消失。这些不是重复许多次就能像我们之前水果箱的情况那样定义概率概念的事件。尽管如此，我们也有一些想法，例如，我们考虑极地冰层融化的多么快。如果我们现在获得了新的证据，例如从一个新的地球观测卫星上收集到诊断信息，我们就可以修改我们对冰损失率的观点。我们对这些事项的评估将影响我们采取的行动，例如我们努力减少温室气体排放的程度。在这种情况下，我们希望能以量化我们不确定性的表达并且用新的证据做出精确的不确定性修订，随后就能够采取最佳的行动或决定。这都可以通过优雅且非常普通的贝叶斯概率解释实现。
然而，使用概率表示不确定性不是一个专门的选择，但是，如果我们要尊重常识同时得到合理的一致性推论，它就是不可避免的。例如，Cox（1946）表明如果数值用来表示置信度，那么一个简单的编码常识性质的公理集导致唯一的一套操纵置信度规则，该规则与概率的求和与乘积规则等价。这提供了第一个概率论可被视为布尔逻辑扩展的证明，其中布尔逻辑涉及到不确定性（Jaynes，2003年）的情况。许多其他作者提出了不同的属性集或公理集，这类不确定性方法都是满足的（Ramsey，1931年Good，1950年，Savage，1961年; deFinetti，1970年;Lindley，1982）。在每一种情况下，产生的数字量根据概率规则精确地表现。因此，自然要参考这些数量作为（贝叶斯）概率。
在模式识别领域中，有更一般的概率概念是有帮助的。考虑第1.1节所讨论的多项式曲线拟合。应用频率论概念到观测变量tn的随机值似乎是合理的。然而，我们想解决并量化不确定性，该不确定性围绕模型参数w的合适选择。我们应当看到，从贝叶斯的角度看，我们可以使用概率论来描述模型参数（如w）的不确定性，或者是模型本身的选择。
现在贝叶斯定理获得了新的意义。回想一下，在水果箱的例子中，水果身份的观测提供了改变所选择的箱子是红色的相关信息。在该示例中，通过加入由观测数据所提供的证据，贝叶斯定理变换先验概率为后验概率。正如我们之后将要看到的细节，当作数量（例如多项式曲线拟合例子中的参数w）的推论时，我们可以采取类似的做法。在观测数据之前，我们捕捉关于w的假设，用先验概率分布p（w）的形式。观察数据D= {t1，， ，tn}的作用通过条件概率p（D | w）来表达，我们将在后面第1.2.5节看到它能被多么明确地表示。贝叶斯定理采取的形式如下：
![这里写图片描述](https://img-blog.csdn.net/20150510000812132)[ ](https://img-blog.csdn.net/20150510000812132)
然后我们在知道了观测D后就能估计w的不确定性。
贝叶斯定理的右侧p（D | w）被评估为观察到的数据集D并且可以被看作是参数向量w的函数，在这种情况下，它被称为似然函数。它表达了观测数据集支持参数向量w不同设置的可能性大小。需要注意的是似然不是w上的概率分布，并且对w的积分不等于一。
给定了似然分布，那么我们就可以用词语来陈述贝叶斯定理：
![这里写图片描述](https://img-blog.csdn.net/20150510001911920)[ ](https://img-blog.csdn.net/20150510001911920)
其中，所有这些量都被看作是w函数。（1.43）的分母是归一化常数，这保证了左侧的后验分布是一个有效的概率密度并整合到一。事实上，对于整合（1.43）的两侧，我们用先验分布和似然函数的形式来表达贝叶斯定理中的分母：
![这里写图片描述](https://img-blog.csdn.net/20150510002416230)[ ](https://img-blog.csdn.net/20150510002416230)
在贝叶斯和频率论范式中，似然函数p（D | w）都起着核心的作用。然而，使用它的方式是完全不同的两种方法。在频率论设置中，w是一个固定的参数，其值由某种’估计’的形式确定，这个估计的误差带通过考虑可能数据集D的分布得到。与此相反，根据贝叶斯的观点，只存在一个数据集D（即被实际观察到的数据集），并且通过w上的概率分布来表达参数的不确定性。
一种广泛使用的频率论估计器是最大似然，其中w被设为最大化似然函数p（D | w）的值。这对应于选择w的值，该值使观察数据集的概率最大。在机器学习文献中，似然函数的负对数称为误差函数。因为负对数是单调递减函数，最大化似然相当于最小化误差。
确定频率论误差线的一种方法是bootstrap（Efron，1979;Hastie等人，2001），其中多个数据集被创建如下。假设我们的原始数据集包括N个数据点X ={x1，， ，xN}。我们在X上用抽出放回的方式随机选N个点来创建一个新的数据集XB，从而X上的某些数据集可能被复制到XB中，而其他的点可能被XB抛弃。这个过程可以重复L次以产生L个数据集。通过查看不同bootstrap数据集之间预测的变化来评估参数估计的统计精度。
贝叶斯视点的一个优点是先验知识自然出现。例如，假设一枚硬币扔3次且每次头朝下，那么头朝下概率的古典最大似然估计是1，这意味着之后所有的抛掷将头朝下！与此相反，有合理先验的贝叶斯方法将很少产生极端的结论。
目前，关于频率论和贝叶斯范式的相对价值有很多争论和辩论，对于没有任何独特的频率论或贝叶斯视点这个事实来说，这些都是没有帮助的。例如，贝叶斯方法的一个常见批评是先验分布往往在数学便利的基础上选择出来的，而不是作为一个任何先验置信的映射。甚至结论（依赖于先验选择）的主观性是困难的来源。减少对先验的依赖是所谓无信息先验的一个动机。然而，当比较不同模型时，这些导致了一些困难，基于糟糕先验的贝叶斯方法可以更自信的给出差的结果。频率论评价方法提供了来自此问题的一些保护和技术，例如交叉验证在模型比较领域依然是有用的。
本书非常强调贝叶斯观点，反映了在过去的几年中贝叶斯方法的实际重要性有巨大的增长，同时根据需要还讨论了频率论概念
虽然贝叶斯框架起源于18世纪，但由于进行完整的贝叶斯过程比较困难，特别是需要在整个参数空间边缘化（求和或积分），正如我们将看到的，为了预测或比较不同的模型，这是必须的，所以贝叶斯方法的实际应用很长时间内都被限制着。采样方法的发展，例如马尔可夫链蒙特卡洛（第11章讨论）以及计算机在速度和存储器容量上显着的改善，用令人印象深刻的问题域范围打开了贝叶斯技术实际应用的大门。蒙特卡洛方法非常灵活，可以被应用到大范围的模型。然而，它们在计算上是密集的并主要被用于小规模的问题。
最近，高效确定性近似方案如变贝叶斯和期望传播（第10章中讨论）已被开发出来。这些提供了抽样方法的互补替代，并允许贝叶斯技术使用在大规模应用中（Blei等人，2003）。

