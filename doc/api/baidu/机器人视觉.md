# 机器人视觉 



# 产品介绍

# 产品简介

百度机器人视觉平台的立体惯性相机模组具有三维空间定位，障碍物检测，和物体识别功能。产品具有定位准确度高，延迟低，障碍物检测距离远，不受阳光照射影响，物体检测种类多，准确度高等优点。该专利产品由世界顶尖研发人员历时多年开发，应用了传感器融合，深度学习，和硬件优化等核心技术。立体惯性相机可以支持主流的PC、ARM平台。如果选配合百度机器人视觉平台的计算芯片，软件系统无需占用上位机资源。立体惯性相机已有多个应用案例，可以应用于机器人领域做导航避障，或者应用于可穿戴设备做头部跟踪。

# 硬件构成

![img](https://ai.bdstatic.com/file/86EF0E592080484286E77B335B41D0F9)上图是由百度及其硬件供应商提供的试用模组：

- 模组的硬件包含两个摄像头（可换）和一个六轴IMU
- 基线（两摄像头间距）可调6-20cm （试用模组已固定）
- 内置驱动，Linux下无需额外安装 照相机与IMU时钟硬件同步，精度10us

# 产品性能

| 功能模块             | 技术指标                                                    |
| :------------------- | :---------------------------------------------------------- |
| 照相机               | 90 – 170 FOV, Global Shutter, VGA                           |
| 惯性传感器           | Gyroscope +- 1000 DPS Accelerometer +- 8 G                  |
| 驱动接口             | USB 3.0 或 2.0 支持 x86 或 ARM 平台                         |
| 使用场景             | 居家场景、办公场所、商场等                                  |
| 三维空间定位         | 6自由度，延迟小于10毫秒                                     |
| 空间定位误差         | 无已知地图时小于 1% 行走距离 有已知地图时小于 0.5% 地图尺寸 |
| 障碍物检测范围       | 0最近0.2米，最远 50米                                       |
| 障碍物检测误差       | 障碍物到相机距离的1%                                        |
| 物体、文字、人脸识别 | 连接百度API                                                 |





# 环境安装

# 系统要求

- 硬件平台：x86(不支持32位)或者ARM（仅供商务合作客户）
- CPU：intel core i5（4000系列以上）或者i7（4000系列以上）
- 操作系统：Linux 14.04/16.04，不支持虚拟机

# 环境配置

- 试用模组对应的软件包含两个压缩包，其中命名为3rdparty_lib_lean_MM-DD-YY.tar.gz是环境安装包，打开命令行
- 运行以下命令行以解压，创建目录和安装第三方库：

```
mkdir ~/XP_release
tar -xvf [3rdparty_lib_lean_mmddyyy.tar.gz] -C ~/XP_release
source 3rdparty_lib_lean/update.sh
```

注意：此处路径需要固定为 ~/XP_release，因为后续的脚本全部都会去此处找第三方库。若想使用识别功能，请在运行`update.sh`时加参数 `-enable_recognition`

- *（非必需）* 如果需要之后在本地编译我们提供的范例程序，此时还应该装如下库：

```
sudo apt-get install build-essential cmake libgflags-dev libgoogle-glog-dev
```

- 另一个压缩包命名为XX.YY.ZZ.tar.gz，这是我们的程序及sdk包，其中XX.YY.ZZ为版本号。可以把程序包也解压到 ~/XP_release路径下。



# 参数校正

# 简介

摄像头的标定以及参数校正是至关重要的一步，匹配的参数才能保证程序运行时的良好效果。由于我们的试用模组固定在铁盒中，且在寄出试用套装时已经对每一个模组进行过校正，因此大部分情况下拿到后可以直接引入我们提供的校正文件使用。但如果出现磕碰或是镜头被触碰过，或者发现运行效果不够好，就需要进行重新校正以达到最佳效果（也建议每隔一段时间校正一次）。

# 准备工作

- scripts文件夹下的脚本（.sh）文件中的第一行因release方式不同，可执行程序的路径会有不同。直接使用bin文件夹下的二进制文件运行时从脚本的第二行开始运行对应命令即可。

- 设置环境变量。在根目录下运行：

  ```
  source config_environment.sh
  ```

- 执行命令, 新建校正相关的文件夹:

  ```
  sh ${MASTER_DIR}/pc_apps/scripts/folders.sh
  ```

  or

  ```
  sh ${MASTER_DIR}/scripts/folders.sh
  ```

- 用A4纸打印一张程序包根目录下的ApritTag5x7.png图片，将打印好的纸放在平坦的桌面上，并用尺子测量途中任一个二维码的矩形边长（根据打印纸张以及页边距的不同，不同打印机打印出来的边长稍有差异，请仔细测量，并精确到毫米，一般为3cm左右)。

![img](https://ai.bdstatic.com/file/825D9CFB4EFF48289B19FC501A14BA1A)

# 采集数据

校正的第一步是采集数据，数据的采集决定了校正的质量，请按步骤细心进行。

- 进入之前解压的程序所在的文件夹内，将模组接到PC，运行如下命令：

  ```
  sh ${MASTER_DIR}/pc_apps/scripts/calib_data.sh
  ```

  or

  ```
  sh ${MASTER_DIR}/scripts/calib_data.sh
  ```

- 拿起模组，按照以下方式采集图像（按一次空格采集一张）：

  - 采集的时候除了会显示左右镜头视角，还会出现左右镜头二 维码覆盖率，如下图显示。其中红色方框区域代表该区域覆 盖率还需要增加，应继续在该区域采集，直至左右镜头均无 红色方框为止。 ![img](https://ai.bdstatic.com/file/2704775EC4B2403D915E5253B11CC724)
  - **A类图**：二维码图纸所有二维码均在左右镜头中，约20张。
    ![img](https://ai.bdstatic.com/file/825D9CFB4EFF48289B19FC501A14BA1A)
  - **B类图**：二维码图纸中的部分二维码在镜头外（镜头的各个边缘和角落都要被覆盖采集过），可以只保留部分二维码在镜头中，视情况约40张
    ![img](https://ai.bdstatic.com/file/EAB9159088DE48F2B238D5B60F31A6C7)
  - **采集的目的：要尽量使左右镜头中的每一个部分均被二维码覆盖采集过，以保证之后在使用时整个镜头的各个部分的特征点都能被有效还原，所以采集图片数多多益善，40-50张为宜**
  - **若因为镜头安装原因导致边缘总会有方框区域无法覆盖，则可以在采集时加入-valid_radius参数，并减少有效半径值，默认为360**
  - **注意：采集过程中不要让镜头中出现显示屏、镜子、玻璃等物品，否则二维码会在图片中二次呈像，导致整个校正失败！**
  - 采集完成后，按ESC键退出

# 预验覆盖

采集完成后，首先我们来预验覆盖率。

- 在可执行文件路径下运行如下命令：

  ```
  ./cam_calibration -record_path $HOME/Boteye/calibration/images/ -square_size X -show_coverage
  ```

  `cam_calibration` 为我们预验和校正程序：

  - `-record_path` 为之前采集的图像的目录
  - `-square_size` 为上一步中测量的二维码的变长，此处单位为米，例如0.032
  - `-show_coverage` 为根据采集的图片快速显示镜头视角的二维码覆盖率

  如需查看所有参数及其使用方法，可加 `–helpshort`

- 运行完后，程序会读取采集的图片，生成覆盖率图片（生成第一张后，按任意键生成第二张）如下：
  ![img](https://ai.bdstatic.com/file/541C10074980483A8E9EFF89C5038E03)

- 这里需要看点的覆盖率，如果图像采集的好的话（镜头视角的各个部位都被二维码覆盖过），应该看到点均匀地密布在结果图的所有角落

- **若出现某些区域的点不够密，则程序输出的图上会有红色方框（如上图所示），此时需要重复 采集数据 步骤，在该区域补充二维码拍照（无需删除已有照片），直至运行该预验程序时没有任何红框。**

- **若因为镜头安装原因导致边缘总会有方框区域无法覆盖，则可以在运行时加入-valid_radius参数，并减少有效半径值，默认为360**

- 再次按任意键退出程序

# 校正程序

- 覆盖率验证完成后, 修改 `scripts/calib_compute.sh` 中的square size参数之后执行该脚本：

  ```
  sh ${MASTER_DIR}/pc_apps/scripts/calib_compute.sh
  ```

  or

  ```
  sh ${MASTER_DIR}/scripts/calib_compute.sh
  ```

  脚本中`cam_calibration` 为我们的校正运算程序:

  - `-record_path` 为之前采集的图像的目录
  - `-square_size` 为上一步中测量的二维码的变长，此处单位为米，例如0.032
  - `-save_calib_yaml` 指定程序生成的校正文件（yaml格式）的路径和名称
  - `-show_reproj` 为显示采集的图像二维码覆盖面

  需查看所有参数及其使用方法，可加 `-helpshort`

- 根据数据采集的质量，校正程序运行时间从3-20分钟不等，完成后可以看到左右镜头的图像采集的二维码覆盖面，如下图。

  - **绿色**代表效果好的点，**黄色**代表效果不是很好的点，**红色** 代表效果很差的点。若黄色和红色点太多，代表采集的照片很差（一般因为晃动、模糊、光照等原因），则需删除原校正文件夹，重新校正
  - 除了看点的颜色以外，还需看点的覆盖率，如果图像采集的好的话（镜头视角的各个部位都被二维码覆盖过），应该看到点均匀地密布在结果图上，如下图所示
    ![img](https://ai.bdstatic.com/file/F13DDD9AF23E4822A4D4235A7D2A7912)
  - **若在上一步时因为镜头安装原因导致边缘总会有方框区域无法覆盖，加入过-valid_radius参数，则在此步依旧要使用同样的参数**
  - 当两张结果图都出现后，代表程序运行结束，按ESC退出

# 验证效果

- 运行完校正运算程序后，需要验证校正的结果，在可执行文件目录下运行命令：

  ```
  ./xp_sensor_logger -calib_verify -calib_yaml $HOME/Boteye/calibration/calib.yaml -sensor_type XP2
  ```

  `xp_sensor_logger` 为我们的采集／验证程序，其中：

  - `-calib_verify` 表示这是验证模式
  - `-calib_yaml` 为要验证的校正文件
  - `-sensor_type` 为实际使用的模组硬件版本

  如需查看所有参数及其使用方法，可加 `–helpshort`

- 拿起模组，将模组指向二维码图纸，使得两幅图像中都要出现二维码图纸的全部或部分，可以看到左上角会有分数（score），如下图显示：

  - 分数满分为100分
  - 若图纸在镜头视角中间时不是100分，需要重新采集并校正
  - 图纸在镜头边缘时分数可能会略低，但若大面积出现小于60分时也需重新采集并校正
    ![img](https://ai.bdstatic.com/file/C59367A921B64B119F3C163200745166)

- 若对校正结果满意，打开新生成的校正文件（上例为$HOME/Boteye/calibration/calib.yaml），将下图中的“Camera:”（在angv_noise_var下面）及以下的部分全部复制，并粘贴覆盖旧的校正文件的对应位置。注意：yaml文件对格式要求极其严格，拷贝过程要保证数据和原来一摸一样（对齐），否则会出错。
  ![img](https://ai.bdstatic.com/file/B32F7D75F2C04F058EE50D705B95DA4A)

- 恭喜！至此，整个校正过程已完成。日常使用时注意保护模组，以防磕碰等行为。若今后使用过程发现效果变差，请重复整个校正过程。



# 范例程序

# 功能说明

- 在校正完成后，就可以运行我们的SLAM&导航范例程序`./app_tracking`
- `app_tracking` 最基本的功能是SLAM算法，在模组移动过程中能够根据环境的特征点绘制出运动轨迹，并且能够在模组移动到起点时闭环
- `app_tracking` 具有深度检测的功能，能够展示深度图和障碍物提示
- `app_tracking` 能够根据环境亮度进行自动曝光
- `app_tracking` 能够将走过的路径存储下来，并且能够读取之前的路径，以达到更精确的效果以及实现重定位
- `app_tracking` 能够使得移动机器人在已存的路径周围进行自主导航和避障

# 环境录制

## 准备工作

- 脚本（.sh）文件中的第一行因release方式不同会有不同。直接使用bin文件夹下的二进制文件运行时从脚本的第二行开始运行对应命令即可。

- 完成校正，参见校正文档 (Roboticvision_Calibration.md)。校正完成之后 将record.sh、navi.sh脚本文件末尾的-calib_file字段的值修改成校正得到的标定（.yaml）文件路径

- 将record.sh、navi.sh脚本文件末尾的-sensor_type字段的值修改成使用的模组硬件型号（如：XP, XP2, XP3等

- 配置环境变量 每次打开新的命令行窗口时，在执行安装包内的其他程序前，需要先执行一次以下命令来设置环境变量（一个窗口只需一次）：

  ```
  source config_environment.sh
  ```

## 录制地图及轨迹

- 设置所要存储录制数据的默认文件夹：

  ```
  record_path=$HOME/Boteye/data/???
  ```

- 执行命令

  ```
  sh ${MASTER_DIR}/pc_apps/scripts/record.sh 参数：存储录制数据的文件夹路径
  ```

  or

  ```
  sh ${MASTER_DIR}/scripts/record.sh 参数：同上
  ```

  如：

  ```
  sh ${MASTER_DIR}/scripts/record.sh $record_path
  ```

- 程序启动后，出现两个窗口如下图所示，此时可以带着模组走动，左窗口显示的红线为运行轨迹的俯视图，右窗口显示左摄像头的呈像，其中的彩色小圆圈为算法标记的特征点。行走过程中程序会针对周围环境的明暗自适应调整曝光值，以达到最佳效果。

  ![img](https://ai.bdstatic.com/file/6A6F95BF4210403A8A341CD7E9633BD5)

- 如果左侧窗口右上角显示标定分数小于80，说明校准有问题，需要重新进行校正。

- 行走时，若轨迹回到之前录制的某个位置时，终端可能会出现 `loop closure detected`打印信息，程序会尝试闭环，修正建图过程中的累积误差（需要几秒钟）。此时请停止走动，等待程序回环优化完成，地图路径优化完成后继续录制，否则将会出现路径点的跳变。成功闭环后的效果如下图：
  ![img](https://ai.bdstatic.com/file/84290E70764D46C187E6D44CCF663A51)

- 按ESC键后会自动将当前录制的地图保存到文件中，并退出当前程序。

- 如果房间很大，需要离线处理（例如超过2000平米），请联系我们协助操作。

# 自主导航避障

## 准备工作

- 脚本（.sh）文件中的第一行因release方式不同会有不同。直接二进制文件运行时在bin文件夹下从第二行开始运行即可。

- 完成校准，参见校准文档 (Roboticvision_Calibration.md)

- 完成环境录制，参见上一节“环境录制”

- 底盘参数设置

  - 设置选项在XP/config/navigation_param.yaml中的Actuator字段下

  - 底盘类型：

    - 步科底盘：

    ```
    actuator: reeman或dilili
    ```

    - 仅接收UDP速度角速度信息：

    ```
    actuator: sample
    ```

    ```
    UDP协议接收导航信息的使用方法：
    * guide_receiver程序通过UDP传输的方式从app_tracking处接收导航信息，并打印在命令行窗口中。
    * 在navi.sh脚本末尾另加两行（注意在原先的最后一行末尾加“空格\”）, 分别表示运行guide_receiver程序的设备ip和端口：
      ```bash
      --guide_ip=127.0.0.1 \
      --guide_port=8889
      ```
    * 开启除运行navi.sh程序（具体运行方法见下文）的另一个命令行窗口，切换到guide_receiver可执行文件所在目录，运行 ./guide_receiver
    * guide_receiver 收到的信息格式为：
    guide message from [IP]: [PORT] [A, B, C]
    * 用于接收UDP协议的默认端口是8889，IP地址没有限制
    * A为当前线速度控制量（单位：m/s）
    * B为当前角速度控制量（单位：rad/s，逆时针为正）
    * C为导航状态（0：失败，1：正确，2：停止，3：到达目的地结束，4：SLAM定位丢失，5：避障）。
    ```

- 设置环境变量。

  ```
  source config_environment.sh
  ```

- 设置已录制地图数据的默认文件夹：

  ```
  record_path=$HOME/Boteye/data/???
  ```

- 执行导航数据生成程序：

  ```
  python ${MASTER_DIR}/pc_apps/navigation/pre_navigation.py --record_path=$record_path
  ```

  or

  ```
  python ${MASTER_DIR}/bin/pre_navigation.py --record_path=$record_path
  ```

- 确认设备号及赋予读写权限，如：

  ```
  sudo chmod 666 /dev/ttyUSB0
  ```

## 导航模式

- 导航有两种模式，控制参数在

  ```
  ${MASTER_DIR}/XP/config/navigation_param.yaml -> Navigation/mode
  ```

- 鼠标控制模式 (control)

  ```
  mode: control
  ```

- 指定轨迹模式 (loop)

  ```
  mode: loop
  ```

### 鼠标控制导航

- 确认XP/config/navigation_param.yaml中的use_trajectory_file值为false。

- 执行导航命令:

  ```
  sh ${MASTER_DIR}/pc_apps/scripts/navi.sh 参数：之前导航数据生成程序生成的导航文件夹路径
  ```

  or

  ```
  sh ${MASTER_DIR}/scripts/navi.sh 参数：同上
  ```

  如：

  ```
  sh ${MASTER_DIR}/scripts/navi.sh $record_path/navigation/
  ```

- 出现以下窗口：

  ![img](https://ai.bdstatic.com/file/E6A7C285DA72475D87D0AC5820BC45BF)

- 机器人会原地旋转尝试重定位，成功后左上角会显示normal（如果尝试超时后还未重定位成功，则可以通过手动推动机器人进行重定位），右边两个圆会变成一个。

  ![img](https://ai.bdstatic.com/file/D18289F6DB7E44639D45337F927FD689)

- 在以下窗口中点击目标点，出现蓝色的规划轨迹，机器人开始导航。

  ![img](https://ai.bdstatic.com/file/2702DA8E2854470B80E50390FAE6087D)

### 指定轨迹导航

- 确认XP/config/navigation_param.yaml中的use_trajectory_file值为true。

- 生成轨迹，执行：

  ```
  ${MASTER_DIR}/build/pc_apps/navigation/trajectory_maker --navigation_folder=$record_path/navigation/
  ```

  or

  ```
  ${MASTER_DIR}/bin/trajectory_maker --navigation_folder=$record_path/navigation/
  ```

  - 左边为可操作区域，右边显示规划路径

    ![img](https://ai.bdstatic.com/file/67C67C2FC39944B28CA49963447BB3CF)

  - 点击左边图，按空格，按p，确定起点

    ![img](https://ai.bdstatic.com/file/214845259EB24F9982449102CBC447E0)

  - 再在左边图点击目标点，按空格，确定第一个目标点, 按p规划第一段路径

    ![img](https://ai.bdstatic.com/file/94599225517B407CBD5D4726C8581D41)

  - 再点下一个目标点，按空格确认，按p规划路径。

    ![img](https://ai.bdstatic.com/file/E9C759C368AC4F968A0AE76CDD2D2C22)

  - 如此重复直到按ESC结束

- 执行导航命令：

  ```
  sh ${MASTER_DIR}/pc_apps/scripts/navi.sh 参数：之前导航数据生成程序生成的导航文件夹路径
  ```

  or

  ```
  sh ${MASTER_DIR}/scripts/navi.sh 参数：同上
  ```

  如：

  ```
  sh ${MASTER_DIR}/scripts/navi.sh $record_path/navigation/
  ```

## 其他

注意： 若用户需要根据自己的机器人性能、使用场景自定义导航参数，可以在XP/config/navigation_param.yaml和algorithm_param.yaml文件中对诸如机器人结构、运动速度、避障相关的参数进行调节配置。 当navigation_param.yaml中的参数**enable_obstacle_avoid**参数被设置成**true**时将开启自主障碍物绕行功能（此时的屏幕输出的局部地图如下右图所示）。当机器人前方安全距离以内出现障碍物（灰色）时机器人会根据周围障碍物膨胀后的形状（红色）进行局部路径规划（蓝色），尝试对障碍物进行绕行。 ![img](https://ai.bdstatic.com/file/C2CCF486BD764094842361B422C1FF02)

# 深度图+障碍物提示：

- 开启深度图，只需要在navi.sh脚本末尾另加行（注意在原先的最后一行末尾加“空格\”

  ```
  --show_depth
  ```

- 开启后，程序将会在新的窗口显示深度图

# 识别功能

范例程序app_tracking还具有识别功能，目前支持文字、物体、人脸属性检测、人脸识别，识别是通过在线调用百度云端API实现，若需要识别功能，请先去[百度云控制台](https://console.bce.baidu.com/)注册，每个账号每天有一定的免费调用额度。

- 注册完后将会得到三串字符：

- id: 用户的应用id:

- ak: 用户的api key

- sk: 用户的api secret

- 在~/XP_release文件夹下创立/keys文件，将上述密钥用以下格式放在文件中:

  ```
  id=xxxx
  ak=yyyy
  sk=zzzz
  ```

- 启动识别，运行以下命令：

  ```
  ./app_tracking -sensor_type XP2 -calib_file xxxxx.yaml –ocr –face_attribute –face_recognition
  ```

- `-ocr` 为激活文字识别

- `-face_attribute` 为激活人脸属性检测

- `-face_recognition` 为激活人脸识别

- 请根据需要加上述识别的选项，程序启动后等约5秒钟待初始化完成后，在键盘按下字母R键，将调用已激活的识别功能。

- 人脸属性检测和人脸识别的结果会显示在一个新弹出的窗口中，文字识别结果会显示在命令行窗口中。每按一次R键程序会并行调用一次所有已激活的API，并在所有结果返回后刷新一次结果（不用担心一直刷流量）

- 因窗口有限，范例程序只显示了部分结果，完整的结果和调用说明请参考范例程序和官方文档（见下页）
  ![img](https://ai.bdstatic.com/file/46ABCE8B6F264A7FB59FC11DE53EAF0E)









# 开发使用

# 编译程序

- 软件包内除了已经编译好的范例程序以外，还提供了`app_tracking`的源代码供开发者调试和参考，以及sdk供开发者使用。

- app路径下的源代码都是可以编译的，现在我们来编译

  ```
  app_tracking
  ```

  - 首先，我们需要一些额外的库，详情请参考**环境配置**下的*（非必需）*

  - 然后运行以下命令行进行编译：

    ```
    cd app
    mkdir build
    cd build
    cmake ..
    make
    ```

  - 编译好的`app_tracking`将会在build文件夹里面，用法和程序包自带的一样

# 接口调用

- 程序包还带了SDK并开放了接口供开发者自行调用，所有的头文件都在程序包根目录下的`include`文件夹内。
- 开发者可以参考`app_tracking`的源程序`app_tracking.cpp` 来作为`xp_tracker.h`内的各个函数的调用范例，以开发自己的程序。或者改动`app_tracking.cpp`，并按照上述的方式进行编译。







# 附录

# 常见问题

- 我采集了好几次图像，为什么校正时都失败了？
  - 如果重新采集图像，为了避免之前失败图像的影响，需要先删除原先采集的图像所在文件夹，否则只会往里面添加图片
- 我新生成的校正文件不见了？
  - 范例命令中的校正文件存储路径为`/tmp`，这个目录下的文件会随着机器的重启而清空，校正完后务必及时备份校正文件
- 我运行校正程序的时候出错了？
  - 校正程序`cam_calibration`在采集的图像质量很差或者数量不够的时候会出错，此时应删除之前的图像采集文件夹，重新采集图像数据。
  - 二维码图纸需要放置在平坦的平面上，手拿着或者凹凸不平都会造成结果的不准确，建议将图纸贴在一块平坦的白板上。
- 我运行校正程序后显示的点图全都集中在中间？
  - 采集图像时请多采集二维码在镜头成像边缘的情况，一部分的二维码出了边框是可以的。
  - 采集的图片数量尽量多一些，这样能提高校正的精度。
- 我校正好了模组，运行 `app_tracking` 的时候出错了？
  - 是否忘记运行 `source config_environment`?
  - 运行`ls /dev/video*` 看模组有没有被系统识别，可以尝试插拔模组，或者换个USB口
  - 如果出现了core dump，或者程序崩溃，可在运行 `app_tracking` 时添加参数 `-record_path /tmp/record` ，此时会把此次运行的所有帧图片全部存储在对应路径下，然后可以发给我们来跟踪问题。
- 导航参数文件中常用参数作用介绍
  - XP/config/navigation_param.yaml

| 参数名称                | 参数作用                                                     |
| :---------------------- | :----------------------------------------------------------- |
| Actuator:type           | 底盘类型，程序会根据该字段初始化不同的底盘控制类             |
| Actuator:serial_dev     | 底盘控制的 usb 转串口设备地址                                |
| use_trajectory_file     | 是否使用事先规划好的循环路径点文件，只在 mode 为 loop 时生效 |
| T_AD                    | 摄像头坐标系相对于底盘（双轮）中心的旋转矩阵，最右一列为摄像头相对于地盘的坐标，单位为米 |
| fuse_wheel_odom_pose    | 是否采用码盘，码盘可以辅助定位，在视觉丢失定位时使程序可以继续导航，如需使用码盘请联系我们 |
| wheel_odom_vel_feedback | 采用码盘的刻度计返回的刻度来计算当前速度，用于优化 PD 控制器的输出 |
| lost_recovery_timeout   | 程序一开始机器人自转定位超时时间                             |
| enable_obstacle_avoid   | PD 控制模式下，是否在遇到障碍物时开启绕行                    |
| safe_obstacle_distance  | 触发避障时障碍物距离                                         |
| road_width              | 道路宽度，机器人避障不会走出该宽度规定范围                   |
| v_max                   | PD 控制模式下的机器人最大速度                                |

- XP/config/algorithm_param.yaml

| 参数名称         | 参数作用                                                   |
| :--------------- | :--------------------------------------------------------- |
| height_below_cam | 地面想对于摄像头的高度，用于在导航时避免将地面识别为障碍物 |
| height_above_cam | 天花板想对于摄像头的高度，作用同上                         |



