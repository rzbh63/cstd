## 如何成为一名推荐系统工程师



作者 | 陈开江

责编 | 何永灿



**推荐系统工程师技能树**



**掌握核心原理的技能**



- **数学：**微积分，统计学，线性代数 
- **周边学科：**信息论基础 
- **推荐算法：**CF，LR，SVM，FM，FTRL，GBDT，RF，SVD，RBM，RNN，LSTM，RL 
- **数据挖掘：**分类，聚类，回归，降维，特征选择，模型评价



**实现系统检验想法的技能：**



- **操作系统：**Linux 
- **编程语言：**Python/R， Java/C++/C，sql，shell 
- **RPC框架：**thrift， Dubbo，gRPC 
- **web服务：**tornado, django, flask
- **数据存储：**redis, hbase, cassandra, mongodb, mysql, hdfs，hive, kafka, elasticsearch 
- **机器学习/深度学习：**Spark MLib，GraphLab/GraphCHI，Angel，MXNet，TensorFlow，Caffe, Xgboost，VW，libxxx 
- **文本处理：**Word2vec，Fasttext，Gensim，NLTK 
- **矩阵分解：**Spark ALS，GraphCHI，implicit，qmf，libfm 
- **相似计算：**kgraph, annoy，nmslib, GraphCHI, columnSimilarities(spark.RowMatrix) 
- **实时计算：**Spark Streaming, Storm，Samza



**为效果负责的技能**



- **熟悉常见离线效果指标：**准确率，召回率，AUC，基尼系数 
- **能够定义产品效果指标：**点击率，留存率，转换率，观看完整率 
- **会做对比试验并分析实验结果：**指标数据可视化 
- **知道常见推荐产品的区别：**Feed流推荐，相关推荐，TopN推荐，个性化推送



**其他软技能**



- **英文阅读；**读顶级会议的论文、一流公司和行业前辈的经典论文和技术博客，在Quora和Stack Overflow上和人交流探讨； 
- **代码阅读；**能阅读开源代码，从中学习优秀项目对经典算法的实现； 
- **沟通表达；**能够和其他岗位的人员沟通交流，讲明白所负责模块的原理和方法，能听懂非技术人员的要求和思维，能分别真需求和伪需求并且能达成一致。



![img](http://mmbiz.qpic.cn/mmbiz_png/ptp8P184xjxpnfdm8cT1Ay7L8CwcbQSI5xufhOoeOOqzsqekkVJ1du7sco5joGoWc19t6Nia5bJsK0VXuozCLFw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

图1 推荐系统工程师技能树



**推荐系统工程师成长路线图**



《Item-based collaborative filtering recommendation algorithms》这篇文章发表于2001年，在Google学术上显示，其被引用次数已经是6599了，可见其给推荐系统带来的影响之大。

经过20多年的发展，item-based已经成为推荐系统的标配，而推荐系统已经成为互联网产品的标配。很多产品甚至在第一版就要被投资人或者创始人要求必须“个性化”，可见，推荐系统已经飞入寻常百姓家，作为推荐系统工程师的成长也要比从前更容易，要知道我刚工作时，即使跟同为研发工程师的其他人如PHP工程师（绝无黑的意思，是真的）说“我是做推荐的”，他们也一脸茫然，不知道“推荐”为什么是一个工程师岗位。

如今纵然“大数据”， “AI”，这些词每天360度无死角轰炸我们，让我们很容易浮躁异常焦虑不堪，但不得不承认，这是作为推荐系统工程师的一个好时代。

推荐系统工程师和正常码农们相比，无需把PM们扔过来的需求给像素级实现，从而堆码成山；和机器学习研究员相比，又无需沉迷数学推导，憋出一个漂亮自洽的模型，一统学术界的争论；和数据分析师相比，也不需绘制漂亮的图表，做出酷炫的PPT能给CEO汇报，走上人生巅峰。

那推荐系统工程师的定位是什么呢？为什么需要前面提到的那些技能呢？容我结合自身经历来一一解答。我把推荐系统工程师的技能分为四个维度：

- **掌握核心原理的技能**，是一种知其所以然的基础技能；

- **动手能力**：实现系统，检验想法，都需要扎实的工程能力；

- **为效果负责的能力：**这是推荐系统工程师和其他工种的最大区别；

- **软技能：**任何工程师都需要自我成长，需要团队协作。 

- - **英文阅读：**读顶级会议的论文、一流公司和行业前辈的经典论文和技术博客，在Quora和Stack Overflow上和人交流探讨；
  - **代码阅读：**能阅读开源代码，从中学习优秀项目对经典算法的实现；
  - **沟通表达：**能够和其他岗位的人员沟通交流，讲明白所负责模块的原理和方法，能听懂非技术人员的要求和思维，能分别真伪需求并且能达成一致。



**掌握最最基础的原理**

托开源的福气，现在有很多开箱即用的工具让我们很容易搭建起一个推荐系统。但是浮沙上面筑不起高塔，基础知识必须要有，否则就会在行业里面，被一轮轮概念旋风吹得找不着北。所有基础里面，最最基础的当然就是数学了。

能够看懂一些经典论文对于实现系统非常有帮助：从基本假设到形式化定义，从推导到算法流程，从实验设计到结果分析。这些要求我们对于微积分有基本的知识，有了基本的微积分知识才能看懂梯度下降等基本的优化方法。

概率和统计知识给我们建立起一个推荐系统工程师最基本的三观：不要以是非绝对的眼光看待事物，要有用不确定性思维去思考产品中的每一个事件，因为实现推荐系统，并不是像实现界面上一个按钮的响应事件那样明确可检验。大数据构建了一个高维的数据空间，从数据到推荐目标基本上都可以用矩阵的角度去形式化，比如常见的推荐算法：协同过滤、矩阵分解。

而机器学习算法，如果用矩阵运算角度去看，会让我们更加能够理解“向量化计算”和传统软件工程里面的循环之间的巨大差异。高维向量之间的点积，矩阵之间的运算，如果用向量化方式实现比用循环方式实现，高效不少。建立这样的思维模式，也需要学好线性代数。

学好基础的数学知识之外，我们要稍微延伸学习一些信息科学的基础学科，尤其是信息论。信息论是构建在概率基础上的，信息论给了很多计算机领域问题一个基本的框架：把问题看做是通信问题。

推荐系统要解决的问题也是一个通信问题：用户在以很不明确的方式向我们的产品发报，告诉我们他最喜欢/讨厌的是什么，我们在收到了之后要解码，并且还要给他们回信，如果沟通不顺畅，那用户就会失联。我的专业是信息与通信工程。

读研时从事过NLP相关的课题研究，NLP里面很多问题和方法都用到了信息论知识，这样让我深受信息论影响。有了这些基础知识，再去跟踪不断涌现的新算法新模型，就会容易得多。

推荐系统会用到很多传统数据挖掘和机器学习方法。掌握经典的机器学习算法是一个事半功倍的事情，比如逻辑回归，是一个很简单的分类算法，但它在推荐领域应用之广，其他算法无出其右。在吴恩达的深度学习课程里，从逻辑回归入手逐渐讲到多层神经网络，讲到更复杂的RNN等。应该怎么掌握这些经典的算法呢？最直接的办法是：自己从0实现一遍。

推荐系统不只是模型，推荐系统是一整个数据处理流程，所以模型的上游，就是一些数据挖掘的知识也需要掌握，基本的分类聚类知识，降维知识，都要有所掌握。

**锻炼扎实的工程能力**

前面强调自己实现算法对于掌握算法的必要性，但在实际开发推荐系统的时候，如无必要，一定不要重复造轮子。推荐系统也是一个软件系统，当然要稳定要高效。开源成熟的轮子当然是首选。实现推荐系统，有一些东西是common sense，有一些是好用的工具，都有必要列出来。

首当其冲的常识就是Linux操作系统。由于Windows在PC的市场占率的垄断地位，导致很多软件工程师只会在Windows下开发，这是一个非常普遍、严重、又容易被忽视的短板。我自己深有体会，一定要熟练地在Linux下的用命令行编程，如果你的个人电脑是Mac，会好很多，因为macOS底层是Unix操作系统，和Linux是近亲，用Mac的终端基本上类似在Linux下的命令行，如果不是则一定要有自己的Linux环境供自己平时练习，买一台常备的云服务器是一个不错的选择。这里有两个关键点：

1. 用Linux操作系统；
2. 多用命令行而少用IDE（Eclipse、VS等）。

为什么呢？有以下三点原因：

1. 几乎所有推荐系统要用到的开源工具都是首先在Linux下开发测试完成的，最后再考虑移植到Windows平台上（测试不充分或者根本不移植）；
2. 键盘比鼠标快，用命令行编程会多用键盘，少用鼠标，熟悉之后效率大大提升。而且Linux下的命令非常丰富，处理的也都是标准文本，掌握之后很多时候根本不用写程序就能做很多数据处理工作。
3. 几乎Linux是互联网公司的服务器操作系统标配，不会Linux下的开发，就找不着工作，就问你怕不怕？

常常有人问我，实现推荐系统用什么编程语言比较好。标准的官方回答是：用你擅长的语言。但我深知这个回答不会解决提问者的疑问。实际上我的建议是：你需要掌握一门编译型语言：C++或者Java，然后掌握一门解释型语言，推荐Python或者R。原因如下：

1. 推荐系统的开源项目中以这几种语言最常见；
2. 快速的数据分析和处理、模型调试、结果可视化、系统原型实现等，Python和R是不错的选择，尤其是Python；
3. 当Python在一些地方有效率瓶颈时，通常是用C++实现，再用Python调用；
4. Java在构建后台服务时很有优势，一些大数据开源项目也多用Java来实现；

如果时间有限，只想掌握一门语言的话，推荐Python。从模型到后端服务到web端，都可以用Python，毋庸置疑，Python是AI时代第一编程语言。

推荐系统是一个线上的产品，无论离线时的模型跑得多么爽，可视化多么酷炫，最终一定要做成在线服务才完整。这就涉及到两方面的工作：1. 系统原型； 2. 算法服务化 。这涉及到：

1. **数据存储。**包括存储模型用于在线实时计算，存储离线计算好的推荐结果。除了传统的关系型数据库MySQL之外，还需要掌握非关系型数据库，如KV数据库Redis，列式数据库Cassandra和HBase常常用来存储推荐结果或模型参数。推荐的候选Item也可能存在MongoDB中。
2. **RPC和web。**需要将自己的算法计算模块以服务的形式提供给别人跨进程跨服务器调用，因此RPC框架就很重要，最流行如thrift或者dubbo。在RPC服务之上，再做原型还需要会一点基本的web开发知识，Python、PHP、Java都有相应的web框架来迅速的完成最基本的推荐结果展示。

**当然，最核心的是算法实现。**以机器学习算法为主。下面详细列举一下常见的机器学习/深度学习工具：

1. **Spark MLib**：大概是使用最广的机器学习工具了，因为Spark普及很广，带动了一个并非其最核心功能的MLib，MLib实现了常见的线性模型、树模型和矩阵分解模型等。提供Scala、Java和Python接口，提供了很多例子，学习Spark MLib很值得自己运行它提供的例子，结合文档和源代码学习接口的使用，模型的序列化和反序列化。
2. **GraphLab/GraphCHI**：GraphCHI是开源的单机版，GraphLab是分布式的，但并不开源。所以建议推荐系统工程师重点学习一下GraphCHI，它有Java和C++两个版本，实现了常见的推荐算法，并在单机上能跑出很高的结果。有一个不得不承认的事实是：GraphCHI和GraphLab在业界应用得并不广泛。
3. **Angel**：腾讯在2017年开源的分布式机器学习平台，Java和Scala开发而成，已经在腾讯的10亿维度下有工业级别的应用，最终的是填补了专注传统机器学习（相对于深度学习）分布式计算的空白，值得去学习一下；由于开发团队是中国人，所以文档以中文为主，学习的时候多多和开发团队交流会受益良多，进步神速。
4. **VW**：这是Yahoo开源的一个分布式机器学工具，也支持单机，分布式需要借助Hadoop实现。由于主要开发者后来跳槽去了微软，所以还支持Windows平台。阅读这个工具的源码，非常有助于理解逻辑回归的训练，微博推荐团队和广告团队第一版模型训练都采用了VW，其开发者在Yahoo Group中回答问题很积极，使用期间，我在这个group里面提了大大小小十几个问题，基本上都得到解答，这是一个学习成长方法，建议新学者常常在邮件组或者讨论组里提问题，不要在乎问题是否愚蠢，不要在意别人的取笑。
5. **Xgboost**：这个号称kaggle神器的机器学习工具，非常值得学习和使用，尤其是对于理解Boosting和树模型很有帮助。网上有很多教程，主要开发者陈天奇也是中国人，所以遇到问题是非常容易找到交流的人的。
6. **libxxx**：这里的xxx是一个通配符，包括以lib开头的各种机器学习工具，如liblinear、libsvm、libfm、libmf。都是单机版的工具，虽然是单机版，但足够解决很多中小型数据集的推荐问题了，著名的scikit-learn中的一些分类算法就是封装的libsvm等工具。另外，libsvm不但是一个机器学习工具，而且它还定义了一种应用广泛，成为事实标准的机器学习训练数据格式：libsvm。
7. **MXNet**，TensorFlow，Caffe：深度学习大行其道，并且在识别问题上取到了惊人的效果，自然也间接推动了推荐系统的算法升级，因此，掌握深度学习工具的就很必要，其中尤其以TensorFlow为主，它不但有深度学习模型的实现，还有传统机器学习模型的实现，Python接口，对于掌握Python的人来说学习门槛很低。深度学习工具仍然建议去跑几个例子，玩一些有趣的东西会快速入门，如给照片换风格，或者训练一个动物/人脸识别器，可以有一些粗浅的认识。再系统地学习一下吴恩达的在线课程，他的课程对TensorFlow的使用也有讲解，课后编程作业设计得也很好。

**为最终效果负责的能力**

推荐系统最终要为产品效果负责。衡量推荐系统效果，分为离线和在线两个阶段。

1. **离线阶段。**跑出一些模型，会有定义清晰的指标去衡量模型本身对假设的验证情况，如准确率、召回率、AUC等。这个阶段的效果好，只能说明符合预期假设，但不能保证符合产品最终效果，因此还要有线上实际的检验。
2. **在线阶段：**除了有一些相对通用的指标，如用户留存率、使用时长、点击率等，更多的是和产品本身的定位息息相关，如短视频推荐关注vv，新闻推荐关注CTR等，这些和商业利益结合更紧密的指标才是最终检验推荐系统效果的指标，推荐系统工程师要为这个负责，而不能仅仅盯着离线部分和技术层面的效果。

了解不同产品的展现形式对推荐系统实现的要求，feed流、相关推荐、猜你喜欢等不同产品背后技术要求不同，效果考核不同，多观察、多使用、多思考。

最后，要学会用产品语言理解产品本身，将技术能力作为一种服务输出给团队其他成员是一项软技能。

### 





**推荐系统领域现状**



协同过滤提出于90年代，至今二十几年，推荐系统技术上先后采用过近邻推荐、基于内容的推荐，以矩阵分解为代表的机器学习方法推荐，最近几年深度学习的火热自然也给推荐系统带来了明显的提升。推荐系统的作用无人质疑，简单举几个例子，80%的Netflix电影都是经由推荐系统被观众观看的，YouTube上60%的点击事件是由推荐系统贡献的。

推荐系统领域现状是怎么样的呢？这里分别从技术上和产品上来看一看。先看技术上，推荐系统所依赖的技术分为三类：**传统的推荐技术、深度学习、强化学习。**

首先，传统的推荐技术仍然非常有效。构建第一版推荐系统仍然需要这些传统推荐系统技术，这包括：User-based和Item-based近邻方法，以文本为主要特征来源的基于内容推荐，以矩阵分解为代表的传统机器学习算法。

当一个互联网产品的用户行为数据积累到一定程度，我们用这些传统推荐算法来构建第一版推荐系统，大概率上会取得不俗的成绩，实现0的突破。这类传统的推荐算法已经积累了足够多的实践经验和开源实现。由于对推荐系统的需求比以往更广泛，并且这些技术足够成熟，所以这类技术有SaaS化的趋势，逐渐交给专门的第三方公司来做，中小型、垂直公司不会自建团队来完成。

深度学习在识别问题上取得了不俗的成绩，自然就被推荐系统工程师们盯上了，已经结合到推荐系统中，比如YouTube用DNN构建了他们的视频推荐系统，Google在Google Play中使用Wide&Deep模型，结合了浅层的logistic regression模型和深层模型进行CTR预估，取得了比单用浅层模型或者单独的深层模型更好的效果，Wide&Deep模型也以开源的方式集成在了TensorFlow中，如今很多互联网公司，都在广泛使用这一深度学习和浅层模型结合的模型。在2014年，Spotify就尝试了RNN在序列推荐上，后来RNN又被Yahoo News的推荐系统。传统推荐算法中有一个经典的算法叫做FM，常用于做CTR预估，算是一种浅层模型，最近也有人尝试了结合深度学习，提出DeepFM模型用于CTR预估。

AlphaGo、Alpha Master、Alpha Zero一个比一个厉害，其开挂的对弈能力，让强化学习进入大众视线。强化学习用于推荐系统是一件很自然的事情，把用户看做变化的环境，而推荐系统是Agent，在和用户的不断交互之间，推荐系统就从一脸懵逼到逐渐“找到北”，迎合了用户兴趣。业界已有应用案例，阿里的研究员仁基就公开分享过淘宝把强化学习应用在搜索推荐上的效果。强化学习还以bandit算法这种相对简单的形式应用在推荐系统很多地方，解决新用户和新物品的冷启动，以及取代ABTest成为另一种在线实验的框架。

除了技术上推荐系统有不同侧重，产品形式上也有不同的呈现。最初的推荐系统产品总是存活在产品的边角上，如相关推荐，这种产品形式只能算是“锦上添花”，如果推荐系统不小心开了天窗，也不是性命攸关的问题。如今推荐产品已经演化成互联网产品的主要承载形式：信息流。从最早的社交网站动态，到图文信息流，到如今的短视频。信息流是一种推荐系统产品形式，和相关推荐形式比起来，不再是锦上添花，而是注意力收割利器。

推荐系统产品形式的演进，背景是互联网从PC到移动的演进，PC上是搜索为王，移动下是推荐为王，自然越来越重要。随着各种可穿戴设备的丰富，越来越多的推荐产品还会涌现出来。产品和技术相互协同发展，未来会有更多有意思的推荐算法和产品形式问世，成为一名推荐系统工程师永远都不晚。



> **作者简介：****陈开江，希为科技CTO**，曾任新浪微博资深算法工程师，考拉FM算法主管，个性化导购App《Wave》和《边逛边聊》联合创始人，多年推荐系统从业经历，在算法、架构、产品方面均有丰富的实践经验。
>
> 责编：何永灿 
>
> **本文为《程序员》原创文章，未经允许不得转载。**