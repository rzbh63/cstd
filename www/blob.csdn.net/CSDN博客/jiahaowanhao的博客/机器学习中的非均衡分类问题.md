
# 机器学习中的非均衡分类问题 - jiahaowanhao的博客 - CSDN博客


2018年04月09日 17:00:51[数据分析技术](https://me.csdn.net/jiahaowanhao)阅读数：63


[机器学习中的非均衡分类问题](http://cda.pinggu.org/view/25224.html)
非均衡分类问题是指在分类器训练时，正例数目和反例数目不相等（相差很大），或者错分正反例导致的代价不同（可从代价矩阵观测）时存在的问题。
而大多数情况下，不同类别的分类代价并不相等，而诸如信用卡欺诈等场景中，正反例的样本数目相差巨大，这就需要一些新的分类器性能度量方法和技术，来处理上述非均衡问题。
1、分类器性能度量指标
分类器学习常用的错误率指标会掩盖样例如何被错分的细节，可以采用更好的性能度量指标1 ——正确率TP/(TP+FP)和召回率TP/(TP+FN)。
实际上，单独满足其中一个指标高性能较容易，但构造一个同时高正确率有高召回率的分类器很难。至于具体选择正确率还是召回率，关键在于场景或者说研究问题，例如在购物刷单问题中，正确率远比召回率更重要。
此外可以采用性能度量指标2 ——ROC曲线，即接收者操作特征曲线。
ROC曲线给出的是当阈值变化时，假阳率和真阳率之间的变化情况。因此，我们可以通过观察ROC曲线来调节分类器的阈值，使得分类器的性能最好处于ROC曲线的左上角。由ROC曲线衍生的AUC（曲线下的面积）指标给出了分类器的平均性能值。
def plotROC(predStrengths, classLabels):
import matplotlib.pyplot as plt
cur = (1.0,1.0) \# current plot node
ySum = 0.0 \# for AUC
numPosClas = sum(numpy.array(classLabels)==1.0)
numNegClas = len(classLabels) - numPosClas
yStep = 1/float(numPosClas)
xStep = 1/float(numNegClas)
sortedIndicies = predStrengths.argsort()
fig = plt.figure()
fig.clf()
ax = plt.subplot(111)
for index in sortedIndicies.tolist()[0]:
if classLabels[index] == 1.0:
delX = 0; delY = yStep;
else:
delX = xStep; delY = 0;
ySum += cur[1]
ax.plot([cur[0],cur[0]-delX],[cur[1],cur[1]-delY], c='b')
cur = (cur[0]-delX,cur[1]-delY)
ax.plot([0,1],[0,1],'b--')
plt.xlabel('False positive rate'); plt.ylabel('True positive rate')
plt.title('ROC curve for AdaBoost horse colic detection system')
ax.axis([0,1,0,1])
plt.show()
print "the Area Under the Curve is: ",ySum*xStep
2、基于代价敏感的学习方法
一方面，重构训练数据集。即不改变已有算法，而是根据样本的不同错分代价给训练集中的每一个样本赋一个权值，接着按权重对原始样本集进行重构。
另一方面，引入代价敏感因子，设计出代价敏感的分类算法。通常可以将各分类器学习时的目标函数改造成最小化代价函数，即对小样本赋予较高的代价，大样本赋予较小的代价，期望以此来平衡样本之间的数目差异。
3、改造分类器的训练数据 —— 过抽样或者欠抽样
过抽样，即保留样本数目小的类别的所有样本同时，再进行复制或者进行插值，扩大规模。注意对小样本数目的类别的样本们进行插值有可能造成过拟合。
欠抽样，即欠抽样或者剔除样本数目大的类别中的部分样本，缩小规模。进行剔除时，尽量选择那些离决策边界较远的样例。

