
# Hive安装 - leofionn的博客 - CSDN博客


2018年01月05日 13:10:01[leofionn](https://me.csdn.net/qq_36142114)阅读数：48个人分类：[hadoop搭建																](https://blog.csdn.net/qq_36142114/article/category/7383244)


解压编译出来的hive安装包
```python
cd /usr/
```
```python
local
```
```python
/
```
```python
tar
```
```python
-xf
```
```python
/tmp/apache
```
```python
-hive
```
```python
-
```
```python
1.1
```
```python
.0
```
```python
-cdh5
```
```python
.7
```
```python
.1
```
```python
-bin
```
```python
.
```
```python
tar
```
```python
.
```
```python
gz
ln
```
```python
-s
```
```python
apache
```
```python
-hive
```
```python
-
```
```python
1.1
```
```python
.0
```
```python
-cdh5
```
```python
.7
```
```python
.1
```
```python
-bin
```
```python
hive
chown hadoop: apache
```
```python
-hive
```
```python
-
```
```python
1.1
```
```python
.0
```
```python
-cdh5
```
```python
.7
```
```python
.1
```
```python
-bin
```
```python
-R
```
```python
chown hadoop: hive
```
```python
-R
```
```python
echo
```
```python
'export HIVE_HOME=/usr/local/hive'
```
```python
>>
```
```python
/etc/profile
echo
```
```python
'export PATH=$HIVE_HOME/bin:$PATH'
```
```python
>>
```
```python
/etc/profile
```
配置mysql连接文件
```python
su - hadoop
cd /usr/local/hive
cd conf
cp -av hive-env.sh{.template,}
echo 'HADOOP_HOME=/usr/local/hadoop'>>hive-env.sh
vi hive-site.xml
```
```python
<?xml version="1.0"?>
```
```python
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
```
```python
<
```
```python
configuration
```
```python
>
```
```python
<
```
```python
property
```
```python
>
```
```python
<
```
```python
name
```
```python
>
```
```python
javax.jdo.option.ConnectionURL
```
```python
</
```
```python
name
```
```python
>
```
```python
<
```
```python
value
```
```python
>
```
```python
jdbc:mysql://hadoop001:3306/
```
```python
_hive?createDatabaseIfNotExist=true
```
```python
</
```
```python
value
```
```python
>
```
```python
</
```
```python
property
```
```python
>
```
```python
<
```
```python
property
```
```python
>
```
```python
<
```
```python
name
```
```python
>
```
```python
javax.jdo.option.ConnectionDriverName
```
```python
</
```
```python
name
```
```python
>
```
```python
<
```
```python
value
```
```python
>
```
```python
com.mysql.jdbc.Driver
```
```python
</
```
```python
value
```
```python
>
```
```python
</
```
```python
property
```
```python
>
```
```python
<
```
```python
property
```
```python
>
```
```python
<
```
```python
name
```
```python
>
```
```python
javax.jdo.option.ConnectionUserName
```
```python
</
```
```python
name
```
```python
>
```
```python
<
```
```python
value
```
```python
>
```
```python
root
```
```python
</
```
```python
value
```
```python
>
```
```python
</
```
```python
property
```
```python
>
```
```python
<
```
```python
property
```
```python
>
```
```python
<
```
```python
name
```
```python
>
```
```python
javax.jdo.option.ConnectionPassword
```
```python
</
```
```python
name
```
```python
>
```
```python
<
```
```python
value
```
```python
>
```
```python
root
```
```python
</
```
```python
value
```
```python
>
```
```python
</
```
```python
property
```
```python
>
```
```python
</
```
```python
configuration
```
```python
>
```
```python
# 配置文件中使用主机名hadoop001
# 因此要保证/etc/hosts文件中有正确的解析
# 配置文件hive-site.xml使用了java的mysql驱动包
# 而编译的hive安装包中没有该驱动包
# 需要手动上传
cd /tmp
unzip mysql-connector-java-5.1.45.zip
cd mysql-connector-java-5.1.45
cp mysql-connector-java-5.1.45-bin.jar /usr/local/hive/lib/
```

配置日志
```python
cd /usr/
```
```python
local
```
```python
/hive/conf
```
```python
/
```
```python
cp
```
```python
-av
```
```python
hive
```
```python
-log4j
```
```python
.
```
```python
properties{
```
```python
.
```
```python
template,}
sed
```
```python
-i
```
```python
's#^hive.log.dir=.*#hive.log.dir=/usr/local/hive/log#g'
```
```python
hive
```
```python
-log4j
```
```python
.
```
```python
properties
```
## 4. 命令测试
（这里有坑，我用的是别人的文档，而且参考两份，在my.cnf中需要配置文件。并且，这里会有权限问题，需要加可读权限。也就是将mysql中的date文件添加组和权限给hadoop用户。）
```python
hive
show databases;
exit;
```
```python
# 能够正常进入命令行不报错
```
```python
# 能够查看到defalut库
```
```python
# 代表配置成功
```
```python
echo show databases|mysql -uroot -proot
```
```python
# 发现库自动创建，表示配置无误
```
## 5. 建表测试
```python
hive
create table helloworld(id int,name
```
```python
string
```
```python
) row format delimited fields terminated
```
```python
by
```
```python
'\t';
```
```python
show databases;
use
```
```python
default
```
```python
;
show tables;
desc helloworld;
```
```python
select
```
```python
*
```
```python
from
```
```python
helloworld;
```
```python
exit
```
```python
;
```
```python
# 使用建表语句创建了一个表
```
```python
# 可以查看default库的表，找到该表
```
```python
# 同时可以在mysql库中查询到该表的信息
```
```python
mysql -uroot -pvincent -Dvincent_hive
```
```python
select
```
```python
*
```
```python
from
```
```python
TBLS \G
```
```python
exit
```
```python
;
```
```python
# 表名大小写是敏感的
```
```python
hdfs dfs -ls /user/hive/warehouse
```
```python
# 查看hdfs的目录信息，发现已经创建了该表的目录
```
```python
# 编辑一个文件，上传到该目录下，再次在hive中使用SQL就能查询出来信息了
```
```python
echo -e
```
```python
"1\tzhangsan\n2\tlisi\n3\twangwu"
```
```python
>>/tmp/helloworld.txt
hive
load data local inpath
```
```python
'/tmp/helloworld.txt' into table helloworld;
```
```python
select
```
```python
*
```
```python
from
```
```python
helloworld;
```
```python
select
```
```python
id
```
```python
from
```
```python
helloworld;
```
```python
select
```
```python
count(
```
```python
1
```
```python
)
```
```python
from
```
```python
helloworld;
```
```python
exit
```
```python
;
```
```python
# 在hive中使用load命令，将本地的一个文本文件上传到hdfs的helloworld表对应的目录下
```
```python
# 使用 select count(1) 聚集函数，会生成MR任务
```
```python
# 可以在 http://192.168.1.10:8088/cluster/apps 查看到
```
# 来自@若泽大数据

