# 图像融合总结

# 图像融合方法总结

2019年01月09日 18:03:57 [蓝心释](https://me.csdn.net/nineship) 阅读数：242



版权声明：添加我的微信wlagooble，开启一段不一样的旅程	https://blog.csdn.net/nineship/article/details/86167789

微信公众号：快餐热点，为您每天提供全美资讯，是您学习英语提升眼界的好平台

论文来自：基于特征提取的图像融合，江南大学，王鹏飞

\1. 基于加权平均的融合方法

​    优点在于速度快，图像结构完整性保障，但是遇到融合图像像素差异较大的情况，这种对像素点灰度的平均会产生严重的拼接感。

\2. 基于绝对值取大的融合方法

​    优点在于边缘强度高，纹理清晰，但是拼接感强，结构不完整。

\3. 基于主成分析PCA的融合方法

​    步骤为：计算A的相关系数矩阵，并计算其特征值与特征向量得到各个分量，将B与A的第一主分量做直方图匹配；用匹配到的B代替A的第一主分量；然后与Ad的其他分量一起做PCA反变换得到融合图像。

​    存在空间扭曲，空间细节丢失的问题

\4. IHS融合

​    将待融合RGB转到IHS空间，根据融合规则对三组分量进行融合。最终逆变换到RGB空间，得到融合图像

​    运算简单，但如果相关度较低，容易产生光谱信息的丢失

\5. 基于PCNN的融合方法

​    利用PCNN计算AB对应的点火图FiremapA和FiremapB。

​    这种方法往往会丢失细节和纹理信息，在红外与图像融合的应用中有较好的效果，但是在多聚焦图像融合中的效果不佳。

6.基于金字塔变换的融合

​    重建过程存在不确定性，不稳定性，可能会导致融合结果的模糊

\7. 基于小波变换的图像融合方法

​    小波变换拥有水平，垂直和对角三种高频子带，但是它难以反映线和面的奇异行，还缺乏对自然图像进行稀释表示的能力。

\8. 多尺度变换的融合方法

​    多尺度变换包括轮廓波的变换，非下采样的轮廓波的变换，剪切波的变换，平移不变剪切波的变换。

\9. 轮廓波的变换

​    首先对拉普拉斯进行分解，得到边缘的孤立的端点，利用DFB把一致方向的断点连成线。

\10. 非下采样轮廓波变换NSCT（Non-subsampled Contourlet Transform）

​    NSCT采用非下采样金字塔和非下采样方向滤波器组完成对图像的多尺度，多方向的分解。

\11. 剪切波变换(Shearlet)

​    对图像进行金字塔分解，得到低频子带和高频子带；将低频子带映射到伪极坐标上，并计算其傅里叶变换，并对变换得到的矩形进行带通滤波；将变换得到的系数映射到笛卡尔坐标系上；利用傅里叶变换逆变换获得Shearlet变换系数。

\12. 平移不变剪切变换SIST(Shift Invariant Shearlet Transform)

​    非下采样金字塔和非下采样，滤波器组，在变换过程中没有进行下采样。因此具备平移不变行。    

 

13 栈式稀疏自编码

 

\14. SIFT

 

总结：

   需要改进的地方：权威的图像质量评价标准的建立。融合策略的自动选择，待融合图像的自动配准。





### 图像融合方法总结

- [图像融合分类](https://blog.csdn.net/JINJINGXIAOXINXIN/article/details/84861209#_1)

- - [像素级的图像融合](https://blog.csdn.net/JINJINGXIAOXINXIN/article/details/84861209#_5)
  - [特征级图像融合](https://blog.csdn.net/JINJINGXIAOXINXIN/article/details/84861209#_15)
  - [决策级图像融合](https://blog.csdn.net/JINJINGXIAOXINXIN/article/details/84861209#_23)



# 图像融合分类

根据图像表征层次的不同，图像融合可分为三个层次的融合：像素级融合、特征级融合和决策级融合。图像融合的：1.图像增强，提高图像分辨率和清晰度；2.增强图像的相关特征；3.相互补充相关信息，去除噪声和冗余；4.提高目标检测的额识别能力；5.获得完整的三维重构数据。
图像融合的层级划分图：![图像融合的级别划分](https://img-blog.csdnimg.cn/20181206114155609.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0pJTkpJTkdYSUFPWElOWElO,size_16,color_FFFFFF,t_70)

## 像素级的图像融合

像素级融合：直接对个幅图像的像素点进行融合信息综合的过程。
**像素级融合的局限性：**

1. 图像原始数据规模导致算法实现费时；
2. .数据未经处理，传感器原始信息的优缺点会叠加，影响融合效果；
3. 对硬件的设施的要求相当高，进行图像融合时，配准的精度要求精确的各传感器数据之间每个像素；
4. 因为基于像素计算，像素信息易受污染，噪声等干扰，所以效果不稳定。

## 特征级图像融合

特征级融合:对图像进行特征抽取，将边缘、形状、轮廓、局部特征等信息进行综合处理的过程。特征级图像融合是对图像进行特征抽取后，将边缘、形状、轮廓、局部特征等信息进行综合处理的过程。特征级融合包括：目标状态信息融合，目标特征性融合。特征级融合包含的几个模块：源图像的获取，图像的预处理，图像分割，特征提取，特征数据融合及目标识别。图像的特征是一种代价处理，降低了数据量，保留了大部分信息，仍损失部分细节信息。原始特征的组合形成特征，增加特征维数，提高目标的是被准确率。特征向量可以直接融合也可以根据特征本身的属性进行重新组合，边缘，形状、轮廓灯都是描述特征的重要参数，他们的几何变换也具有一定的特征属性。

**目标状态特征融合**
是一种基于多尺度和多分辨率的目标统计特征，它对图像的原始数据状态的提取被描述，需要经过严格的配准，最后得到的是一幅包含更多图像信息的图像。它是对图像的状态信息统计，进行模式匹配的问题。核心思想是实现多传感器目标的精确状态估计，与先验知识的有效关联，应用广泛的是目标跟踪领域。
**目标特性融合**
按照特定的语义对图像特征提取特征的内在描述，或特征属性的重新组合，这些特征向量代表抽象的图像信息，直接对特征进行机器学习理论融合识别，增加了特征的维度，提高了目标识别的精确度。目标特性融合是特征向量融合识别，一般处理的都是高维问题，随意实质上该融合应用最多是模式识别。多传感器比单一传感器提供的信息增大了特征空间的维数，扩大了细信息特征散射的空间，从分类的角度上提高了识别率。特征实际上涉及了图像分割、特征提取和特征层信息融合等几个方面。

## 决策级图像融合

决策级融合：在每种传感器独立完成决策或分类的基础上，将多个传感器的识别结果进行融合做出全局的最优决策。决策级融合根据一定的规则对提取特征和识别后的源图像决策综合，获得融合图像。决策的输入是对目标的认识框架。认识框架是通过同质异质传感器观测同一场景的目标，经过预处理、特征提取、识别的基本处理后形成的。对该框架通过最优化决策得到融合结果。决策级是趋向智能逻辑的，综合多传感器的识别结果比单一识别更精准，更有效。但多传感器的数据同时也增加了误差和风险，每一传感器的可能的错误都会传递到决策层，决策函数的容错能力直接影响融合分类性能。
**决策级融合的优点：**

1. 具有很好的实时性、自适应性；
2. 数据要求低，刚干扰能力强；
3. 高效的兼容了多传感器的环境特征信息；
4. 很好的纠错能力，通过适当的融合，消除单个传感器造成的误差，系统还能获得正确的结果。









# 图像融合知识相关网页整理（持续更新。。。）

2018年12月22日 13:49:35 [Daniel__Shi](https://me.csdn.net/shitao99) 阅读数：126



版权声明：本文为博主原创文章，未经博主允许不得转载。如有问题，欢迎评论指正。	https://blog.csdn.net/shitao99/article/details/85177929

之前发布了一篇博客，整理了一些学术论文中常用的图像融合数据集（数据库）的网址。这里附上博客链接：

<https://blog.csdn.net/shitao99/article/details/83994908>

 

本篇博客主要想总结一下关于图像融合领域的一些网页。

1、**Investigations of Image Fusion**

网页：<http://www.ece.lehigh.edu/SPCRL/IF/image_fusion.htm#If_scheme>

网页内讲解了一些多传感图像融合知识（早期的基于多尺度金字塔变换的图像融合算法，以及图像融合应用场景）。

附网页截图：

![img](https://img-blog.csdnimg.cn/20181221232445324.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoaXRhbzk5,size_16,color_FFFFFF,t_70)

另外，网页 <http://www.ece.lehigh.edu/SPCRL/> 内罗列了大牛Rick S. Blum教授（理海大学）出版的专著、发表的文章、做过的项目。

（Rick S. Blum教授的个人主页：<https://engineering.lehigh.edu/faculty/rick-s-blum>）

 

2、网页：<http://www.metapix.de/fusion.htm>

比较早期的网站，网站更新日期截止于1999年九月。

网页截图：

![img](https://img-blog.csdnimg.cn/20181222134708143.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoaXRhbzk5,size_16,color_FFFFFF,t_70)

该网页内介绍了基本的像素级图像融合知识。并且提供了几种早期的融合算法。

- linear superposition
- nonlinear methods
- optimization approaches
- artificial neural networks
- image pyramids
- wavelet transform
- generic multiresolution fusion scheme

点击左侧的“toolbox”，可以下载代码。解压后，运行其中的fusetool.m文件，可以看到作者提供的图像融合GUI系统。下图。

![img](https://img-blog.csdnimg.cn/20181222134616444.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoaXRhbzk5,size_16,color_FFFFFF,t_70)











# 图像融合数据集，图像融合数据库（有了新的会更新）

置顶 2018年12月12日 21:58:25 [Daniel__Shi](https://me.csdn.net/shitao99) 阅读数：883



 版权声明：本文为博主原创文章，未经博主允许不得转载。如有问题，欢迎评论指正。	https://blog.csdn.net/shitao99/article/details/83994908

一、论文中常用的网址：

[http://www.imagefusion.org](http://www.imagefusion.org/)  （论文中经常引用，但是目前打不开）

二、多聚焦图像：

1、Toet A. TNO Image fusion dataset[J]. Figshare. data, 2014.

<https://figshare.com/articles/TN_Image_Fusion_Dataset/1008029>

2、http://www.pxleyes.com/photography-contest/19726

 

3、Lytro Multi-focus Dataset（常用）

“ This dataset contains 20 pairs of color multi-focus images of size 520×520 pixels and four series of multi-focus images with three sources.

Please cite the following paper if you use this dataset:

M. Nejati, S. Samavi, and S. Shirani, "Multi-focus Image Fusion Using Dictionary-Based Sparse Representation", Information Fusion, vol. 25, Sept. 2015, pp. 72-84.

网址：<https://mansournejati.ece.iut.ac.ir/content/lytro-multi-focus-dataset>

4、Paper：Slavica Savic, "Multifocus Image Fusion Based on Empirical Mode Decomposition", Twentieth International Electrotechnical and Computer Science Conference, ERK 2011.

网站内提供27对多聚焦图像。

网址：<http://dsp.etfbl.net/mif/>

5、“The dataset which includes 150 different images is created to use in Multi-focus Image Fusion algorithms. This dataset is different from other datasets in this area. The new dataset includes more than two images to fuse. And this propoerty is very important for this dataset.The dataset is prepared by Samet Aymaz.”（包含150张图像，21.3M）

<https://github.com/sametaymaz/Multi-focus-Image-Fusion-Dataset>

6、<https://ww2.mathworks.cn/matlabcentral/fileexchange/45992-standard-images-for-multifocus-image-fusion?s_tid=FX_rc3_behav>

该网页也提供了一些多聚焦图像素材。

 

三、红外与可见光图像

1、TNO Image Fusion Dataset(117.03 MB)——图像序列

网址：<https://figshare.com/articles/TN_Image_Fusion_Dataset/1008029>

（内容很丰富，常用的图像都是从该库里挑出来的。论文中也常引用该网址。）

简介：

"The TNO Image Fusion Dataset contains multispectral (intensified visual, near-infrared, and longwave infrared or thermal) nighttime imagery of different military relevant scenerios, registered with different multiband camnera systems."

2、OTCBVS Benchmark Dataset Collection

网址：<http://vcipl-okstate.org/pbvs/bench/>

网站内的简介：

" This is a publicly available benchmark dataset for testing and evaluating novel and state-of-the-art computer vision algorithms. Several researchers and students have requested a benchmark of non-visible (e.g., infrared) images and videos. The benchmark contains videos and images recorded in and beyond the visible spectrum and is available for free to all researchers in the international computer vision communities. Also it will allow a large spectrum of IEEE and SPIE vision conference and workshop participants to explore the benefits of the non-visible spectrum in real-world applications, contribute to the OTCBVS workshop series, and boost this research field significantly. This effort was initiated by Dr. Riad I. Hammoud in 2004. It was hosted at Ohio State University and managed by Dr. James W. David until 2013. It is currently managed by Dr. Guoliang Fan at Oklahoma State University.

This benchmark is to be used for educational and research purposes only, and this benchmark must be acknowledged by the users.

其中通常使用第三个数据集——Dataset 03: OSU Color-Thermal Database

引用：IEEE OTCBVS WS Series Bench; J. Davis and V. Sharma, "Background-Subtraction using Contour-based Fusion of Thermal and Visible Imagery," *Computer Vision and Image Understanding*, Vol 106, No. 2-3, 2007, pp. 162-182.

3、DATA SET 3: Bristol Eden Project Multi-Sensor Data Set

<http://www.cis.rit.edu/pelz/scanpaths/data/bristol-eden.htm>

4、Visible-Infrared Database

<http://www02.smt.ufrj.br/~fusion/>

5、[https://www.goes.noaa.gov](https://www.goes.noaa.gov/)

6、RGB-NIR Scene Dataset（大约1GB）（EPFL 2015 EPFL database）

网址：<https://ivrl.epfl.ch/research-2/research-downloads/supplementary_material-cvpr11-index-html/>

网站内的简介：

“This dataset consists of 477 images in 9 categories captured in RGB and Near-infrared (NIR). The images were captured using separate exposures from modified SLR cameras, using visible and NIR filters. For more info on NIR photography, see the references below. The scene categories are: country, field, forest, indoor, mountain, oldbuilding, street, urban, water.”

 

四、医学图像：

www.med.harvard.edu/aanlib/home.html
 

五、真彩色图像

<http://r0k.us/graphics/kodak/>

 

最后：

[Durga Prasad Bavirisetti](https://sites.google.com/view/durgaprasadbavirisetti/home)提供了各种融合图像数据集（下面的网址），包含医学图像，多聚焦图像，多模态图像，多曝光图像，遥感图像。（该库里的图像与前面的链接里的图像会有重复）

网站：<https://sites.google.com/view/durgaprasadbavirisetti/datasets>

 

 





# 图像融合论文及代码网址整理总结（1）——多聚焦图像融合（持续更新）

置顶 2018年12月23日 20:41:16 [Daniel__Shi](https://me.csdn.net/shitao99) 阅读数：1676



 版权声明：本文为博主原创文章，未经博主允许不得转载。如有问题，欢迎评论指正。	https://blog.csdn.net/shitao99/article/details/85205304

写在前面的话：

本篇博文主要整理汇总一下现有的多聚焦图像融合算法（文章和代码）。适当地，也会整理出相关作者的学术主页。整理这些的初衷，是为了方便自己，顺便也给同领域的研究者在找代码等方面提供些许便利。另外，该领域的文章很多，本篇博文也只是整理了其中的一部分，并且，本人不会对论文内容做过多评论。

 

同系列的博文还有：

[图像融合论文及代码网址整理总结（2）——红外与可见光图像融合（持续更新）](https://blog.csdn.net/shitao99/article/details/85214279)

[图像融合论文及代码网址整理总结（3）——题目中未加区分的图像融合算法（持续更新）](https://blog.csdn.net/shitao99/article/details/85215086)

[图像融合数据集，图像融合数据库（有了新的会更新）](https://blog.csdn.net/shitao99/article/details/83994908)

====================== 分 ========== 割 ========== 线 ======================

**目录**

[【2019】](https://blog.csdn.net/shitao99/article/details/85205304#%E3%80%902019%E3%80%91)

[1、文章：Multi-focus image fusion using deep support value convolutional neural network  【深度学习】](https://blog.csdn.net/shitao99/article/details/85205304#1%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AMulti-focus%20image%20fusion%20using%20deep%20support%20value%20convolutional%20neural%20network%20%C2%A0%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91)

[【2018】](https://blog.csdn.net/shitao99/article/details/85205304#%E3%80%902018%E3%80%91)

[1、文章：Robust sparse representation based multi-focus image fusion with dictionary construction and local spatial consistency](https://blog.csdn.net/shitao99/article/details/85205304#1%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9ARobust%20sparse%20representation%20based%20multi-focus%20image%20fusion%20with%20dictionary%20construction%20and%20local%20spatial%20consistency)

[2、文章：Multi-focus image fusion based on edges and focused region extraction](https://blog.csdn.net/shitao99/article/details/85205304#2%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AMulti-focus%20image%20fusion%20based%20on%20edges%20and%20focused%20region%20extraction)

[3、文章：Multi-focus: Focused region finding and multi-scale transform for image fusion](https://blog.csdn.net/shitao99/article/details/85205304#3%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AMulti-focus%3A%20Focused%20region%20finding%20and%20multi-scale%20transform%20for%20image%20fusion)

[4、文章：Fully Convolutional Network-Based Multifocus Image Fusion【深度学习】](https://blog.csdn.net/shitao99/article/details/85205304#4%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AFully%20Convolutional%20Network-Based%20Multifocus%20Image%20Fusion%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91)

[5、文章：Convolutional Neural Network Based Multi-Focus Image Fusion  【CNN】     【深度学习】](https://blog.csdn.net/shitao99/article/details/85205304#5%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AConvolutional%20Neural%20Network%20Based%20Multi-Focus%20Image%20Fusion%20%C2%A0%E3%80%90CNN%E3%80%91%20%C2%A0%20%C2%A0%20%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91)

[6、文章：Pixel convolutional neural network for multi-focus image fusion【深度学习】  【CNN】](https://blog.csdn.net/shitao99/article/details/85205304#4%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9APixel%20convolutional%20neural%20network%20for%20multi-focus%20image%20fusion%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91)

[7、文章：Multi-focus image fusion with the all convolutional neural network  【深度学习】](https://blog.csdn.net/shitao99/article/details/85205304#6%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AMulti-focus%20image%20fusion%20with%20the%20all%20convolutional%20neural%20network%20%C2%A0%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91)

[8、文章：Neural Network Based Multi-Focus Image Fusion（点击下载文章）【深度学习】](https://blog.csdn.net/shitao99/article/details/85205304#7%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9ANeural%20Network%20Based%20Multi-Focus%20Image%20Fusion%EF%BC%88%E7%82%B9%E5%87%BB%E4%B8%8B%E8%BD%BD%E6%96%87%E7%AB%A0%EF%BC%89%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91)

[9、文章：Robust Multi-Focus Image Fusion Using Edge Model and Multi-Matting](https://blog.csdn.net/shitao99/article/details/85205304#9%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9ARobust%20Multi-Focus%20Image%20Fusion%20Using%C2%A0Edge%20Model%20and%20Multi-Matting)

[10、文章：Multi-focus image fusion with a natural enhancement via joint multi-level deeply supervised convolutional neural network 【深度学习】](https://blog.csdn.net/shitao99/article/details/85205304#10%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AMulti-focus%20image%20fusion%20with%20a%20natural%20enhancement%20via%20joint%20multi-level%20deeply%20supervised%20convolutional%20neural%20network%20%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91)

[11、文章：Unsupervised Deep Multi-focus Image Fusion【深度学习】](https://blog.csdn.net/shitao99/article/details/85205304#11%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AUnsupervised%20Deep%20Multi-focus%20Image%20Fusion%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91)

[【2017】](https://blog.csdn.net/shitao99/article/details/85205304#%E3%80%902017%E3%80%91)

[1、文章：Multi-focus Image Fusion Using Dictionary Learning and Low-Rank Representation     【LRR用于图像融合】](https://blog.csdn.net/shitao99/article/details/85205304#1%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AMulti-focus%20Image%20Fusion%20Using%20Dictionary%20Learning%20and%20Low-Rank%20Representation)

[2、文章：Multi-focus Noisy Image Fusion using Low-Rank Representation  （点击下载文章）     【LRR用于图像融合】](https://blog.csdn.net/shitao99/article/details/85205304#2%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AMulti-focus%20Noisy%20Image%20Fusion%20using%20Low-Rank%20Representation%20%C2%A0%EF%BC%88%E7%82%B9%E5%87%BB%E4%B8%8B%E8%BD%BD%E6%96%87%E7%AB%A0%EF%BC%89%20%C2%A0%20%C2%A0%C2%A0%E3%80%90LRR%E7%94%A8%E4%BA%8E%E5%9B%BE%E5%83%8F%E8%9E%8D%E5%90%88%E3%80%91)

[3、文章：Boundary finding based multi-focus image fusion through multi-scale morphological focus-measure](https://blog.csdn.net/shitao99/article/details/85205304#2%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9ABoundary%20finding%20based%20multi-focus%20image%20fusion%20through%20multi-scale%20morphological%20focus-measure)

[4、文章：Multi-focus image fusion with a deep convolutional neural network 【深度学习】](https://blog.csdn.net/shitao99/article/details/85205304#3%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AMulti-focus%20image%20fusion%20with%20a%20deep%20convolutional%20neural%20network%C2%A0%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91)

[5、文章：Surface area-based focus criterion for multi-focus image fusion](https://blog.csdn.net/shitao99/article/details/85205304#4%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9ASurface%20area-based%20focus%20criterion%20for%20multi-focus%20image%20fusion)

[6、文章：Multi-focus image fusion and super-resolution with convolutional neural network  【深度学习】【CNN】](https://blog.csdn.net/shitao99/article/details/85205304#5%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9A)

[7、文章：Image Segmentation-Based Multi-Focus Image Fusion Through Multi-Scale Convolutional Neural Network（点击下载文章）  【深度学习】【CNN】](https://blog.csdn.net/shitao99/article/details/85205304#7%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AImage%20Segmentation-Based%20Multi-Focus%20Image%20Fusion%20Through%20Multi-Scale%20Convolutional%20Neural%20Network%EF%BC%88%E7%82%B9%E5%87%BB%E4%B8%8B%E8%BD%BD%E6%96%87%E7%AB%A0%EF%BC%89%20%C2%A0%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E3%80%90CNN%E3%80%91)

[8、文章：Multi-focus image fusion based on multi-scale focus measures and generalized random walk](https://blog.csdn.net/shitao99/article/details/85205304#1%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9ARobust%20Multi-Focus%20Image%20Fusion%20Using%20Multi-Task%C2%A0Sparse%20Representation%20and%20Spatial%20Context)

[9、文章：Multi-focus image fusion using HOSVD and edge intensity](https://blog.csdn.net/shitao99/article/details/85205304#9%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AMulti-focus%20image%20fusion%20using%20HOSVD%20and%20edge%20intensity)

[10、文章：Multifocus Image Fusion Based on Extreme Learning Machine and Human Visual System](https://blog.csdn.net/shitao99/article/details/85205304#10%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AMultifocus%20Image%20Fusion%20Based%20on%20Extreme%20Learning%20Machine%20and%20Human%20Visual%20System)

[【2016】](https://blog.csdn.net/shitao99/article/details/85205304#%E3%80%902016%E3%80%91)

[1、文章：Robust Multi-Focus Image Fusion Using Multi-Task Sparse Representation and Spatial Context     【RSR】](https://blog.csdn.net/shitao99/article/details/85205304#1%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9ARobust%20Multi-Focus%20Image%20Fusion%20Using%20Multi-Task%C2%A0Sparse%20Representation%20and%20Spatial%20Context%20%C2%A0%20%C2%A0%20%E3%80%90RSR%E3%80%91)

[2、文章：Multifocus image fusion using superpixel segmentation and superpixel-based mean filtering     【基于超像素做图像融合】](https://blog.csdn.net/shitao99/article/details/85205304#2%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AMultifocus%20image%20fusion%20using%20superpixel%20segmentation%20and%20superpixel-based%20mean%20filtering)

[3、文章：Multi-focus image fusion using multi-scale image decomposition and saliency detection    【结合图像显著性检测】](https://blog.csdn.net/shitao99/article/details/85205304#3%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AMulti-focus%20image%20fusion%20using%20multi-scale%20image%20decomposition%20and%20saliency%20detection)

[4、文章：Multi-focus image fusion algorithm based on focused region extraction      【结合图像显著性检测】【GBVS检测算法】](https://blog.csdn.net/shitao99/article/details/85205304#4%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AMulti-focus%20image%20fusion%20algorithm%20based%20on%20focused%20region%20extraction%20%C2%A0%20%C2%A0%20%C2%A0%E3%80%90%E7%BB%93%E5%90%88%E5%9B%BE%E5%83%8F%E6%98%BE%E8%91%97%E6%80%A7%E6%A3%80%E6%B5%8B%E3%80%91%E3%80%90GBVS%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95%E3%80%91)

[【2015】](https://blog.csdn.net/shitao99/article/details/85205304#%E3%80%902015%E3%80%91)

[1、文章：Multi-focus image fusion using dictionary-based sparse representation     【SRCF】](https://blog.csdn.net/shitao99/article/details/85205304#1%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AMulti-focus%20image%20fusion%20using%20dictionary-based%20sparse%20representation)

[2、文章：Quadtree-based multi-focus image fusion using a weighted focus-measure](https://blog.csdn.net/shitao99/article/details/85205304#2%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AQuadtree-based%20multi-focus%20image%20fusion%20using%20a%20weighted%20focus-measure)

[3、文章：Multi-focus image fusion with dense SIFT     【DSIFT】](https://blog.csdn.net/shitao99/article/details/85205304#3%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AMulti-focus%20image%20fusion%20with%20dense%20SIFT)

[4、文章：Multifocus image fusion using phase congruency](https://blog.csdn.net/shitao99/article/details/85205304#4%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AMultifocus%20image%20fusion%20using%20phase%20congruency)

[5、文章：A Novel Explicit Multi-focus Image Fusion Method](https://blog.csdn.net/shitao99/article/details/85205304#5%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AA%20Novel%20Explicit%20Multi-focus%20Image%20Fusion%20Method)

[【2014】](https://blog.csdn.net/shitao99/article/details/85205304#%E3%80%902014%E3%80%91)

[1、文章：Multi-scale weighted gradient-based fusion for multi-focus images    【MWGF】](https://blog.csdn.net/shitao99/article/details/85205304#1%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AMulti-scale%20weighted%20gradient-based%20fusion%20for%20multi-focus%20images)

[2、文章：Effective Multifocus Image Fusion Based on HVS and BP Neural Network](https://blog.csdn.net/shitao99/article/details/85205304#2%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AEffective%20Multifocus%20Image%20Fusion%20Based%20on%20HVS%20and%20BP%20Neural%20Network)

[3、文章：High quality multi-focus image fusion using self-similarity and depth information](https://blog.csdn.net/shitao99/article/details/85205304#3%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AHigh%20quality%20multi-focus%20image%20fusion%20using%20self-similarity%20and%20depth%20information)

[4、文章：Region level based multi-focus image fusion using quaternion wavelet and normalized cut](https://blog.csdn.net/shitao99/article/details/85205304#4%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9ARegion%20level%20based%20multi-focus%20image%20fusion%20using%20quaternion%20wavelet%20and%20normalized%20cut)

[【2013】](https://blog.csdn.net/shitao99/article/details/85205304#%E3%80%902013%E3%80%91)

[1、文章：Image matting for fusion of multi-focus images in dynamic scenes（点击下载文章）](https://blog.csdn.net/shitao99/article/details/85205304#1%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AImage%20matting%20for%C2%A0fusion%C2%A0of%20multi-focus%20images%20in%20dynamic%20scenes%EF%BC%88%E7%82%B9%E5%87%BB%E4%B8%8B%E8%BD%BD%E6%96%87%E7%AB%A0%EF%BC%89)

[2、文章：Multi-focus image fusion using a morphology-based focus measure in a quad-tree structure](https://blog.csdn.net/shitao99/article/details/85205304#2%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AMulti-focus%20image%20fusion%20using%20a%20morphology-based%20focus%20measure%20in%20a%20quad-tree%20structure)

[3、文章：Regional multifocus image fusion using sparse representation](https://blog.csdn.net/shitao99/article/details/85205304#3%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9ARegional%20multifocus%20image%20fusion%20using%20sparse%20representation)

[【2012】](https://blog.csdn.net/shitao99/article/details/85205304#%E3%80%902012%E3%80%91)

[1、文章：Adaptive multi-focus image fusion using a wavelet-based statistical sharpness measure](https://blog.csdn.net/shitao99/article/details/85205304#1%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AAdaptive%20multi-focus%20image%20fusion%20using%20a%20wavelet-based%20statistical%20sharpness%20measure)

[【2011】](https://blog.csdn.net/shitao99/article/details/85205304#%E3%80%902011%E3%80%91)

[1、文章：Multi-focus image fusion using a bilateral gradient-based sharpness criterion](https://blog.csdn.net/shitao99/article/details/85205304#1%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AMulti-focus%20image%20fusion%20using%20a%20bilateral%20gradient-based%20sharpness%20criterion)

[【2010】](https://blog.csdn.net/shitao99/article/details/85205304#%E3%80%902010%E3%80%91)

[1、文章：Multifocus Image Fusion and Restoration With Sparse Representation     【第一篇将SR应用于图像融合】](https://blog.csdn.net/shitao99/article/details/85205304#1%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AMultifocus%20Image%20Fusion%20and%20Restoration%20With%20Sparse%20Representation)

[【2008】](https://blog.csdn.net/shitao99/article/details/85205304#%E3%80%902008%E3%80%91)

[1、文章：Multifocus image fusion using region segmentation and spatial frequency](https://blog.csdn.net/shitao99/article/details/85205304#1%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AMultifocus%20image%20fusion%20using%20region%20segmentation%20and%20spatial%20frequency)

------

 

# **【2019】**

## 1、文章：Multi-focus image fusion using deep support value convolutional neural network  【**深度学习】**

Paper：<https://doi.org/10.1016/j.ijleo.2018.09.089>

作者：西北工业大学自动化学院ChaoBen Du（杜超本） , SheSheng Gao（高社生） , Ying Liu , BingBing Gao

 

# 【2018】

## 1、文章：Robust sparse representation based multi-focus image fusion with dictionary construction and local spatial consistency

Paper：<https://doi.org/10.1016/j.patcog.2018.06.003>

作者：张强，西安电子科技大学机电工程学院。

 

## 2、文章：Multi-focus image fusion based on edges and focused region extraction

Paper：<https://doi.org/10.1016/j.ijleo.2018.06.093>

作者：Juanxiu Tian，Guocai Liu，Jingguang Liu 湖南大学电气与信息工程学院

 

## 3、文章：Multi-focus: Focused region finding and multi-scale transform for image fusion

Paper：<https://doi.org/10.1016/j.neucom.2018.09.018>

作者：云南大学信息学院，贺康建（2017级博士），[周冬明](http://www.ise.ynu.edu.cn/teacher/733)，[聂仁灿](http://www.ise.ynu.edu.cn/teacher/903)

 

## 4、文章：Fully Convolutional Network-Based Multifocus Image Fusion【**深度学习】**

Paper：<https://www.mitpressjournals.org/doi/full/10.1162/neco_a_01098>

<https://doi.org/10.1162/neco_a_01098> 

作者：云南大学信息学院，[聂仁灿](http://www.ise.ynu.edu.cn/teacher/903)，[周冬明](http://www.ise.ynu.edu.cn/teacher/733)

 

## 5、文章：Convolutional Neural Network Based Multi-Focus Image Fusion  【CNN】     【深度学习】

Paper：<https://dl.acm.org/citation.cfm?id=3242863>

作者：李华光，[聂仁灿](http://www.ise.ynu.edu.cn/teacher/903)，[周冬明](http://www.ise.ynu.edu.cn/teacher/733)，云南大学信息学院  

 

## 6、文章：Pixel convolutional neural network for multi-focus image fusion【**深度学习】**  【CNN】

Paper：<https://doi.org/10.1016/j.ins.2017.12.043>

作者：重庆邮电大学，Han Tang（唐翰）, Bin Xiao（肖斌）, Weisheng Li（李伟生）, Guoyin Wang（王国胤）

**肖斌**，重庆邮电大学，副教授，博士，硕士生导师

主页：

<http://cs.cqupt.edu.cn/info/1078/4189.htm>（重庆邮电大学计算机科学与技术学院硕导主页）

<http://yjs.cqupt.edu.cn/info/1063/3175.htm>（学校招生主页）

 

## 7、文章：Multi-focus image fusion with the all convolutional neural network  【**深度学习】**

Paper：<https://link.springer.com/article/10.1007/s11801-018-7207-x>

作者：Chao-ben Du (杜超本)，She-sheng Gao (高社生)，西北工业大学自动化学院。

**杜超本**，西安邮电大学通信与信息工程学院，教师。西工大博士（导师：高社生）

**高社生**，西北工业大学自动化学院教师，博导

主页：

<http://teacher.nwpu.edu.cn/gaoshesheng>（校内导师主页）

<http://zdhxy.nwpu.edu.cn/info/1167/2562.htm>（校内导师主页）

 

## 8、文章：[Neural Network Based Multi-Focus Image Fusion](http://www.ijaerd.com/papers/finished_papers/Neural_Network_Based_Multi-Focus_Image_Fusion-IJAERDV05I0425704.pdf)（点击下载文章）【**深度学习】**

作者：Riddhi Shukla, Pragnesh Patel

 

## 9、文章：Robust Multi-Focus Image Fusion Using Edge Model and Multi-Matting

Paper：<https://ieeexplore.ieee.org/document/8125753>

作者：

**Yibo Chen（陳軼博）**，香港中文大学。

主页：

<http://www.ee.cuhk.edu.hk/~ybchen/>（港中文主页）

<https://scholar.google.com/citations?user=F3GZ4Q0AAAAJ&hl=zh-CN&oi=sra>（Google学术主页）

**Jingwei Guan**，香港中文大学博士（导师：Wai-Kuen Cham（湛伟权））。

主页：

<http://www.ee.cuhk.edu.hk/en-gb/~jwguan>（港中文主页）

<https://scholar.google.com.hk/citations?user=yV9HSogAAAAJ&hl=zh-CN>（Google学术主页）

**Wai-Kuen Cham（湛伟权）**，香港中文大学。

主页：

<http://www.ee.cuhk.edu.hk/~wkcham/welcome.html>（港中文主页）

<https://scholar.google.com/citations?user=HWb447UAAAAJ&hl=zh-CN&oi=sra>（Google学术主页）

 

## 10、文章：Multi-focus image fusion with a natural enhancement via joint multi-level deeply supervised convolutional neural network 【深度学习】

Paper：<https://ieeexplore.ieee.org/document/8328901>

（DOI：10.1109/TCSVT.2018.2821177）

作者：Wenda Zhao（赵文达）, Dong Wang（王栋）, and Huchuan Lu（卢湖川）

**王栋**，大连理工大学，副教授。

主页：<http://www.escience.cn/people/wangdongdut/index.html>

**卢湖川**，SeniorMember, IEEE

主页：<http://faculty.dlut.edu.cn/Huchuan_Lu/zh_CN/index.htm>

<http://ice.dlut.edu.cn/lu/publications.html>

 

## 11、文章：Unsupervised Deep Multi-focus Image Fusion【深度学习】

Paper：<https://arxiv.org/abs/1806.07272>

<https://www.researchgate.net/publication/325862747_Unsupervised_Deep_Multi-focus_Image_Fusion>

作者：Xiang Yan（延翔）, Student Member, IEEE, Syed Zulqarnain Gilani, Hanlin Qin（秦翰林）,  Ajmal Mian

**秦翰林**，西安电子科技大学物理与光电工程学院 副教授 硕士生导师

教师主页：<http://web.xidian.edu.cn/hlqin/>

 

# 【2017】

## 1、文章：Multi-focus Image Fusion Using Dictionary Learning and Low-Rank Representation     【LRR用于图像融合】

Paper：<https://arxiv.org/abs/1804.08355> 

（DOI:[10.1007/978-3-319-71607-7_59](https://arxiv.org/ct?url=https%3A%2F%2Fdx.doi.org%2F10.1007%252F978-3-319-71607-7_59&v=a4f0f2f5)）

**Code：**<https://github.com/hli1221/imagefusion_dllrr>

作者：**李辉**，江南大学博士。（导师：[吴小俊](http://iot.jiangnan.edu.cn/info/1059/1532.htm)）

 

## 2、文章：[Multi-focus Noisy Image Fusion using Low-Rank Representation ](https://arxiv.org/pdf/1804.09325.pdf) （点击下载文章）     【LRR用于图像融合】

Paper：<https://arxiv.org/abs/1804.09325>

**Code：**<https://github.com/hli1221/imagefusion_noisy_lrr>

作者：**李辉**，江南大学博士。（导师：[吴小俊](http://iot.jiangnan.edu.cn/info/1059/1532.htm)）

**吴小俊**：

主页：<http://iot.jiangnan.edu.cn/info/1059/1532.htm>（学校导师主页）

<https://scholar.google.com/citations?user=5IST34sAAAAJ&hl=zh-CN&oi=sra>（Google学术主页）

 

## 3、文章：Boundary finding based multi-focus image fusion through multi-scale morphological focus-measure

Cite as：

Yu Zhang, Xiangzhi Bai, and Tao Wang. Boundary find Based Multi-focus Image Fusion through Multi-scale Morphological Focus-measure, Information Fusion 35 (2017) 81-101

Paper：<https://doi.org/10.1016/j.inffus.2016.09.006>

**Code：**<https://github.com/uzeful/Boundary-Finding-based-Multi-focus-Image-Fusion>

作者：**张余**，清华大学博士。

主页：

<https://sites.google.com/site/uze1989/>

<https://uzeful.github.io/>

GitHub地址：<https://github.com/uzeful>

 

## 4、文章：Multi-focus image fusion with a deep convolutional neural network 【**深度学习】**

Cite as：

**Yu Liu**, Xun Chen, Hu Peng, Zengfu Wang, Multi-focus image fusion with a deep convolutional neural network,**Information Fusion**, 36: 191-207, 2017. 

Paper：<https://doi.org/10.1016/j.inffus.2016.12.001>

**Code：**<http://www.escience.cn/people/liuyu1/Codes.html>

作者：刘羽，合肥工业大学讲师。硕导。

主页：

<http://www.escience.cn/people/liuyu1/index.html>（科研在线 科研主页）

<https://sites.google.com/site/yuliu316316/>（Google学术主页）

 

## 5、文章：Surface area-based focus criterion for multi-focus image fusion

Paper：<https://doi.org/10.1016/j.inffus.2016.12.009>

作者：**Mansour Nejati**，Isfahan University of Technology

主页：

[https://mansournejati.ece.iut.ac.ir](https://mansournejati.ece.iut.ac.ir/)（网页内包含了**频繁使用的多聚焦图像融合数据集**[Lytro Multi-focus Dataset](https://mansournejati.ece.iut.ac.ir/content/lytro-multi-focus-dataset)）

<https://www.researchgate.net/profile/Mansour_Nejati>（内容更丰富，更详细地罗列出文章和代码）

（作者也做过多曝光图像融合，图像配准，基于低秩和稀疏的图像去噪）

 

## 6、文章：Multi-focus image fusion and super-resolution with convolutional neural network  【**深度学习】【CNN】**

Paper：<https://doi.org/10.1142/S0219691317500370>

作者：Bin Yang, Jinying Zhong, Yuehua Li, Zhongze Chen

 

## 7、文章：[Image Segmentation-Based Multi-Focus Image Fusion Through Multi-Scale Convolutional Neural Network](https://ieeexplore.ieee.org/iel7/6287639/6514899/08000301.pdf)（点击下载文章）  【**深度学习】【CNN】**

Paper：（DOI：10.1109/ACCESS.2017.2735019）

作者：西北工业大学自动化学院ChaoBen Du（杜超本） , SheSheng Gao（高社生） , Ying Liu , BingBing Gao

**杜超本**，西安邮电大学通信与信息工程学院，教师。西工大博士（导师：高社生）

**高社生**，西北工业大学自动化学院教师，博导

主页：

<http://teacher.nwpu.edu.cn/gaoshesheng>（校内导师主页）

<http://zdhxy.nwpu.edu.cn/info/1167/2562.htm>（校内导师主页）

 

## 8、文章：Multi-focus image fusion based on multi-scale focus measures and generalized random walk

Paper：<https://ieeexplore.ieee.org/abstract/document/8028223>

（DOI：[10.23919/ChiCC.2017.8028223](https://doi.org/10.23919/ChiCC.2017.8028223)）

**Code：**<https://github.com/JinleiMa/Multi-focus-Image-Fusion-with-Multi-scale-Focus-Measures>（**代码包里包含论文原文**）

作者：

**马金磊**，北京理工大学自动化学院。

GitHub地址：[https://github.com/JinleiMa?utf8=✓](https://github.com/JinleiMa?utf8=%E2%9C%93)

**周志强**，北京理工大学自动化学院，副教授

主页：<http://ac.bit.edu.cn/szdw/jsdw/mssbyznxtyjs_20150206131517284801/20150206115445413049_20150206131517284801/index.htm>

GitHub地址：<https://github.com/bitzhouzq>

 

## 9、文章：Multi-focus image fusion using HOSVD and edge intensity

Paper：<https://doi.org/10.1016/j.jvcir.2017.02.006>

作者：XiaoqingLuo，ZhanchengZhang，CuiyingZhang，XiaojunWu（吴小俊），江南大学

**吴小俊**：

主页：<http://iot.jiangnan.edu.cn/info/1059/1532.htm>（学校导师主页）

<https://scholar.google.com/citations?user=5IST34sAAAAJ&hl=zh-CN&oi=sra>（Google学术主页）

 

## 10、文章：Multifocus Image Fusion Based on Extreme Learning Machine and Human Visual System

Paper：<https://ieeexplore.ieee.org/document/7906593>

（DOI：[10.1109/ACCESS.2017.2696119](https://doi.org/10.1109/ACCESS.2017.2696119)）

 

# 【2016】

## 1、文章：Robust Multi-Focus Image Fusion Using Multi-Task Sparse Representation and Spatial Context     【RSR】

Cite as：

Zhang Q , Levine M D . Robust Multi-Focus Image Fusion Using Multi-Task Sparse Representation and Spatial Context[J]. IEEE Transactions on Image Processing, 2016, 25(5):2045 - 2058.

Paper：<https://ieeexplore.ieee.org/document/7398058>

（DOI：[10.1109/TIP.2016.2524212](https://doi.org/10.1109/TIP.2016.2524212)）

作者：张强，西安电子科技大学机电工程学院。

 

## 2、文章：Multifocus image fusion using superpixel segmentation and superpixel-based mean filtering     【**基于超像素做图像融合**】

Paper：<https://www.osapublishing.org/ao/abstract.cfm?uri=ao-55-36-10352>

（<https://doi.org/10.1364/AO.55.010352>）

 

## 3、文章：Multi-focus image fusion using multi-scale image decomposition and saliency detection    【结合图像显著性检测】

Paper：<https://doi.org/10.1016/j.asej.2016.06.011>

**Code：**<https://ww2.mathworks.cn/matlabcentral/fileexchange/63592-multi-focus-image-fusion-using-multi-scale-image-decomposition-and-saliency-detection?s_tid=FX_rc3_behav>

作者：**Durga Prasad Bavirisetti**

主页：<https://sites.google.com/view/durgaprasadbavirisetti/home>

（**主页中右上角Datasets中提供了各种图像融合数据集。**）

<https://scholar.google.com/citations?user=hc0VdQQAAAAJ&hl=zh-CN&oi=sra>（Google学术主页）

 

## 4、文章：Multi-focus image fusion algorithm based on focused region extraction      【结合图像显著性检测】【GBVS检测算法】

Paper：<https://doi.org/10.1016/j.neucom.2015.09.092>

作者：

**张宝华**，内蒙古科技大学信息工程学院副教授，硕导。

主页：<http://graduate.imust.cn/info/1063/2331.htm>

**吕晓琪**，内蒙古科技大学信息工程学院教授，博导。

主页：<http://graduate.imust.cn/info/1063/2860.htm>

 

# 【2015】

## 1、文章：Multi-focus image fusion using dictionary-based sparse representation     【SRCF】

Paper：<https://doi.org/10.1016/j.inffus.2014.10.004>

**Code：**<https://www.researchgate.net/publication/324132140_Demo_Code_for_Sparse_Representation-based_Multi-Focus_Image_Fusion_Algorithm>（SRCF）

作者：Mansour Nejati，Shadrokh Samavi，Shahram Shirani

**Mansour Nejati**，Isfahan University of Technology

主页：

[https://mansournejati.ece.iut.ac.ir](https://mansournejati.ece.iut.ac.ir/)（网页内包含了**频繁使用的多聚焦图像融合数据集**[Lytro Multi-focus Dataset](https://mansournejati.ece.iut.ac.ir/content/lytro-multi-focus-dataset)）

<https://www.researchgate.net/profile/Mansour_Nejati>（内容更丰富，更详细地罗列出文章和代码）

（作者也做过多曝光图像融合，图像配准，基于低秩和稀疏的图像去噪）

 

## 2、文章：Quadtree-based multi-focus image fusion using a weighted focus-measure

Cite as：

Xiangzhi Bai, Yu Zhang, Fugen Zhou, and Bindang Xue. Quadtree-based multi-focus image fusion using a weighted focus-measure[J]. Information Fusion, 2015, 22: 105-118.

Paper：<https://doi.org/10.1016/j.inffus.2014.05.003>

**Code：**<https://github.com/uzeful/Quadtree-Based-Multi-focus-Image-Fusion>

作者：**张余**，清华大学博士。

主页：<https://uzeful.github.io/>

GitHub地址：<https://github.com/uzeful>

 

## 3、文章：Multi-focus image fusion with dense SIFT     【DSIFT】

Cite as：

Yu Liu, Shuping Liu, Zengfu Wang, Multi-focus image fusion with  dense SIFT, Information Fusion, 23: 139-155, 2015.

Paper：<https://doi.org/10.1016/j.inffus.2014.05.004>

**Code：**<http://www.escience.cn/people/liuyu1/Codes.html>

作者：刘羽，合肥工业大学讲师。硕导。

主页：

<http://www.escience.cn/people/liuyu1/index.html>（科研在线 科研主页）

<https://sites.google.com/site/yuliu316316/>（Google学术主页）

 

## 4、文章：Multifocus image fusion using phase congruency

Paper：<http://dx.doi.org/10.1117/1.JEI.24.3.033014>

**Code：**<https://github.com/kunzhan/PC_fusion>

作者：**绽琨**，兰州大学。

主页：[https://kunzhan.github.io](https://kunzhan.github.io/)

<https://scholar.google.com/citations?user=sk7TcGAAAAAJ&hl=zh-CN&oi=sra>

GitHub地址：<https://github.com/kunzhan>

 

## 5、文章：[A Novel Explicit Multi-focus Image Fusion Method](http://bit.kuas.edu.tw/~jihmsp/2015/vol6/JIH-MSP-2015-03-018.pdf)

Paper：<https://www.researchgate.net/profile/Jinhui_Shi3/publication/281701555_A_novel_explicit_multi-focus_image_fusion_method/links/566e8a7208ae1a797e40686b/A-novel-explicit-multi-focus-image-fusion-method.pdf>

**Code：**<https://ww2.mathworks.cn/matlabcentral/fileexchange/49956-a-novel-explicit-multi-focus-image-fusion-method>

作者：**绽琨**

 

# 【2014】

## 1、文章：Multi-scale weighted gradient-based fusion for multi-focus images    【MWGF】

Paper：<https://doi.org/10.1016/j.inffus.2013.11.005>

**Code：**<https://github.com/lsauto/MWGF-Fusion>（MWGF）

作者：周志强，北京理工大学自动化学院，副教授

主页：<http://ac.bit.edu.cn/szdw/jsdw/mssbyznxtyjs_20150206131517284801/20150206115445413049_20150206131517284801/index.htm>

 

## 2、文章：Effective Multifocus Image Fusion Based on HVS and BP Neural Network

Paper：<http://dx.doi.org/10.1155/2014/281073>

作者：**杨勇**，江西财经大学

个人主页：

<http://sim.jxufe.cn/down/show-1555.aspx?id=98>

<https://www.hindawi.com/16956424/>

 

## 3、文章：High quality multi-focus image fusion using self-similarity and depth information

Paper：<https://doi.org/10.1016/j.optcom.2014.10.031> （DOI：10.1016/j.optcom.2014.10.031）

**Code：**[http://csrc.xmu.edu.cn](http://csrc.xmu.edu.cn/)（网页内——‘software’栏目内）

作者：

**屈小波**，厦门大学，副教授，博导

主页：

<http://csrc.xmu.edu.cn/xiaobo/index_cn.html>

<https://esci.xmu.edu.cn/e6/48/c9602a190024/page.psp>

<https://scholar.google.com/citations?user=JXw9c2sAAAAJ&hl=zh-CN&oi=sra>（Google学术主页）

 

## 4、文章：Region level based multi-focus image fusion using quaternion wavelet and normalized cut

Paper：<https://doi.org/10.1016/j.sigpro.2013.10.010>（DOI：10.1016/j.sigpro.2013.10.010）

作者：刘义鹏，金晶，王强

刘义鹏，哈工大控制科学与工程博士，浙江工业大学讲师。

主页：<https://liuyipeng.weebly.com/publications.html>

<https://zz.glgoo.top/citations?user=rNcJNosAAAAJ&hl=zh-CN&oi=sra>（Google学术主页）

金晶，哈尔滨工业大学，博导

校内主页：<http://homepage.hit.edu.cn/jinjing>

王强，哈尔滨工业大学，博导

校内主页：<http://homepage.hit.edu.cn/wangqiang>

 

# 【2013】

## 1、文章：[Image matting for fusion of multi-focus images in dynamic scenes](http://xudongkang.weebly.com/uploads/1/6/4/6/16465750/if1.pdf)（点击下载文章）

Cite as：

Li S , Kang X , Hu J , et al. Image matting for fusion of multi-focus images in dynamic scenes[J]. Information Fusion, 2013, 14(2):147-162.

Paper：<https://doi.org/10.1016/j.inffus.2011.07.001>

**Code：**

<http://xudongkang.weebly.com/uploads/1/6/4/6/16465750/ifm.rar> （解压密码：LIvoJeaimnniTgain）

<https://ww2.mathworks.cn/matlabcentral/fileexchange/68963-a-demo-for-image-fusion>

作者：

**康旭东**，湖南大学博士。导师：李树涛。

主页：[http://xudongkang.weebly.com](http://xudongkang.weebly.com/)

**李树涛**，湖南大学，教授，博导。

主页：<https://scholar.google.com/citations?user=PlBq8n8AAAAJ&hl=zh-CN&oi=sra>（Google学术主页）

 

## 2、文章：Multi-focus image fusion using a morphology-based focus measure in a quad-tree structure

Paper：<https://doi.org/10.1016/j.inffus.2012.01.007>

作者：Ishita De, Bhabatosh Chanda

**Bhabatosh Chanda**, Professor, Computer and Communication Science, Indian Statistical Institute

主页：<https://www.isical.ac.in/~chanda/>（学校个人主页）

<https://scholar.google.com/citations?user=Ku-LgdUAAAAJ&hl=zh-CN&oi=sra>（Google学术主页）

 

## 3、文章：[Regional multifocus image fusion using sparse representation](https://pdfs.semanticscholar.org/ee41/fe7105291f7488105f8e8031e7ad7721c659.pdf)

Paper：<https://doi.org/10.1364/OE.21.005182>

作者：Long Chen, Jinbo Li, and C. L. Philip Chen

**C. L. Philip Chen（陈俊龙）**，Chair Professor, University of Macau（澳门大学）

主页：<https://www.fst.umac.mo/en/staff/pchen.html>

<https://scholar.google.com/citations?user=Q5248zwAAAAJ&hl=zh-CN&oi=sra>（Google学术主页）

 

# 【2012】

## 1、文章：Adaptive multi-focus image fusion using a wavelet-based statistical sharpness measure

Cite as：

J. Tian and L. Chen “Adaptive multi-focus image fusion using a wavelet-based statistical sharpness measure,” Signal Processing, Vol. 92, No. 9, Sep. 2012, pp. 2137-2146.

Paper：<https://doi.org/10.1016/j.sigpro.2012.01.027>

**Code：**<https://ww2.mathworks.cn/matlabcentral/fileexchange/36231-adaptive-multi-focus-image-fusion-using-a-wavelet-based-statistical-sharpness-measure>

（http://www.mathworks.com/matlabcentral/fileexchange/36231）

作者：Jing Tian , Li Chen（武汉科技大学）

 

# 【2011】

## 1、文章：Multi-focus image fusion using a bilateral gradient-based sharpness criterion

Cite as：

Tian J , Chen L , Ma L , et al. Multi-focus image fusion using a bilateral gradient-based sharpness criterion[J]. Optics Communications, 2011, 284(1):80-87.

Paper：<https://doi.org/10.1016/j.optcom.2010.08.085>

**Code：**<https://github.com/smart-media-lab/Multi-focus-image-fusion-using-a-bilateral-gradient-based-sharpness-criterion>（**该代码包里包含论文原文**）

或者：<https://ww2.mathworks.cn/matlabcentral/fileexchange/29926-multi-focus-image-fusion-using-a-bilateral-gradient-based-sharpness-criterion>

作者：Jing Tian , Li Chen（武汉科技大学）

 

# 【2010】

## 1、文章：Multifocus Image Fusion and Restoration With Sparse Representation     【第一篇将SR应用于图像融合】

Cite as：

Yang B , Li S . Multifocus Image Fusion and Restoration With Sparse Representation[J]. IEEE Transactions on Instrumentation and Measurement, 2010, 59(4):884-892.

Paper：<https://ieeexplore.ieee.org/document/5299095>

**Code：**<http://www.escience.cn/people/liuyu1/Codes.html>

（刘羽的文章“A general framework for image fusion based on multi-scale transform and sparse representation”的代码包里有本文的代码。）

作者：杨斌，李树涛，湖南大学。

**杨斌**，南华大学电气工程学院，湖南大学博士（导师：李树涛）

主页：<http://tutor.eol.cn/web/school/info?school_id=73&dsid=955>（教师主页）

**李树涛**，湖南大学，教授，博导。

主页：<https://scholar.google.com/citations?user=PlBq8n8AAAAJ&hl=zh-CN&oi=sra>（Google学术主页）

 

# 【2008】

## 1、文章：Multifocus image fusion using region segmentation and spatial frequency

Paper：<https://doi.org/10.1016/j.imavis.2007.10.012>

作者：杨斌，李树涛，湖南大学。

**杨斌**，南华大学电气工程学院，湖南大学博士（导师：李树涛）

主页：<http://tutor.eol.cn/web/school/info?school_id=73&dsid=955>（教师主页）

**李树涛**，湖南大学，教授，博导。

主页：<https://scholar.google.com/citations?user=PlBq8n8AAAAJ&hl=zh-CN&oi=sra>（Google学术主页）

 

====================== 分 ========== 割 ========== 线 ======================

PS：早期的代码中用到的某些函数可能随着MATLAB版本的升级更新，会被删掉，导致运行错误。解决办法就是在自己电脑上保留着低版本的MATLAB。然后用到哪个函数，复制出来粘贴到代码文件夹里。

 











# 图像融合论文及代码网址整理总结（2）——红外与可见光图像融合（持续更新）

置顶

 

2018年12月23日 20:34:14

 

Daniel__Shi

 

阅读数：2159

 

标签： [论文整理](http://so.csdn.net/so/search/s.do?q=%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86&t=blog)[作者主页整理](http://so.csdn.net/so/search/s.do?q=%E4%BD%9C%E8%80%85%E4%B8%BB%E9%A1%B5%E6%95%B4%E7%90%86&t=blog)[代码整理](http://so.csdn.net/so/search/s.do?q=%E4%BB%A3%E7%A0%81%E6%95%B4%E7%90%86&t=blog)[红外与可见光图像融合](http://so.csdn.net/so/search/s.do?q=%E7%BA%A2%E5%A4%96%E4%B8%8E%E5%8F%AF%E8%A7%81%E5%85%89%E5%9B%BE%E5%83%8F%E8%9E%8D%E5%90%88&t=blog) 更多

个人分类： [图像融合](https://blog.csdn.net/shitao99/article/category/8591630)



 版权声明：本文为博主原创文章，未经博主允许不得转载。如有问题，欢迎评论指正。	https://blog.csdn.net/shitao99/article/details/85214279

写在前面的话：

本篇博文主要整理汇总一下现有的红外与可见光图像融合算法（文章和代码）。适当地，也会整理出作者的学术主页。整理这些的初衷，是为了方便自己，顺便也给同领域的研究者在找代码等方面提供些许便利。另外，该领域的文章很多，本篇博文也只是整理了其中的一部分，并且，本人不会对论文内容做过多评论。

 

同系列的博文还有：

[图像融合论文及代码网址整理总结（1）——多聚焦图像融合（持续更新）](https://blog.csdn.net/shitao99/article/details/85205304)

[图像融合论文及代码网址整理总结（3）——题目中未加区分的图像融合算法（持续更新）](https://blog.csdn.net/shitao99/article/details/85215086)

[图像融合数据集，图像融合数据库（有了新的会更新）](https://blog.csdn.net/shitao99/article/details/83994908)

===================== 分 ========== 割 ========== 线 =====================

 

**目录**

[【2019】](https://blog.csdn.net/shitao99/article/details/85214279#%E3%80%902019%E3%80%91)

[1、文章：FusionGAN：A generative adversarial network for infrared and visible image fusion  【深度学习】](https://blog.csdn.net/shitao99/article/details/85214279#1%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AFusionGAN%EF%BC%9AA%20generative%20adversarial%20network%20for%20infrared%20and%20visible%20image%20fusion%20%C2%A0%20%C2%A0%20%C2%A0%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91)

[2、文章：Infrared and visible image fusion methods and applications: A survey 【综述文章】](https://blog.csdn.net/shitao99/article/details/85214279#2%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AInfrared%20and%20visible%20image%20fusion%20methods%20and%20applications%3A%20A%20survey%20%C2%A0%20%C2%A0%20%C2%A0%20%C2%A0%E3%80%90%E7%BB%BC%E8%BF%B0%E6%96%87%E7%AB%A0%E3%80%91)

[【2018】](https://blog.csdn.net/shitao99/article/details/85214279#%E3%80%902018%E3%80%91)

[1、文章：Infrared and Visible Image Fusion with ResNet and zero-phase component analysis（点击下载文章）【深度学习】](https://blog.csdn.net/shitao99/article/details/85214279#1%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AInfrared%20and%20Visible%20Image%20Fusion%20with%20ResNet%20and%20zero-phase%20component%20analysis%EF%BC%88%E7%82%B9%E5%87%BB%E4%B8%8B%E8%BD%BD%E6%96%87%E7%AB%A0%EF%BC%89%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91)

[2、文章：DenseFuse: A Fusion Approach to Infrared and Visible Images（点击下载文章）【深度学习】](https://blog.csdn.net/shitao99/article/details/85214279#2%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9ADenseFuse%3A%20A%20Fusion%20Approach%20to%20Infrared%20and%C2%A0Visible%20Images%EF%BC%88%E7%82%B9%E5%87%BB%E5%8F%AF%E7%9B%B4%E6%8E%A5%E4%B8%8B%E8%BD%BD%E6%96%87%E7%AB%A0%EF%BC%89%20%C2%A0%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91)

[3、文章：Infrared and Visible Image Fusion using a Deep Learning Framework（点击下载文章）【深度学习】](https://blog.csdn.net/shitao99/article/details/85214279#3%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AInfrared%20and%20Visible%20Image%20Fusion%20using%20a%20Deep%C2%A0Learning%20Framework%EF%BC%88%E7%82%B9%E5%87%BB%E4%B8%8B%E8%BD%BD%E6%96%87%E7%AB%A0%EF%BC%89%C2%A0%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91)

[4、文章：Infrared and visible image fusion using Latent Low-Rank Representation     【LRR用于图像融合】](https://blog.csdn.net/shitao99/article/details/85214279#4%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AInfrared%20and%20visible%20image%20fusion%20using%20Latent%C2%A0Low-Rank%20Representation)

[5、文章：Infrared and visible image fusion using a novel deep decomposition method（点击下载文章）【深度学习】](https://blog.csdn.net/shitao99/article/details/85214279#5%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AInfrared%20and%20visible%20image%20fusion%20using%20a%20novel%20deep%20decomposition%20method%EF%BC%88%E7%82%B9%E5%87%BB%E4%B8%8B%E8%BD%BD%E6%96%87%E7%AB%A0%EF%BC%89%C2%A0%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91)

[6、文章：Infrared and visual image fusion method based on discrete cosine transform and local spatial frequency in discrete stationary wavelet transform domain](https://blog.csdn.net/shitao99/article/details/85214279#6%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AInfrared%20and%20visual%20image%20fusion%20method%20based%20on%20discrete%20cosine%20transform%20and%20local%20spatial%20frequency%20in%20discrete%20stationary%20wavelet%20transform%20domain)

[7、文章：Infrared-Visible Image Fusion Based on Convolutional Neural Networks (CNN)【深度学习】](https://blog.csdn.net/shitao99/article/details/85214279#7%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AInfrared-Visible%20Image%20Fusion%20Based%20on%20Convolutional%20Neural%20Networks%20(CNN)%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91)

[8、文章：Multi-scale decomposition based fusion of infrared and visible image via total variation and saliency analysis](https://blog.csdn.net/shitao99/article/details/85214279#8%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AMulti-scale%20decomposition%20based%20fusion%20of%20infrared%20and%20visible%20image%20via%20total%20variation%20and%20saliency%20analysis)

[9、文章：Visible and infrared image fusion using DTCWT and adaptive combined clustered dictionary](https://blog.csdn.net/shitao99/article/details/85214279#9%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AVisible%20and%20infrared%20image%20fusion%20using%20DTCWT%20and%20adaptive%20combined%20clustered%20dictionary)

[10、文章：Infrared and visible image fusion based on convolutional neural network model and saliency detection via hybrid l0-l1 layer decomposition 【CNN】【深度学习】【显著性检测】](https://blog.csdn.net/shitao99/article/details/85214279#10%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AInfrared%20and%20visible%20image%20fusion%20based%20on%20convolutional%20neural%20network%20model%20and%20saliency%20detection%20via%20hybrid%20l0-l1%20layer%20decomposition)

[【2017】](https://blog.csdn.net/shitao99/article/details/85214279#%E3%80%902017%E3%80%91)

[1、文章：Fusion of visible and infrared images using global entropy and gradient constrained regularization](https://blog.csdn.net/shitao99/article/details/85214279#1%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AFusion%20of%20visible%20and%20infrared%20images%20using%20global%20entropy%20and%20gradient%20constrained%20regularization)

[2、文章：A survey of infrared and visual image fusion methods   【综述文章】](https://blog.csdn.net/shitao99/article/details/85214279#2%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AA%20survey%20of%20infrared%20and%20visual%20image%20fusion%20methods%20%C2%A0%C2%A0%E3%80%90%E7%BB%BC%E8%BF%B0%E6%96%87%E7%AB%A0%E3%80%91)

[3、文章：Infrared and Visual Image Fusion through Infrared Feature Extraction and Visual Information Preservation](https://blog.csdn.net/shitao99/article/details/85214279#3%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AInfrared%20and%20Visual%20Image%20Fusion%20through%20Infrared%20Feature%20Extraction%20and%20Visual%20Information%20Preservation)

[4、文章：Visible and NIR image fusion using weight-map-guided Laplacian–Gaussian pyramid for improving scene visibility](https://blog.csdn.net/shitao99/article/details/85214279#4%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AVisible%20and%20NIR%20image%20fusion%20using%20weight-map-guided%C2%A0Laplacian%E2%80%93Gaussian%20pyramid%20for%20improving%20scene%20visibility)

[5、文章：Infrared and visible image fusion based on visual saliency map and weighted least square optimization](https://blog.csdn.net/shitao99/article/details/85214279#5%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AInfrared%20and%20visible%20image%20fusion%20based%20on%20visual%20saliency%20map%C2%A0and%20weighted%20least%20square%20optimization)

[6、文章：Infrared and visible image fusion method based on saliency detection in sparse domain](https://blog.csdn.net/shitao99/article/details/85214279#6%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AInfrared%20and%20visible%20image%20fusion%20method%20based%20on%20saliency%20detection%20in%20sparse%20domain)

[7、文章：Infrared and visible image fusion with convolutional neural networks 【深度学习】【CNN】](https://blog.csdn.net/shitao99/article/details/85214279#7%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AInfrared%20and%20visible%20image%20fusion%20with%20convolutional%20neural%20networks%20%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91)

[8、文章：Infrared and visible image fusion based on total variation and augmented Lagrangian](https://blog.csdn.net/shitao99/article/details/85214279#8%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AInfrared%20and%20visible%20image%20fusion%20based%20on%20total%C2%A0variation%20and%20augmented%20Lagrangian)

[9、文章：Fusion of infrared-visible images using improved multi-scale top-hat transform and suitable fusion rules](https://blog.csdn.net/shitao99/article/details/85214279#9%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AFusion%20of%20infrared-visible%20images%20using%20improved%20multi-scale%20top-hat%20transform%20and%20suitable%20fusion%20rules)

[【2016】](https://blog.csdn.net/shitao99/article/details/85214279#%E3%80%902016%E3%80%91)

[1、文章：Infrared and visible image fusion via gradient transfer and total variation minimization（点击下载文章）](https://blog.csdn.net/shitao99/article/details/85214279#1%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AInfrared%20and%20visible%20image%20fusion%20via%20gradient%20transfer%20and%20total%20variation%20minimization%EF%BC%88%E7%82%B9%E5%87%BB%E5%8F%AF%E7%9B%B4%E6%8E%A5%E4%B8%8B%E8%BD%BD%E6%96%87%E7%AB%A0%EF%BC%89)

[2、文章：Multi-window visual saliency extraction for fusion of visible and infrared images](https://blog.csdn.net/shitao99/article/details/85214279#2%E3%80%81)

[3、文章：Two-scale image fusion of visible and infrared images using saliency detection](https://blog.csdn.net/shitao99/article/details/85214279#3%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9ATwo-scale%20image%20fusion%20of%20visible%20and%20infrared%20images%20using%20saliency%20detection)

[4、文章：Fusion of Infrared and Visible Sensor Images Based on Anisotropic Diffusion and Karhunen-Loeve Transform](https://blog.csdn.net/shitao99/article/details/85214279#4%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AFusion%20of%20Infrared%20and%20Visible%20Sensor%20Images%20Based%20on%20Anisotropic%20Diffusion%20and%20Karhunen-Loeve%20Transform)

[5、文章：Perceptual fusion of infrared and visible images through a hybrid multi-scale decomposition with Gaussian and bilateral filters     【HMSD】](https://blog.csdn.net/shitao99/article/details/85214279#4%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9APerceptual%20fusion%20of%20infrared%20and%20visible%20images%20through%20a%20hybrid%20multi-scale%20decomposition%20with%20Gaussian%20and%20bilateral%20filters%20%C2%A0%20%C2%A0%20%E3%80%90HMSD%E3%80%91)

[6、文章：Fusion of infrared and visible images for night-vision context enhancement](https://blog.csdn.net/shitao99/article/details/85214279#5%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AFusion%20of%20infrared%20and%20visible%20images%20for%20night-vision%20context%20enhancement)

[【2015】](https://blog.csdn.net/shitao99/article/details/85214279#%E3%80%902015%E3%80%91)

[1、文章：Attention-based hierarchical fusion of visible and infrared images](https://blog.csdn.net/shitao99/article/details/85214279#1%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AAttention-based%20hierarchical%20fusion%20of%20visible%20and%20infrared%20images)

[【2014】](https://blog.csdn.net/shitao99/article/details/85214279#%E3%80%902014%E3%80%91)

[1、文章：Fusion method for infrared and visible images by using non-negative sparse representation     【NNSR】](https://blog.csdn.net/shitao99/article/details/85214279#1%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AFusion%20method%20for%20infrared%20and%20visible%20images%20by%20using%20non-negative%20sparse%20representation)

[2、文章：The infrared and visible image fusion algorithm based on target separation and sparse representation](https://blog.csdn.net/shitao99/article/details/85214279#2%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AThe%20infrared%20and%20visible%20image%20fusion%20algorithm%20based%20on%20target%20separation%20and%20sparse%20representation)

------

 

# 【2019】

## 1、文章：FusionGAN：A generative adversarial network for infrared and visible image fusion  【**深度学习】**

Cite as：

Jiayi Ma, Wei Yu, Pengwei Liang, Chang Li, and Junjun Jiang. FusionGAN: A generative adversarial network for infrared and visible image fusion, Information Fusion, 48, pp. 11-26, Aug. 2019.

Paper：<https://doi.org/10.1016/j.inffus.2018.09.004>

Code：<https://github.com/jiayi-ma/FusionGAN>

作者：

**马佳义**，武汉大学。

个人主页：

<http://www.escience.cn/people/jiayima/index.html> （科研在线 科研主页）

<http://mvp.whu.edu.cn/jiayima/>

GitHub地址：<https://github.com/jiayi-ma>

**李畅**，合肥工业大学，讲师。

个人主页：<http://www.escience.cn/people/lichang/index.html>（科研在线 科研主页）

（值得一提：主页内Data栏总结了高光谱图像数据链接。）

[ ](http://www.escience.cn/institution/hfut/index.html)GitHub地址：<https://github.com/Chang-Li-HFUT>

**江俊君**，哈尔滨工业大学，教授。

个人主页：

<http://www.escience.cn/people/jiangjunjun/index.html>（科研在线 科研主页）

[https://jiangjunjun.wordpress.com](https://jiangjunjun.wordpress.com/)

<http://homepage.hit.edu.cn/jiangjunjun>（哈工大主页）

<https://scholar.google.com/citations?user=WNH2_rgAAAAJ&hl=zh-CN&oi=ao>（Google学术主页）

<https://github.com/junjun-jiang>（GitHub主页）

 

## 2、文章：Infrared and visible image fusion methods and applications: A survey **【综述文章】**

Cite as：

 Jiayi Ma, Yong Ma, and Chang Li. "Infrared and visible image fusion methods and applications: A survey", Information Fusion, 45, pp. 153-178, 2019.

Paper：<https://doi.org/10.1016/j.inffus.2018.02.004>

作者：**马佳义**，武汉大学。[马泳](http://mvp.whu.edu.cn/%E9%A9%AC%E6%B3%B3-%E6%95%99%E6%8E%88/)，[李畅](http://www.escience.cn/people/lichang/index.html)。

 

# 【2018】

## 1、文章：[Infrared and Visible Image Fusion with ResNet and zero-phase component analysis](https://arxiv.org/pdf/1806.07119.pdf)（点击下载文章）【**深度学习】**

Cite as：

Li H , Wu X J , Durrani T S . Infrared and Visible Image Fusion with ResNet and zero-phase component analysis[J]. 2018.

Paper：<https://arxiv.org/abs/1806.07119>

Code：<https://github.com/hli1221/imagefusion_resnet50>

作者：

**李辉**，江南大学博士。（导师：[吴小俊](http://iot.jiangnan.edu.cn/info/1059/1532.htm)）

主页：[https://hli1221.github.io](https://hli1221.github.io/)

GitHub地址：

<https://github.com/hli1221> （primary GitHub）

<https://github.com/exceptionLi>

**吴小俊**：

主页：<http://iot.jiangnan.edu.cn/info/1059/1532.htm>（学校导师主页）

<https://scholar.google.com/citations?user=5IST34sAAAAJ&hl=zh-CN&oi=sra>（Google学术主页）

 

## 2、文章：[DenseFuse: A Fusion Approach to Infrared and Visible Images](https://arxiv.org/pdf/1804.08361.pdf)（点击下载文章）【**深度学习】**

Cite as：

H. Li, X. J. Wu, DenseFuse: A Fusion Approach to Infrared and Visible Images, IEEE Trans. Image Process.(Early Access), pp. 1-1, 2018.

Paper：<https://arxiv.org/abs/1804.08361>

（DOI：[10.1109/TIP.2018.2887342](https://arxiv.org/ct?url=https%3A%2F%2Fdx.doi.org%2F10.1109%252FTIP.2018.2887342&v=b39983f9)）

Code：<https://github.com/hli1221/imagefusion_densefuse>

另一个实现：<https://github.com/srinu007/MultiModelImageFusion>（代码包里也包含有图像融合MATLAB客观评价指标函数）

作者：**李辉**，江南大学博士。（导师：[吴小俊](http://iot.jiangnan.edu.cn/info/1059/1532.htm)）

 

## 3、文章：[Infrared and Visible Image Fusion using a Deep Learning Framework](https://arxiv.org/pdf/1804.06992.pdf)（点击下载文章）【**深度学习】**

Cite as：

Li H, Wu X J, Kittler J. Infrared and Visible Image Fusion using a Deep Learning Framework[C]//Pattern Recognition (ICPR), 2018 24rd International Conference on. IEEE, 2018: 2705 - 2710.

Paper：<https://arxiv.org/pdf/1804.06992>

（**DOI:** [10.1109/ICPR.2018.8546006](https://doi.org/10.1109/ICPR.2018.8546006)）

Code：<https://github.com/hli1221/imagefusion_deeplearning>

作者：**李辉**，江南大学博士。（导师：[吴小俊](http://iot.jiangnan.edu.cn/info/1059/1532.htm)）

 

## 4、文章：Infrared and visible image fusion using Latent Low-Rank Representation     【LRR用于图像融合】

Cite as：

Li H, Wu X J. Infrared and visible image fusion using Latent Low-Rank Representation[J]. 2018.

Paper：<https://arxiv.org/abs/1804.08992>

Code：<https://github.com/exceptionLi/imagefusion_Infrared_visible_latlrr>

作者：**李辉**，江南大学博士。（导师：[吴小俊](http://iot.jiangnan.edu.cn/info/1059/1532.htm)）

 

## 5、文章：[Infrared and visible image fusion using a novel deep decomposition method](https://arxiv.org/vc/arxiv/papers/1811/1811.02291v1.pdf)（点击下载文章）【**深度学习】**

Paper：<https://arxiv.org/abs/1811.02291>

Code：<https://github.com/hli1221/imagefusion_deepdecomposition>

作者：**李辉**，江南大学博士。（导师：[吴小俊](http://iot.jiangnan.edu.cn/info/1059/1532.htm)）

 

## 6、文章：Infrared and visual image fusion method based on discrete cosine transform and local spatial frequency in discrete stationary wavelet transform domain

Paper：<https://doi.org/10.1016/j.infrared.2017.10.004>

Code：<https://github.com/jinxinhuo/SWT_DCT_SF-for-image-fusion>

<https://ww2.mathworks.cn/matlabcentral/fileexchange/68674-infrared-and-visual-image-fusion-method-based-on-swt_dct_sf?s_tid=FX_rc2_behav>

作者：**金鑫**——2013级云南大学博士。

 

## 7、文章：[Infrared-Visible Image Fusion Based on Convolutional Neural Networks (CNN)](https://link.springer.com/content/pdf/10.1007%2F978-3-030-02698-1_26.pdf)【**深度学习】**

Paper：<https://link.springer.com/chapter/10.1007%2F978-3-030-02698-1_26>

<https://doi.org/10.1007/978-3-030-02698-1_26>

作者：Xianyi Ren, Fanyang Meng, Tao Hu, Zhijun Liu, Changwei Wang，Shenzhen Institute of Information Technology

 

## 8、文章：Multi-scale decomposition based fusion of infrared and visible image via total variation and saliency analysis

Paper：<https://doi.org/10.1016/j.infrared.2018.06.002>

作者：Siwen Quan (**权思文**)

主页：<https://sites.google.com/view/siwenquanshomepage>

<https://scholar.google.com/citations?user=9CS008EAAAAJ&hl=zh-CN&oi=sra>（Google学术主页）

 

## 9、文章：Visible and infrared image fusion using DTCWT and adaptive combined clustered dictionary

Paper：<https://doi.org/10.1016/j.infrared.2018.08.013>

 

## 10、文章：Infrared and visible image fusion based on convolutional neural network model and saliency detection via hybrid l0-l1 layer decomposition 【CNN】【深度学习】【显著性检测】

Paper：<https://doi.org/10.1117/1.JEI.27.6.063036>

作者：

周冬明——云南大学教授，博导
聂仁灿——云南大学信息学院副教授，博士，硕士生导师 

 

# 【2017】

## 1、文章：Fusion of visible and infrared images using global entropy and gradient constrained regularization

Paper：<https://doi.org/10.1016/j.infrared.2017.01.012>

作者：赵巨峰，杭州电子科技大学副教授，硕导。

个人主页：<http://mypage.hdu.edu.cn/zhaojufeng/0.html>

 

## 2、文章：A survey of infrared and visual image fusion methods   **【综述文章】**

Paper：<https://doi.org/10.1016/j.infrared.2017.07.010>

作者：

金鑫——2013级云南大学博士。
姚邵文——云南大学软件学院院长
周冬明——云南大学教授，博导
聂仁灿——云南大学信息学院副教授，博士，硕士生导师 

贺康建——2014级云南大学博士

 

## 3、文章：Infrared and Visual Image Fusion through Infrared Feature Extraction and Visual Information Preservation

Cite as：

Yu Zhang, Lijia Zhang, Xiangzhi Bai and Li Zhang. Infrared and Visual Image Fusion through Infrared Feature Extraction and Visual Information Preservation, Infrared Physics & Technology 83 (2017) 227-237.

Paper：<http://dx.doi.org/10.1016/j.infrared.2017.05.007>（DOI：10.1016/j.infrared.2017.05.007）

Code：<https://github.com/uzeful/Infrared-and-Visual-Image-Fusion-via-Infrared-Feature-Extraction-and-Visual-Information-Preservation>

作者：**张余**，清华大学博士。

主页：

<https://sites.google.com/site/uze1989/>

<https://uzeful.github.io/>

GitHub地址：<https://github.com/uzeful>

 

## 4、文章：Visible and NIR image fusion using weight-map-guided Laplacian–Gaussian pyramid for improving scene visibility

Cite as：

Vanmali A V , Gadre V M . Visible and NIR image fusion using weight-map-guided Laplacian–Gaussian pyramid for improving scene visibility[J]. Sādhanā, 2017, 42(7):1063-1082.

Paper： （DOI：10.1007/s12046-017-0673-1）

Code：<https://drive.google.com/file/d/0B-hGkOHjv3gzVnU5Slg2YWZRWVE/view?usp=sharing>

 

## 5、文章：Infrared and visible image fusion based on visual saliency map and weighted least square optimization

Cite as：

Ma J, Zhou Z, Wang B, et al. Infrared and visible image fusion based on visual saliency map and weighted least square optimization[J]. Infrared Physics & Technology, 2017, 82:8-17.

Paper：<https://doi.org/10.1016/j.infrared.2017.02.005>（DOI：10.1016/j.infrared.2017.02.005）

Code：<https://github.com/JinleiMa/Image-fusion-with-VSM-and-WLS>

作者：马金磊，北京理工大学。

GitHub地址：[https://github.com/JinleiMa?utf8=✓](https://github.com/JinleiMa?utf8=%E2%9C%93)

 

## 6、文章：Infrared and visible image fusion method based on saliency detection in sparse domain

Cite as：

Liu C H , Qi Y , Ding W R . Infrared and visible image fusion method based on saliency detection in sparse domain[J]. Infrared Physics & Technology, 2017:S1350449516307150.

Paper：<https://doi.org/10.1016/j.infrared.2017.04.018>（DOI：10.1016/j.infrared.2017.04.018）

 

## 7、文章：Infrared and visible image fusion with convolutional neural networks 【深度学习】【CNN】

Cite as：

**Yu Liu**, Xun Chen, Juan Cheng, Hu Peng, Zengfu Wang,“Infrared and visible image fusion with convolutional neural networks”, International Journal of Wavelets,Multiresolution and Information Processing, vol. 16, no. 3, 1850018: 1-20, 2018.

Paper：<https://www.worldscientific.com/doi/abs/10.1142/S0219691318500182>

<https://www.researchgate.net/publication/321799375_Infrared_and_visible_image_fusion_with_convolutional_neural_networks>

（DOI：10.1142/S0219691318500182）

Code：<http://www.escience.cn/people/liuyu1/Codes.html>（刘羽）

**作者：**

**刘羽**

**陈勋，教授、博导**

<http://staff.ustc.edu.cn/~xunchen/>

<https://scholar.google.com/citations?user=aBnUWyQAAAAJ&hl=zh-CN&oi=sra>（Google学术主页）

**成娟**

<http://www.escience.cn/people/chengjuanhfut/index.html>

<https://scholar.google.com/citations?user=fMOOhH8AAAAJ&hl=zh-CN&oi=sra>（Google学术主页）

 

## 8、文章：Infrared and visible image fusion based on total variation and augmented Lagrangian

Paper：https://doi.org/10.1364/JOSAA.34.001961

作者：HANQI GUO, YONG MA（[马泳](http://mvp.whu.edu.cn/%E9%A9%AC%E6%B3%B3-%E6%95%99%E6%8E%88/)）, XIAOGUANG MEI（[梅晓光](http://mvp.whu.edu.cn/meixiaoguang/)）, JIAYI MA（**马佳义**），武汉大学。

 

## 9、文章：Fusion of infrared-visible images using improved multi-scale top-hat transform and suitable fusion rules

Paper：<https://doi.org/10.1016/j.infrared.2017.01.013>

 

## 10、Fusion of infrared and visible images based on nonsubsampled contourlet transform and sparse K-SVD dictionary learning

Paper：（DOI：10.1016/j.infrared.2017.01.026）

作者：

Jiajun Cai，武汉大学

<https://c.glgoo.top/citations?user=1jAmUp0AAAAJ&hl=zh-CN&oi=sra>

 

 

# 【2016】

## 1、文章：[Infrared and visible image fusion via gradient transfer and total variation minimization](https://docs.google.com/viewer?a=v&pid=sites&srcid=ZGVmYXVsdGRvbWFpbnxqaWF5aW1hMjAxM3xneDoxNTVmNjdkNTg5Y2FmMzM2)（点击下载文章）

Cite as：

Jiayi Ma, Chen Chen, Chang Li, and Jun Huang. Infrared and visible image fusion via gradient transfer and total variation minimization, Information Fusion, 31, pp. 100-109, Sept. 2016.

Paper：<https://doi.org/10.1016/j.inffus.2016.02.001>

Code：<https://github.com/jiayi-ma/GTF>

**（代码包里也提供了论文中用作对比实验的其他八种算法的代码，以及图像融合MATLAB客观评价指标函数）**

作者：**马佳义**，武汉大学。

 

## 2、文章：Multi-window visual saliency extraction for fusion of visible and infrared images

Cite as：

Zhao J , Gao X , Chen Y , et al. Multi-window visual saliency extraction for fusion of visible and infrared images[J]. Infrared Physics & Technology, 2016, 76:295-302.

Paper：<https://doi.org/10.1016/j.infrared.2016.01.020>

作者：**赵巨峰**，杭州电子科技大学副教授，硕导。

个人主页：<http://mypage.hdu.edu.cn/zhaojufeng/0.html>

 

## 3、文章：Two-scale image fusion of visible and infrared images using saliency detection

Cite as：

Bavirisetti D P , Dhuli R . Two-scale image fusion of visible and infrared images using saliency detection[J]. Infrared Physics & Technology, 2016, 76:52-64.

Paper：<https://doi.org/10.1016/j.infrared.2016.01.009>

Code：<https://www.mathworks.com/matlabcentral/fileexchange/63571-two-scale-image-fusion-of-visible-and-infrared-images-using-saliency-detection>

作者：**Durga Prasad Bavirisetti**

主页：<https://sites.google.com/view/durgaprasadbavirisetti/home>

（**主页中右上角Datasets中提供了各种图像融合数据集。**）

<https://scholar.google.com/citations?user=hc0VdQQAAAAJ&hl=zh-CN&oi=sra>（Google学术主页）

 

## 4、文章：Fusion of Infrared and Visible Sensor Images Based on Anisotropic Diffusion and Karhunen-Loeve Transform

Paper：<https://ieeexplore.ieee.org/document/7264981>

（**DOI:** [10.1109/JSEN.2015.2478655](https://doi.org/10.1109/JSEN.2015.2478655)）

Code：<https://ww2.mathworks.cn/matlabcentral/fileexchange/63591-fusion-of-infrared-and-visible-sensor-images-based-on-anisotropic-diffusion-and-kl-transform?s_tid=FX_rc2_behav>

作者：**Durga Prasad Bavirisetti**

主页：<https://sites.google.com/view/durgaprasadbavirisetti/home>

（**主页中右上角Datasets中提供了各种图像融合数据集。**）

<https://scholar.google.com/citations?user=hc0VdQQAAAAJ&hl=zh-CN&oi=sra>（Google学术主页）

 

## 5、文章：Perceptual fusion of infrared and visible images through a hybrid multi-scale decomposition with Gaussian and bilateral filters     【HMSD】

Cite as:

Zhiqiang Zhou et al. "Perceptual fusion of infrared and visible images through a hybrid multi-scale decomposition with Gaussian and bilateral filters", Information Fusion, 30, 2016

Paper：<https://doi.org/10.1016/j.inffus.2015.11.003>

Code：<https://github.com/bitzhouzq/Hybrid-MSD-Fusion>

或：<https://www.researchgate.net/publication/304246314>

作者：**周志强**，北京理工大学自动化学院，副教授

主页：<http://ac.bit.edu.cn/szdw/jsdw/mssbyznxtyjs_20150206131517284801/20150206115445413049_20150206131517284801/index.htm>

GitHub地址：<https://github.com/bitzhouzq>

 

## 6、文章：Fusion of infrared and visible images for night-vision context enhancement

Paper：<https://doi.org/10.1364/AO.55.006480>

Code：<https://github.com/bitzhouzq/Context-Enhance-via-Fusion>

作者：**周志强**，北京理工大学自动化学院，副教授

主页：<http://ac.bit.edu.cn/szdw/jsdw/mssbyznxtyjs_20150206131517284801/20150206115445413049_20150206131517284801/index.htm>

GitHub地址：<https://github.com/bitzhouzq>

 

# 【2015】

## 1、文章：Attention-based hierarchical fusion of visible and infrared images

Paper：<https://doi.org/10.1016/j.ijleo.2015.08.120>

作者：

**陈艳菲**，副教授，硕士生导师。

主页：<http://eie.wit.edu.cn/info/1067/1028.htm>（教师主页）

**桑农**，华中科技大学自动化学院教授，博士生导师

主页：<http://auto.hust.edu.cn/info/1154/3414.htm>（教师主页）

 

# 【2014】

## 1、文章：Fusion method for infrared and visible images by using non-negative sparse representation     【NNSR】

Cite as：

Wang J , Peng J , Feng X , et al. Fusion method for infrared and visible images by using non-negative sparse representation[J]. Infrared Physics & Technology, 2014, 67:477-489.

Paper：<https://doi.org/10.1016/j.infrared.2014.09.019>

作者：西北工业大学 **王珺**，[彭进业](http://ist.nwu.edu.cn/home/index/article/mid/5357/id/189980.html)，[冯晓毅](http://dianzi.nwpu.edu.cn/info/1290/8223.htm)，[何贵青](http://dianzi.nwpu.edu.cn/info/1291/8327.htm)

 

## 2、文章：The infrared and visible image fusion algorithm based on target separation and sparse representation

Cite as：

Lu X , Zhang B , Zhao Y , et al. The infrared and visible image fusion algorithm based on target separation and sparse representation[J]. Infrared Physics & Technology, 2014, 67:397-407.

Paper：<https://doi.org/10.1016/j.infrared.2014.09.007>

作者：吕晓琪，张宝华，赵瑛，内蒙古科技大学

**吕晓琪**，内蒙古科技大学信息工程学院教授，博导。

主页：<http://graduate.imust.cn/info/1063/2860.htm>

**张宝华**，内蒙古科技大学信息工程学院副教授，硕导。

主页：<http://graduate.imust.cn/info/1063/2331.htm>

**赵瑛**，内蒙古科技大学信息工程学院讲师，硕导。

主页：<http://graduate.imust.cn/info/1063/2409.htm>

 

 

 

===================== 分 ========== 割 ========== 线 =====================

PS：早期的代码中用到的某些函数可能随着MATLAB版本的升级更新，会被删掉，导致运行错误。解决办法就是在自己电脑上保留着低版本的MATLAB。然后用到哪个函数，复制出来粘贴到代码文件夹里。

 











# 图像融合论文及代码网址整理总结（3）——题目中未加区分的图像融合算法（持续更新）

置顶

 

2018年12月25日 16:37:35

 

Daniel__Shi

 

阅读数：506

 

标签： [图像融合](http://so.csdn.net/so/search/s.do?q=%E5%9B%BE%E5%83%8F%E8%9E%8D%E5%90%88&t=blog)[论文整理](http://so.csdn.net/so/search/s.do?q=%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86&t=blog)[论文代码](http://so.csdn.net/so/search/s.do?q=%E8%AE%BA%E6%96%87%E4%BB%A3%E7%A0%81&t=blog)更多

个人分类： [图像融合](https://blog.csdn.net/shitao99/article/category/8591630)



版权声明：本文为博主原创文章，未经博主允许不得转载。如有问题，欢迎评论指正。	https://blog.csdn.net/shitao99/article/details/85215086

写在前面的话：

之前写过两篇博文，针对性地整理汇总了多聚焦图像融合和红外与可见光图像融合的算法。之所以这样分类，是基于论文的标题和内容中明确指出了所处理的图像类型。

而本篇博文主要整理那些论文标题中未明确指出所处理的图像对象。换句话说，作者提出的算法既可以处理多聚焦图像，也可以处理红外与可见光等多模态图像（包括医学图像融合）（当然，这些也可以在论文的实验部分看到），多曝光图像等。

整理这些的初衷，是为了方便自己，顺便也给同领域的研究者在找代码等方面提供些许便利。另外，该领域的文章很多，本篇博文也只是整理了其中的一部分，并且，本人不会对论文内容做过多评论。

 

同系列的博文还有：

[图像融合论文及代码网址整理总结（1）——多聚焦图像融合（持续更新）](https://blog.csdn.net/shitao99/article/details/85205304)

[图像融合论文及代码网址整理总结（2）——红外与可见光图像融合（持续更新）](https://blog.csdn.net/shitao99/article/details/85214279)

[图像融合数据集，图像融合数据库（有了新的会更新）](https://blog.csdn.net/shitao99/article/details/83994908)

====================== 分 ========== 割 ========== 线 ======================

**目录**

[【2019】](https://blog.csdn.net/shitao99/article/details/85215086#%E3%80%902019%E3%80%91)

[1、文章：A survey on region based image fusion methods  【综述文章】](https://blog.csdn.net/shitao99/article/details/85215086#1%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AA%20survey%20on%20region%20based%20image%20fusion%20methods%20%C2%A0%E3%80%90%E7%BB%BC%E8%BF%B0%E6%96%87%E7%AB%A0%E3%80%91)

[【2018】](https://blog.csdn.net/shitao99/article/details/85215086#%E3%80%902018%E3%80%91)

[1、文章：Deep learning for pixel-level image fusion: Recent advances and future prospects     【综述文章】【深度学习】](https://blog.csdn.net/shitao99/article/details/85215086#1%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9ADeep%20learning%20for%20pixel-level%20image%20fusion%3A%20Recent%20advances%20and%20future%20prospects)

[2、文章：Medical image fusion with parameter-adaptive pulse coupled neural network in nonsubsampled shearlet transform domain](https://blog.csdn.net/shitao99/article/details/85215086#2%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AMedical%20image%20fusion%20with%20parameter-adaptive%20pulse%20coupled%20neural%20network%20in%20nonsubsampled%20shearlet%20transform%20domain)

[3、文章：Image Fusion through Deep Convolutional Neural Network and Laplacian Pyramid（点击下载文章）     【CNN】【深度学习】](https://blog.csdn.net/shitao99/article/details/85215086#2%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AImage%20Fusion%20through%20Deep%20Convolutional%20Neural%20Network%20and%20Laplacian%20Pyramid%EF%BC%88%E7%82%B9%E5%87%BB%E4%B8%8B%E8%BD%BD%E6%96%87%E7%AB%A0%EF%BC%89)

[4、文章：Sparse representation based multi-sensor image fusion for multi-focus and multi-modality images: A review     【综述文章】](https://blog.csdn.net/shitao99/article/details/85215086#2%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9ASparse%20representation%20based%20multi-sensor%20image%20fusion%20for%20multi-focus%20and%20multi-modality%20images%3A%20A%20review)

[5、文章：Structure-aware image fusion](https://blog.csdn.net/shitao99/article/details/85215086#3%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AStructure-aware%20image%20fusion)

[6、文章：Convolutional neural network-based multimodal image fusion via similarity learning in the shearlet domain  【CNN】【深度学习】](https://blog.csdn.net/shitao99/article/details/85215086#5%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AConvolutional%20neural%20network-based%20multimodal%20image%20fusion%20via%20similarity%20learning%20in%20the%20shearlet%20domain%C2%A0%20%E3%80%90CNN%E3%80%91)

[7、文章：Scale-Invariant Structure Saliency Selection for Fast Image Fusion](https://blog.csdn.net/shitao99/article/details/85215086#6%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AScale-Invariant%20Structure%20Saliency%20Selection%20for%20Fast%20Image%20Fusion)

[【2017】](https://blog.csdn.net/shitao99/article/details/85215086#%E3%80%902017%E3%80%91)

[1、文章：Pixel-level image fusion: A survey of the state of the art【综述文章】](https://blog.csdn.net/shitao99/article/details/85215086#1%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9APixel-level%20image%20fusion%3A%20A%20survey%20of%20the%20state%20of%20the%20art%E3%80%90%E7%BB%BC%E8%BF%B0%E6%96%87%E7%AB%A0%E3%80%91)

[2、文章：Simultaneous image fusion and denosing with adaptive sparse representation](https://blog.csdn.net/shitao99/article/details/85215086#2%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9ASimultaneous%20image%20fusion%20and%20denosing%20with%20adaptive%20sparse%20representation)

[3、文章：A medical image fusion method based on convolutional neural networks     【深度学习】](https://blog.csdn.net/shitao99/article/details/85215086#3%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AA%20medical%20image%20fusion%20method%20based%20on%20convolutional%20neural%20networks)

[【2016】](https://blog.csdn.net/shitao99/article/details/85215086#%E3%80%902016%E3%80%91)

[1、文章：Image fusion with convolutional sparse representation     【CSR】](https://blog.csdn.net/shitao99/article/details/85215086#1%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AImage%20fusion%20with%20convolutional%20sparse%20representation)

[2、文章：Joint patch clustering-based dictionary learning for multimodal image fusion     【JCPD】](https://blog.csdn.net/shitao99/article/details/85215086#4%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AJoint%20patch%20clustering-based%20dictionary%20learning%20for%20multimodal%20image%20fusion)

[3、文章：Image fusion via nonlocal sparse K-SVD dictionary learning     【SR】【字典学习】](https://blog.csdn.net/shitao99/article/details/85215086#3%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AImage%20fusion%20via%20nonlocal%20sparse%20K-SVD%20dictionary%20learning%20%C2%A0%20%C2%A0%20%E3%80%90SR%E3%80%91%E3%80%90%E5%AD%97%E5%85%B8%E5%AD%A6%E4%B9%A0%E3%80%91)

[4、文章：Remote Sensing Image Fusion with Convolutional Neural Network  【CNN】【遥感图像融合】](https://blog.csdn.net/shitao99/article/details/85215086#4%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9ARemote%20Sensing%20Image%20Fusion%20with%20Convolutional%20Neural%20Network%20%C2%A0%E3%80%90CNN%E3%80%91%E3%80%90%E9%81%A5%E6%84%9F%E5%9B%BE%E5%83%8F%E8%9E%8D%E5%90%88%E3%80%91)

[【2015】](https://blog.csdn.net/shitao99/article/details/85215086#%E3%80%902015%E3%80%91)

[1、文章：A general framework for image fusion based on multi-scale transform and sparse representation（点击下载文章）     【MST-SR】](https://blog.csdn.net/shitao99/article/details/85215086#1%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AA%20general%20framework%20for%20image%20fusion%20based%20on%20multi-scale%20transform%20and%20sparse%20representation%EF%BC%88%E7%82%B9%E5%87%BB%E4%B8%8B%E8%BD%BD%E6%96%87%E7%AB%A0%EF%BC%89)

[2、文章：Simultaneous image fusion and denosing with adaptive sparse representation  【ASR】](https://blog.csdn.net/shitao99/article/details/85215086#2%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9ASimultaneous%20image%20fusion%20and%20denosing%20with%20adaptive%20sparse%20representation%20%C2%A0%E3%80%90ASR%E3%80%91)

[3、文章：Sparse representation with learned multiscale dictionary for image fusion](https://blog.csdn.net/shitao99/article/details/85215086#3%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9ASparse%20representation%20with%20learned%20multiscale%20dictionary%20for%20image%20fusion)

[【2014】](https://blog.csdn.net/shitao99/article/details/85215086#%E3%80%902014%E3%80%91)

[1、文章：Visual attention guided image fusion with sparse representation](https://blog.csdn.net/shitao99/article/details/85215086#4%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AVisual%20attention%20guided%20image%20fusion%20with%C2%A0sparse%C2%A0representation)

[2、文章：Multimodal image fusion via sparse representation with local patch dictionaries     【LPD】](https://blog.csdn.net/shitao99/article/details/85215086#2%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AMultimodal%20image%20fusion%20via%20sparse%20representation%20with%20local%20patch%20dictionaries%20%C2%A0%20%C2%A0%20%E3%80%90LPD%E3%80%91)

[3、文章：Medical image fusion: A survey of the state of the art     【综述文章】【医学图像融合】](https://blog.csdn.net/shitao99/article/details/85215086#3%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AMedical%20image%20fusion%3A%20A%20survey%20of%20the%20state%20of%20the%20art%20%C2%A0%20%C2%A0%20%E3%80%90%E7%BB%BC%E8%BF%B0%E6%96%87%E7%AB%A0%E3%80%91%E3%80%90%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F%E8%9E%8D%E5%90%88%E3%80%91)

[4、文章：Hybrid DDCT-PCA based multi sensor image fusion（点击下载文章）](https://blog.csdn.net/shitao99/article/details/85215086#4%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AHybrid%20DDCT-PCA%20based%20multi%20sensor%20image%20fusion%EF%BC%88%E7%82%B9%E5%87%BB%E4%B8%8B%E8%BD%BD%E6%96%87%E7%AB%A0%EF%BC%89)

[【2013】](https://blog.csdn.net/shitao99/article/details/85215086#%E3%80%902013%E3%80%91)

[1、文章：Simultaneous image fusion and super-resolution using sparse representation](https://blog.csdn.net/shitao99/article/details/85215086#1%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9ASimultaneous%20image%20fusion%20and%20super-resolution%20using%20sparse%20representation)

[2、文章：Image fusion with guided filtering（点击下载文章）    【GFF】](https://blog.csdn.net/shitao99/article/details/85215086#2%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AImage%20fusion%20with%20guided%20filtering%EF%BC%88%E7%82%B9%E5%87%BB%E4%B8%8B%E8%BD%BD%E6%96%87%E7%AB%A0%EF%BC%89)

[3、文章：Dictionary learning method for joint sparse representation-based image fusion（点击下载文章）     【JSR】](https://blog.csdn.net/shitao99/article/details/85215086#3%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9ADictionary%20learning%20method%20for%20joint%20sparse%C2%A0representation-based%20image%20fusion%EF%BC%88%E7%82%B9%E5%87%BB%E4%B8%8B%E8%BD%BD%E6%96%87%E7%AB%A0%EF%BC%89)

[4、文章：A Neuro-Fuzzy Approach for Medical Image Fusion 【医学图像融合】](https://blog.csdn.net/shitao99/article/details/85215086#4%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AA%20Neuro-Fuzzy%20Approach%20for%20Medical%20Image%20Fusion%20%E3%80%90%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F%E8%9E%8D%E5%90%88%E3%80%91)

[5、文章：Image fusion based on pixel significance using cross bilateral filter 【CBF】](https://blog.csdn.net/shitao99/article/details/85215086#5%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AImage%20fusion%20based%20on%20pixel%20significance%20using%20cross%20bilateral%20filter)

[6、文章：Multifocus and Multispectral Image Fusion based on Pixel Significance using Discrete Cosine Harmonic Wavelet Transform  【DCHWT】](https://blog.csdn.net/shitao99/article/details/85215086#6%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AMultifocus%20and%20Multispectral%20Image%20Fusion%20based%20on%20Pixel%20Significance%20using%20Discrete%20Cosine%20Harmonic%20Wavelet%20Transform)

[【2012】](https://blog.csdn.net/shitao99/article/details/85215086#%E3%80%902012%E3%80%91)

[1、文章：Group-sparse representation with dictionary learning for medical image denoising and fusion     【GSR】](https://blog.csdn.net/shitao99/article/details/85215086#1%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AGroup-sparse%20representation%20with%20dictionary%20learning%20for%20medical%20image%20denoising%20and%C2%A0fusion)

[2、文章：Pixel-level image fusion with simultaneous orthogonal matching pursuit     【SOMP】](https://blog.csdn.net/shitao99/article/details/85215086#2%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9APixel-level%20image%20fusion%20with%20simultaneous%20orthogonal%20matching%20pursuit)

[3、文章：Image fusion using higher order singular value decomposition  【HOSVD】](https://blog.csdn.net/shitao99/article/details/85215086#3%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AImage%20fusion%20using%20higher%20order%20singular%20value%20decomposition)

[4、文章：NSCT-based multimodal medical image fusion using pulse-coupled neural network and modified spatial frequency（点击下载文章）     【医学图像融合】](https://blog.csdn.net/shitao99/article/details/85215086#4%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9ANSCT-based%20multimodal%20medical%20image%20fusion%20using%20pulse-coupled%20neural%20network%20and%20modified%20spatial%20frequency%EF%BC%88%E7%82%B9%E5%87%BB%E4%B8%8B%E8%BD%BD%E6%96%87%E7%AB%A0%EF%BC%89)

[【2011】](https://blog.csdn.net/shitao99/article/details/85215086#%E3%80%902011%E3%80%91)

[1、文章：Multimodal image fusion with joint sparsity model     【JSR】](https://blog.csdn.net/shitao99/article/details/85215086#1%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AMultimodal%20image%20fusion%20with%20joint%C2%A0sparsity%20model%20%C2%A0%20%C2%A0%C2%A0%E3%80%90JSR%E3%80%91)

[2、文章：Image Features Extraction and Fusion Based on Joint Sparse Representation    【JSR】](https://blog.csdn.net/shitao99/article/details/85215086#2%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AImage%20Features%20Extraction%20and%20Fusion%20Based%C2%A0on%20Joint%20Sparse%20Representation%20%C2%A0%20%C2%A0%E3%80%90JSR%E3%80%91)

[3、文章：Image fusion technique using multi-resolution singular value decomposition（点击下载文章）     【MSVD】](https://blog.csdn.net/shitao99/article/details/85215086#3%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AImage%20fusion%20technique%20using%20multi-resolution%20singular%20value%20decomposition%EF%BC%88%E7%82%B9%E5%87%BB%E4%B8%8B%E8%BD%BD%E6%96%87%E7%AB%A0%EF%BC%89)

[4、文章：Generalized Random Walks for Fusion of Multi-Exposure Images 【多曝光图像融合】](https://blog.csdn.net/shitao99/article/details/85215086#4%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AGeneralized%20Random%20Walks%20for%20Fusion%20of%20Multi-Exposure%20Images%20%E3%80%90%E5%A4%9A%E6%9B%9D%E5%85%89%E5%9B%BE%E5%83%8F%E8%9E%8D%E5%90%88%E3%80%91)

[【2008】](https://blog.csdn.net/shitao99/article/details/85215086#%E3%80%902008%E3%80%91)

[1、文章：Image Fusion Algorithm Based on Spatial Frequency-Motivated Pulse Coupled Neural Networks in Nonsubsampled Contourlet Transform Domain](https://blog.csdn.net/shitao99/article/details/85215086#1%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AImage%20Fusion%20Algorithm%20Based%20on%20Spatial%C2%A0Frequency-Motivated%20Pulse%20Coupled%20Neural%20Networks%20in%C2%A0Nonsubsampled%20Contourlet%20Transform%20Domain)

[【2007】](https://blog.csdn.net/shitao99/article/details/85215086#%E3%80%902007%E3%80%91)

[1、文章：A novel image fusion algorithm based on bandelet transform](https://blog.csdn.net/shitao99/article/details/85215086#1%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AA%20novel%20image%20fusion%20algorithm%20based%20on%20bandelet%20transform)

[【2003】](https://blog.csdn.net/shitao99/article/details/85215086#%E3%80%902003%E3%80%91)

[1、文章：A general framework for multiresolution image fusion: from pixels to regions【综述文章】【关于传统的多分辨率的图像融合】](https://blog.csdn.net/shitao99/article/details/85215086#1%E3%80%81%E6%96%87%E7%AB%A0%EF%BC%9AA%20general%20framework%20for%20multiresolution%20image%20fusion%3A%20from%20pixels%20to%20regions%E3%80%90%E7%BB%BC%E8%BF%B0%E6%96%87%E7%AB%A0%E3%80%91%E3%80%90%E5%85%B3%E4%BA%8E%E4%BC%A0%E7%BB%9F%E7%9A%84%E5%A4%9A%E5%88%86%E8%BE%A8%E7%8E%87%E7%9A%84%E5%9B%BE%E5%83%8F%E8%9E%8D%E5%90%88%E3%80%91)

------

 

# 【2019】

## 1、文章：A survey on region based image fusion methods  **【综述文章】**

Paper：<https://doi.org/10.1016/j.inffus.2018.07.010>

作者：Bikash Meher, Sanjay Agrawal, Rutuparna Panda,  Ajith Abraham

 

# 【2018】

## 1、文章：Deep learning for pixel-level image fusion: Recent advances and future prospects     【综述文章】【深度学习】

Paper：<https://doi.org/10.1016/j.inffus.2017.10.007>

作者：

**刘羽**，合肥工业大学讲师。硕导。

主页：

<http://www.escience.cn/people/liuyu1/index.html>（科研在线 科研主页）

<https://sites.google.com/site/yuliu316316/>（Google学术主页）

**陈勋**，中国科学技术大学，教授，博导。

主页：

<http://staff.ustc.edu.cn/~xunchen/Chinese.htm>（中文主页）

<http://staff.ustc.edu.cn/~xunchen/>

<https://scholar.google.com.hk/citations?user=aBnUWyQAAAAJ&hl=zh-CN&oi=sra>（Google学术主页）

**汪增福**，中国科学技术大学教授，博导。

主页：<https://scholar.google.com.hk/citations?user=uDtOVBAAAAAJ&hl=zh-CN&oi=sra>（Google学术主页）

**Rabab Ward**，the University of British Columbia，Canada

主页：[http://ipl.ece.ubc.ca](http://ipl.ece.ubc.ca/)（学校个人主页）

<https://scholar.google.com.hk/citations?hl=zh-CN&user=dqsw1u8AAAAJ&view_op=list_works&sortby=pubdate>（Google学术主页）

 

## 2、文章：Medical image fusion with parameter-adaptive pulse coupled neural network in nonsubsampled shearlet transform domain

Paper：<https://ieeexplore.ieee.org/document/8385209>（**DOI:** [10.1109/TIM.2018.2838778](https://doi.org/10.1109/TIM.2018.2838778)）

Code：<http://www.escience.cn/people/liuyu1/Codes.html>

作者：**刘羽**，合肥工业大学讲师。硕导。

 

## 3、文章：[Image Fusion through Deep Convolutional Neural Network and Laplacian Pyramid](https://www.ijcseonline.org/pub_paper/65-IJCSE-03066.pdf)（点击下载文章）     【CNN】【深度学习】

作者：B. Asha Latha, M. Babu Reddy, Krishna University, Machilipatnam, India

 

## 4、文章：Sparse representation based multi-sensor image fusion for multi-focus and multi-modality images: A review     **【综述文章】**

Paper：<https://doi.org/10.1016/j.inffus.2017.05.006>

作者：张强，西安电子科技大学机电工程学院。

 

## 5、文章：Structure-aware image fusion

Cite as：

Wen L , Yuange X , Haole Z , et al. Structure-aware image fusion[J]. Optik, 2018, 172:1-11.

Paper：<https://doi.org/10.1016/j.ijleo.2018.06.123>

Code：<https://github.com/kunzhan/Structure-Aware_Image_Fusion>

作者：**绽琨**，兰州大学。

主页：[https://kunzhan.github.io](https://kunzhan.github.io/)

GitHub地址：<https://github.com/kunzhan>

 

## 6、文章：[Convolutional neural network-based multimodal image fusion via similarity learning in the shearlet domain](https://link.springer.com/content/pdf/10.1007/s00521-018-3441-1.pdf)  【CNN】【深度学习】

Paper：<https://doi.org/10.1007/s00521-018-3441-1>

作者：[Haithem Hermessi](https://scholar.google.co.jp/citations?user=WRRxv28AAAAJ&hl=zh-CN&oi=sra)，Olfa Mourali， [Ezzeddine Zagrouba](https://sites.google.com/site/zagroubaezzeddine/)

 

## 7、文章：[Scale-Invariant Structure Saliency Selection for Fast Image Fusion](http://aixpaper.com/view/scaleinvariant_structure_saliency_selection_for_fast_image_fusion)

Paper：<https://arxiv.org/abs/1810.12553>

<https://www.researchgate.net/publication/328627579_Scale-Invariant_Structure_Saliency_Selection_for_Fast_Image_Fusion>

作者：Yixiong Liang（梁毅雄），中南大学

主页：<https://sites.google.com/site/liangyixiong/>

 

# 【2017】

## 1、文章：Pixel-level image fusion: A survey of the state of the art**【综述文章】**

Cite as：

Li S , Kang X , Fang L , et al. Pixel-level image fusion: A survey of the state of the art[J]. Information Fusion, 2017, 33:100-112.

Paper：<https://doi.org/10.1016/j.inffus.2016.05.004>

作者：

**李树涛**，湖南大学。教授，博导。（<http://gra.hnu.edu.cn/dsdw/jcrc/zjxztpjs.htm>，大牛的主页进不去）

**康旭东**，湖南大学博士。导师：李树涛。

主页：[http://xudongkang.weebly.com](http://xudongkang.weebly.com/)

**方乐缘**，湖南大学博士, 副教授，博士生导师。导师：李树涛。

主页：<http://www.escience.cn/people/LeyuanFang/index.html>（科研在线 科研主页）

**胡建文，**长沙理工大学电气与信息工程学院。

主页：<http://www.csust.edu.cn/dq/info/1084/4094.htm>（教师主页）

**尹海涛**，南京邮电大学。

主页：<http://yjs.njupt.edu.cn/epstar/web/outer/dsfc_ny_.jsp?dsgh=20130018>（教师主页）

 

## **2、**文章：Simultaneous image fusion and denosing with adaptive sparse representation

Cite as：

Yu Liu, Zengfu Wang, Simultaneous image fusion and denosing with adaptive sparse representation, IET Image Processing, 9(5): 347-357, 2015. 

**Paper：**<https://ieeexplore.ieee.org/abstract/document/7095698>（**DOI:** [10.1049/iet-ipr.2014.0311](https://doi.org/10.1049/iet-ipr.2014.0311)）

**Code：**<http://www.escience.cn/people/liuyu1/Codes.html>

**作者：刘羽**，合肥工业大学讲师。硕导。

**主页：**

<http://www.escience.cn/people/liuyu1/index.html>（科研在线 科研主页）

<https://sites.google.com/site/yuliu316316/>（Google学术主页）

 

## 3**、**文章：A medical image fusion method based on convolutional neural networks     【深度学习】

Cite as：

**Yu Liu**, Xun Chen, Juan Cheng,Hu Peng, “A medical image fusion method based on convolutional neural networks”, 20th International Conferenceon Information Fusion (ICIF), Xi’an, China, July 10-13, 2017, pp.1070-1076.

Paper：<https://ieeexplore.ieee.org/document/8009769/>（**DOI:** [10.23919/ICIF.2017.8009769](https://doi.org/10.23919/ICIF.2017.8009769)）

**Code：**<http://www.escience.cn/people/liuyu1/Codes.html>（刘羽）

 

# 【2016】

## 1、文章：Image fusion with convolutional sparse representation     【CSR】

Cite as：

Yu Liu, Xun Chen, Rabab Ward, Z. Jane Wang, Image fusion with convolutional sparse representation, IEEE Signal Processing Letters, 23(12): 1882-1886, 2016.

Paper：<https://ieeexplore.ieee.org/document/7593316>（**DOI:** [10.1109/LSP.2016.2618776](https://doi.org/10.1109/LSP.2016.2618776)）

**Code：**<http://www.escience.cn/people/liuyu1/Codes.html>

作者：**刘羽**，合肥工业大学讲师。硕导。中科大博士，导师：汪增福。

主页：

<http://www.escience.cn/people/liuyu1/index.html>（科研在线 科研主页）

<https://sites.google.com/site/yuliu316316/>（Google学术主页）

 

## 2、文章：Joint patch clustering-based dictionary learning for multimodal image fusion     【JCPD】

Paper：<https://doi.org/10.1016/j.inffus.2015.03.003>

作者：Minjae Kim，[David K. Han](https://scholar.google.com/citations?user=oGc4QlsAAAAJ&hl=zh-CN&oi=sra)，[Hanseok Ko](https://scholar.google.com/citations?user=jAX1mzYAAAAJ&hl=zh-CN&oi=sra)

 

## 3、文章：Image fusion via nonlocal sparse K-SVD dictionary learning     【SR】【字典学习】

Paper：<https://www.osapublishing.org/ao/abstract.cfm?uri=ao-55-7-1814>（**DOI：**[10.1364/AO.55.001814](https://doi.org/10.1364/AO.55.001814)）

作者：Ying Li, Fangyi Li, Bendu Bai, and Qiang Shen（西北工业大学）

 

## 4、文章：Remote Sensing Image Fusion with Convolutional Neural Network  【CNN】【遥感图像融合】

Paper：<https://link.springer.com/article/10.1007%2Fs11220-016-0135-6>

 

# 【2015】

## 1、文章：[A general framework for image fusion based on multi-scale transform and sparse representation](https://ac.els-cdn.com/S1566253514001043/1-s2.0-S1566253514001043-main.pdf?_tid=0b97e937-e55d-42ba-9dcb-32880bb2bd33&acdnat=1545584261_7fa2b6c9d9e10285869f87f593c86538)（点击下载文章）     【MST-SR】

Cite as：

Yu Liu, Shuping Liu, Zengfu Wang, A general framework for image fusion based on multi-scale transform and sparse representation,Information Fusion, 24: 147-164, 2015. 

Paper：<https://doi.org/10.1016/j.inffus.2014.09.004>

**Code：**<http://www.escience.cn/people/liuyu1/Codes.html>

（本文的代码中也包含了传统经典的基于多尺度分解的图像融合算法代码。内容丰富。）

作者：

**刘羽**，合肥工业大学讲师。硕导。中科大博士，导师：汪增福。

主页：

<http://www.escience.cn/people/liuyu1/index.html>（科研在线 科研主页）

<https://sites.google.com/site/yuliu316316/>（Google学术主页）

**汪增福**

Google学术主页：<https://scholar.google.com.hk/citations?user=uDtOVBAAAAAJ&hl=zh-CN&oi=sra>

 

## 2、文章：[Simultaneous image fusion and denosing with adaptive sparse representation](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7095698)  【ASR】

Cite as：

Yu Liu, Zengfu Wang, Simultaneous image fusion and denosing with adaptive sparse representation, IET Image Processing, 9(5): 347-357, 2015.

Paper：<https://ieeexplore.ieee.org/abstract/document/7095698>

（DOI: 10.1049/iet-ipr.2014.0311）

**Code：**<http://www.escience.cn/people/liuyu1/Codes.html>（刘羽）

 

## 3、文章：Sparse representation with learned multiscale dictionary for image fusion

Paper：<https://doi.org/10.1016/j.neucom.2014.07.003>

作者：[尹海涛](http://yjs.njupt.edu.cn/epstar/web/outer/dsfc_ny_.jsp?dsgh=20130018)，南京邮电大学。

学校主页：<http://yjs.njupt.edu.cn/epstar/web/outer/dsfc_ny_.jsp?dsgh=20130018>

 

# 【2014】

## 1、文章：Visual attention guided image fusion with sparse representation

Paper：<https://doi.org/10.1016/j.ijleo.2014.04.036>

作者：杨斌，[李树涛](https://scholar.google.com/citations?user=PlBq8n8AAAAJ&hl=zh-CN&oi=sra)，湖南大学。

**杨斌**，南华大学电气工程学院，湖南大学博士（导师：李树涛）

主页：<http://tutor.eol.cn/web/school/info?school_id=73&dsid=955>（教师主页）

 

## 2、文章：Multimodal image fusion via sparse representation with local patch dictionaries     【LPD】

Paper：<https://ieeexplore.ieee.org/document/6738268/>

作者：Minjae Kim，[David K. Han](https://scholar.google.com/citations?user=oGc4QlsAAAAJ&hl=zh-CN&oi=sra)，[Hanseok Ko](https://scholar.google.com/citations?user=jAX1mzYAAAAJ&hl=zh-CN&oi=sra)

 

## 3、文章：Medical image fusion: A survey of the state of the art     【综述文章】【医学图像融合】

Paper：<https://doi.org/10.1016/j.inffus.2013.12.002>

作者：Alex PappachenJames，Belur V.Dasarathy

**Belur V.Dasarathy**

主页：

<https://scholar.google.com/citations?user=qiWt7LEAAAAJ&hl=zh-CN&oi=sra>（Google学术主页）

<http://belur.tripod.com/index.html>

 

## 4、文章：[Hybrid DDCT-PCA based multi sensor image fusion](https://link.springer.com/content/pdf/10.1007%2Fs12596-013-0148-7.pdf)（点击下载文章）

Paper：<https://link.springer.com/article/10.1007/s12596-013-0148-7>

**Code：**<https://ww2.mathworks.cn/matlabcentral/fileexchange/46169-directional-discrete-cosine-transform-and-principal-component-analysis-based-image-fusion>

作者：**VPS Naidu**（**发表了多篇图像融合论文**）

主页：<https://scholar.google.com/citations?user=pdAZ1wsAAAAJ&hl=zh-CN&oi=sra>（Google学术主页）

代码网址：<https://ww2.mathworks.cn/matlabcentral/fileexchange/?term=authorid%3A104729>（该网页内作者提供了多个经典图像融合算法的代码）

 

# 【2013】

## 1、文章：Simultaneous image fusion and super-resolution using sparse representation

Cite as：

Yin H , Li S , Fang L . Simultaneous image fusion and super-resolution using sparse representation[J]. Information Fusion, 2013, 14(3):229-240.

Paper：<https://doi.org/10.1016/j.inffus.2012.01.008>

作者：[尹海涛](http://yjs.njupt.edu.cn/epstar/web/outer/dsfc_ny_.jsp?dsgh=20130018)，李树涛，方乐缘，湖南大学。

**李树涛**，湖南大学，教授，博导。

主页：<https://scholar.google.com/citations?user=PlBq8n8AAAAJ&hl=zh-CN&oi=sra>（Google学术主页）

 

## 2、文章：[Image fusion with guided filtering](http://xudongkang.weebly.com/uploads/1/6/4/6/16465750/tip1.pdf)（点击下载文章）    【GFF】

Cite as：

S﻿hutao Li, Xudong Kang and Jianwen Hu, Image fusion with guided filtering, *IEEE Transactions on Image Processing*, vol. 22, no. 7, pp. 2864-2875, July, 2013

**Code：**[http://xudongkang.weebly.com](http://xudongkang.weebly.com/)（作者主页内可找到，解压密码：LIvoJeaimnniTgain）

作者：

**康旭东**，湖南大学博士（导师：李树涛）

主页：[http://xudongkang.weebly.com](http://xudongkang.weebly.com/)

**李树涛**，湖南大学，教授，博导。

主页：<https://scholar.google.com/citations?user=PlBq8n8AAAAJ&hl=zh-CN&oi=sra>（Google学术主页）

 

## 3、文章：[Dictionary learning method for joint sparse representation-based image fusion](http://www.escience.cn/system/download/62702)（点击下载文章）     【JSR】

Paper：<https://doi.org/10.1117/1.OE.52.5.057006>

作者：[Qiheng Zhang](https://www.spiedigitallibrary.org/profile/notfound?author=Qiheng_Zhang)，Yuli Fu，Haifeng Li，Jian Zou，华南理工大学电子信息学院。

 

## 4、文章：A Neuro-Fuzzy Approach for Medical Image Fusion 【医学图像融合】

Paper：<https://ieeexplore.ieee.org/abstract/document/6603271>

（**DOI:** [10.1109/TBME.2013.2282461](https://doi.org/10.1109/TBME.2013.2282461)）

**Code：**<https://drive.google.com/file/d/0Bxq5-QWgPHedWXcxTzBGVkMtejQ/view>

作者：

**Sudeb Das**

主页：<https://sites.google.com/site/wodrsdas/publica>（**该作者做了许多医学图像方面的研究**）

<https://scholar.google.com/citations?user=viK7TRUAAAAJ&hl=zh-CN&oi=sra>（Google学术主页）

**Malay Kumar Kundu**

主页：<https://www.isical.ac.in/~malay/>

<https://scholar.google.com/citations?user=0589ICUAAAAJ&hl=zh-CN&oi=sra>（Google学术主页）

 

## 5、文章：Image fusion based on pixel significance using cross bilateral filter 【CBF】

Paper：<http://dx.doi.org/10.1007/s11760-013-0556-9>（DOI：10.1007/s11760-013-0556-9）

Code：<https://sites.google.com/view/shreyamsha/research/image-fusion/image-fusion-using-CBF> 或者：

<https://ww2.mathworks.cn/matlabcentral/fileexchange/43781-image-fusion-based-on-pixel-significance-using-cross-bilateral-filter>

作者：**B. K. Shreyamsha Kumar**

主页：<https://sites.google.com/view/shreyamsha>

<https://ccc.glgoo.top/citations?user=jX5csycAAAAJ&hl=zh-CN&oi=sra>（Google学术主页）

 

## 6、文章：Multifocus and Multispectral Image Fusion based on Pixel Significance using Discrete Cosine Harmonic Wavelet Transform  【DCHWT】

Paper：（DOI：10.1007/s11760-012-0361-x）

**Code：**<https://sites.google.com/view/shreyamsha/research/image-fusion/image-fusion-using-DCHWT> 或者：

作者：B. K. Shreyamsha Kumar

主页：<https://sites.google.com/view/shreyamsha>

<https://ccc.glgoo.top/citations?user=jX5csycAAAAJ&hl=zh-CN&oi=sra>（Google学术主页）

 

# 【2012】

## 1、文章：Group-sparse representation with dictionary learning for medical image denoising and fusion     【GSR】

Cite as：

Li, Shutao and Yin, Haitao and Fang, Leyuan. Biomedical Engineering, IEEE Transactions on: 2012 ,59(12) ,3450--3459

Paper：<https://ieeexplore.ieee.org/document/6296694>

作者：[李树涛](https://scholar.google.com/citations?user=PlBq8n8AAAAJ&hl=zh-CN&oi=sra)，[尹海涛](http://yjs.njupt.edu.cn/epstar/web/outer/dsfc_ny_.jsp?dsgh=20130018)，方乐缘，湖南大学。

 

## 2、文章：Pixel-level image fusion with simultaneous orthogonal matching pursuit     【SOMP】

Paper：<https://doi.org/10.1016/j.inffus.2010.04.001>

作者：[杨斌](http://tutor.eol.cn/web/school/info?school_id=73&dsid=955)，[李树涛](https://scholar.google.com/citations?user=PlBq8n8AAAAJ&hl=zh-CN&oi=sra)，湖南大学。

 

## 3、文章：Image fusion using higher order singular value decomposition  【HOSVD】

Paper：<https://ieeexplore.ieee.org/abstract/document/6126030>

（**DOI:** [10.1109/TIP.2012.2183140](https://doi.org/10.1109/TIP.2012.2183140)）

作者：Junli Liang，Yang He（贺洋），Ding Liu（刘丁），西安理工大学自动化与信息工程学院

**贺洋**，Max Planck Institute for Informatics博士。

主页：

<https://scholar.google.com/citations?user=OaAO-aIAAAAJ&hl=zh-CN&oi=sra>（Google学术主页）

<https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/people/yang-he/>

 

## 4、文章：[NSCT-based multimodal medical image fusion using pulse-coupled neural network and modified spatial frequency](https://drive.google.com/file/d/0Bxq5-QWgPHedOGlMdFF3UGNYZGc/view)（点击下载文章）     【医学图像融合】

Paper：<https://link.springer.com/article/10.1007/s11517-012-0943-3>

**Code：**<https://drive.google.com/file/d/0Bxq5-QWgPHedUXo0VzdGbWxZa3c/view>

作者：

**Sudeb Das**

主页：<https://sites.google.com/site/wodrsdas/publica>（**该作者做了许多医学图像方面的研究**）

<https://scholar.google.com/citations?user=viK7TRUAAAAJ&hl=zh-CN&oi=sra>（Google学术主页）

**Malay Kumar Kundu**

主页：<https://www.isical.ac.in/~malay/>

<https://scholar.google.com/citations?user=0589ICUAAAAJ&hl=zh-CN&oi=sra>（Google学术主页）

 

# 【2011】

## 1、文章：Multimodal image fusion with joint sparsity model     【JSR】

Paper：<https://doi.org/10.1117/1.3584840>

附：[Joint sparsity model improves multimodal image fusion](http://spie.org/newsroom/3921-joint-sparsity-model-improves-multimodal-image-fusion?SSO=1)

作者：[尹海涛](http://yjs.njupt.edu.cn/epstar/web/outer/dsfc_ny_.jsp?dsgh=20130018)，[李树涛](https://scholar.google.com/citations?user=PlBq8n8AAAAJ&hl=zh-CN&oi=sra)，湖南大学。

 

## 2、文章：Image Features Extraction and Fusion Based on Joint Sparse Representation    【JSR】

Paper：<https://ieeexplore.ieee.org/document/5709967>

作者：

**余南南**，江苏师范大学教师，大连理工大学博士（导师：邱天爽）

**邱天爽**，大连理工大学教授，博导。

教师个人主页：<http://faculty.dlut.edu.cn/qiutsh/zh_CN/index.htm>

 

## 3、文章：[Image fusion technique using multi-resolution singular value decomposition](https://nal-ir.nal.res.in/11320/1/msvdimfuse.pdf)（点击下载文章）     【MSVD】

Paper：<https://nal-ir.nal.res.in/11320/>

**Code：**<https://ww2.mathworks.cn/matlabcentral/fileexchange/38802-image-fusion-technique-using-multi-resolution-singular-value-decomposition>（**代码包中包含了论文原文**）

作者：**VPS Naidu**（**发表了多篇图像融合论文**）

主页：<https://scholar.google.com/citations?user=pdAZ1wsAAAAJ&hl=zh-CN&oi=sra>（Google学术主页）

代码网址：<https://ww2.mathworks.cn/matlabcentral/fileexchange/?term=authorid%3A104729>（该网页内作者提供了多个经典图像融合算法的代码）

 

## 4、文章：Generalized Random Walks for Fusion of Multi-Exposure Images 【多曝光图像融合】

Paper：<https://ieeexplore.ieee.org/abstract/document/5762601>

（**DOI:** [10.1109/TIP.2011.2150235](https://doi.org/10.1109/TIP.2011.2150235)）

**Code：**<https://sites.ualberta.ca/~rshen/papers/tip11/>

作者：

Rui Shen

<https://sites.ualberta.ca/~rshen/>

<https://scholar.google.com/citations?user=LOBosaUAAAAJ&hl=zh-CN&oi=sra>（Google学术主页）

<https://sites.ualberta.ca/~rshen/projects/if/index.html>（该网页是作者Rui Shen的图像融合项目网页）

Jianbo Shi

<https://scholar.google.com/citations?user=Sm14jYIAAAAJ&hl=zh-CN&oi=sra>（Google学术主页）

Anup Basu

<https://scholar.google.com/citations?user=x8Nn-jQAAAAJ&hl=zh-CN&oi=sra>（Google学术主页）

 

# 【2008】

## 1、文章：Image Fusion Algorithm Based on Spatial Frequency-Motivated Pulse Coupled Neural Networks in Nonsubsampled Contourlet Transform Domain

Paper：<https://doi.org/10.1016/S1874-1029(08)60174-3>（DOI：10.1016/S1874-1029(08)60174-3）

**Code：**[http://csrc.xmu.edu.cn](http://csrc.xmu.edu.cn/)（网页内——‘software’栏目内，最下面找到本文题目，点击进去。貌似链接失效了。可以去该网页下，找到“Toolbox for High quality multi-focus image fusion using self-similarity and depth information”，下载代码包，里面包含了我们要找的本文的代码。）

作者：**屈小波**，厦门大学。

 

# 【2007】

## 1、文章：A novel image fusion algorithm based on bandelet transform

Paper：<https://www.osapublishing.org/col/abstract.cfm?uri=col-5-10-569>

作者：Xiaobo Qu（屈小波）, Jingwen Yan（闫敬文）, Guofu Xie（谢国富）, Ziqian Zhu, and Bengang Chen

**屈小波**，厦门大学，副教授，博导

主页：

<http://csrc.xmu.edu.cn/xiaobo/index_cn.html>

<https://esci.xmu.edu.cn/e6/48/c9602a190024/page.psp>

<https://scholar.google.com/citations?user=JXw9c2sAAAAJ&hl=zh-CN&oi=sra>（Google学术主页）

**谢国富**, University of Montreal（蒙特利尔大学）

主页：<http://lcs.ios.ac.cn/~guofu/>

<https://scholar.google.com/citations?user=6LT9mQYAAAAJ&hl=zh-CN&oi=sra>（Google学术主页）

 

# 【2003】

## 1、文章：A general framework for multiresolution image fusion: from pixels to regions【综述文章】【关于传统的多分辨率的图像融合】

Paper：<https://doi.org/10.1016/S1566-2535(03)00046-0>

作者：Gemma Piella

主页：<https://scholar.google.com/citations?user=Q6zjCpsAAAAJ&hl=zh-CN&oi=sra>（Google学术主页）

 

====================== 分 ========== 割 ========== 线 ======================

PS：早期的代码中用到的某些函数可能随着MATLAB版本的升级更新，会被删掉，导致运行错误。解决办法就是在自己电脑上保留着低版本的MATLAB。然后用到哪个函数，复制出来粘贴到代码文件夹里。











































