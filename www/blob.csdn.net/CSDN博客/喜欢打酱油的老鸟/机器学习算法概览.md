
# 机器学习算法概览 - 喜欢打酱油的老鸟 - CSDN博客


2018年08月09日 08:08:28[喜欢打酱油的老鸟](https://me.csdn.net/weixin_42137700)阅读数：148标签：[机器学习																](https://so.csdn.net/so/search/s.do?q=机器学习&t=blog)[算法																](https://so.csdn.net/so/search/s.do?q=算法&t=blog)[
							](https://so.csdn.net/so/search/s.do?q=机器学习&t=blog)个人分类：[人工智能																](https://blog.csdn.net/weixin_42137700/article/category/7820233)


[https://blog.csdn.net/tkkzc3E6s4Ou4/article/details/81463974](https://blog.csdn.net/tkkzc3E6s4Ou4/article/details/81463974)
**1、 监督式学习**
工作机制：这个算法由一个目标变量或结果变量(或因变量)组成。这些变量由已知的一系列预示变量(自变量)预测而来。利用这一系列变量，我们生成一个将输入值映射到期望输出值的函数。这个训练过程会一直持续，直到模型在训练数据上获得期望的精确度。监督式学习的例子有：回归、决策树、随机森林、K – 近邻算法、逻辑回归等。
**2、非监督式学习**
工作机制：在这个算法中，没有任何目标变量或结果变量要预测或估计。这个算法用在不同的组内聚类分析。这种分析方式被广泛地用来细分客户，根据干预的方式分为不同的用户组。非监督式学习的例子有：关联算法和 K – 均值算法。
**3、强化学习**
工作机制：这个算法训练机器进行决策。它是这样工作的：机器被放在一个能让它通过反复试错来训练自己的环境中。机器从过去的经验中进行学习，并且尝试利用了解最透彻的知识作出精确的商业判断。 强化学习的例子有马尔可夫决策过程。
**回归(Regression)**
回归是在自变量和需要预测的变量之间构建一个模型，并使用迭代的方法逐渐降低预测值和真实值之间的误差。回归方法是统计机器学习的一种 。
**常用的回归算法如下：**
• Ordinary Least Squares(最小二乘法)
• Logistic Regression(逻辑斯底回归)
• Stepwise Regression(逐步回归)
• Multivariate Adaptive Regression Splines(多元自适应回归样条法)
• Locally Estimated Scatterplot Smoothing(局部加权散点平滑法)
**基于样例的方法(Instance-based Methods)**
基于样例的方法需要一个样本库，当新样本出现时，在样本库中找到最佳匹配的若干个样本，然后做出推测。基于样例的方法又被成为胜者为王的方法和基于内存的学习，该算法主要关注样本之间相似度的计算方法和存储数据的表示形式。
• k-Nearest Neighbour (kNN)
• Learning Vector Quantization (LVQ)
• Self-Organizing Map (SOM)
**正则化方法(Regularization Methods)**
这是一个对其他方法的延伸(通常是回归方法)，这个延伸就是在模型上加上了一个惩罚项，相当于奥卡姆提到，对越简单的模型越有利，有防止过拟合的作用，并且更擅长归纳。我在这里列出它是因为它的流行和强大。
• Ridge Regression
• Least Absolute Shrinkage and Selection Operator (LASSO)
• Elastic Net
**决策树模型(Decision Tree Learning)**
决策树方法建立了一个根据数据中属性的实际值决策的模型。决策树用来解决归纳和回归问题。
• Classification and Regression Tree (CART)
• Iterative Dichotomiser 3 (ID3)
• C4.5
• Chi-squared Automatic Interaction Detection (CHAID)
• Decision Stump
• Random Forest
• Multivariate Adaptive Regression Splines (MARS)
• Gradient Boosting Machines (GBM)
**贝叶斯(Bayesian)**
贝叶斯方法是在解决归类和回归问题中应用了贝叶斯定理的方法。
• Naive Bayes
• Averaged One-Dependence Estimators (AODE)
• Bayesian Belief Network (BBN)
**核方法(Kernel Methods)**
核方法中最有名的是Support Vector Machines(支持向量机)。这种方法把输入数据映射到更高维度上，将其变得可分，使得归类和回归问题更容易建模。
• Support Vector Machines (SVM)
• Radial Basis Function (RBF)
• Linear Discriminate Analysis (LDA)
**聚类(Clustering Methods)**
聚类本身就形容了问题和方法。聚类方法通常是由建模方式分类的比如基于中心的聚类和层次聚类。所有的聚类方法都是利用数据的内在结构来组织数据，使得每组内的点有最大的共同性。
• K-Means
• Expectation Maximisation (EM)
**联合规则学习(Association Rule Learning)**
联合规则学习是用来对数据间提取规律的方法，通过这些规律可以发现巨量多维空间数据之间的联系，而这些重要的联系可以被组织拿来使用或者盈利。
• Apriori algorithm
• Eclat algorithm
**人工神经网络(Artificial Neural Networks)**
受生物神经网络的结构和功能的启发诞生的人工神经网络属于模式匹配一类，经常被用于回归和分类问题，但是它存在上百个算法和变种组成。其中有一些是经典流行的算法(深度学习拿出来单独讲)：
• Perceptron
• Back-Propagation
• Hopfield Network
• Self-Organizing Map (SOM)
• Learning Vector Quantization (LVQ)
**深度学习(Deep Learning)**
Deep Learning(深度学习)方法是人工神经网络在当下的一个变种。相比传统的神经网络，它更关注更加复杂的网络构成，许多方法都是关心半监督学习，就是一个大数据集中只有少量标注数据的那种问题。
• Restricted Boltzmann Machine (RBM)
• Deep Belief Networks (DBN)
• Convolutional Network
• Stacked Auto-encoders
**降维(Dimensionality Reduction)**
与聚类方法类似，对数据中的固有结构进行利用，使用无监督的方法学习一种方式，该方式用更少的信息来对数据做归纳和描述。这对于对数据进行可视化或者简化数据很有用，也有去除噪声的影响，经常采用这种方法使得算法更加高效。
• Principal Component Analysis (PCA)
• Partial Least Squares Regression (PLS)
• Sammon Mapping
• Multidimensional Scaling (MDS)
• Projection Pursuit
**组合方法(Ensemble Methods)**
Ensemble methods(组合方法)由许多小的模型组成，这些模型经过独立训练，做出独立的结论，最后汇总起来形成最后的预测。组合方法的研究点集中在使用什么模型以及这些模型怎么被组合起来。
• Boosting
• Bootstrapped Aggregation (Bagging)
• AdaBoost
• Stacked Generalization (blending)
• Gradient Boosting Machines (GBM)
• Random Forest
本文作者：young-nlp 来源：

