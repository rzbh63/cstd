
# 【基础知识二】模型的评估与选择 - AYE89 - 博客园|[AYE89](https://www.cnblogs.com/eniac1946/)
|coding & learning|
|posts - 153, comments - 3, trackbacks - 0, articles - 2

|
|导航
|[博客园](https://www.cnblogs.com/)|[首页](https://www.cnblogs.com/eniac1946/)|[新随笔](https://i.cnblogs.com/EditPosts.aspx?opt=1)|[联系](https://msg.cnblogs.com/send/AYE89)![订阅](//www.cnblogs.com/images/xml.gif)|[订阅](https://www.cnblogs.com/eniac1946/rss)|[管理](https://i.cnblogs.com/)
|公告


|[【基础知识二】模型的评估与选择](https://www.cnblogs.com/eniac1946/p/7331003.html)
|Posted on|2017-08-09 22:44|[AYE89](https://www.cnblogs.com/eniac1946/)|阅读(|...|) 评论(|...|)|[编辑](https://i.cnblogs.com/EditPosts.aspx?postid=7331003)|[收藏](#)
|一、经验误差
|精度vs错误率
|1. 误差：经验误差，泛化误差
|过拟合
|欠拟合
|模型选择：理想的方案是对候选模型的泛化误差进行评估，然后选择泛化误差最小的那个模型。然而现实中无法直接获得泛化误差。
|二、评估方法
|用“测试误差”作为泛化误差的近似。
|留出法 hold-out
|交叉验证法 cross validation
|自助法 bootstrapping （有放回采样） ——在数据集较小、难以有效划分训练/测试集时很有用
|三、性能度量
|查准率 precision
|查全率 recall
|P-R图，若一个学习器的P-R曲线被另一个学习器完全“包住”，则后者性能优于前者；
|F1 是P和R的调和平均值（平滑）
|ROC|与AUC
|ROC：真正例率y-假正例率x
|AUC：ROC曲线下的面积；
|四、比较检验
|问题：已知测试错误率，那么泛化错误率是多少，（泛化错误率<=测试错误率）把握有多大？
|可根据测试错误率估推出泛化错误率的分布；
|二项分布：一次留出法
|t检验：多次重复留出法，交叉验证
|五、偏差与方差
|对于回归任务
|偏差：期望输出与真实标记的差别，集算法本身的拟合能力；
|方差度量了同样大小的训练集的变动所导致学习性能的变化
|泛化误差 可分解为偏差、方差与噪声之和；
|偏差-方差dilema
![](https://images2017.cnblogs.com/blog/1181483/201712/1181483-20171219184453850-490794310.png)
![](https://images2017.cnblogs.com/blog/1181483/201712/1181483-20171219184534006-1336992599.png)







|[刷新评论](javascript:void(0);)|[刷新页面](#)|[返回顶部](#top)






|
|Powered by:
|博客园
|Copyright © AYE89
|
