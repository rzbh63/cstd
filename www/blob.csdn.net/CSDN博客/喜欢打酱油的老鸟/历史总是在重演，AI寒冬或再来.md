
# 历史总是在重演，AI寒冬或再来 - 喜欢打酱油的老鸟 - CSDN博客


2019年01月21日 08:11:30[喜欢打酱油的老鸟](https://me.csdn.net/weixin_42137700)阅读数：24标签：[AI寒冬																](https://so.csdn.net/so/search/s.do?q=AI寒冬&t=blog)个人分类：[人工智能																](https://blog.csdn.net/weixin_42137700/article/category/7820233)


[https://www.toutiao.com/a6646335224504402436/](https://www.toutiao.com/a6646335224504402436/)
2019-01-14 20:55:08
![历史总是在重演，AI寒冬或再来](http://p1.pstatp.com/large/pgc-image/46d21ad43b6d47c2809ed59a678d0ec3)
**【新智元导读】**本文结合了近三年技术和产业发展的回顾，再论“深度学习已死”。作者认为，深度学习对于大多数问题来说不是正确方法，无法为所有问题寻找一个通用AI解决方案。
许多人认为，算法能以认知意识超越人性。机器可以在没有人工干预的情况下了解和学习任务，并大规模地替换人类工人。它们完全可以“思考”。许多人甚至提出我们是否可以将机器人视作配偶的问题。
但我今天不是讨论这些。如果我告诉你这些想法在20世纪60年代时就已广泛流传，AI先驱Jerome Wiesner、Oliver Selfridge和克劳德·香农(Claude Shannon)都曾坚持认为这在不久的将来就会发生，你怎么想？如果你对此感到惊讶，请看看下面这个视频，你会惊讶于这些情绪是多么的熟悉。
快进到1973年，AI的炒作和夸大适得其反。英国议会派数学家詹姆斯·莱特希尔爵士(Sir James Lighthill)编写英国人工智能研究的现状报告。该报告对AI研究的许多核心方面给出了非常悲观的预测，指出 “在该领域的任何部分迄今为止都没有产生重大影响”。有趣的是，莱特希尔还指出专门的程序(或人类)如何比他们的“AI”同行表现得更好，以及AI如何在现实环境中没有前景。因此，英国政府取消了所有的AI研究经费。
![历史总是在重演，AI寒冬或再来](http://p1.pstatp.com/large/pgc-image/060723b95c254ee692d7c3e22a56f2e6)
Lighthill Debate, BBC, 1973
在大西洋彼岸，美国国防部曾在AI研究上投入巨资，但后来又因为同样的挫折取消了几乎所有的资助：对AI能力的夸大，高成本却没有回报，以及AI在现实世界中的价值令人怀疑。
在20世纪80年代，日本在“AI”上进行大胆的尝试，推出“第五代电脑项目”(Fifth generation computer)。然而，这最终也只是造成了8.5亿美元的损失。
# 第一个AI冬天
80年代末出现了**AI冬天(AI Winter)**，这是计算机科学的一个黑暗时期，“人工智能”研究给组织和政府带来沉没成本。这种失败使人工智能研究停滞了数十年。
到了1990年代，“AI”成了一个贬义词，这种情况持续到2000年代。人们普遍认为“AI根本不能起作用”。编写看似智能的程序的软件公司会使用“搜索算法”、“业务规则引擎”、“约束求解器”和“运算研究”等术语。值得一提的是，这些有用的工具的确来自AI研究，但由于未能实现更宏伟的目标，它们被打上了非AI的标签。
但在2010年前后，情况开始发生变化。人们对AI的兴趣再次迅速增长，图像分类竞赛引起了媒体的大量关注。硅谷拥有大量的数据，这是第一次有足够的数据足以使神经网络变得有用。
到2015年，“AI”研究已成为许多财富500强企业的巨额预算去向，他们担心自己会被自动化竞争对手甩在后面。毕竟，让一个神经网络来识别图像中的物体真的令人印象深刻！对于外行来说，下一步肯定就是天网能力了。
但这真的是迈向真正的人工智能的一步吗？或许历史在重演，但这一次确实是受到了一些成功用例的鼓舞。
# AI的定义不断发展，经常与“神经网络”联系在一起
很长一段时间以来，我一直不喜欢“AI”这个词。它是模糊而遥远的，它更多的是由营销人员而不是科学家定义的。当然，营销和流行语对于刺激积极的变革和接受新思维是必要的。然而，流行语不可避免地会导致混淆。我的新智能手机有一个“人工智能铃声”(AI Ringtone)功能，可以动态地调节铃声音量，使其刚好超过环境噪音。我猜可以用一系列“if”语句或简单的线性函数来编程的东西都被称为“AI”。
鉴于此，“AI”的定义受到广泛争议或许就不足为奇了。我喜欢Geoffrey De Smet的定义，它指出AI解决方案是针对具有不确定性答案和/或不可避免的误差范围的问题。在这个定义下，AI包括大量的工具，从机器学习到概率到搜索算法。
也可以说，AI的定义在不断发展，但只包括突破性的发展，而过去的成功(如光学字符识别或语言翻译)不再被认为是“AI”。因此，“AI是一个相对的术语，而不是绝对的。
近年来，“AI”经常与“神经网络”联系在一起，这也是本文的重点。其他的“AI”解决方案，包括其他机器学习模型(朴素贝叶斯、支持向量机、XGBoost)，搜索算法，等等。然而，神经网络可以说是目前最热门、最经常被炒作的技术。
# AI文艺复兴？
2010年之后AI热潮的复苏，仅仅是因为AI掌握了一类新的任务：分类。更具体地说，是多亏了神经网络，科学家们已经开发出有效的方法来对大多数类型的数据进行分类，包括图像和自然语言。甚至自动驾驶汽车也属于一种分类任务，其中周围道路的每个图像都可以转化为一组独立的动作(加油、刹车、左转、右转等)。
在我看来，自然语言处理比单纯的分类更令人印象深刻。人们很容易相信这些算法是有感知能力的，但如果你仔细研究算法，就会发现它们依赖于语言模式，而不是依赖于有意识构建的思想。这些可以带来一些有趣的结果。
Google Duplex可能是最令人印象深刻的自然语言处理技术，它能让你的Android手机代替你打电话，甚至进行预约。但是，Google Duplex是仅仅为了完成这个任务而训练、构造甚至硬编码的“AI”。当然，Google Duplex打的电话听起来很自然，有停顿，有“啊”和“嗯”……但是，这也是通过对语音模式的操作来实现的，而不是通过实际的推理和思考。
这一切都非常令人印象深刻，并且肯定有一些是有用的应用程序。但我们确实需要调整我们的期望值，停止炒作夸大“深度学习”能力。如果不这样做，我们可能会发现我们进入了另一个“AI冬天”。
# 历史总是在重演
康奈尔大学的Gary Marcus写了一篇关于深度学习局限性的文章，并提出了几个发人深省的观点。Rodney Brooks也写了一篇文章，整理了时间轴，并通过引用的研究跟踪他对AI炒作周期的预测。
怀疑论者通常有几个共同观点。神经网络需要大量的数据，即使在今天，数据也是有限的。这也是为什么你在YouTube上看到的“游戏”AI的例子经常需要几天不断的训练，并且不断地失败，直到神经网络找到一个让它获胜的模式。
神经网络之所以“深”，是因为它们在技术上有很多层的节点，而不是因为它对问题的理解有多深刻。这些层也使得神经网络难以理解，甚至对它的开发者来说也是如此。最重要的是，当神经网络冒险进入其他问题空间(如旅行推销员问题)时，它们的回报就会减少。这是有道理的。为什么我要用神经网络来解决旅行推销员的问题，明明搜索算法更加有效、可扩展而且成本低？当然，有些人希望将神经网络推广到更多问题空间，尽管这很有趣，但神经网络在这些问题上似乎很少能胜过任何专门的算法。
正如MIT教授Luke Hewitt所说：
> 仅仅基于一项任务，凭直觉去了解一台机器的智能范围有多广，或者它具备多少智能能力，这不是一个好主意。20世纪50年代的跳棋机器让研究人员感到惊讶，许多人认为这是AI走向人类水平推理的巨大飞跃，但我们现在意识到，在这个游戏中达到人类水平或超越人类水平远比实现人类水平的一般智能要容易得多。事实上，即使是最优秀的人也很容易被简单的启发式搜索算法打败。在一项任务中达到或超越人类的表现，不一定是能够在大多数任务中接近人类表现的垫脚石。— Luke Hewitt
我认为同样值得指出的是，神经网络需要大量的硬件和能量才能进行训练。我认为这不是可持续的。当然，神经网络的预测效率要高得多。然而，我认为人们对神经网络的期待使得它需要不断的训练，因此需要指数级的能量和成本。当然，计算机是越来越快了，但是芯片制造商能继续维持摩尔定律吗?
正是由于这些原因，我认为另一个AI冬天即将来临。越来越多的专家站出来指出这些局限性。公司在争夺“深度学习”和“人工智能”人才方面仍然不遗余力，但我认为许多公司会意识到深度学习并不是它们需要的，这只是时间问题。更糟糕的是，如果你的公司没有谷歌那样高的研究预算，没有那么多的博士人才，或者没有能够从用户那里收集到大量数据，你很快就会发现实际的“深度学习”前景非常有限。
每一个AI冬季来临之前，科学家都会夸大它们的创造潜力。仅仅说他们的算法能很好地完成一项任务是不够的。他们希望AI能适应任何任务，或者至少能给人留下这样的印象。例如，AlphaZero是一种更好的国际象棋算法。媒体的反应是“天哪，通用AI来了。大家快跑！机器人来了！”而科学家们不是费心去纠正他们，而是鼓励他们使用更聪明的词语。毕竟，降低预期对VC融资没有帮助。
# 下一步是什么？
当然，并不是每一家使用“机器学习”或“人工智能”的公司实际上都在使用“深度学习”。一位优秀的数据科学家可能被雇来构建一个神经网络，但当他真正研究这个问题时，他会选择构建一个更适合的朴素贝叶斯分类器。对于那些已经成功地使用图像识别和语言处理的公司来说，他们将继续愉快地这样做。但我确实认为神经网络不会在其他问题空间取得进展。
上一个AI冬天对计算机科学的发展是毁灭性的。值得指出的是，这样的研究也产生了一些有用的东西，比如搜索算法，它可以有效地在国际象棋中获胜，或者用最小的成本解决交通问题。简单地说，创新的算法往往在某项特定任务上表现出色。
我想说的是，对于很多类型的问题，都有很多行之有效的解决方案。为了避免AI冬天，你能做的最好的事情就是把你试图解决的问题具体化，并理解它的本质。在此之后，寻找为特定问题提供解决方案的直观路径。比如，如果要对文本消息进行分类，可能需要使用朴素贝叶斯。如果要优化交通网络，可能应该使用离散优化。不管来自同行的压力有多大，你都可以带着适当的怀疑态度来处理复杂的模型，并质疑它是否是正确的方法。
希望这篇文章清楚地表明，深度学习对于大多数问题来说不是正确方法。不要为所有问题寻找一个通用AI解决方案，因为你找不到的。
原文：
https://towardsdatascience.com/is-deep-learning-already-hitting-its-limitations-c81826082ac3

