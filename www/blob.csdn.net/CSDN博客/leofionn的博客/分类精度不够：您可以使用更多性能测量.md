
# 分类精度不够：您可以使用更多性能测量 - leofionn的博客 - CSDN博客


2018年06月01日 17:02:42[leofionn](https://me.csdn.net/qq_36142114)阅读数：745


原文https://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/
当您为分类问题建立模型时，您几乎总是希望将该模型的准确性视为所有预测中正确预测的数量。
这是分类的准确性。
在之前的文章中，我们[研究了](http://machinelearningmastery.com/how-to-choose-the-right-test-options-when-evaluating-machine-learning-algorithms/)使用交叉验证和多重交叉验证来评估未预见数据预测的模型的鲁棒性，我们使用了分类准确率和平均分类准确率。
一旦你有一个模型，你相信可以做出强大的预测，你需要决定它是否是一个足够好的模型来解决你的问题。分类准确性本身通常不足以作出此决定的信息。
![分类精度](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2014/03/classification-accuracy.jpg)分类准确性
摄影：Nina Matthews Photography，保留部分权利
在这篇文章中，我们将介绍Precision和Recall性能度量，您可以使用这些度量来评估您的模型是否存在二进制分类问题。
## 乳腺癌复发
在[乳腺癌的数据集](http://archive.ics.uci.edu/ml/datasets/Breast+Cancer)是一个标准的机器学习数据集。它包含9个属性，描述了286名女性患乳腺癌并在5年内复发的情况。
这是一个二元分类问题。在286名女性中，201人没有患乳腺癌复发，剩下的85人没有。
我认为这个问题的假阴性可能比误报更差。你同意吗？更详细的筛选可以清除假阳性结果，但是假阴性结果会被送回家并失去后续评估。
## 分类精度
[分类准确性](http://en.wikipedia.org/wiki/Accuracy_and_precision)是我们的出发点。这是正确预测的数量除以预测总数再乘以100得到的百分比。
### 全部不再发生
仅预测乳腺癌无复发的模型将达到（201/286）* 100或70.28％的准确度。我们将此称为我们的“全部不复发”。这是一个高准确度，但是一个可怕的模型。如果它被单独用于决策支持以通知医生（不可能，但是一起玩耍），它将使85名女性错误地认为自己的乳腺癌不会再发生（高假阴性）。
### 所有复发
仅预测乳腺癌复发的模型将达到（75/286）* 100或29.72％的准确度。我们将这称为“所有复发”。这种模式的准确性非常差，并且会让201名女性认为乳腺癌复发，但确实没有（高假阳性）。
### 大车
CART或[分类和回归树](http://en.wikipedia.org/wiki/Predictive_analytics#Classification_and_regression_trees)是一个强大而简单的决策树算法。在这个问题上，CART可以达到69.23％的准确度。这比我们的“所有不复发”模型要低，但是这个模型更有价值吗？
我们可以看到，分类准确性本身并不足以为这个问题选择一个模型。
## 混乱矩阵
呈现分类器预测结果的干净而明确的方法是使用[混淆矩阵](http://en.wikipedia.org/wiki/Table_of_confusion#Table_of_confusion)（也称为[应急表](http://en.wikipedia.org/wiki/Contingency_table)）。
对于二元分类问题，表格有2行和2列。顶部是观察到的类标签，而下面是预测的类标签。每个单元格都包含分类器落入该单元格的预测数量。
![真值表混淆矩阵](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2014/03/truth_table.png)真值表混淆矩阵
在这种情况下，一个完美的分类器可以正确地预测201无复发和85复发，这将进入左上角的细胞，无复发/无复发（True Negatives）和右下角细胞复发/复发（True Positives）。
错误的预测显然分解为另外两个单元格。错误否定分类器标记为不重复的重复。我们没有任何这些。假阳性不是分类器标记为复发的复发。
这是一个有用的表格，它显示了数据中的类别分布和分类器预测的类别分布以及错误类型的细分。
### 所有无复发混淆矩阵
混乱矩阵凸显了大量（85）的假阴性。
![所有无复发混淆矩阵](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2014/03/no_recurrence_confusion_matrix.png)所有无复发混淆矩阵

### 所有复发混淆矩阵
混淆矩阵凸显了大量（201）的误报。
![所有复发混淆矩阵](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2014/03/recurrence_confusion_matrix.png)所有复发混淆矩阵

### CART混淆矩阵
这看起来像一个更有价值的分类器，因为它正确预测了10个复发事件以及188个无复发事件。该模型还显示了适量的假阴性（75）和假阳性（13）。
![CART混淆矩阵](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2014/03/cart_confusion_matrix.png)CART混淆矩阵

## 准确性悖论
正如我们在这个例子中看到的那样，准确性可能会引起误解。有时可能需要选择精度较低的模型，因为它对问题具有更强的预测能力。
例如，在存在大量类别不平衡的问题中，模型可以预测大多数类别对于所有预测的价值，并获得较高的分类准确性，问题在于该模型在问题领域没有用处。正如我们在乳腺癌例子中看到的那样。
这就是所谓的[准确性悖论](http://en.wikipedia.org/wiki/Accuracy_paradox)。对于类似问题，需要采取这些附加措施来评估分类器。
## 精确
[精度](http://en.wikipedia.org/wiki/Information_retrieval#Precision)是真正正数和真正正数的差值。换言之，正数预测的数量除以预测的正数级数的总数。它也被称为[正向预测值](http://en.wikipedia.org/wiki/Positive_predictive_value)（PPV）。
精度可以被认为是分类器正确性的度量。低精度也可能表示大量的误报。
All No Recurrence模型的精度为0 /（0 + 0）或不是数字或0。
所有复发模型的精确度为85 /（85 + 201）或0.30。
CART模型的精确度为10 /（10 + 13）或0.43。
精度表明CART是一个更好的模型，并且即使精度较低，所有循环比全部不循环模型更有用。所有复发模型和CART之间的精确度差异可以通过所有复发模型预测的大量假阳性来解释。
## 召回
[回想一下](http://en.wikipedia.org/wiki/Information_retrieval#Recall)真正的正数除以真正的数量和假阴性的数量。换句话说，正数预测的数量除以测试数据中正数类别值的数量。它也被称为灵敏度或真正的正面率。
回忆可以被认为是分类器完整性的度量。低回忆表明许多假阴性。
所有不重复模型的召回是0 /（0 + 85）或0。
所有复发模型的召回是85 /（85 + 0）或1。
CART的召回是10 /（10 + 75）或0.12。
正如你所期望的那样，所有的复发模型都有完美的回忆，因为它预测了所有情况下的“复发”。CART召回率低于全部复发模型。这可以通过CART模型预测的大量（75）假阴性来解释。
## F1得分
的[F1分数](http://en.wikipedia.org/wiki/F1_score)是2 *（（*精度召回）/（精度+召回））。它也被称为F分数或F度量。换句话说，F1分数表达了精确度和召回率之间的平衡。
所有不复发模型的F1是2 *（（0 * 0）/ 0 + 0）或0。
所有复发模型的F1为2 *（（0.3 * 1）/0.3+1）或0.46。
CART模型的F1为2 *（（0.43 * 0.12）/0.43+0.12）或0.19。
如果我们希望根据精度和召回之间的平衡选择一个模型，那么F1度量表明所有的复发模型都是要击败的模型，并且CART模型还没有足够的竞争力。
## 概要
在这篇文章中，您了解了准确性悖论以及阶级失衡的问题，因为只有分类准确性无法被信任才能选择一个效果良好的模型。
通过实例，您了解了混淆矩阵，以此来描述未预见数据集的预测中的错误分解。您了解了衡量模型的精确度（准确性）和回忆（完整性）以及F1比分中两者之间平衡的说明。

