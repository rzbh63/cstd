
# [ECCV2018][端到端文字识别] - SIGAI_CSDN的博客 - CSDN博客
# [SIGAI_CSDN的博客](https://blog.csdn.net/sigai_csdn)


[博客首页](https://blog.csdn.net/SIGAI_CSDN)
[关于我们](https://me.csdn.net/SIGAI_CSDN)

2018年12月28日 11:35:59[SIGAI_csdn](https://me.csdn.net/SIGAI_CSDN)阅读数：223


> SIGAI特约作者

> 谢恩泽
> 同济计算机研三在读，face++ 研究实习生

> 主要研究方向为目标检测，语义分割等其中包括文字检测和识别

![image.png](https://img-blog.csdnimg.cn/20181228113600316)
前言：这篇文章是第一个做弯曲文本的端到端检测+识别。
传统的方法将文字检测和文字识别分为两个分开的部分，即输入一张图，先进行文字检测，检测出文字的位置，再进行文字识别，即对检测出的文字抠出来并送入识别网络。这样一方面比较费时间，第二没有共享检测和识别的特征。
一  什么是端到端检测识别？
即只需要一个网络，输入一张图片，同时输出检测和识别的结果，相比传统先检测再识别的好处在于
(1)速度更快，因为流程更简单
(2)效果更好，由于多任务学习使得网络能提取更为鲁棒的特征，每一个任务都可以有一定程度的提高。
端到端训练文字检测和识别可以使得这两个任务都能得到提高，使得梯度能从这两个分支分别回传到主干网络，能使得定位更加精准并减少错误样本的检测。
传统做法大多数分为以下四步
(1)检测出旋转的文字框
(2)并做一个仿射变换
(3)在feature map上将文字区域抠出来
(4)用crnn或者类似sequence的方法识别。
这种方法的缺点在于文字可能检测的不够精准，这样对于识别来说就会造成一定困难，比如文字边缘多框了一些空白区域等。
二  弯曲文本的检测和识别
弯曲文本检测：过去的方法主要解决水平文字检测或者倾斜的文字检测，而弯曲文字在自然场景中大量出现，如星巴克标志。
![image.png](https://img-blog.csdnimg.cn/20181228113600417)
水平文字检测只需要检测出文字的左上角和右下角，即4个变量[x1,y1,x2,y2]
倾斜文字一般有两种方法，1是用4个点表示，即8个变量，[x1,y1,x2,y2,x3,y3,x4,y4]，2是用水平矩形+旋转角度表示，需要5个变量，[x1,y1,x2,y2,theta]
而弯曲文字往往需要用更多的点才能精准描述。如下图所示。
因此，过去的方法无法很好的适应弯曲文字检测的任务。
![image.png](https://img-blog.csdnimg.cn/20181228113600498)
传统文字识别的方法是把文字区域当做一个序列，用lstm从左到右扫描文字，得到文字识别结果，代表方法为CRNN，这种方法对于水平的文字效果很好，但是对于弯曲的文字效果却很差。
弯曲文本识别的难度在于水平检测框或者四边形检测框 做仿射变换，如下图所示
(1)无法精准定位文字区域，水平检测框和四边形检测框中文字区域都只占据很小的一部分，大部分都是背景，而基于分割的方法可以准确的包围弯曲文字区域。
(2)水平或者倾斜检测框无法扭正文本，因此基于lstm的CRNN识别方法效果就会很差，而用实例分割的方法可以精准检测文字并识别
![image.png](https://img-blog.csdnimg.cn/20181228113600582)
三 网络结构介绍
该方法是基于Mask R-CNN的，Mask R-CNN是Facebook提出的通用物体检测分割框架，可以同时对80类物体做检测和分割，其中有三个分支
(1)classification分支，用来对目标分类
(2)bounding box regression分支，用来定位物体
(3)mask分支，用来对框内的物体做实例分割。如下图所示
![image.png](https://img-blog.csdnimg.cn/20181228113600657)
这篇文章是基于mask rcnn的，流程图如下。
创新点主要是对mask分支进行了改进，其中把mask 分支做了类似于人体关键点的检测，把一个个字符当做整个文字的关键点，即不仅对bounding box内的整个文字区域做instance segmentation，同时对每个字符做分割，这里要注意的是每个字符的标注并不来源于真实数据，而是来自于人造数据集synth800k数据,因为真实数据集中往往只有单词级别的标注，并没有字符级别的标注。
![image.png](https://img-blog.csdnimg.cn/20181228113600732)
这篇文章的创新之处主要在于在mask 分支加入了文字识别的分支，详细分析一下mask 分支
可以看到mask 分支一共分三部分，第一部分是global word map,第二部分是每个字符的character map，这关系到如何识别，第三部分是字符的关键点，即background map，用来区分背景和字符
![image.png](https://img-blog.csdnimg.cn/20181228113600792)
(1) global word map 和标准的mask rcnn分割的分支一样，目的是分割出word的区域。
(2) character maps 该map的channel数量和要识别的文字类别一致，一般数据集为36(10数字+26字母)，即对所有字符的中心做语义分割，这个字符属于哪一类就会在channel对应层上响应最高。
(3) bachground map 是定位字符的，和（2）类似，但是不需要区分是哪个字符，只需要区分是不是字符。
识别是通过一种 叫pixel-voting的方法，即通过bachground map去算他在36个字符的fmap上的响应，通过投影的方式，取响应最大的当做类别。
可以说这是一种基于语义分割的方法的文字识别。
pixel-voting做文字识别
![image.png](https://img-blog.csdnimg.cn/20181228113600859)
上图 描述了(2）（3）如何做文字识别的细节。通过background map中的字符位置投影到character map上，去计算在每一层的响应值，哪一层响应最大，就认为这个字属于哪一类。主要是通过pixel-voting的方法。
通过这种方法识别的好处在于：
（1）借鉴了语义分割的思路，直接分割出字符的中心区域并判断类别
（2）抛弃了基于lstm的序列识别的方法，因此对于无论是水平文字还是弯曲文字识别效果都很鲁棒。
标签生成
训练神经网络需要label，如何准备label呢？
![image.png](http://www.sigai.cn/upload/image/20181228/1545967134830686.png)
可以看到，左图中蓝色的水平box是rpn 产生的候选框，红色的多边形框是word的真实框，黄色的box是每个字符的真实 box框，绿色的水平框是红色多边形的最小外接矩形框。 右边：上图是mask rcnn做实例分割的label,下边是根据黄色框进行等比例缩圈得到的不同字符的语义分割的label(不同颜色代表不同字符。)
细节：其中大量的字符标注(黄色框)不来源于真实数据集，而是来自人造数据集Synth800k，其中包括了80万张人工合成图。
实验结果
![image.png](https://img-blog.csdnimg.cn/20181228113600925)
可视化结果：作者在icdar2013,2015和total-text上做了实验，效果还是很不错的，红色框表示fast rcnn分支出的水平box，白点是每个字符的定位。
作者对比Textboxes+CRNN这种水平box检测识别的效果,这种方法在弯曲文本上优越性的确更强。
可以看到Textboxes检测只能检测水平框，精准度很低，其次这样检测出的结果送给识别网络效果很差，很多地方都识别错了。
![image.png](https://img-blog.csdnimg.cn/20181228113600998)
实验数据：
作者分别在ICDAR2013,2015和Total-Text这三个数据集上做了实验。
ICDAR2013是水平文本，ICDAR2015是多方向文本，Total-Text是弯曲文本，因此这三个数据集代表了不同类型的文字检测识别任务。
可以看到所提出的方法在弯曲文字上大幅度超过现有方法，在传统的水平和多方向文字检测识别上效果也领先现有的方法。
![image.png](https://img-blog.csdnimg.cn/2018122811360181)
总结：
这个方法是一个可以端到端检测和识别弯曲文字的方法，基于目前最好的实例分割模型Mask R-CNN,对于曲形文字的端到端识别基于top-down自顶向下的方法基本是做的很好了。
此外该方法有一个缺点，对于中文识别估计效果不好，因为中文类别数太多，他们识别的feature map层数和类别成正比，因此feature map层数会很大，会很拖累速度。
不过瑕不掩瑜，该方法是第一个尝试做端到端的弯曲文字检测和识别，创新度非常高，其中在Mask分支通过关键点的思路做文字识别更是首创，值得大家多学习一下。

