
# 机器学习：循环神经网络知识要点 - 喜欢打酱油的老鸟 - CSDN博客


2019年04月12日 08:25:44[喜欢打酱油的老鸟](https://me.csdn.net/weixin_42137700)阅读数：9


[https://www.toutiao.com/a6678275630674477581/](https://www.toutiao.com/a6678275630674477581/)

# 概述
循环神经网络特点是可以挖掘出数据序列之间的关系信息，实际使用中每一个样本的输入是数据序列，也就是一系列的数据，其中的每个数据是一个时间步。
# RNN
RNN层也是由一个或者多个神经元组成的，每个神经元的输入由两部分构成，一部分是序列数据中的某一个数据，另一部分是这个数据的前一个数据经过循环层神经元时，神经元输出的隐藏状态。神经元的输出也包含两部分，一部分时输出的预测值，另一部分时隐藏状态。RNN的结构图如下：
![机器学习：循环神经网络知识要点](http://p3.pstatp.com/large/pgc-image/ab4d37adc8c747668e44b467bb640799)
循环神经网络 RNN
# 使用keras实现循环神经网络
每一个时刻的输入包含两部分，一个是这个时刻的输入数据，另一个是上一时刻的输出数据；
keras的实现如下：
![机器学习：循环神经网络知识要点](http://p1.pstatp.com/large/pgc-image/54460889a23a4481aa926bc2c847b4d5)
基础的RNN
# LSTM
下面以LSTM层中只有一个神经元为例(units=1)，说明前向传播过程。下面的ot,ht,ct都是一维的。如果units不只一个，则每个神经元均按照如下方式计算，可类比一个全连接层有一个和多个神经元，同一层的这些神经元之间是没有联系的。
![机器学习：循环神经网络知识要点](http://p9.pstatp.com/large/pgc-image/5031a3f52ccc467d8e1c549741a37d40)
LSTM
输入：本次输入X(t)，神经元的上一个状态C(t-1),神经元的上一个隐藏状态H(t-1)
输出：本次更新后的神经元状态C(t),本次的隐藏状态H(t)
遗忘门计算：
![机器学习：循环神经网络知识要点](http://p1.pstatp.com/large/pgc-image/aff6304dd3694d72867179a8a9347eea)
遗忘门
输入门：
![机器学习：循环神经网络知识要点](http://p1.pstatp.com/large/pgc-image/89a1cbbcf7a7494989852ed9a5c12b0a)
输入门
状态更新：
![机器学习：循环神经网络知识要点](http://p1.pstatp.com/large/pgc-image/80905ae9816c485b9239d0c307bcf583)
状态更新
输出门计算：
![机器学习：循环神经网络知识要点](http://p1.pstatp.com/large/pgc-image/70dc252387f3446990fd1b9309f3ce63)
输出门

