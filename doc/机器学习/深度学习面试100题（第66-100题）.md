# 深度学习面试100题（第66-100题）

66 下图是一个利用sigmoid函数作为激活函数的含四个隐藏层的神经网络训练的梯度下降图。这个神经网络遇到了梯度消失的问题。下面哪个叙述是正确的？

[![微信图片_20180801184737.jpg](https://ask.julyedu.com/uploads/questions/20180801/a855de3cdc72a46ab72a57cf057169b0.jpg)](https://ask.julyedu.com/uploads/questions/20180801/a855de3cdc72a46ab72a57cf057169b0.jpg)

A、第一隐藏层对应D，第二隐藏层对应C，第三隐藏层对应B，第四隐藏层对应A

B、第一隐藏层对应A，第二隐藏层对应C，第三隐藏层对应B，第四隐藏层对应D

C、第一隐藏层对应A，第二隐藏层对应B，第三隐藏层对应C，第四隐藏层对应D

D、第一隐藏层对应B，第二隐藏层对应D，第三隐藏层对应C，第四隐藏层对应A

正确答案是：A

解析：

由于反向传播算法进入起始层，学习能力降低，这就是梯度消失。换言之，梯度消失是梯度在前向传播中逐渐减为0, 按照图标题所说, 四条曲线是4个隐藏层的学习曲线, 那么第一层梯度最高(损失函数曲线下降明显), 最后一层梯度几乎为零(损失函数曲线变成平直线). 所以D是第一层, A是最后一层。

67

考虑某个具体问题时，你可能只有少量数据来解决这个问题。不过幸运的是你有一个类似问题已经预先训练好的神经网络。可以用下面哪种方法来利用这个预先训练好的网络？

A、把除了最后一层外所有的层都冻结，重新训练最后一层

B、对新数据重新训练整个模型

C、只对最后几层进行调参(fine tune)

D、对每一层模型进行评估，选择其中的少数来用

正确答案是：C

解析：

如果有个预先训练好的神经网络, 就相当于网络各参数有个很靠谱的先验代替随机初始化. 若新的少量数据来自于先前训练数据(或者先前训练数据量很好地描述了数据分布, 而新数据采样自完全相同的分布), 则冻结前面所有层而重新训练最后一层即可; 但一般情况下, 新数据分布跟先前训练集分布有所偏差, 所以先验网络不足以完全拟合新数据时, 可以冻结大部分前层网络, 只对最后几层进行训练调参(这也称之为fine tune)。

68

在选择神经网络的深度时，下面哪些参数需要考虑？

 

1 神经网络的类型(如MLP,CNN)

 

2 输入数据

 

3 计算能力(硬件和软件能力决定)

 

4 学习速率

 

5 映射的输出函数

A、1,2,4,5

B、2,3,4,5

C、都需要考虑

D、1,3,4,5

正确答案是：C

解析：

所有上述因素对于选择神经网络模型的深度都是重要的。特征抽取所需分层越多, 输入数据维度越高, 映射的输出函数非线性越复杂, 所需深度就越深. 另外为了达到最佳效果, 增加深度所带来的参数量增加, 也需要考虑硬件计算能力和学习速率以设计合理的训练时间。

69

当数据过大以至于无法在RAM中同时处理时，哪种梯度下降方法更加有效？

A、随机梯度下降法(Stochastic Gradient Descent)

B、不知道

C、整批梯度下降法(Full Batch Gradient Descent)

D、都不是

正确答案是：A

解析：

梯度下降法分随机梯度下降(每次用一个样本)、小批量梯度下降法(每次用一小批样本算出总损失, 因而反向传播的梯度折中)、全批量梯度下降法则一次性使用全部样本。这三个方法, 对于全体样本的损失函数曲面来说, 梯度指向一个比一个准确. 但是在工程应用中,受到内存/磁盘IO的吞吐性能制约, 若要最小化梯度下降的实际运算时间, 需要在梯度方向准确性和数据传输性能之间取得最好的平衡. 所以, 对于数据过大以至于无法在RAM中同时处理时, RAM每次只能装一个样本, 那么只能选随机梯度下降法。

70

当在卷积神经网络中加入池化层(pooling layer)时，变换的不变性会被保留，是吗？

A、不知道

B、看情况

C、是

D、否

正确答案是：C

解析：

池化算法比如取最大值/取平均值等, 都是输入数据旋转后结果不变, 所以多层叠加后也有这种不变性。

71、深度学习是当前很热门的机器学习算法，在深度学习中，涉及到大量的矩阵相乘，现在需要计算三个稠密矩阵 A,B,C 的乘积ABC,假设三个矩阵的尺寸分别为m∗n，n∗p，p∗q，且m < n < p < q，以下计算顺序效率最高的是（）

A、 (AB)C

B、 AC(B)

C、 A(BC)

D、 所以效率都相同

正确答案是：A

解析：

首先，根据简单的矩阵知识，因为 A*B ， A 的列数必须和 B 的行数相等。因此，可以排除 B 选项，

然后，再看 A 、 C 选项。在 A 选项中，m∗n 的矩阵 A 和n∗p的矩阵 B 的乘积，得到 m∗p的矩阵 A*B ，而 A∗B的每个元素需要 n 次乘法和 n-1 次加法，忽略加法，共需要 m∗n∗p次乘法运算。同样情况分析 A*B 之后再乘以 C 时的情况，共需要 m∗p∗q次乘法运算。因此， A 选项 (AB)C 需要的乘法次数是 m∗n∗p+m∗p∗q 。同理分析， C 选项 A (BC) 需要的乘法次数是 n∗p∗q+m∗n∗q。

由于m∗n∗p

72、输入图片大小为200×200，依次经过一层卷积（kernel size 5×5，padding 1，stride 2），pooling（kernel size 3×3，padding 0，stride 1），又一层卷积（kernel size 3×3，padding 1，stride 1）之后，输出特征图大小为

A、 95

B、 96

C、 97

D、 98

正确答案是：C

解析：

首先我们应该知道卷积或者池化后大小的计算公式，其中，padding指的是向外扩展的边缘大小，而stride则是步长，即每次移动的长度。

这样一来就容易多了，首先长宽一般大，所以我们只需要计算一个维度即可，这样，经过第一次卷积后的大小为: 本题 （200-5+2*1）/2+1 为99.5，取99

经过第一次池化后的大小为： （99-3）/1+1 为97

经过第二次卷积后的大小为： （97-3+2*1）/1+1 为97

73、基于二次准则函数的H-K算法较之于感知器算法的优点是()？

A、 计算量小

B、 可以判别问题是否线性可分

C、 其解完全适用于非线性可分的情况

正确答案是：B

解析：

HK算法思想很朴实,就是在最小均方误差准则下求得权矢量.

他相对于感知器算法的优点在于,他适用于线性可分和非线性可分得情况,对于线性可分的情况,给出最优权矢量,对于非线性可分得情况,能够判别出来,以退出迭代过程。

来源：@刘炫320，链接：

http://blog.csdn.net/column/details/16442.html

74、在一个神经网络中，知道每一个神经元的权重和偏差是最重要的一步。如果知道了神经元准确的权重和偏差，便可以近似任何函数，但怎么获知每个神经的权重和偏移呢？

A、搜索每个可能的权重和偏差组合，直到得到最佳值

B、赋予一个初始值，然后检查跟最佳值的差值，不断迭代调整权重

C、随机赋值，听天由命

D、以上都不正确的

正确答案是：B

解析：

答案：（B）

选项B是对梯度下降的描述。

75、神经网络模型（Neural Network）因受人类大脑的启发而得名

[![1.jpg](https://ask.julyedu.com/uploads/questions/20180803/6ab74d5e947a7293900eb49b065c5d41.jpg)](https://ask.julyedu.com/uploads/questions/20180803/6ab74d5e947a7293900eb49b065c5d41.jpg)

神经网络由许多神经元（Neuron）组成，每个神经元接受一个输入，对输入进行处理后给出一个输出，如下图所示。请问下列关于神经元的描述中，哪一项是正确的？

[![2.jpg](https://ask.julyedu.com/uploads/questions/20180803/d464fd9fae31756f5a222af94a05203b.jpg)](https://ask.julyedu.com/uploads/questions/20180803/d464fd9fae31756f5a222af94a05203b.jpg)

A、 每个神经元可以有一个输入和一个输出

B、 每个神经元可以有多个输入和一个输出

C、 每个神经元可以有一个输入和多个输出

D、 每个神经元可以有多个输入和多个输出

E、 上述都正确

正确答案是：E

解析：

答案：（E）

每个神经元可以有一个或多个输入，和一个或多个输出。

76、下图所示的网络用于训练识别字符H和T，如下所示

[![1.jpg](https://ask.julyedu.com/uploads/questions/20180806/59d43b31fc9d6e28b3e8eedc1a84d781.jpg)](https://ask.julyedu.com/uploads/questions/20180806/59d43b31fc9d6e28b3e8eedc1a84d781.jpg)

A、 

[![2.jpg](https://ask.julyedu.com/uploads/questions/20180806/dd10c98771d82c586a4312c02cee4c30.jpg)](https://ask.julyedu.com/uploads/questions/20180806/dd10c98771d82c586a4312c02cee4c30.jpg)

B、

[![3.jpg](https://ask.julyedu.com/uploads/questions/20180806/ca47a1803456eebd58c95da0767ab203.jpg)](https://ask.julyedu.com/uploads/questions/20180806/ca47a1803456eebd58c95da0767ab203.jpg)

C、

[![4.jpg](https://ask.julyedu.com/uploads/questions/20180806/bc1cbd4df2c5cca17fe27e6103db0b9d.jpg)](https://ask.julyedu.com/uploads/questions/20180806/bc1cbd4df2c5cca17fe27e6103db0b9d.jpg)

D、 可能是A或B，取决于神经网络的权重设置

正确答案是：D

解析：

不知道神经网络的权重和偏差是什么，则无法判定它将会给出什么样的输出。

77、如果我们用了一个过大的学习速率会发生什么？

A、神经网络会收敛

B、不好说

C、都不对

D、神经网络不会收敛

正确答案是：D

解析

学习率过大，会使得迭代时，越过最低点。

78、在一个神经网络中，下面哪种方法可以用来处理过拟合？

A、Dropout

B、分批归一化(Batch Normalization)

C、正则化(regularization)

D、都可以

正确答案是：D

解析：

都可以。对于选项C，分批归一化处理过拟合的原理，是因为同一个数据在不同批中被归一化后的值会有差别，相当于做了data augmentatio。

79、批规范化(Batch Normalization)的好处都有啥？

A、让每一层的输入的范围都大致固定

B、它将权重的归一化平均值和标准差

C、它是一种非常有效的反向传播(BP)方法

D、这些均不是

正确答案是：A

80、下列哪个神经网络结构会发生权重共享？

A、卷积神经网络

B、循环神经网络

C、全连接神经网络

D、选项A和B

正确答案是：D

81、下列哪个函数不可以做激活函数？

A、y = tanh(x)

B、y = sin(x)

C、y = max(x,0)

D、y = 2x

正确答案是：D

解析：

线性函数不能作为激活函数。

82、假设我们有一个如下图所示的隐藏层。隐藏层在这个网络中起到了一定的降纬作用。假如现在我们用另一种维度下降的方法，比如说主成分分析法(PCA)来替代这个隐藏层。

[![5.jpg](https://ask.julyedu.com/uploads/questions/20180807/e3cc7d24da123c59d9b487195501992f.jpg)](https://ask.julyedu.com/uploads/questions/20180807/e3cc7d24da123c59d9b487195501992f.jpg)

深度学习面试100题（第81-85题）

那么，这两者的输出效果是一样的吗？

A、是

B、否

正确答案是：B

解析：

PCA 提取的是数据分布方差比较大的方向，隐藏层可以提取有预测能力的特征

83、下图显示了训练过的3层卷积神经网络准确度，与参数数量(特征核的数量)的关系。

[![6.jpg](https://ask.julyedu.com/uploads/questions/20180807/f0da0f6833ee9d49fea52613718e4843.jpg)](https://ask.julyedu.com/uploads/questions/20180807/f0da0f6833ee9d49fea52613718e4843.jpg)

深度学习面试100题（第81-85题）

从图中趋势可见，如果增加神经网络的宽度，精确度会增加到一个特定阈值后，便开始降低。造成这一现象的可能原因是什么？

A、即使增加卷积核的数量，只有少部分的核会被用作预测

B、当卷积核数量增加时，神经网络的预测能力（Power）会降低

C、当卷积核数量增加时，导致过拟合

D、以上都不正确

正确答案是：C

解析：

网络规模过大时，就可能学到数据中的噪声，导致过拟合

84、在下面哪种情况下，一阶梯度下降不一定正确工作（可能会卡住）？

A、

[![1.png](https://ask.julyedu.com/uploads/questions/20180807/9e06d605c07324b2b23adac54921378d.png)](https://ask.julyedu.com/uploads/questions/20180807/9e06d605c07324b2b23adac54921378d.png)

B、

[![2.png](https://ask.julyedu.com/uploads/questions/20180807/34c1604540ffacb8b96ae29a107da90f.png)](https://ask.julyedu.com/uploads/questions/20180807/34c1604540ffacb8b96ae29a107da90f.png)

C、

[![3.png](https://ask.julyedu.com/uploads/questions/20180807/80a0a66b89f8780ab9219a4b93d87a51.png)](https://ask.julyedu.com/uploads/questions/20180807/80a0a66b89f8780ab9219a4b93d87a51.png)

正确答案是：B

解析：

这是鞍点（Saddle Point）的梯度下降的经典例子。另，本题来源于：

https://www.analyticsvidhya.co ... ning/

。

85、假设你需要调整超参数来最小化代价函数（cost function），会使用下列哪项技术？

A、穷举搜索

B、随机搜索

C、Bayesian优化

D、都可以

正确答案是：D

# 深度学习面试100题（第86-90题）

86、在感知机中（Perceptron）的任务顺序是什么？

1、随机初始化感知机的权重

2、去到数据集的下一批（batch）

3、如果预测值和输出不一致，则调整权重

4、对一个输入样本，计算输出值

A、 1, 2, 3, 4

B、 4, 3, 2, 1

C、 3, 1, 2, 4

D、 1, 4, 3, 2

正确答案是：D

87、构建一个神经网络，将前一层的输出和它自身作为输入。

[![1.png](https://ask.julyedu.com/uploads/questions/20180808/f64bb9b40012e07cdc60a568324c2f19.png)](https://ask.julyedu.com/uploads/questions/20180808/f64bb9b40012e07cdc60a568324c2f19.png)

下列哪一种架构有反馈连接？

A、循环神经网络

B、卷积神经网络

C、限制玻尔兹曼机

D、都不是

正确答案是：A

88、如果增加多层感知机（Multilayer Perceptron）的隐藏层层数，分类误差便会减小。这种陈述正确还是错误？

A、正确

B、错误

正确答案是：B

解析：

并不总是正确。层数增加可能导致过拟合，从而可能引起错误增加。

89、下列哪项关于模型能力（model capacity）的描述是正确的？（指神经网络模型能拟合复杂函数的能力）

A、隐藏层层数增加，模型能力增加

B、Dropout的比例增加，模型能力增加

C、学习率增加，模型能力增加

D、都不正确

正确答案是：A

解析：

A是对的，其它选项不确定

90、在训练神经网络时，损失函数(loss)在最初的几个epochs时没有下降，可能的原因是？

[![2.jpg](https://ask.julyedu.com/uploads/questions/20180808/d51fb331cdd3d839702b321ac1a11f9d.jpg)](https://ask.julyedu.com/uploads/questions/20180808/d51fb331cdd3d839702b321ac1a11f9d.jpg)

A、学习率(learning rate)太低

B、正则参数太高

C、陷入局部最小值

D、以上都有可能

正确答案是：D

  91、深度学习与机器学习算法之间的区别在于，后者过程中无需进行特征提取工作，也就是说，我们建议在进行深度学习过程之前要首先完成特征提取的工作。这种说法是：

A、正确的

B、错误的

正确答案是： B

解析：

正好相反，深度学习可以自行完成特征提取过程而机器学习需要人工来处理特征内容。

92、下列哪一项属于特征学习算法（representation learning algorithm）？

A、K近邻算法

B、随机森林

C、神经网络

D、都不属于

正确答案是：C

解析：

神经网络会将数据转化为更适合解决目标问题的形式，我们把这种过程叫做特征学习。

93、下列哪些项所描述的相关技术是错误的？

A、AdaGrad使用的是一阶差分(first order differentiation)

B、L-BFGS使用的是二阶差分(second order differentiation)

C、AdaGrad使用的是二阶差分

正确答案是：C

94、提升卷积核(convolutional kernel)的大小会显著提升卷积神经网络的性能，这种说法是

A、正确的

B、错误的

正确答案是： B

解析：

卷积核的大小是一个超参数(hyperparameter)，也就意味着改变它既有可能提高亦有可能降低模型的表现。

95、阅读以下文字：

假设我们拥有一个已完成训练的、用来解决车辆检测问题的深度神经网络模型，训练所用的数据集由汽车和卡车的照片构成，而训练目标是检测出每种车辆的名称（车辆共有10种类型）。现在想要使用这个模型来解决另外一个问题，问题数据集中仅包含一种车（福特野马）而目标变为定位车辆在照片中的位置。

A、除去神经网络中的最后一层，冻结所有层然后重新训练

B、对神经网络中的最后几层进行微调，同时将最后一层（分类层）更改为回归层

C、使用新的数据集重新训练模型

D、所有答案均不对

正确答案是： B  

  96、假设你有5个大小为7x7、边界值为0的卷积核，同时卷积神经网络第一层的深度为1。此时如果你向这一层传入一个维度为224x224x3的数据，那么神经网络下一层所接收到的数据维度是多少？

A、218x218x5

B、217x217x8

C、217x217x3

D、220x220x5

正确答案是：A

97、假设我们有一个使用ReLU激活函数(ReLU activation function)的神经网络，假如我们把ReLU激活替换为线性激活，那么这个神经网络能够模拟出同或函数(XNOR function)吗？

A、可以

B、不好说

C、不一定

D、不能

正确答案是：D

解析：

使用ReLU激活函数的神经网络是能够模拟出同或函数的。

但如果ReLU激活函数被线性函数所替代之后，神经网络将失去模拟非线性函数的能力。

98、考虑以下问题：

假设我们有一个5层的神经网络，这个神经网络在使用一个4GB显存显卡时需要花费3个小时来完成训练。而在测试过程中，单个数据需要花费2秒的时间。 如果我们现在把架构变换一下，当评分是0.2和0.3时，分别在第2层和第4层添加Dropout，那么新架构的测试所用时间会变为多少？

A、少于2s

B、大于2s

C、仍是2s

D、说不准

正确答案是：C

解析：

在架构中添加Dropout这一改动仅会影响训练过程，而并不影响测试过程。

99、下列的哪种方法可以用来降低深度学习模型的过拟合问题？

1 增加更多的数据

2 使用数据扩增技术(data augmentation)

3 使用归纳性更好的架构

4 正规化数据

5 降低架构的复杂度

A、1 4 5

B、1 2 3

C、1 3 4 5

D、所有项目都有用

正确答案是：D

解析：

上面所有的技术都会对降低过拟合有所帮助。

100、混沌度(Perplexity)是一种常见的应用在使用深度学习处理NLP问题过程中的评估技术，关于混沌度，哪种说法是正确的？

A、混沌度没什么影响

B、混沌度越低越好

C、混沌度越高越好

D、混沌度对于结果的影响不一定

正确答案是： B  

