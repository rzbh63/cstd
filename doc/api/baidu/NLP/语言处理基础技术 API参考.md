# 语言处理基础技术 API参考

# 简介

Hi，您好，欢迎使用百度自然语言处理API服务。

本文档主要针对API开发者，描述百度自然语言处理接口服务的相关技术内容。如果您对文档内容有任何疑问，可以通过以下几种方式联系我们：

- 在百度云控制台内**提交工单**，咨询问题类型请选择**人工智能服务**；
- 如有疑问，进入[AI社区交流](http://ai.baidu.com/forum/topic/list/169)

## 接口能力

| 接口名称     | 接口能力简要描述                                             |
| :----------- | :----------------------------------------------------------- |
| 词法分析     | 分词、词性标注、专名识别                                     |
| 依存句法分析 | 自动分析文本中的依存句法结构信息                             |
| 词向量表示   | 查询词汇的词向量，实现文本的可计算                           |
| DNN语言模型  | 判断一句话是否符合语言表达习惯，输出分词结果并给出每个词在句子中的概率值 |
| 词义相似度   | 计算两个给定词语的语义相似度                                 |
| 短文本相似度 | 判断两个文本的相似度得分                                     |
| 评论观点抽取 | 提取一个句子观点评论的情感属性                               |
| 情感倾向分析 | 对包含主观观点信息的文本进行情感极性类别（积极、消极、中性）的判断，并给出相应的置信度 |
| 文章标签     | 对文章的标题和内容进行深度分析，输出能够反映文章关键信息的主题、话题、实体等多维度标签以及对应的置信度 |
| 文章分类     | 对文章按照内容类型进行自动分类                               |
| 文本纠错     | 识别输入文本中有错误的片段，提示错误并给出正确的文本结果     |
| 对话情绪识别 | 针对用户日常沟通文本背后所蕴含情绪的一种直观检测，可自动识别出当前会话者所表现出的情绪类别及其置信度 |
| 中文分词     | 切分出连续文本中的基本词汇序列（已合并到词法分析接口）       |
| 词性标注     | 为自然语言文本中的每个词汇赋予词性（已合并到词法分析接口）   |

## 请求格式

POST方式调用

**注意**：要求使用JSON格式的结构体来描述一个请求的具体内容。**发送时默认需要对body整体进行GBK编码。**若使用UTF-8编码，请在url参数中添加charset=UTF-8 （大小写敏感） 例如：https://aip.baidubce.com/rpc/2.0/nlp/v1/lexer?charset=UTF-8&access_token=24.f9ba9c5241b67688bb4adbed8bc91dec.2592000.1485570332.282335-8574074

## 返回格式

JSON格式，**返回内容为GBK编码**

# 调用方式

调用AI服务相关的API接口有两种调用方式，两种不同的调用方式采用相同的接口URL。

区别在于**请求方式**和**鉴权方法**不一样，请求参数和返回结果一致。

## 调用方式一

向API服务地址使用POST发送请求，必须在URL中带上参数：

**access_token:** 必须参数，参考“[Access Token获取](http://ai.baidu.com/docs#/Auth)。

POST中参数按照API接口说明调用即可。

例如自然语言处理API，使用HTTPS POST发送：

```
https://aip.baidubce.com/rpc/2.0/nlp/v1/lexer?access_token=24.f9ba9c5241b67688bb4adbed8bc91dec.2592000.1485570332.282335-8574074
```

**获取access_token示例代码**

bash

PHP

Java

Python

C++

C#

Node

```
#!/bin/bash
curl -i -k 'https://aip.baidubce.com/oauth/2.0/token?grant_type=client_credentials&client_id=【百度云应用的AK】&client_secret=【百度云应用的SK】'
```

> **说明：** 方式一鉴权使用的Access_token必须通过API Key和Secret Key获取。

## 调用方式二

**请求头域内容**

NLP的API服务需要在请求的HTTP头域中包含以下信息：

- host（必填）
- x-bce-date （必填）
- x-bce-request-id（选填）
- authorization（必填）
- content-type（选填）
- content-length（选填）

作为示例，以下是一个标准的请求头域内容:

```
POST rpc/2.0/nlp/v1/wordseg? HTTP/1.1
accept-encoding: gzip, deflate
x-bce-date: 2015-03-24T13:02:00Z
connection: keep-alive
accept: */*
host: aip.baidubce.com
x-bce-request-id: 73c4e74c-3101-4a00-bf44-fe246959c05e
content-type: application/x-www-form-urlencoded;
authorization: bce-auth-v1/46bd9968a6194b4bbdf0341f2286ccce/2015-03-24T13:02:00Z/1800/host;x-bce-date/994014d96b0eb26578e039fa053a4f9003425da4bfedf33f4790882fb4c54903
```

> **说明：** 方式二鉴权使用的[API认证机制](https://cloud.baidu.com/doc/Reference/AuthenticationMechanism.html)authorization必须通过百度云的[AK/SK](https://cloud.baidu.com/doc/Reference/GetAKSK.html)生成。

# 词法分析接口

## 接口描述

（通用版）词法分析接口：向用户提供分词、词性标注、专名识别三大功能；能够识别出文本串中的基本词汇（分词），对这些词汇进行重组、标注组合后词汇的词性，并进一步识别出命名实体。 （定制版）词法分析接口：向用户提供分词、词性标注、专名识别三大功能；用户在控制台中进行个性化配置，支持自定义词表与规则，通过定制版可有效识别应用场景中的小众词汇与类别。定制版接口的使用教程请看链接：http://ai.baidu.com/forum/topic/show/496975

## 请求说明

**请求示例一**

- HTTP方法: `POST`
- （通用版）请求URL: `https://aip.baidubce.com/rpc/2.0/nlp/v1/lexer`
- （定制版）请求URL: `https://aip.baidubce.com/rpc/2.0/nlp/v1/lexer_custom`
- URL参数：

| 参数         | 值                                                           |
| :----------- | :----------------------------------------------------------- |
| access_token | 通过API Key和Secret Key获取的access_token,参考“[Access Token获取](http://ai.baidu.com/docs#/Auth)” |

- Header如下：

| 参数         | 值               |
| :----------- | :--------------- |
| Content-Type | application/json |

- body请求示例:

  ```
  {
    "text": "百度是一家高科技公司"
  }
  ```

**请求参数**

| **参数名称** | **类型** | **详细说明**                                         |
| :----------- | :------- | :--------------------------------------------------- |
| text         | string   | 待分析文本（目前仅支持GBK编码），长度不超过20000字节 |

## 返回说明

**返回参数**

| 参数名称      | 类型             | **必需** | 详细说明                                                     |
| :------------ | :--------------- | :------- | :----------------------------------------------------------- |
| text          | string           | 是       | 原始单条请求文本                                             |
| items         | array of objects | 是       | 词汇数组，每个元素对应结果中的一个词                         |
| +item         | string           | 是       | 词汇的字符串                                                 |
| +ne           | string           | 是       | 命名实体类型，命名实体识别算法使用。词性标注算法中，此项为空串 |
| +pos          | string           | 是       | 词性，词性标注算法使用。命名实体识别算法中，此项为空串       |
| +byte_offset  | int              | 是       | 在text中的字节级offset（使用GBK编码）                        |
| +byte_length  | int              | 是       | 字节级length（使用GBK编码）                                  |
| +uri          | string           | 否       | 链指到知识库的URI，只对命名实体有效。对于非命名实体和链接不到知识库的命名实体，此项为空串 |
| +formal       | string           | 否       | 词汇的标准化表达，主要针对时间、数字单位，没有归一化表达的，此项为空串 |
| +basic_words  | array of strings | 是       | 基本词成分                                                   |
| +loc_details  | array of objects | 否       | 地址成分，非必需，仅对地址型命名实体有效，没有地址成分的，此项为空数组。 |
| ++type        | string           | 是       | 成分类型，如省、市、区、县                                   |
| ++byte_offset | int              | 是       | 在item中的字节级offset（使用GBK编码）                        |
| ++byte_length | int              | 是       | 字节级length（使用GBK编码）                                  |

**返回示例**

```
{
      "text":"百度是一家高科技公司",
      "items":[
         {
           "byte_length":4,
           "byte_offset":0,
           "formal":"",
           "item":"百度",
           "ne":"ORG",
           "pos":"",
           "uri":"",
           "loc_details":[ ],
           "basic_words":["百度"]
         },
         {
           "byte_length":2,
           "byte_offset":4,
           "formal":"",
           "item":"是",
           "ne":"",
           "pos":"v",
           "uri":"",
           "loc_details":[ ],
           "basic_words":["是"]
         },
         {
           "byte_length":4,
           "byte_offset":6,
           "formal":"",
           "item":"一家",
           "ne":"",
           "pos":"m",
           "uri":"",
           "loc_details":[ ],
           "basic_words":["一","家"]
         },
         {
           "byte_length":6,
           "byte_offset":10,
           "formal":"",
           "item":"高科技",
           "ne":"",
           "pos":"n",
           "uri":"",
           "loc_details":[ ],
           "basic_words":["高","科技"]
         },
         {
           "byte_length":4,
           "byte_offset":16,
           "formal":"",
           "item":"公司",
           "ne":"",
           "pos":"n",
           "uri":"",
           "loc_details":[ ],
           "basic_words":["公司"]
         }
      ]
}
```

**词性缩略说明**

| **词性** | **含义** | **词性** | **含义** | **词性** | **含义**   | **词性** | **含义** |
| :------- | :------- | :------- | :------- | :------- | :--------- | :------- | :------- |
| n        | 普通名词 | f        | 方位名词 | s        | 处所名词   | t        | 时间名词 |
| nr       | 人名     | ns       | 地名     | nt       | 机构团体名 | nw       | 作品名   |
| nz       | 其他专名 | v        | 普通动词 | vd       | 动副词     | vn       | 名动词   |
| a        | 形容词   | ad       | 副形词   | an       | 名形词     | d        | 副词     |
| m        | 数量词   | q        | 量词     | r        | 代词       | p        | 介词     |
| c        | 连词     | u        | 助词     | xc       | 其他虚词   | w        | 标点符号 |

**专名识别缩略词含义**

| **缩略词** | **含义** | **缩略词** | **含义** | **缩略词** | **含义** | **缩略词** | **含义** |
| :--------- | :------- | :--------- | :------- | :--------- | :------- | :--------- | :------- |
| PER        | 人名     | LOC        | 地名     | ORG        | 机构名   | TIME       | 时间     |

# 依存句法分析接口

## 接口描述

依存句法分析接口可自动分析文本中的依存句法结构信息，利用句子中词与词之间的依存关系来表示词语的句法结构信息（如“主谓”、“动宾”、“定中”等结构关系），并用树状结构来表示整句的结构（如“主谓宾”、“定状补”等）。

## 请求说明

**请求示例一**

- HTTP方法: `POST`
- 请求URL: `https://aip.baidubce.com/rpc/2.0/nlp/v1/depparser`
- URL参数：

| 参数         | 值                                                           |
| :----------- | :----------------------------------------------------------- |
| access_token | 通过API Key和Secret Key获取的access_token,参考“[Access Token获取](http://ai.baidu.com/docs#/Auth)” |

- Header如下：

| 参数         | 值               |
| :----------- | :--------------- |
| Content-Type | application/json |

- body请求示例:

```
{
	"text": "今天天气怎么样",
	"mode": 1
}
```

**请求参数**

| **参数名称** | **类型** | **是否必须** | **描述**                                                     |
| :----------- | :------- | :----------- | :----------------------------------------------------------- |
| text         | string   | 是           | 待分析文本（目前仅支持GBK编码），长度不超过256字节           |
| mode         | int      | 否           | 模型选择。默认值为0，可选值mode=0（对应web模型）；mode=1（对应query模型） |

**关于模型选择**

依存句法分析接口，可由用户自主选择合适的模型：

***Query模型***：该模型的训练数据来源于用户在百度的日常搜索数据，适用于处理信息需求类的搜索或口语query。

例如：

"手机缝隙灰尘怎么清除"

"百度云登陆首页"

"给我订一张明天上海到北京的飞机票"

***Web模型***：该模型的训练数据来源于全网网页数据，适用于处理网页文本等书面表达句子。

例如：

"后台任务定义为某过程在用户当时未登录机器期间运行"

"一般而言,股份的表现形式可以是股票、股权份额等等”

"有两条途径可以让本土的商业智慧在西方发扬光大”

## 返回说明

**返回参数**

| 参数名称 | 类型   | 详细说明                                         |
| :------- | :----- | :----------------------------------------------- |
| log_id   | uint64 | 随机数，本次请求的唯一标识码                     |
| id       | int    | 词的ID                                           |
| word     | string | 词                                               |
| postag   | string | 词性，请参照下方**词性（postag)取值范围**        |
| head     | int    | 词的父节点ID                                     |
| deprel   | string | 词与父节点的依存关系，请参照下方**依存关系标识** |

**返回示例**

```
{
    "log_id": 12345,
    "text":"今天天气怎么样",
    "items":[
        {
            "id":"1", //id
            "word":"今天", //word
            "postag":"t", //POS tag
            "head":"2", //id of current word's parent
            "deprel":"ATT"  //depend relations between current word and parent
        },
        {
            "id":"2",
            "word":"天气",
            "postag":"n",
            "head":"3",
            "deprel":"SBV",
        },
        {
            "id":"3",
            "word":"怎么样",
            "postag":"r",
            "head":"0",
            "deprel":"HED",
        }  
    ]
}
```

**词性取值范围**

| **词性** | **含义** | **词性** | **含义** | **词性** | **含义** | **词性** | **含义** |
| :------- | :------- | :------- | :------- | :------- | :------- | :------- | :------- |
| Ag       | 形语素   | g        | 语素     | ns       | 地名     | u        | 助词     |
| a        | 形容词   | h        | 前接成分 | nt       | 机构团体 | vg       | 动语素   |
| ad       | 副形词   | i        | 成语     | nz       | 其他专名 | v        | 动词     |
| an       | 名形词   | j        | 简称略语 | o        | 拟声词   | vd       | 副动词   |
| b        | 区别词   | k        | 后接成分 | p        | 介词     | vn       | 名动词   |
| c        | 连词     | l        | 习用语   | q        | 量词     | w        | 标点符号 |
| dg       | 副语素   | m        | 数词     | r        | 代词     | x        | 非语素字 |
| d        | 副词     | Ng       | 名语素   | s        | 处所词   | y        | 语气词   |
| e        | 叹词     | n        | 名词     | tg       | 时语素   | z        | 状态词   |
| f        | 方位词   | nr       | 人名     | t        | 时间词   | un       | 未知词   |

**依存关系标识**

句法依存关系接口可以解析出的依存关系标识如下：

**1.定中关系ATT**

定中关系就是定语和中心词之间的关系，定语对中心词起修饰或限制作用。

如：工人/n师傅/n（工人/n ← 师傅/n）。

**2. 数量关系QUN（quantity）**

数量关系是指量词或名词同前面的数词之间的关系，该关系中，数词作修饰成分，依存于量词或名词。

如：三/m天/q（三/m ← 天/q）。

**3.并列关系COO（coordinate）**

并列关系是指两个相同类型的词并列在一起。

如：奔腾/v咆哮/v的怒江激流（奔腾/v → 咆哮/v）。

**4.同位关系APP（appositive）**

同位语是指所指相同、句法功能也相同的两个并列的词或词组。

如：我们大家 （我们 → 大家）。

**5.附加关系ADJ（adjunct）**

附加关系是一些附属词语对名词等成分的一种补充说明，使意思更加完整，有时候去掉也不影响意思。

如：约/d 二十/m 多/m 米/q 远/a 处/n （二十/m → 多/m，米/q → 远/a）。

**6.动宾关系VOB（verb-object）**

对于动词和宾语之间的关系我们定义了两个层次，一是句子的谓语动词及其宾语之间的关系，我们定为OBJ，在下面的单句依存关系中说明；二是非谓语动词及其宾语的关系，即VOB。这两种关系在结构上没有区别，只是在语法功能上，OBJ中的两个词充当句子的谓语动词和宾语，VOB中的两个词构成动宾短语，作为句子的其他修饰成分。

如：历时/v 三/m 天/q 三/m夜/q（历时/v → 天/q）。

**7.介宾关系POB（preposition-object）**

介词和宾语之间的关系，介词的属性同动词相似。

如：距/p球门/n（距/p → 球门/n）。

**8.主谓关系SBV（subject-verb）**

主谓关系是指名词和动作之间的关系。

如：父亲/n 逝世/v １０/m 周年/q 之际/nd（父亲/n ← 逝世/v）。

**9.比拟关系SIM（similarity）**

比拟关系是汉语中用于表达比喻的一种修辞结构。

如：炮筒/n 似的/u 望远镜/n（炮筒/n ← 似的/u）。

**10.时间关系TMP（temporal）**

时间关系定义的是时间状语和其所修饰的中心动词之间的关系。

如：十点以前到公司（以前 ← 到）。

**11.处所关系LOC（locative）**

处所关系定义的是处所状语和其所修饰的中心动词之间的关系，如：在公园里玩耍（在 ← 玩耍）。

**12.“的”字结构DE**

“的”字结构是指结构助词“的”和其前面的修饰语以及后面的中心词之间的关系。

如：上海/ns 的/u 工人/n（上海/ns ← 的/u，的/u ← 工人/n）。

**13.“地”字结构DI**

“地”字结构在构成上同DE类似，只是在功能上不同，DI通常作状语修饰动词。

如： 方便/a 地/u 告诉/v 计算机/n（方便/a ← 地/u，地/u ← 告诉/v）。

**14.“得”字结构DEI**

助词“得”同其后的形容词或动词短语等构成“得”字结构，对前面的动词进行补充说明。

如：讲/v 得/u 很/d 对/a（讲/v → 得/u，得/u → 对/a）。

**15.“所”字结构SUO**

“所”字为一结构助词，后接一宾语悬空的动词做“的”字结构的修饰语，“的”字经常被省略，使结构更加简洁。

如：机电/b 产品/n 所/u 占/v 比重/n 稳步/d 上升/v（所/u ← 占/v）。

**16.“把”字结构BA**

把字句是主谓句的一种，句中谓语一般都是及物动词。

如：我们把豹子打死了（把/p → 豹子/n）。

**17.“被”字结构BEI**

被字句是被动句，是主语接受动作的句子。

如：豹子被我们打死了（豹子/n ← 被/p）。

**18.状中结构ADV（adverbial）**

状中结构是谓词性的中心词和其前面的修饰语之间的关系，中心词做谓语时，前面的修饰成分即为句子的状语，中心词多为动词、形容词，修饰语多为副词，介词短语等。

如：连夜/d 安排/v 就位/v（连夜/d ← 安排/v）。

**19.动补结构CMP（complement）**

补语用于对核心动词的补充说明。

如：做完了作业（做/v → 完）。

**20.兼语结构DBL（double）**

兼语句一般有两个动词，第二个动词是第一个动作所要表达的目的或产生的结果。

如：[7]曾经/d [8]使/v [9]多少/r [10]旅游/n [11]人/n [12]隔/v [13]岸/n [14]惊叹/v [15]！/wp（使 → 人/n ，/v使/v → 惊叹/v）。

**21.关联词CNJ（conjunction）**

关联词语是复句的有机部分。

如：只要他请客，我就来。（只要 ← 请 ，就 ← 来）。

**22.关联结构 CS(conjunctive structure)**

当句子中存在关联结构时，关联词所在的两个句子（或者两个部分）之间通过各部分的核心词发生依存关系CS。

如：只要他请客，我就来。（请 ← 来）。

**23.语态结构MT（mood-tense）**

汉语中，经常用一些助词表达句子的时态和语气，这些助词分语气助词，如：吧，啊，呢等；还有时态助词，如：着，了，过。

如： [12]答应/v [13]孩子/n [14]们/k [15]的/u [16]要求/n [17]吧/u [18]，/wp [19]他们/r [20]这/r [21]是/v [22]干/v [23]事业/n [24]啊/u [25]！/wp（[12]答应/v ← [17]吧/u，[21]是/v ← [24]啊/u）。

**24.连谓结构VV（verb-verb）**

连谓结构是同多项谓词性成分连用、这些成分间没有语音停顿、书面标点，也没有关联词语，没有分句间的逻辑关系，且共用一个主语。

如：美国总统来华访问。（来华/v → 访问/v）。

**25.核心HED（head）**

该核心是指整个句子的核心，一般是句子的核心词和虚拟词（<EOS>或ROOT）的依存关系。

如：这/r 就是/v恩施/ns最/d]便宜/a的/u出租车/n，/wp相当于/v北京/ns的/u “/wp 面的/n ”/wp 。/wp <EOS>/<EOS>（就是/v ← <EOS>/<EOS>）

**26.前置宾语FOB（fronting object）**

在汉语中，有时将句子的宾语前置，或移置句首，或移置主语和谓语之间，以起强调作用，我认识这个人 ← 这个人我认识。

如：他什么书都读（书/n ← 读/v）。

**27.双宾语DOB（double object）**

动词后出现两个宾语的句子叫双宾语句，分别是直接宾语和间接宾语。

如：我送她一束花。（送/v → 她/r，送/v → 花/n）。

**28.主题TOP（topic）**

在表达中，我们经常会先提出一个主题性的内容，然后对其进行阐述说明；而主题部分与后面的说明部分并没有直接的语法关系，主题部分依存于后面的核心成分，且依存关系为TOP。

如：西直门，怎么走？（西直门 ← 走）。

**29.独立结构IS（independent structure）**

独立成分在句子中不与其他成分产生结构关系，但意义上又是全句所必需的，具有相对独立性的一种成分。

如：事情明摆着，我们能不管吗？

**30.独立分句IC（independent clause）**

两个单句在结构上彼此独立，都有各自的主语和谓语。

如：我是中国人，我们爱自己的祖国。（是 → 爱）

**31.依存分句DC（dependent clause）**

两个单句在结构上不是各自独立的，后一个分句的主语在形式上被省略，但不是前一个分句的主语，而是存在于前一个分句的其他成分中，如宾语、主题等成分。规定后一个分句的核心词依存于前一个分句的核心词。该关系同连谓结构的区别是两个谓词是否为同一主语，如为同一主语，则为VV，否则为DC。

如：大家/r叫/v 它/r “/wp 麻木/a 车/n ”/wp ，/wp 听/v起来/v 怪怪的/a 。/wp（叫/v → 听/v）。

**32.叠词关系VNV （verb-no-verb or verb-one-verb)**

如果叠词被分开了，如“是 不 是”、“看一看”，那么这几个词先合并在一起，然后预存到其他词上，叠词的内部关系定义为：(是1→不；不→是2） 。

**33.一个词YGC**

当专名或者联绵词等切散后，他们之间本身没有语法关系，应该合起来才是一个词。如：百 度。

**34.标点 WP**

大部分标点依存于其前面句子的核心词上，依存关系WP。

# 词向量表示接口

## 接口描述

> 本接口已于2017年5月25日升级，仅支持词向量查询。如果希望查询两个词的相似度，可使用**词义相似度**。

> 如果您需要查阅旧版接口文档，请查看中文词向量表示接口（旧版），但建议您尽快升级到新版接口。

词向量表示接口提供中文词向量的查询功能。

## 请求说明

**请求示例**

HTTP方法: `POST`

请求URL: `https://aip.baidubce.com/rpc/2.0/nlp/v2/word_emb_vec`

URL参数：

| 参数         | 值                                                           |
| :----------- | :----------------------------------------------------------- |
| access_token | 通过API Key和Secret Key获取的access_token,参考“[Access Token获取](http://ai.baidu.com/docs#/Auth)” |

Header如下：

| 参数         | 值               |
| :----------- | :--------------- |
| Content-Type | application/json |

Body请求示例:

```
{
    "word":"张飞"
}
```

**请求参数**

| 参数 | 是否必选 | 类型   | 描述                                               |
| :--- | :------- | :----- | :------------------------------------------------- |
| word | 是       | string | 文本内容（GBK编码），最大64字节                    |
| dem  | 否       | int    | 词向量维度。默认值为0(对应1024维)，目前仅支持dem=0 |

## 返回说明

**返回参数**

| 参数   | 类型   | 描述           |
| :----- | :----- | :------------- |
| log_id | uint64 | 请求唯一标识码 |
| word   | string | 查询词         |
| vec    | float  | 词向量结果表示 |

**返回示例**

```
{
  "word": "张飞",
  "vec": [
    0.233962,
    0.336867,
    0.187044,
    0.565261,
    0.191568,
    0.450725,
    ...
    0.43869,
    -0.448038,
    0.283711,
    -0.233656,
    0.555556
  ]
}
```

# DNN语言模型接口

## 接口描述

> 本接口已于2017年5月25日升级，如果您需要查阅旧版接口文档，请查看中文DNN语言模型（旧版），但建议您尽快升级到新版接口。

中文DNN语言模型接口用于输出切词结果并给出每个词在句子中的概率值,判断一句话是否符合语言表达习惯。

## 请求说明

**请求示例**

HTTP方法：`POST`

请求URL： `https://aip.baidubce.com/rpc/2.0/nlp/v2/dnnlm_cn`

URL参数：

| 参数         | 值                                                           |
| :----------- | :----------------------------------------------------------- |
| access_token | 通过API Key和Secret Key获取的access_token,参考“[Access Token获取](http://ai.baidu.com/docs#/Auth)” |

Header如下：

| 参数         | 值               |
| :----------- | :--------------- |
| Content-Type | application/json |

Body请求示例:

```
{
    "text":"床前明月光"
}
```

**请求参数**

| 参数 | 类型   | 描述                                         |
| :--- | :----- | :------------------------------------------- |
| text | string | 文本内容（GBK编码），最大256字节，不需要切词 |

## 返回说明

**返回参数**

| 参数   | 类型   | 说明                                   |
| :----- | :----- | :------------------------------------- |
| log_id | uint64 | 请求唯一标识码                         |
| word   | string | 句子的切词结果                         |
| prob   | float  | 该词在句子中的概率值,取值范围[0,1]     |
| ppl    | float  | 描述句子通顺的值：数值越低，句子越通顺 |

**返回示例**

```
{
  "text": "床前明月光",
  "items": [
    {
      "word": "床",
      "prob": 0.0000385273
    },
    {
      "word": "前",
      "prob": 0.0289018
    },
    {
      "word": "明月",
      "prob": 0.0284406
    },
    {
      "word": "光",
      "prob": 0.808029
    }
  ],
  "ppl": 79.0651
}
```

# 词义相似度接口

## 接口描述

输入两个词，得到两个词的相似度结果。

## 请求说明

**请求示例**

HTTP方法: `POST`

请求URL: `https://aip.baidubce.com/rpc/2.0/nlp/v2/word_emb_sim`

URL参数：

| 参数         | 值                                                           |
| :----------- | :----------------------------------------------------------- |
| access_token | 通过API Key和Secret Key获取的access_token,参考“[Access Token获取](http://ai.baidu.com/docs#/Auth)” |

Header如下：

| 参数         | 值               |
| :----------- | :--------------- |
| Content-Type | application/json |

Body请求示例:

```
{
    "word_1":"北京",
    "word_2":"上海"
}
```

**请求参数**

| 参数   | 是否必选 | 类型   | 描述                       |
| :----- | :------- | :----- | :------------------------- |
| word_1 | 是       | string | 词1（GBK编码），最大64字节 |
| word_2 | 是       | string | 词2（GBK编码），最大64字节 |

## 返回说明

**返回参数**

| 参数   | 类型   | 描述                                      |
| :----- | :----- | :---------------------------------------- |
| log_id | uint64 | 请求唯一标识码,随机数                     |
| score  | float  | 相似度结果，(0,1]，分数越高说明相似度越高 |

**返回示例**

```
{
    "score": 0.456862,
    "words": {
      "word_1": "北京",
      "word_2": "上海"
    }
}
```

# 短文本相似度接口

## 接口描述

> 本接口已于2017年6月15日升级，如果您需要查阅旧版接口文档，请查看短文本相似度接口（旧版），但建议您尽快升级到新版接口。

短文本相似度接口用来判断两个文本的相似度得分。

## 请求说明

**请求示例**

HTTP方法：`POST`

请求URL：`https://aip.baidubce.com/rpc/2.0/nlp/v2/simnet`

URL参数：

| 参数         | 值                                                           |
| :----------- | :----------------------------------------------------------- |
| access_token | 通过API Key和Secret Key获取的access_token,参考“[Access Token获取](http://ai.baidu.com/docs#/Auth)” |

Header如下：

| 参数         | 值               |
| :----------- | :--------------- |
| Content-Type | application/json |

Body请求示例:

```
{
	"text_1": "浙富股份", // 待比较文本1
	"text_2": "万事通自考网" // 待比较文本2
}
```

**请求参数**

| 参数   | 类型   | 是否必须 | 描述                                  |
| :----- | :----- | :------- | :------------------------------------ |
| text_1 | string | 是       | 待比较文本1（GBK编码），最大512字节   |
| text_2 | string | 是       | 待比较文本2（GBK编码），最大512字节   |
| model  | string | 否       | 默认为"BOW"，可选"BOW"、"CNN"与"GRNN" |

**关于模型选择**

短文本相似度接口，可由用户自主选择合适的模型：

BOW（词包）模型

基于bag of words的BOW模型，特点是泛化性强，效率高，比较轻量级，适合任务：输入序列的 term “确切匹配”、不关心序列的词序关系，对计算效率有很高要求；

GRNN（循环神经网络）模型

基于recurrent，擅长捕捉短文本“跨片段”的序列片段关系，适合任务：对语义泛化要求很高，对输入语序比较敏感的任务；

CNN（卷积神经网络）模型

模型语义泛化能力介于 BOW/RNN 之间，对序列输入敏感，相较于 GRNN 模型的一个显著优点是计算效率会更高些。

## 返回说明

**返回参数**

| 参数   | 描述   | 取值                                        |
| :----- | :----- | :------------------------------------------ |
| log_id | uint64 | 随机数，请求唯一标识码                      |
| score  | float  | 相似度结果取值(0,1]，分数越高说明相似度越高 |

**返回示例**

```
{
	"log_id": 12345,
    "texts":{
        "text_1":"浙富股份",
        "text_2":"万事通自考网"
    },
    "score":0.3300237655639648 //相似度结果
},
```

# 评论观点抽取接口

## 接口描述

> 本接口已于2017年5月25日升级，如果您需要查阅旧版接口文档，请查看评论观点抽取接口（旧版），但建议您尽快升级到新版接口。

评论观点抽取接口（通用版）：提取评论句子的关注点和评论观点，并输出评论观点标签及评论观点极性。 评论观点抽取接口（定制版）：提取评论句子的关注点和评论观点，并输出评论观点标签及评论观点极性；用户可以在控制台中的【个性化定制】中选择【评论观点抽取定制】，通过定制版用户可以上传13个行业垂类的自定义评论词表，可有效提高通用行业评论抽取的精度，同时支持用户自定义评论的“归一化标签”。定制版接口的详细使用教程您可以查看链接：http://ai.baidu.com/forum/topic/show/869264

## 请求说明

**请求示例**

HTTP方法: `POST`

- （通用版）请求URL: `https://aip.baidubce.com/rpc/2.0/nlp/v2/comment_tag`
- （定制版）请求URL: `https://aip.baidubce.com/rpc/2.0/nlp/v2/comment_tag_custom`
- URL参数：

| 参数         | 值                                                           |
| :----------- | :----------------------------------------------------------- |
| access_token | 通过API Key和Secret Key获取的access_token,参考“[Access Token获取](http://ai.baidu.com/docs#/Auth)” |

Header如下：

| 参数         | 值               |
| :----------- | :--------------- |
| Content-Type | application/json |

Body请求示例:

```
{
    "text":"三星电脑电池不给力",
    "type":13
}
```

**请求参数**

| 参数 | 是否必选 | 类型   | 描述                               |
| :--- | :------- | :----- | :--------------------------------- |
| text | 必选     | string | 评论内容（GBK编码），最大10240字节 |
| type | 可选     | int    | 评论行业类型，默认为4（餐饮美食）  |

其中type包含13个类别，具体取值说明如下：

| type参数 | 说明     | 实例                                                         |
| :------- | :------- | :----------------------------------------------------------- |
| 1        | 酒店     | 『酒店设备齐全、干净卫生』->『酒店设备齐全』、『干净卫生』   |
| 2        | KTV      | 『环境一般般把，音响设备也一般，隔音太差』->『环境一般』、『音响设备一般』、『隔音差』 |
| 3        | 丽人     | 『手法专业，重要的是效果很棒』->『手法专业』、『效果不错』   |
| 4        | 美食餐饮 | 『但是味道太好啦，舍不得剩下』->『味道不错』                 |
| 5        | 旅游     | 『景区交通方便，是不错的旅游景点』->『交通方便』、『旅游景点不错』 |
| 6        | 健康     | 『环境很棒，技师服务热情』->『环境不错』、『服务热情』       |
| 7        | 教育     | 『教学质量不错，老师很有经验』->『教学质量不错』、『老师有经验』 |
| 8        | 商业     | 『该公司服务好，收费低，效率高』->『服务好』、『收费低』、『效率高』 |
| 9        | 房产     | 『该房周围设施齐全、出行十分方便』->『设施齐全』、『出行方便』 |
| 10       | 汽车     | 『路宝的优点就是安全性能高、空间大』->『安全性能高』、『空间大』 |
| 11       | 生活     | 『速度挺快、服务态度也不错』->『速度快』、『服务好』         |
| 12       | 购物     | 『他家的东西还是挺贵的』->『消费贵』                         |
| 13       | 3C       | 『手机待机时间长』->『待机时间长』                           |

## 返回说明

**返回参数**

| 参数      | 类型   | 描述                                                |
| :-------- | :----- | :-------------------------------------------------- |
| log_id    | uint64 | 请求唯一标识码                                      |
| prop      | string | 匹配上的属性词                                      |
| adj       | string | 匹配上的描述词                                      |
| sentiment | int    | 该情感搭配的极性（0表示消极，1表示中性，2表示积极） |
| begin_pos | int    | 该情感搭配在句子中的开始位置                        |
| end_pos   | int    | 该情感搭配在句子中的结束位置                        |
| abstract  | string | 对应于该情感搭配的短句摘要                          |

**返回示例**

```
{
	"items": [
		{
	    "prop":"电池",  
        "adj": "不给力", 
        "sentiment": 0, 
        "begin_pos": 8, 
        "end_pos": 18,
		"abstract":"三星电脑<span>电池不给力</span>"
	    }
    ]
}
```

# 情感倾向分析接口

## 接口描述

对包含主观观点信息的文本进行情感极性类别（积极、消极、中性）的判断，并给出相应的置信度。

## 请求说明

**请求示例**

HTTP方法: `POST`

请求URL: `https://aip.baidubce.com/rpc/2.0/nlp/v1/sentiment_classify`

URL参数：

| 参数         | 值                                                           |
| :----------- | :----------------------------------------------------------- |
| access_token | 通过API Key和Secret Key获取的access_token,参考“[Access Token获取](http://ai.baidu.com/docs#/Auth)” |

Header如下：

| 参数         | 值               |
| :----------- | :--------------- |
| Content-Type | application/json |

Body请求示例:

```
{
    "text": "苹果是一家伟大的公司" 
}
```

**请求参数**

| 参数 | 类型   | 描述                              |
| :--- | :----- | :-------------------------------- |
| text | string | 文本内容（GBK编码），最大2048字节 |

## 返回说明

**返回参数**

| 参数          | 说明   | 描述                                         |
| :------------ | :----- | :------------------------------------------- |
| log_id        | uint64 | 请求唯一标识码                               |
| sentiment     | int    | 表示情感极性分类结果，0:负向，1:中性，2:正向 |
| confidence    | float  | 表示分类的置信度，取值范围[0,1]              |
| positive_prob | float  | 表示属于积极类别的概率 ，取值范围[0,1]       |
| negative_prob | float  | 表示属于消极类别的概率，取值范围[0,1]        |

**返回示例**

```
{
    "text":"苹果是一家伟大的公司",
    "items":[
        {
            "sentiment":2,    //表示情感极性分类结果
            "confidence":0.40, //表示分类的置信度
            "positive_prob":0.73, //表示属于积极类别的概率
            "negative_prob":0.27  //表示属于消极类别的概率
        }
    ]
}
```

# 文章标签接口

## 接口描述

文本标签服务对文章的标题和内容进行深度分析，输出能够反映文章关键信息的主题、话题、实体等多维度标签以及对应的置信度，该技术在个性化推荐、文章聚合、内容检索等场景具有广泛的应用价值。

## 请求说明

**请求示例**

HTTP方法: `POST`

请求URL: `https://aip.baidubce.com/rpc/2.0/nlp/v1/keyword`

URL参数：

| 参数         | 值                                                           |
| :----------- | :----------------------------------------------------------- |
| access_token | 通过API Key和Secret Key获取的access_token,参考“[Access Token获取](http://ai.baidu.com/docs#/Auth)” |

Header如下：

| 参数         | 值               |
| :----------- | :--------------- |
| Content-Type | application/json |

Body请求示例:

```
{
	"title":"iphone手机出现“白苹果”原因及解决办法，用苹果手机的可以看下",
	"content": "如果下面的方法还是没有解决你的问题建议来我们门店看下成都市锦江区红星路三段99号银石广场24层01室。在通电的情况下掉进清水，这种情况一不需要拆机处理。尽快断电。用力甩干，但别把机器甩掉，主意要把屏幕内的水甩出来。如果屏幕残留有水滴，干后会有痕迹。^H3 放在台灯，射灯等轻微热源下让水分慢慢散去。"
}
```

**请求参数**

| 参数    | 类型   | 描述                               | 是否必填 |
| :------ | :----- | :--------------------------------- | :------- |
| title   | string | 文章标题（GBK编码），最大80字节    | 必填     |
| content | string | 文章内容（GBK编码），最大65535字节 | 必填     |

## 返回说明

**返回参数**

| 参数   | 说明             | 描述                  |
| :----- | :--------------- | :-------------------- |
| items  | array of objects | 分析结果数组          |
| +tag   | string           | 内容标签              |
| +score | float            | 权重值，取值范围[0,1] |

**返回示例**

```
{
    "log_id": 4457308639853058292,
    "items": [
        {
            "score": 0.997762,
            "tag": "iphone"
        },
        {
            "score": 0.861775,
            "tag": "手机"
        },
        {
            "score": 0.845657,
            "tag": "苹果"
        },
        {
            "score": 0.83649,
            "tag": "苹果公司"
        },
        {
            "score": 0.797243,
            "tag": "数码"
        }
    ]
}
```

# 文章分类接口

## 接口描述

对文章按照内容类型进行自动分类，首批支持娱乐、体育、科技等26个主流内容类型，为文章聚类、文本内容分析等应用提供基础技术支持。 目前支持的一级粗粒度分类类目如下：1、国际 2、体育 3、娱乐 4、社会 5、财经 6、时事 7、科技 8、情感 9、汽车 10、教育 11、时尚 12、游戏 13、军事 14、旅游 15、美食 16、文化 17、健康养生 18、搞笑 19、家居 20、动漫 21、宠物 22、母婴育儿 23、星座运势 24、历史 25、音乐 26、综合

## 请求说明

**请求示例**

HTTP方法: `POST`

请求URL: `https://aip.baidubce.com/rpc/2.0/nlp/v1/topic`

URL参数：

| 参数         | 值                                                           |
| :----------- | :----------------------------------------------------------- |
| access_token | 通过API Key和Secret Key获取的access_token,参考“[Access Token获取](http://ai.baidu.com/docs#/Auth)” |

Header如下：

| 参数         | 值               |
| :----------- | :--------------- |
| Content-Type | application/json |

Body请求示例:

```
{
	"title":"欧洲冠军联赛",
	"content": "欧洲冠军联赛是欧洲足球协会联盟主办的年度足球比赛，代表欧洲俱乐部足球最高荣誉和水平，被认为是全世界最高素质、最具影响力以及最高水平的俱乐部赛事，亦是世界上奖金最高的足球赛事和体育赛事之一。"
}
```

**请求参数**

| 参数    | 类型   | 描述                               | 是否必填 |
| :------ | :----- | :--------------------------------- | :------- |
| title   | string | 文章标题（GBK编码），最大80字节    | 必填     |
| content | string | 文章内容（GBK编码），最大65535字节 | 必填     |

## 返回说明

**返回参数**

| 参数          | 说明             | 描述                      |
| :------------ | :--------------- | :------------------------ |
| item          | object           | 分析结果数组              |
| +lv1_tag_list | array of objects | 一级分类结果（唯一）      |
| +lv2_tag_list | array of objects | 二级分类结果              |
| ++score       | float            | 类别标签对应得分，范围0-1 |
| ++tag         | string           | 类别标签                  |

**返回示例**

```
{
    "log_id": 3591049593939822907,
    "item": {
        "lv2_tag_list": [
            {
                "score": 0.877436,
                "tag": "足球"
            },
            {
                "score": 0.793682,
                "tag": "国际足球"
            },
            {
                "score": 0.775911,
                "tag": "英超"
            }
        ],
        "lv1_tag_list": [
            {
                "score": 0.824329,
                "tag": "体育"
            }
        ]
    }
}
```

# 文本纠错接口

## 接口描述

识别输入文本中有错误的片段，提示错误并给出正确的文本结果。支持短文本、长文本、语音等内容的错误识别，纠错是搜索引擎、语音识别、内容审查等功能更好运行的基础模块之一。

## 请求说明

**请求示例**

HTTP方法: `POST`

请求URL: `https://aip.baidubce.com/rpc/2.0/nlp/v1/ecnet`

URL参数：

| 参数         | 值                                                           |
| :----------- | :----------------------------------------------------------- |
| access_token | 通过API Key和Secret Key获取的access_token,参考“[Access Token获取](http://ai.baidu.com/docs#/Auth)” |

Header如下：

| 参数         | 值               |
| :----------- | :--------------- |
| Content-Type | application/json |

Body请求示例:

```
{
    "text": "百度是一家人工只能公司"
}
```

**请求参数**

| 参数 | 类型   | 描述                        | 是否必填 |
| :--- | :----- | :-------------------------- | :------- |
| text | string | 待纠错文本，输入限制511字节 | 必填     |

## 返回说明

**返回参数**

| 参数           | 说明   | 描述             |
| :------------- | :----- | :--------------- |
| log_id         | uint64 | 请求唯一标识码   |
| correct_query  | string | 纠错后的文本     |
| score          | double | 模型置信度打分   |
| item           | object | 分析结果         |
| +vec_fragment  | list   | 替换候选片段信息 |
| ++ori_frag     | string | 原片段           |
| ++correct_frag | double | 替换片段         |
| ++begin_pos    | int    | 起始(长度单位)   |
| ++end_pos      | list   | 结尾(长度单位)   |

**返回示例**

```
{
    "log_id": 6770395607901559829,
    "item": {
        "vec_fragment": [
            {
                "ori_frag": "只能",
                "begin_pos": 21,
                "correct_frag": "智能",
                "end_pos": 27
            }
        ],
        "score": 0.875169,
        "correct_query": "百度是一家人工智能公司"
    },
    "text": "百度是一家人工只能公司"
}
```

# 新闻摘要接口【邀测期，权限需工单申请】

## 接口描述

自动抽取新闻文本中的关键信息，进而生成指定长度的新闻摘要

## 请求说明

**请求示例**

HTTP方法: `POST`

请求URL: `https://aip.baidubce.com/rpc/2.0/nlp/v1/news_summary`

URL参数：

| 参数         | 值                                                           |
| :----------- | :----------------------------------------------------------- |
| access_token | 通过API Key和Secret Key获取的access_token,参考“[Access Token获取](http://ai.baidu.com/docs#/Auth)” |

Header如下：

| 参数         | 值               |
| :----------- | :--------------- |
| Content-Type | application/json |

Body请求示例:

```
{
    "title": "麻省理工学院为无人机配备RFID技术，进行仓库货物管理",
	"content": "麻省理工学院的研究团队为无人机在仓库中使用RFID技术进行库存查找等工作，创造了一种聪明的新方式。它允许公司使用更小，更安全的无人机在巨型建筑物中找到之前无法找到的东西。使用RFID标签更换仓库中的条形码，将帮助提升自动化并提高库存管理的准确性。与条形码不同，RFID标签不需要对准扫描，标签上包含的信息可以更广泛和更容易地更改。它们也可以很便宜，尽管有优点，但是它具有局限性，对于跟踪商品没有设定RFID标准，“标签冲突”可能会阻止读卡器同时从多个标签上拾取信号。扫描RFID标签的方式也会在大型仓库内引起尴尬的问题。固定的RFID阅读器和阅读器天线只能扫描通过设定阈值的标签，手持式读取器需要人员出去手动扫描物品。几家公司已经解决了无人机读取RFID的技术问题。配有RFID读卡器的无人机可以代替库存盘点的人物，并以更少的麻烦更快地完成工作。一个人需要梯子或电梯进入的高箱，可以通过无人机很容易地达到，无人机可以被编程为独立地导航空间，并且他们比执行大规模的重复任务的准确性和效率要比人类更好。目前市场上的RFID无人机需要庞大的读卡器才能连接到无人机的本身。这意味着它们必须足够大，以支持附加硬件的尺寸和重量，使其存在坠机风险。麻省理工学院的新解决方案，名为Rfly，允许无人机阅读RFID标签，而不用捆绑巨型读卡器。相反，无人机配备了一个微小的继电器，它像Wi-Fi中继器一样。无人机接收从远程RFID读取器发送的信号，然后转发它读取附近的标签。由于继电器很小，这意味着可以使用更小巧的无人机，可以使用塑料零件，可以适应较窄的空间，不会造成人身伤害的危险。麻省理工学院的Rfly系统本质上是对现有技术的一个聪明的补充，它不仅消除了额外的RFID读取器，而且由于它是一个更轻的解决方案，允许小型无人机与大型无人机做同样的工作。研究团队正在马萨诸塞州的零售商测试该系统。",
    "max_summary_len":200
}
```

**请求参数**

| 参数            | 类型   | 是否必填 | 描述                                                         |
| :-------------- | :----- | :------- | :----------------------------------------------------------- |
| title           | string | 否       | 字符串（限200字符数） 字符串仅支持GBK编码，长度需小于200字符数（即400字节），请输入前确认字符数没有超限，若字符数超长会返回错误。标题在算法中具有重要的作用，若文章确无标题，不必输入此参数 |
| content         | string | 必填     | 字符串（限3000字符数以内） 字符串仅支持GBK编码，长度需小于3000字符数（即6000字节），请输入前确认字符数没有超限，若字符数超长会返回错误。正文中如果包含段落信息，请使用"\n"分隔，段落信息算法中有重要的作用，请尽量保留 |
| max_summary_len | number | 必填     | 此数值将作为摘要结果的最大长度。例如：原文长度1000字，本参数设置为150，则摘要结果的最大长度是150字；推荐最优区间：200-500字 |

## 返回说明

**返回参数**

| 参数    | 说明   | 描述           |
| :------ | :----- | :------------- |
| log_id  | uint64 | 请求唯一标识码 |
| summary | string | 摘要结果       |

**返回示例**

```
{
    "log_id": 7310552510652020090,
    "summary": "麻省理工学院的研究团队为无人机在仓库中使用RFID技术进行库存查找等工作，创造了一种聪明的新方式。使用RFID标签更换仓库中的条形码，将帮助提升自动化并提高库存管理的准确性。几家公司已经解决了无人机读取RFID的技术问题。麻省理工学院的新解决方案，名为Rfly，允许无人机阅读RFID标签，而不用捆绑巨型读卡器。无人机接收从远程RFID读取器发送的信号，然后转发它读取附近的标签。"
}
```

# 对话情绪识别接口

## 接口描述

针对用户日常沟通文本背后所蕴含情绪的一种直观检测，可自动识别出当前会话者所表现出的一级和二级细分情绪类别及其置信度，针对正面和负面的情绪，还可给出参考回复话术。帮助企业更全面地把握产品服务质量、监控客户服务质量。在自动监控中如果发现有负面情绪出现，可以及时介入人工处理，帮助在有限的人工客服条件下，降低客户流失。

## 请求说明

**请求示例**

HTTP方法: `POST`

请求URL: `https://aip.baidubce.com/rpc/2.0/nlp/v1/emotion`

URL参数：

| 参数         | 值                                                           |
| :----------- | :----------------------------------------------------------- |
| access_token | 通过API Key和Secret Key获取的access_token,参考“[Access Token获取](http://ai.baidu.com/docs#/Auth)” |

Header如下：

| 参数         | 值               |
| :----------- | :--------------- |
| Content-Type | application/json |

Body请求示例:

```
{
    "scene":"talk",
    "text": "本来今天高高兴兴"
}
```

**请求参数**

| 参数  | 类型   | 是否必选 | 描述                                                         |
| :---- | :----- | :------- | :----------------------------------------------------------- |
| text  | string | 是       | 待识别情感文本，输入限制512字节                              |
| scene | string | 否       | default（默认项-不区分场景），talk（闲聊对话-如度秘聊天等），task（任务型对话-如导航对话等），customer_service（客服对话-如电信/银行客服等） |

## 返回说明

**返回参数**

| 参数       | 说明            | 描述                                                         |
| :--------- | :-------------- | :----------------------------------------------------------- |
| log_id     | uint64          | 请求唯一标识码                                               |
| text       | string          | 输入的对话文本内容                                           |
| items      | list            | 分析结果数组                                                 |
| ++label    | string          | 情绪一级分类标签；pessimistic（负向情绪）、neutral（中性情绪）、optimistic（正向情绪） |
| ++prob     | double          | 情绪一级分类标签对应的概率                                   |
| ++subitems | double          | 二级分析结果数组                                             |
| +++label   | string          | 情绪二级分类标签；客服模型正向（thankful感谢、happy愉快）、客服模型负向（complaining抱怨、angry愤怒）；闲聊模型正向（like喜爱、happy愉快）、闲聊模型负向（angry愤怒、disgusting厌恶、fearful恐惧、sad悲伤） |
| +++prob    | double          | 情绪二级分类标签对应的概率                                   |
| +++replies | array of string | 参考回复话术，中性情绪下该项为空                             |

**返回示例**

```
{
    "log_id": 4258005459150262970,
    "text":"你真棒",
    "items":[
        {
            "prob":0.97848,
            "label":"optimistic",
            "subitems":[
                {
                    "prob":0.656986,
                    "label":"like"
					"replies":[
                    "谢谢，我很开心"
                    ]
                }
			]
        },
    ]
}
```

# 分词接口（旧版）

## 接口描述

> 本接口已合并到词法分析接口，即将逐步下线，建议直接使用**词法分析接口**。

分词接口提供基本词和混排两种粒度的分词结果，基本词粒度较小，适用于搜索引擎等需要更多召回的任务，而混排粒度倾向于保留更多的短语。

## 请求说明

**请求示例**

HTTP方法: `POST`

请求URL: `https://aip.baidubce.com/rpc/2.0/nlp/v1/wordseg`

URL参数：

| 参数         | 值                                                           |
| :----------- | :----------------------------------------------------------- |
| access_token | 通过API Key和Secret Key获取的access_token,参考“[Access Token获取](http://ai.baidu.com/docs#/Auth)” |

Header如下：

| 参数         | 值               |
| :----------- | :--------------- |
| Content-Type | application/json |

Body请求示例:

```
{
  "query":"百度是一家高科技公司",
  "lang_id":1
}
```

**请求参数**

| 参数名称 | 类型   | 是否必选 | 详细说明                                                     |
| :------- | :----- | :------- | :----------------------------------------------------------- |
| query    | String | 是       | 待分词的文本（GBK编码的URL编码形式）                         |
| lang_id  | Int    | 否       | 默认为1，输入字符串的语言对应的id，简体中文设置为1（目前不支持其他语言） |

**请求示例代码**

**提示一**：使用示例代码前，请记得替换其中的示例Token、图片地址或Base64信息。

**提示二**：部分语言依赖的类或库，请在代码注释中查看下载地址。

bash

PHP

Java

Python

C++

C#

```
分词接口
curl -i -k 'https://aip.baidubce.com/rpc/2.0/nlp/v1/wordseg?access_token=24.bb41cb1bd46dd44b9c801b10ce010240.2592000.1492322377.282335-9252280' --data '{"query":"百度是一家高科技公司","lang_id":1}' -H 'Content-Type:application/json; charset=UTF-8'
```

## 返回说明

**返回参数**

| 参数名称       | 类型   | 详细说明                                                     |
| :------------- | :----- | :----------------------------------------------------------- |
| wordsepbuf     | String | 基本词粒度结果，以\t分割                                     |
| wsbtermcount   | int    | 基本词粒度输出的词个数                                       |
| wsbtermoffsets | List   | 该参数为列表，元素个数为切分出来的词个数，每个元素值表示对应的基本词在被切分文本的起始位置（字节偏移） |
| wsbtermpos     | List   | 参数值为列表，元素值为对应切分出来的基本词在 wordsepbuf的字节偏移以及长度，整数的低24bit为偏移，高8bit为长度 |
| wpcompbuf      | String | 混排粒度结果，以\t分割                                       |
| wpbtermcount   | Int    | 混排粒度输出的词个数                                         |
| wpbtermoffsets | List   | 该参数为列表，元素个数为切分出来的词个数，每个元素值表示对应的词是从第几个基本词开始的（基本词偏移） |
| wpbtermpos     | List   | 参数值为列表，元素值为对应切分出来的词在 wpcompbuf的字节偏移以及长度，整数的低24bit为偏移，高8bit为长度 |
| subphrbuf      | String | 所有识别出来的短语，以\t分割                                 |
| spbtermcount   | Int    | 识别出来的短语个数                                           |
| spbtermoffsets | List   | 该参数为列表，元素个数为识别出来的短语个数，每个元素值表示对应短语是从第几个基本词开始的（基本词偏移） |
| spbtermpos     | List   | 参数值为列表，元素值为对应切分出来的短语在 subphrbuf的字节偏移以及长度，整数的低24bit为偏移，高8bit为长度 |

**返回示例**

```
{
    "scw_out": {
        "phrase_merged": 0,
        "pdisambword": {
            "newwordbuf": "",
            "newwordb_curpos": 0,
            "newwordbmaxcount": 0,
            "newwordbsize": 0,
            "newwordbtermcount": 0,
            "newwordneprop": [],
            "newwordbtermoffsets": [],
            "newwordbtermpos": []
        },
        "pnewword": {
            "newwordbuf": "",
            "newwordb_curpos": 0,
            "newwordbmaxcount": 0,
            "newwordbsize": 0,
            "newwordbtermcount": 0,
            "newwordneprop": [],
            "newwordbtermoffsets": [],
            "newwordbtermpos": []
        },
        "booknamebuf": "",
        "mergebuf": "",
        "namebuf": "",
        "subphrbuf": "\t\u4f60\u597d\t",
        "wordsepbuf": "\t\u4f60\t\u597d\t\u767e\u5ea6\t",
        "wpcompbuf": "\t\u4f60\u597d\t\u767e\u5ea6\t",
        "bnb_curpos": 0,
        "bnbsize": 0,
        "bnbtermcount": 0,
        "mb_curpos": 0,
        "mbsize": 0,
        "mbtermcount": 0,
        "nameb_curpos": 0,
        "namebsize": 0,
        "namebtermcount": 0,
        "spb_curpos": 6,
        "spbsize": 1024000,
        "spbtermcount": 1,
        "wordtotallen": 8,
        "wpb_curpos": 11,
        "wpbsize": 1024000,
        "wpbtermcount": 2,
        "wsb_curpos": 12,
        "wsbsize": 1024000,
        "wsbtermcount": 3,
        "bnbtermprop": [],
        "namebtermprop": [],
        "spbtermprop": [
            {
                "m_hprop": 1,
                "m_lprop": 32
            }
        ],
        "wpbtermprop": [
            {
                "m_hprop": 1,
                "m_lprop": 32
            },
            {
                "m_hprop": 0,
                "m_lprop": 32
            }
        ],
        "wsbtermprop": [
            {
                "m_hprop": 0,
                "m_lprop": 32
            },
            {
                "m_hprop": 0,
                "m_lprop": 32
            },
            {
                "m_hprop": 0,
                "m_lprop": 32
            }
        ],
        "bnbtermoffsets": [],
        "bnbtermpos": [],
        "mbtermoffsets": [],
        "mbtermpos": [],
        "namebtermoffsets": [],
        "namebtermpos": [],
        "spbtermoffsets": [
            0
        ],
        "spbtermpos": [
            67108865
        ],
        "wpbtermoffsets": [
            0,
            2
        ],
        "wpbtermpos": [
            67108865,
            67108870
        ],
        "wsbtermoffsets": [
            0,
            2,
            4
        ],
        "wsbtermpos": [
            33554433,
            33554436,
            67108871
        ]
    }
}
```

# 词性标注接口（旧版）

## 接口描述

> 本接口已合并到词法分析接口，即将下线，建议直接使用**词法分析接口**

词性标注接口为分词结果中的每个单词标注一个正确的词性的程序，也标注每个词是名词、动词、形容词或其他词性。

## 请求说明

**请求示例**

HTTP方法: `POST`

请求URL: `https://aip.baidubce.com/rpc/2.0/nlp/v1/wordpos`

URL参数：

| 参数         | 值                                                           |
| :----------- | :----------------------------------------------------------- |
| access_token | 通过API Key和Secret Key获取的access_token,参考“[Access Token获取](http://ai.baidu.com/docs#/Auth)” |

Header如下：

| 参数         | 值               |
| :----------- | :--------------- |
| Content-Type | application/json |

Body请求示例:

```
  {
    "query": "你好百度"
  }
```

**请求参数**

| Key   | 类型   | 含义及备注                                                   |
| :---- | :----- | :----------------------------------------------------------- |
| query | string | 带标注的文本串。算法内部使用GBK编码，外部如果要求UTF8编码，则需进行编码转换。 |

**请求示例代码**

**提示一**：使用示例代码前，请记得替换其中的示例Token、图片地址或Base64信息。

**提示二**：部分语言依赖的类或库，请在代码注释中查看下载地址。

bash

PHP

Java

Python

C++

C#

```
词性标注接口
curl -i -k 'https://aip.baidubce.com/rpc/2.0/nlp/v1/wordpos?access_token=24.bb41cb1bd46dd44b9c801b10ce010240.2592000.1492322377.282335-9252280' --data '{"query":"你好百度"}' -H 'Content-Type:application/json; charset=UTF-8'
```

## 返回说明

**返回参数**

| Key         | 类型   | 含义及备注                                                   |
| :---------- | :----- | :----------------------------------------------------------- |
| result_out  | array  | 词性标注结果数组，数组中每个元素对应一个词汇。每个词汇是一个dict |
| +word       | string | 词汇的字面                                                   |
| +offset     | int    | 偏移量，以基本粒度词汇为单位                                 |
| +length     | int    | 长度，以基本粒度词汇为单位                                   |
| +type       | string | 词性                                                         |
| +confidence | float  | 置信度分值，0~1                                              |

**返回示例**

```
{
  "result_out" :
     [
           {"word" : "你好", "offset" : 0, "length" : 1, "type" : "v", "confidence" : 1.0},
           {"word" : "百度", "offset" : 1, "length" : 1, "type" : "nz", "confidence" : 1.0}
      ]
}
```

**词性缩略词说明**

| type | 代码 | 名称     | 帮助记忆的诠释                                         |
| :--- | :--- | :------- | :----------------------------------------------------- |
| 1    | Ag   | 形语素   | 形容词性语素。形容词代码为a，语素代码ｇ前面置以A       |
| 2    | Dg   | 副语素   | 副词性语素。副词代码为d，语素代码ｇ前面置以D。         |
| 3    | Ng   | 名语素   | 名词性语素。名词代码为n，语素代码ｇ前面置以N。         |
| 4    | Tg   | 时语素   | 时间词性语素。时间词代码为t,在语素的代码g前面置以T。   |
| 5    | Vg   | 动语素   | 动词性语素。动词代码为v。在语素的代码g前面置以V        |
| 6    | a    | 形容词   | 取英语形容词adjective的第1个字母                       |
| 7    | ad   | 副形词   | 直接作状语的形容词。形容词代码a和副词代码d并在一起。   |
| 8    | an   | 名形词   | 具有名词功能的形容词。形容词代码a和名词代码n并在一起。 |
| 9    | b    | 区别词   | 取汉字“别”的声母。                                     |
| 10   | c    | 连词     | 取英语连词conjunction的第1个字母。                     |
| 11   | d    | 副词     | 取adverb的第2个字母，因其第1个字母已用于形容词。       |
| 12   | e    | 叹词     | 取英语叹词exclamation的第1个字母                       |
| 13   | f    | 方位词   | 取汉字“方”                                             |
| 14   | g    | 语素     | 绝大多数语素都能作为合成词的“词根”，取汉字“根”的声母   |
| 15   | h    | 前接成分 | 取英语head的第1个字母                                  |
| 16   | i    | 成语     | 取英语成语idiom的第1个字母                             |
| 17   | j    | 简称略语 | 取汉字“简”的声母。                                     |
| 18   | k    | 后接成分 |                                                        |
| 19   | l    | 习用语   | 习用语尚未成为成语，有点“临时性”，取“临”的声母。       |
| 20   | m    | 数词     | 取英语numeral的第3个字母，n，u已有他用。               |
| 21   | n    | 名词     | 取英语名词noun的第1个字母。                            |
| 22   | nr   | 人名     | 名词代码n和“人(ren)”的声母并在一起。                   |
| 23   | ns   | 地名     | 名词代码n和处所词代码s并在一起。                       |
| 24   | nt   | 机构团体 | “团”的声母为t，名词代码n和t并在一起。                  |
| 25   | nx   | 外文专名 | 一般是全角英文专名，如：ＺＢＴ                         |
| 26   | nz   | 其他专名 | “专”的声母的第1个字母为z，名词代码n和z并在一起         |
| 27   | o    | 拟声词   | 取英语拟声词onomatopoeia的第1个字母。                  |
| 28   | p    | 介词     | 取英语介词prepositional的第1个字母。                   |
| 29   | q    | 量词     | 取英语quantity的第1个字母。                            |
| 30   | r    | 代词     | 取英语代词pronoun的第2个字母,因p已用于介词。           |
| 31   | s    | 处所词   | 取英语space的第1个字母。                               |
| 32   | t    | 时间词   | 取英语time的第1个字母。                                |
| 33   | u    | 助词     | 取英语助词auxiliary                                    |
| 34   | v    | 动词     | 取英语动词verb的第一个字母。                           |
| 35   | vd   | 副动词   | 直接作状语的动词。动词和副词的代码并在一起。           |
| 36   | vn   | 名动词   | 指具有名词功能的动词。动词和名词的代码并在一起         |
| 37   | w    | 标点符号 |                                                        |
| 38   | y    | 语气词   | 取汉字“语”的声母。                                     |
| 39   | z    | 状态词   | 取汉字“状”的声母的前一个字母。                         |

# 中文词向量表示接口（旧版）

## 接口描述

> 新版中文词向量表示接口已上线，建议您及时升级，旧版本即将逐步下线。

中文词向量表示接口提供两种功能：输入两个词tid=1得到两个词的相似度结果，输入1个词tid=2得到词的词向量。

## 请求说明

**请求示例**

HTTP方法: `POST`

请求URL: `https://aip.baidubce.com/rpc/2.0/nlp/v1/wordembedding`

URL参数：

| 参数         | 值                                                           |
| :----------- | :----------------------------------------------------------- |
| access_token | 通过API Key和Secret Key获取的access_token,参考“[Access Token获取](http://ai.baidu.com/docs#/Auth)” |

Header如下：

| 参数         | 值               |
| :----------- | :--------------- |
| Content-Type | application/json |

Body请求示例:

**输入两个词**

```
  {
    "query1":"百度",
    "query2":"谷歌",
    "tid":1
  }
```

**输入一个词**

```
  {
    "query1":"百度",
    "tid":2
  }
```

**请求参数**

| 参数   | 是否必选 | 说明                                                       |
| :----- | :------- | :--------------------------------------------------------- |
| query1 | 是       | 输入的第一个词                                             |
| query2 | 是       | 输入的第二个词                                             |
| tid    | 是       | 指定算法类型，tid=1，返回两个词的相似度；tid=2，返回词向量 |

**请求示例代码**

**提示一**：使用示例代码前，请记得替换其中的示例Token、图片地址或Base64信息。

**提示二**：部分语言依赖的类或库，请在代码注释中查看下载地址。

bash

PHP

Java

Python

C++

C#

```
词向量表示接口
curl -i -k 'https://aip.baidubce.com/rpc/2.0/nlp/v1/wordembedding?access_token=24.bb41cb1bd46dd44b9c801b10ce010240.2592000.1492322377.282335-9252280' --data '{"query1":"百度","query2":"谷歌","tid":1}' -H 'Content-Type:application/json; charset=UTF-8'
```

## 返回说明

**返回参数**

| 参数    | 描述           |
| :------ | :------------- |
| ret     | 属性对象的集合 |
| message | 词汇的字面     |
| data    | 返回数据       |
| +vec    | 词向量结果     |
| +sim    | 相似度对象     |
| ++sim   | 相似度         |

**返回示例**

```
{
  "ret":0,
  "message":"",
  "data":
    {  "sim":
        {
          "sim":0.180343},
          "vec":null
        }
}
```

# 中文DNN语言模型接口（旧版）

## 接口描述

> 新版中文DNN语言模型已上线，建议您及时升级，旧版本即将逐步下线。

中文DNN语言模型接口用于输出切词结果并给出每个词在句子中的概率值。

## 请求说明

**请求示例**

HTTP方法：`POST`

请求URL： `https://aip.baidubce.com/rpc/2.0/nlp/v1/dnnlm_cn`

URL参数：

| 参数         | 值                                                           |
| :----------- | :----------------------------------------------------------- |
| access_token | 通过API Key和Secret Key获取的access_token,参考“[Access Token获取](http://ai.baidu.com/docs#/Auth)” |

Header如下：

| 参数         | 值               |
| :----------- | :--------------- |
| Content-Type | application/json |

Body请求示例:

```
  {
    "input_sequence":"百度是个搜索公司"
  }
```

**请求参数**

| 参数           | 说明                   |
| :------------- | :--------------------- |
| input_sequence | 输入的句子，不需要切词 |

**请求示例代码**

**提示一**：使用示例代码前，请记得替换其中的示例Token。

**提示二**：部分语言依赖的类或库，请在代码注释中查看下载地址。

bash

PHP

Java

Python

C++

C#

```
中文DNN语言模型
curl -i -k 'https://aip.baidubce.com/rpc/2.0/nlp/v1/dnnlm_cn?access_token=24.bb41cb1bd46dd44b9c801b10ce010240.2592000.1492322377.282335-9252280' --data '{"input_sequence":"百度是个搜索公司"}' -H 'Content-Type:application/json; charset=UTF-8'
```

## 返回说明

**返回参数**

| 参数     | 说明                         |
| :------- | :--------------------------- |
| seq_seg  | 句子的切词结果               |
| seq_prob | 切词后每个词在句子中的概率值 |

**返回示例**

```
{
  "seq_seg":"百度 是 个 搜索 公司",
  "seq_prob":" 0.00059052   0.00373688  0.0372463   0.00137015  0.000118814 "
}
```

# 短文本相似度接口（旧版）

## 接口描述

> 新版短文本相似度接口已上线，建议您及时升级，旧版本即将逐步下线。

短文本相似度接口用来判断两个文本的相似度得分。

## 请求说明

**请求示例**

HTTP方法：`POST`

请求URL：`https://aip.baidubce.com/rpc/2.0/nlp/v1/simnet`

URL参数：

| 参数         | 值                                                           |
| :----------- | :----------------------------------------------------------- |
| access_token | 通过API Key和Secret Key获取的access_token,参考“[Access Token获取](http://ai.baidu.com/docs#/Auth)” |

Header如下：

| 参数         | 值               |
| :----------- | :--------------- |
| Content-Type | application/json |

Body请求示例:

```
{
  "input":
    {
      "qslots":[{"terms_sequence":"你好百度” ", "type":0, "items":[]}],
      "tslots":[{"terms_sequence":"你好世界” ", "type":0, "items":[]}],
      "type":0
    }
}
```

**请求参数**

| 参数                     | 说明            |
| :----------------------- | :-------------- |
| qslots中的terms_sequence | 短文本1         |
| tslots中的terms_sequence | 短文本2         |
| items                    | 均设置为空列表  |
| type                     | 类别，均设置为0 |

**请求示例代码**

**提示一**：使用示例代码前，请记得替换其中的示例Token。

**提示二**：部分语言依赖的类或库，请在代码注释中查看下载地址。

bash

PHP

Java

Python

C++

C#

```
短文本相似度接口
curl -i -k 'https://aip.baidubce.com/rpc/2.0/nlp/v1/simnet?access_token=24.bb41cb1bd46dd44b9c801b10ce010240.2592000.1492322377.282335-9252280' --data '{"input":{"qslots":[{"terms_sequence":"你好百度","type":0,"items":[]},{"terms_sequence":"你好北京” ", "type":0, "items":[]}],"tslots":[{"terms_sequence":"你好世界","type":0,"items":[]}],"type":0}}' -H 'Content-Type:application/json; charset=UTF-8'
```

## 返回说明

**返回参数**

| 参数       | 说明               |
| :--------- | :----------------- |
| score      | 两个文本相似度得分 |
| error      | error code         |
| type       | 默认为0            |
| error_note | error对应文字说明  |
| items      | 默认为空           |

**返回示例**

```
{
  "output":
    {
      "score":0.758419,
      "error":0,
      "type":0,
      "error_note":"",
      "items":[]
    }
}
```

**此接口业务错误码说明**

| Code | Message            | 返回说明           |
| :--- | :----------------- | :----------------- |
| 0    | NO_ERROR           | 正确返回           |
| 1    | BEYOND_SLOT_LENGTH | 输入长度过长       |
| 2    | OOV_ERROR          | 输入文本不在词表中 |
| 3    | LEGO_LIB_RET_ERROR | 内部库错误         |
| 4    | OTHER_SERVER_ERROR | 其它服务错误       |
| 5    | INPUT_HAS_EMPTY    | 输入为空           |
| 6    | INPUT_FORMAT_ERROR | 输入格式错误       |
| 7    | OTHER_CLIENT_ERROR | 客服端错误         |

# 评论观点抽取接口（旧版）

## 接口描述

> 新版评论观点抽取接口已上线，建议您及时升级，旧版本即将逐步下线。

评论观点抽取接口用来提取一个句子观点评论的情感属性。

## 请求说明

**请求示例**

HTTP方法: `POST`

请求URL: `https://aip.baidubce.com/rpc/2.0/nlp/v1/comment_tag`

URL参数：

| 参数         | 值                                                           |
| :----------- | :----------------------------------------------------------- |
| access_token | 通过API Key和Secret Key获取的access_token,参考“[Access Token获取](http://ai.baidu.com/docs#/Auth)” |

Header如下：

| 参数         | 值               |
| :----------- | :--------------- |
| Content-Type | application/json |

Body请求示例:

```
  {
    "comment":"个人觉得福克斯好，外观漂亮年轻，动力和操控性都不错",
    "entity":"NULL",
    "type":"10"
  }
```

**请求参数**

| 参数    | 类型   | 说明                               |
| :------ | :----- | :--------------------------------- |
| comment | string | 评论内容                           |
| entity  | string | 实体名，当前取值为NULL，暂时不生效 |
| type    | string | 类别,默认类别为4（餐厅）           |

其中type包含12个类别，具体取值说明如下：

| 参数 | 说明         |
| :--- | :----------- |
| 1    | 酒店         |
| 2    | KTV          |
| 3    | 丽人         |
| 4    | 美食（默认） |
| 5    | 旅游         |
| 6    | 健康         |
| 7    | 教育         |
| 8    | 商业         |
| 9    | 房产         |
| 10   | 汽车         |
| 11   | 生活         |
| 12   | 购物         |

**请求示例代码**

**提示一**：使用示例代码前，请记得替换其中的示例Token。

**提示二**：部分语言依赖的类或库，请在代码注释中查看下载地址。

bash

PHP

Java

Python

C++

C#

```
评论观点抽取接口
curl -i -k 'https://aip.baidubce.com/rpc/2.0/nlp/v1/comment_tag?access_token=24.bb41cb1bd46dd44b9c801b10ce010240.2592000.1492322377.282335-9252280' --data '{"comment":"个人觉得福克斯好，外观漂亮年轻，动力和操控性都不错","type":"10","entity":"NULL"}' -H 'Content-Type:application/json; charset=UTF-8'
```

## 返回说明

**返回参数**

| 参数     | 说明                                                  |
| :------- | :---------------------------------------------------- |
| abstract | 表示评论观点在评论文本中的位置。                      |
| adj      | 表示抽取结果中的评价词                                |
| comment  | 表示待抽取观点的评论文本。                            |
| entity   | 实体名，当前取值为NULL，暂时不生效                    |
| fea      | 抽取结果中的属性词                                    |
| type     | 表示情感极性（其中2表示积极、1表示中性、0表示消极）。 |
| 其他参数 | 暂不生效                                              |

**返回示例**

```
{
  "abstract":"<span>动力和操控性都不错</span>",
  "adj":"不错",
  "comment":"个人觉得福克斯好，外观漂亮年轻，动力和操控性都不错",
  "entity":"NULL",
  "fea":"动力",
  "type":"2"
}
```

# 错误信息

若请求错误，服务器将返回的JSON文本包含以下参数：

- **error_code**：错误码。
- **error_msg**：错误描述信息，帮助理解和解决发生的错误。

例如Access Token失效返回：

```
{
  "error_code": 110,
  "error_msg": "Access token invalid or no longer valid"
}
```

需要重新获取新的Access Token再次请求即可。

## 错误码

| 错误码 | 错误信息                                | 描述                                                         |
| :----- | :-------------------------------------- | :----------------------------------------------------------- |
| 1      | Unknown error                           | 服务器内部错误，请再次请求，如果持续出现此类错误，请通过QQ群（224994340）或工单联系技术支持团队 |
| 2      | Service temporarily unavailable         | 服务暂不可用，请再次请求，如果持续出现此类错误，请通过QQ群（224994340）或工单联系技术支持团队 |
| 3      | Unsupported openapi method              | 调用的API不存在，请检查后重新尝试                            |
| 4      | Open api request limit reached          | 集群超限额                                                   |
| 6      | No permission to access data            | 无权限访问该用户数据                                         |
| 17     | Open api daily request limit reached    | 每天请求量超限额                                             |
| 18     | Open api qps request limit reached      | QPS超限额                                                    |
| 19     | Open api total request limit reached    | 请求总量超限额                                               |
| 100    | Invalid parameter                       | 包含了无效或错误参数，请检查代码                             |
| 110    | Access token invalid or no longer valid | Access Token失效                                             |
| 111    | Access token expired                    | Access token过期                                             |
| 282000 | internal error                          | 服务器内部错误，请再次请求， 如果持续出现此类错误，请通过QQ群（632426386）或工单联系技术支持团队。 |
| 282002 | input encoding error                    | 编码错误，请使用GBK编码                                      |
| 282004 | invalid parameter(s)                    | 请求中包含非法参数，请检查后重新尝试                         |
| 282008 | unsupported charset:{字符编码名称}      | 仅支持GBK和UTF-8，其余为不支持的字符编码，请检查后重新尝试   |
| 282130 | no result                               | 当前查询无结果返回，出现此问题的原因一般为：参数配置存在问题，请检查后重新尝试 |
| 282131 | input text too long                     | 输入长度超限，请查看文档说明                                 |
| 282133 | param {参数名} not exist                | 接口参数缺失                                                 |
| 282134 | input empty                             | 输入为空                                                     |
| 282300 | word error                              | word不在算法词典中                                           |
| 282301 | word_1 error                            | word_1提交的词汇暂未收录，无法比对相似度                     |
| 282302 | word_2 error                            | word_2提交的词汇暂未收录，无法比对相似度                     |
| 282303 | word_1&word_2 error                     | word_1和word_2暂未收录，无法比对相似度                       |