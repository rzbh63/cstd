
# 如何理解李飞飞价值十亿美金的“人文AI”计划 ？ - 喜欢打酱油的老鸟 - CSDN博客


2019年03月30日 08:38:47[喜欢打酱油的老鸟](https://me.csdn.net/weixin_42137700)阅读数：237


[https://www.tmtpost.com/3850181.html?rss=toutiao2](https://www.tmtpost.com/3850181.html?rss=toutiao2)
摘要： 以往我们总觉得，技术永远只是研发者和应用之间的故事。如今看来，或许AI已经成为了一个世界命题。
![图片来源@视觉中国](https://images.tmtpost.com/uploads/images/2019/03/20190329184348213.jpg?imageMogr2/strip/interlace/1/quality/85/thumbnail/1400x878/gravity/center/crop/!1400x878&ext=.jpg)
图片来源@视觉中国
> 文 | 脑极体
AI自从以应用角度走进大众视野，就一直逃不出“人文主义”的苛责。作为一种依靠于海量数据运转的技术，AI之所以能够作为提升效率的工具，主要还是因为对人类经验的高度集中。
而“人类经验”这件事，本身就是不够完美的。普遍能够累积成海量数据的经验，有时反而更加充满偏见。就像如果把AI带入哥伦布时代，AI也会成为一位坚定的地心论支持者。
而李飞飞离开谷歌回归斯坦福后，主导的第一个项目HAI——以人为本人AI研究院(Stanford Human-Centered AI Institute)，就在着重解决AI与人文主义之间的沟壑。
## AI 拟人化，竟是一位“富裕的白人男性”？
首先要知道的，究竟是什么让AI无法“以人为本”？
目前从人文、从公平的角度来看，AI公认的两个问题是“白人至上（White Guy Problem）”和“男性之海（Sea of Dudes）”。
所谓白人至上，是指在算法驱动下AI所做出的一些种族歧视行为。例如谷歌的图片自动分类曾经将黑人照片分类成大猩猩，以及惠普的摄像头算法无法识别深肤色的人。在犯罪预测软件中，甚至会将黑人的犯罪率识别成普通白人的两倍以上。
而男性之海，则指的是AI从业者中有极大的性别倾斜，在2015年的NIPS上，女性与会者的人数竟然只占到了13.7%，李飞飞提到，在论文引用量，男性作者的被引用次数要比女性作者高100倍。
![如何理解李飞飞价值十亿美金的“人文AI”计划 ？](https://images.tmtpost.com/uploads/images/2019/03/cd708a89776393fb1e37b629cdab98d3_1553856355.jpeg?imageMogr2/strip/interlace/1/quality/85/thumbnail/1400x905/gravity/center/crop/!1400x905&ext=.jpeg)
用《纽约时报》的话讲，两者结合，让AI被塑造出了一个“富裕白人男性”的价值观——刚好和那些掌握着科技霸权的企业主们一模一样。
如此以来，对于AI的应用很可能反而会让人们一直以来对于推动种族、性别间平等所做的努力白费。
就像平权主义者一直在推动男女收入平等，而去年卡内基梅隆大学的计算机科学家却发现，在谷歌的广告推送机制中，更倾向于将高收入工作的招聘广告推送给男性用户。
而当美国各地警察部门在执行预测性警务工作时，数据驱动的风险评估工具会让他们更多的前往有色人种聚集区，无形中加重了对某一人群的偏见和标签化。
可怕的是，当女性在职场上遇到歧视时，她还可以对自己情况进行发声。而当AI驱动一切在无声中进行时，女性甚至不知道自己正在处在歧视链之中——如果从没见过这项招聘启事，女性自然不知道高收入工作更倾向于招聘男性。
而当AI行业中充斥着“富裕的白人男性”时，他们自然也很难注意到算法黑箱中产生了这样的问题。最终万事万物都在人类歧视造就的规则下运行，被驱动的每一个群体却又看不清规则的真正面目。
## 十亿美金的远大目标
李飞飞在斯坦福主导的HAI项目，大概有着以下三个目标：第一是推进和发展下一代AI科学（重点在于脑科学和认知科学），第二是研究和预测AI对人类社会和生活的影响，第三是设计和实践以人为本的AI技术和应用。
这么一看，所谓“以人为本”的说法其实挺虚的。但综合斯坦福的一些公开资料，以及李飞飞的一些讲话，我们可以大概总结出HAI究竟想做些什么。
首先是在AI研究中引入更多样化的视角和交叉思维。
最主要的，就是支持女性和有色人种进入AI研究。例如斯坦福所支持的“Black in AI”项目，就在号召有色人种关注目前的AI研究，关注AI无形中所带来的歧视问题。
同时还有持续追踪各个领域应用AI后所带来的影响。
初次之外，HAI还邀请了社会各界人士共同参与，如教育、工业、艺术等等领域，试图让他们一起发表意见，尤其是对技术研发者给出反馈，告诉他们AI究竟对这一领域产生了哪些影响，以权衡技术的未来走向。
至于推动下一代AI科学就很好理解了，主要是帮助研究者圈定研究方向，推动AI的可解释性等等，这里就不再进行赘述。
![如何理解李飞飞价值十亿美金的“人文AI”计划 ？](https://images.tmtpost.com/uploads/images/2019/03/d0ba0c42e743be33a0b6fc538c25e39f_1553856355.jpeg?imageMogr2/strip/interlace/1/quality/85/thumbnail/1400x778/gravity/center/crop/!1400x778&ext=.jpeg)
但有趣的是，HAI作为一个非常政治正确并伟光正的项目，并没有在舆论获得一致性的支持。尤其有媒体指出，该机构有121位教职工，其中有100位以上都是白人，并只有30%的女性。
于是事情就变成了，HAI邀请了一群富裕的白人男性，试图募集10亿美金去从人文角度矫正人工智能的“富裕白人男性”价值观。
## 齿轮之下：如何看待商业效率以外的 AI ？
虽然HAI获得的评价不一，但AI所带来的公平性问题，确实已经开始影响人们的正常生活。
就像上文提到的算法错误估计有色人种犯罪率将其提升了两倍，同样意味着算法将白人的犯罪率错误的低估了两倍。如果执法者依赖这种错误的算法，则意味着不仅可能冤枉好人，也可能错放坏人。
又比如前两年亚马逊曾经闹出的丑闻，用户发现算法在分配货物能否当日送达时，一旦输入了黑人聚集区的邮政编码，就无法使用当日送达服务。
![如何理解李飞飞价值十亿美金的“人文AI”计划 ？](https://images.tmtpost.com/uploads/images/2019/03/e66b931a9cade336f69e568dcc956aea_1553856355.jpeg?imageMogr2/strip/interlace/1/quality/85/thumbnail/1400x787/gravity/center/crop/!1400x787&ext=.jpeg)
**（被评价为“高风险”的有色人种，和拥有数次犯罪记录却被评定为低风险的白人）**
这种偏见现象正在越来越多地出现在种种服务中：贷款的AI风控、保险的AI审核机制。最后就导致了越是弱势群体，越容易被算法边缘化，进而难以获得资源与帮助，最后进一步地向弱势一方倾斜，甚至最终走向犯罪，加重了算法歧视。
如此看来HAI的很多策略，是非常值得我们仔细思考的。
例如，当我们在关注产业AI的效率问题时，我们是否也应该考虑在效率之外，AI对于产业的更多影响？当AI对于拥有强大IT基础的零售集团发挥作用，他们更加理解用户心智时，那些小而美的微型零售店是否在风潮中被遗忘和挤压，最终退出舞台？
又比如除了那些研发技术和为技术买单的人之外，我们是否有责任去倾听更多人的声音？AI的研发者与技术采买者或许清晰地知道AI是如何推动我们生活运转的，但那些同样被卷在齿轮之下的人，是否也有权力了解到这些齿轮的运转规则？
更重要的，我们是否应该尽力去推动AI黑箱的透明化，在发现问题时能够从内部技术机制上解决？
以往我们总觉得，技术永远只是研发者和应用之间的故事。如今看来，或许AI已经成为了一个世界命题。
世界命题，就应该广泛参与。

