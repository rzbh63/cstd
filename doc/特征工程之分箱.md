# 特征工程之分箱

2017年12月23日 21:13:39 [Pylady](https://me.csdn.net/Pylady) 阅读数：6804



一般在建立分类模型时，需要对连续变量离散化，特征离散化后，模型会更稳定，降低了模型过拟合的风险。比如在建立申请评分卡模型时用logsitic作为基模型就需要对连续变量进行离散化，离散化通常采用分箱法。

**分箱的重要性及其优势**

1. 离散特征的增加和减少都很容易，易于模型的快速迭代；
2. 稀疏向量内积乘法运算速度快，计算结果方便存储，容易扩展；
3. 离散化后的特征对异常数据有很强的鲁棒性：比如一个特征是年龄>30是1，否则0。如果特征没有离散化，一个异常数据“年龄300岁”会给模型造成很大的干扰；
4. 逻辑回归属于广义线性模型，表达能力受限；单变量离散化为N个后，每个变量有单独的权重，相当于为模型引入了非线性，能够提升模型表达能力，加大拟合；
5. 离散化后可以进行特征交叉，由M+N个变量变为M*N个变量，进一步引入非线性，提升表达能力；
6. 特征离散化后，模型会更稳定，比如如果对用户年龄离散化，20-30作为一个区间，不会因为一个用户年龄长了一岁就变成一个完全不同的人。当然处于区间相邻处的样本会刚好相反，所以怎么划分区间是门学问；
7. 特征离散化以后，起到了简化了逻辑回归模型的作用，降低了模型过拟合的风险。
8. 可以将缺失作为独立的一类带入模型。
9. 将所有变量变换到相似的尺度上。

**有监督分箱：**

**卡方分箱法(ChiMerge)**

自底向上的(即基于合并的)数据离散化方法。

它依赖于卡方检验:具有最小卡方值的相邻区间合并在一起,直到满足确定的停止准则。

基本思想:

对于精确的离散化，相对类频率在一个区间内应当完全一致。因此,如果两个相邻的区间具有非常类似的类分布，则这两个区间可以合并；否则，它们应当保持分开。而低卡方值表明它们具有相似的类分布。 
![img](https://img-blog.csdn.net/20171223211118460?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvUHlsYWR5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

这里需要注意初始化时需要对实例进行排序，在排序的基础上进行合并。

卡方阈值的确定：

根据显著性水平和自由度得到卡方值

自由度比类别数量小1。例如：有3类,自由度为2，则90%置信度(10%显著性水平)下，卡方的值为4.6。

阈值的意义

类别和属性独立时,有90%的可能性,计算得到的卡方值会小于4.6。 大于阈值4.6的卡方值就说明属性和类不是相互独立的，不能合并。如果阈值选的大,区间合并就会进行很多次,离散后的区间数量少、区间大。

注：

1、ChiMerge算法推荐使用0.90、0.95、0.99置信度,最大区间数取10到15之间.

2、也可以不考虑卡方阈值,此时可以考虑最小区间数或者最大区间数。指定区间数量的上限和下限,最多几个区间,最少几个区间。

3、对于类别型变量,需要分箱时需要按照某种方式进行排序。

**最小熵法分箱**

(1) 假设因变量为分类变量，可取值1，… ，J。令pijpij表示第i个分箱内因变量取值为j的观测的比例，i=1，…，k，j=1，…，J；那么第i个分箱的熵值为∑Jj=0−pij×logpij∑j=0J−pij×logpij。如果第i个分箱内因变量各类别的比例相等，即p11=p12=p1J=1/Jp11=p12=p1J=1/J，那么第i个分箱的熵值达到最大值；如果第i个分箱内因变量只有一种取值，即某个pijpij等于1而其他类别的比例等于0，那么第i个分箱的熵值达到最小值。

(2) 令riri表示第i个分箱的观测数占所有观测数的比例；那么总熵值为∑ki=0∑Jj=0(−pij×logpij)∑i=0k∑j=0J(−pij×logpij)。需要使总熵值达到最小，也就是使分箱能够最大限度地区分因变量的各类别。

**无监督分箱法:**

**等距分箱**

　　从最小值到最大值之间,均分为 N 等份, 这样, 如果 A,B 为最小最大值, 则每个区间的长度为 W=(B−A)/N , 则区间边界值为A+W,A+2W,….A+(N−1)W 。这里只考虑边界，每个等份里面的实例数量可能不等。

**等频分箱**

　　区间的边界值要经过选择,使得每个区间包含大致相等的实例数量。比如说 N=10 ,每个区间应该包含大约10%的实例。

以上两种算法的弊端

比如,等宽区间划分,划分为5区间,最高工资为50000,则所有工资低于[10000](https://www.baidu.com/s?wd=10000&tn=24004469_oem_dg&rsv_dl=gh_pl_sl_csd)的人都被划分到同一区间。等频区间可能正好相反,所有工资高于50000的人都会被划分到50000这一区间中。这两种算法都忽略了实例所属的类型,落在正确区间里的偶然性很大。

**聚类分箱**

基于k均值聚类的分箱：k均值聚类法将观测值聚为k类，但在聚类过程中需要保证分箱的有序性：第一个分箱中所有观测值都要小于第二个分箱中的观测值，第二个分箱中所有观测值都要小于第三个分箱中的观测值，等等。

我们对特征进行分箱后，需要对分箱后的每组（箱）进行woe编码和IV值的计算，通过IV值进行变量筛选后，然后才能放进模型训练。 