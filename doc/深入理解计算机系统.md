# 深入理解计算机系统





# 堆区和栈区的区别



C++程序内存布局：

程序内存空间

- 代码区(code area)
- 全局数据区(data area)
- 堆区(heap area)
- 栈区(stack area)

一个由C/C++编译的程序占用的内存分为以下几个部分,

1)**全局区（静态区）（static）**存放全局变量、静态数据，const常量。程序结束后有系统释放

2)**栈区（stack）** 函数运行时分配，函数结束时释放。由编译器自动分配释放 ，存放为运行函数而分配的局部变量、函数参数、返回数据、返回地址等。其操作方式类似于数据结构中的栈。

3)**堆区（heap）** 一般由程序员分配释放， 若程序员不释放，程序结束时可能由OS（操作系统）回收。分配方式类似于链表。

4)文字**常量区** 常量字符串就是放在这里的。 程序结束后由系统释放。

5)程序**代码区**存放函数体（类成员函数和全局函数）的二进制代码。

![img](https://images2015.cnblogs.com/blog/609046/201608/609046-20160809103426449-920803321.png)

 

------

栈区和堆区的区别：

1)申请方式： 栈区内存由系统**自动**分配，函数结束时释放；堆区内存由**程序员**自己申请，并指明大小，用户忘释放时，会造成内存泄露，不过进程结束时会由系统回收。

2)申请后系统的响应： 只要栈的剩余空间大于所申请的空间，系统将为程序提供内存，否则将报异常提示**栈溢出**；堆区，**空闲链表**，分配与回收机制，会产生碎片问题（外部碎片）-->（固定分区存在内部碎片（分配大于实际），可变分区存在外部碎片（太碎无法分配））。

3)申请大小的限制：栈是1或者2M，可以自己改，但是最大不超过8M；堆，看主机是多少位的，如果是32位，就是4G

4)申请效率：栈由系统自动分配，速度较快，程序员无法控制；堆是由new分配的内存，一般速度较慢，而且容易导致内存碎片，但是用起来方便！

5)存储内容：栈，函数调用（返回值，各个参数，局部变量（**静态变量不入栈**））；堆，一般在堆的头部用一个字节存放堆的大小，堆中的具体内容由程序员安排。

6)存取效率的比较：栈比堆快，Eg :char c[] = /"1234567890/";char *p =/"1234567890/";读取c[1]和p[1],c[1]读取时直接吧字符串中的元素读到寄存器cl中，而p[1]先把指针值读到edx中，再根据edx读取字符，多一次操作。

7)管理方式不同：栈，数据结构中的栈；堆，链表

8)生长方向：栈，高到低；堆，低到高



|                  | 栈                                                           | 堆                                                           |
| ---------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 申请方式         | 由系统**自动**分配，函数结束时释放                           | 由**程序员**自己申请，并指明大小，用户忘释放时，会造成内存泄露，不过进程结束时会由系统回收 |
| 申请后系统的响应 | 只要栈的剩余空间大于所申请的空间，系统将为程序提供内存，否则将报异常提示**栈溢出 | 堆区，**空闲链表**，分配与回收机制，会产生碎片问题（外部碎片）-->（固定分区存在内部碎片（分配大于实际），可变分区存在外部碎片（太碎无法分配）） |
| 申请大小的限制   | 1或者2M，可以自己改，但是最大不超过8M                        | 看主机是多少位的，如果是32位，就是4G                         |
| 申请效率         | 由系统自动分配，速度较快，程序员无法控制                     | 由new分配的内存，一般速度较慢，而且容易导致内存碎片，但是用起来方便 |
| 存储内容         | 函数调用（返回值，各个参数，局部变量（**静态变量不入栈**）） | 一般在堆的头部用一个字节存放堆的大小，堆中的具体内容由程序员安排 |
| 存取效率的比较   | 栈比堆快                                                     |                                                              |
| 管理方式不同     |                                                              |                                                              |
| 生长方向         | 高到低                                                       | 低到高                                                       |







# 进程和线程的区别



|                  | 多进程                                                       | 多线程                            | 总结     |
| ---------------- | ------------------------------------------------------------ | --------------------------------- | -------- |
| 数据共享、同步   | 数据是分开的；同步简单；共享复杂，需要用IPC                  | 共享简单；同步复杂                | 各有优势 |
| 内存、CPU        | 占用内存多，切换复杂；CPU利用率低                            | 占用内存少，切换简单；CPU利用率高 | 线程占优 |
| 编程调试         | 编程简单，调试简单                                           | 编程复杂，调试复杂                | 进程占优 |
| 可靠性           | 进程间不会互相影响                                           | 一个线程挂掉将导致整个进程挂掉    | 进程占优 |
| 分布式           | 适应与多核、多机分布；如果一台机器不够，扩展到多台机器容易； | 适应于多核分布                    | 进程占优 |
| 创建、销毁、切换 | 创建销毁复杂；切换复杂；速度慢                               | 创建销毁简单，切换简单，速度快    | 线程占优 |



# [内部碎片、外部碎片](https://www.cnblogs.com/zlcxbb/p/5759790.html)



　　“碎片的内存”描述一个系统中所有不可用的空闲内存。这些资源之所以仍然未被使用，是因为负责分配内存的分配器使这些内存无法使用。这一问题通常都会发生，原因在于空闲内存以小而不连续方式出现在不同的位置。由于分 配方法决定内存碎片是否是一个问题，因此内存分配器在保证空闲资源可用性方面扮演着重要的角色。

------

 

## **内部碎片、外部碎片剖析**

**internal fragmentation:**when memory allocated to a process is larger than requested memory, 

the difference between these two numbers is internal fragmentation.

**external fragmentation:**External fragments exists when total memory space exists to satisfy a request,

but it is not continous. storage is broken into little pieces. 

------

 

在内存管理中，**内部碎片是已经被分配出去的的内存空间大于请求所需的内存空间**。

**外部碎片**是指**还没有分配出去，但是由于大小太小而无法分配给申请空间的新进程的内存空间空闲块**。

------

 

一般情况下，**固定分区存在内部碎片，可变式分区分配会存在外部碎片**；

**页式虚拟存储系统**存在内部碎片；**段式虚拟存储系统**，存在外部碎片

------

 

## 针对碎片问题，如何有效利用内存？

为了有效的利用内存，使内存产生更少的碎片，要**对内存分页**，内存以页为单位来使用，最后一页往往装不满，于是形成了内部碎片。

为了共享要分段，在段的换入换出时形成外部碎片，比如5K的段换出后，有一个4k的段进来放到原来5k的地方，于是形成1k的外部碎片。





# [内存为程序分配空间的四种分配方式](https://www.cnblogs.com/zlcxbb/p/5759873.html)



存储器是个宝贵但却有限的资源。一流的操作系统，需要能够有效地管理及利用存储器。

**内存为程序分配空间有四种分配方式：**

**1、连续分配方式**

**2、基本分页存储管理方式**

**3、基本分段存储管理方式**

**4、段页式存储管理方式**

------

 

## **连续分配方式**

　　首先讲连续分配方式。**连续分配方式**出现的时间比较早，曾广泛应用于20世纪60~70年代的OS中，但是它至今仍然在内存管理方式中占有一席之地，原因在于它**实现起来比较方便，所需的硬件支持最少**。连续分配方式又可细分为四种：**单一连续分配、固定分区分配、动态分区分配和动态重定位分区分配**。

　　其中固定分区分配方式，因为分区固定，所以缺乏灵活性，即**当程序太小时，会造成内存空间的浪费（内部碎片）**；**程序太大时，一个分区又不足以容纳，致使程序无法运行（外部碎片）**。但尽管如此，当一台计算机去控制多个相同对象的时候，由于这些对象内存大小相同，所以完全可以采用这种内存管理方式，而且是最高效的。这里我们可以看出存储器管理机制的多面性：即没有那种存储器管理机制是完全没有用的，在适合的场合下，一种被认为最不合理的分配方案却可能称为最高效的分配方案。**一切都要从实际问题出发，进行设计。**

 　　为了解决固定分区分配方式的缺乏灵活性，出现了**动态分配方式**。动态分配方式采用一些**寻表（Eg：空闲链表）**的方式，查找能符合程序需要的空闲内存分区。但代价是增加了系统运行的开销，而且内存空闲表本身是一个文件，必然会占用一部分宝贵的内存资源，而且有些算法还会增加内存碎片。

 　　可重定位分区分配通过对程序实现成定位，从而可以将内存块进行搬移，将小块拼成大块，将小空闲“紧凑”成大空闲，腾出较大的内存以容纳新的程序进程。

------

 

## **基本分页存储管理方式**

　　**连续分配方式**会形成许多“碎片”，虽然可以通过“紧凑”方式将许多碎片拼接成可用的大块空间，但须为之付出很大开销。所以提出了“**离散分配方式**”的想法。如果**离散分配的基本单位是页，则称为分页管理方式；如果离散分配的基本单位是段，则称为分段管理方式**。

 　　分页存储管理是将一个进程的逻辑地址空间分成若干个大小相等的片，称为页面或页，并为各页加以编号，从0开始，如第0页、第1页等。相应地，也把内存空间分成与页面相同大小的若干个存储块，称为(物理)块或页框(frame)，也同样为它们加以编号，如0#块、1#块等等。在为进程分配内存时，以块为单位将进程中的若干个页分别装入到多个可以不相邻接的物理块中。由于进程的最后一页经常装不满一块而形成了不可利用的碎片，称之为“**页内碎片**”。

 　　**在分页系统中，允许将进程的各个页离散地存储在内存不同的物理块中（所以能实现离散分配方式）**，但系统应能保证进程的正确运行，即能在内存中找到每个页面所对应的物理块。为此，系统又为每个进程建立了一张页面映像表，简称**页表**。在进程地址空间内的所有页，依次在页表中有一页表项，其中记录了相应页在内存中对应的物理块号。在配置了页表后，进程执行时，通过查找该表，即可找到每页在内存中的物理块号。可见，**页表的作用是实现从页号到物理块号的地址映射**。

 　　为了能够将用户地址空间中的**逻辑地址，变换为内存空间中的物理地址**，在系统中必须设置**地址变换机构**。地址变换任务是借助于页表来完成的。

　　**页表**的功能可由一组专门的寄存器来实现。由于寄存器成本较高，且大多数现代计算机的页表又很大，使页表项总数可达几千甚至几十万个，显然这些页表项不可能都用寄存器来实现，因此，页表大多驻留在内存中。因为一个进程可以通过它的PCB来时时保存自己的状态，等到CPU要处理它的时候才将PCB交给寄存器，所以，系统中虽然可以运行多个进程，但也只需要一个页表寄存器就可以了。

　　**由于页表是存放在内存中的，这使得CPU在每存取一个数据时，都要两次访问内存。为了提高地址变换速度，在地址变化机构中增设了一个具有并行查询能力的告诉缓冲寄存器，又称为“联想寄存器”（Associative Lookaside Buffer）。**

　　在单级页表的基础上，为了适应非常大的逻辑地址空间，出现了两级和多级页表，但是，他们的原理和单级页表是一样的，只不过为了适应地址变换层次的增加，需要在地址变换机构中增设外层的页表寄存器。

------

 

## **基本分段存储管理方式**

　　**分段存储管理方式**的目的，主要是为了满足用户（程序员）在编程和使用上多方面的要求，其中有些要求是其他几种存储管理方式所难以满足的。因此，这种存储管理方式已成为当今所有存储管理方式的基础。

（1）方便编程；

（2）**信息共享**：分页系统中的“页”只是存放信息的物理单位（块），并无完整的意义，不便于实现共享；然而段却是信息的逻辑单位。由此可知，为了实现段的共享，希望存储器管理能与用户程序分段的组织方式相适应。

（3）信息保护；

（4）**动态增长**；

（5）**动态链接**。

　　分段管理方式和分页管理方式在实现思路上是很相似的，只不过他们的基本单位不同。分段有**段表**，也有**地址变换机构**，为了提高检索速度，同样增设**联想寄存器（具有并行查询能力的告诉缓冲寄存器）**。所以有些具体细节在这个不再赘述。

 

**分页和分段的主要区别：**

1、两者相似之处：两者**都采用离散分配方式，且都要通过地址映射机构来实现地址变换**。

2、两者不同之处：

（1）页是信息的**物理****单位**，分页是为实现离散分配方式，以消减内存的外零头，提高内存的利用率。或者说，分页仅仅是由于**系统管理的需要**而不是用户的需要。段则是信息的**逻辑单位**，它含有一组其意义相对完整的信息。**分段的目的是为了能更好地满足用户的需要**。

（2）**页的大小固定**且由系统决定，而**段的长度却不固定**。

（3）分页的作业地址空间是**一维**的，即单一的线性地址空间；而分段的作业地址空间则是**二维**的。

------

 

## **段页式存储管理方式**

　　前面所介绍的分页和分段存储管理方式都各有优缺点。**分页系统能有效地提高内存利用率，而分段系统则能很好地满足用户需求。**我们希望能够把两者的优点结合，于是出现了段页式存储管理方式。

　　段页式系统的基本原理，是分段和分页原理的结合，即**先将用户程序分成若干个段，再把每个段分成若干个页**，并为每一个段赋予一个段名。在段页式系统中，地址结构由段号、段内页号和页内地址三部分所组成。

　　和前两种存储管理方式相同，段页式存储管理方式同样需要增设联想寄存器。

　　**离散分配方式**基于将一个进程直接分散地分配到许多不相邻的分区中的思想，分为分页式存储管理，分段存储管理和段页式存储管理. 分页式存储管理旨在提高内存利用率，满足系统管理的需要，分段式存储管理则旨在满足用户(程序员)的需要，在实现共享和保护方面优于分页式存储管理，而段页式存储管理则是将两者结合起来，取长补短，即具有分段系统便于实现，可共享，易于保护，可动态链接等优点，又能像分页系统那样很好的解决外部碎片的问题，以及为各个分段可离散分配内存等问题，显然是一种比较有效的存储管理方式。



# [linux 用户空间与内核空间——高端内存详解](https://www.cnblogs.com/zlcxbb/p/5841417.html)



摘要：Linux 操作系统和驱动程序运行在内核空间，应用程序运行在用户空间，两者不能简单地使用指针传递数据，因为Linux使用的虚拟内存机制，用户空间的数据可能被换出，当内核空间使用用户空间指针时，对应的数据可能不在内存中。用户空间的内存映射采用段页式，而内核空间有自己的规则；本文旨在探讨内核空间的地址映射。



 

**Linux内核地址空间划分**

通常**32位Linux内核虚拟**地址空间划分0~3G为用户空间，3~4G为内核空间(注意，内核可以使用的线性地址只有1G)。注意这里是32位内核地址空间划分，64位内核地址空间划分是不同的。

![img](http://ilinuxkernel.com/wp-content/uploads/2011/09/091011_1614_Linux2.png)

1）线性地址空间：是指Linux系统中从0x00000000到0xFFFFFFFF整个4GB虚拟存储空间。

2）内核空间：内核空间表示运行在处理器最高级别的超级用户模式（supervisor mode）下的代码或数据，内核空间占用从0xC0000000到0xFFFFFFFF的1GB线性地址空间，内核线性地址空间由所有进程共享，但只有运行在内核态的进程才能访问，用户进程可以通过系统调用切换到内核态访问内核空间，进程运行在内核态时所产生的地址都属于内核空间。

3）用户空间：用户空间占用从0x00000000到0xBFFFFFFF共3GB的线性地址空间，每个进程都有一个独立的3GB用户空间，所以用户空间由每个进程独有，但是内核线程没有用户空间，因为它不产生用户空间地址。另外子进程共享（继承）父进程的用户空间只是使用与父进程相同的用户线性地址到物理内存地址的映射关系，而不是共享父进程用户空间。运行在用户态和内核态的进程都可以访问用户空间。

 

**Linux内核高端内存的由来**

当内核模块代码或线程访问内存时，代码中的内存地址都为逻辑地址，而对应到真正的物理内存地址，需要地址**一对一**的映射，如逻辑地址0xc0000003对应的物理地址为0×3，0xc0000004对应的物理地址为0×4，… …，逻辑地址与物理地址对应的关系为

物理地址 = 逻辑地址 – 0xC0000000：这是内核地址空间的地址转换关系，注意内核的虚拟地址在“高端”，但是ta映射的物理内存地址在低端。

| **逻辑地址**   | **物理内存地址**  |
| -------------- | ----------------- |
| 0xc0000000     | 0×0               |
| 0xc0000001     | 0×1               |
| 0xc0000002     | 0×2               |
| 0xc0000003     | 0×3               |
| …              | …                 |
| 0xe0000000     | 0×20000000        |
| …              | …                 |
| **0xffffffff** | **0×40000000 ??** |

假 设按照上述简单的地址映射关系，那么内核逻辑地址空间访问为0xc0000000 ~ 0xffffffff，那么对应的物理内存范围就为0×0 ~ 0×40000000，即只能访问1G物理内存。若机器中安装8G物理内存，那么内核就只能访问前1G物理内存，后面7G物理内存将会无法访问，因为内核 的地址空间已经全部映射到物理内存地址范围0×0 ~ 0×40000000。即使安装了8G物理内存，那么物理地址为0×40000001的内存，内核该怎么去访问呢？代码中必须要有内存逻辑地址 的，0xc0000000 ~ 0xffffffff的地址空间已经被用完了，所以无法访问物理地址0×40000000以后的内存。

显 然不能将内核地址空间0xc0000000 ~ 0xfffffff全部用来简单的地址映射。因此x86架构中将**内核地址空间**划分三部分：ZONE_DMA、ZONE_NORMAL和 ZONE_HIGHMEM。ZONE_HIGHMEM即为高端内存，这就是内存高端内存概念的由来。


在x86结构中，三种类型的区域（从3G开始计算）如下：

**ZONE_DMA**        内存开始的16MB

**ZONE_NORMAL**       16MB~896MB

**ZONE_HIGHMEM**       896MB ~ 结束（1G）

![img](http://ilinuxkernel.com/wp-content/uploads/2011/09/091011_1614_Linux3.png)

 

**Linux内核高端内存的理解**

前 面我们解释了高端内存的由来。 Linux将内核地址空间划分为三部分ZONE_DMA、ZONE_NORMAL和ZONE_HIGHMEM，高端内存HIGH_MEM地址空间范围为 0xF8000000 ~ 0xFFFFFFFF（896MB～1024MB）。那么如内核是**如何借助128MB高端内存地址空间是如何实现访问可以所有物理内存**？

当内核想访问高于896MB物理地址内存时，从0xF8000000 ~ 0xFFFFFFFF地址空间范围内找一段相应大小空闲的逻辑地址空间，借用一会。借用这段逻辑地址空间，建立映射到想访问的那段物理内存（即填充内核PTE页面表），**临时用一会，用完后归还**。这样别人也可以借用这段地址空间访问其他物理内存，实现了使用有限的地址空间，访问所有所有物理内存。如下图。

![img](http://ilinuxkernel.com/wp-content/uploads/2011/09/091011_1614_Linux4.png)

例 如内核想访问2G开始的一段大小为1MB的物理内存，即物理地址范围为0×80000000 ~ 0x800FFFFF。访问之前先找到一段1MB大小的空闲地址空间，假设找到的空闲地址空间为0xF8700000 ~ 0xF87FFFFF，用这1MB的逻辑地址空间映射到物理地址空间0×80000000 ~ 0x800FFFFF的内存。映射关系如下：

| **逻辑地址** | **物理内存地址** |
| ------------ | ---------------- |
| 0xF8700000   | 0×80000000       |
| 0xF8700001   | 0×80000001       |
| 0xF8700002   | 0×80000002       |
| …            | …                |
| 0xF87FFFFF   | 0x800FFFFF       |

当内核访问完0×80000000 ~ 0x800FFFFF物理内存后，就将0xF8700000 ~ 0xF87FFFFF内核线性空间释放。这样其他进程或代码也可以使用0xF8700000 ~ 0xF87FFFFF这段地址访问其他物理内存。

从上面的描述，我们可以知道**高端内存的最基本思想**：借一段地址空间，建立临时地址映射，用完后释放，达到这段地址空间可以循环使用，访问所有物理内存。

看到这里，不禁有人会问：万一有内核进程或模块一直占用某段逻辑地址空间不释放，怎么办？若真的出现的这种情况，则内核的高端内存地址空间越来越紧张，若都被占用不释放，则没有建立映射到物理内存都无法访问了。



**Linux内核高端内存的划分**
内核将高端内存划分为3部分：VMALLOC_START~VMALLOC_END、KMAP_BASE~FIXADDR_START和FIXADDR_START~4G。

![img](http://ilinuxkernel.com/wp-content/uploads/2011/09/091011_1614_Linux5.png)


对 于高端内存，可以通过 alloc_page() 或者其它函数获得对应的 page，但是要想访问实际物理内存，还得把 page 转为线性地址才行（为什么？想想 MMU 是如何访问物理内存的），也就是说，我们需要为高端内存对应的 page 找一个线性空间，这个过程称为高端内存映射。

对应高端内存的3部分，高端内存映射有三种方式：
**映射到”内核动态映射空间”（noncontiguous memory allocation）**
这种方式很简单，因为通过 vmalloc() ，在”内核动态映射空间”申请内存的时候，就可能从高端内存获得页面（参看 vmalloc 的实现），因此说高端内存有可能映射到”内核动态映射空间”中。

**持久内核映射（permanent kernel mapping）**
如果是通过 alloc_page() 获得了高端内存对应的 page，如何给它找个线性空间？
内核专门为此留出一块线性空间，从 PKMAP_BASE 到 FIXADDR_START ，用于映射高端内存。在 2.6内核上，这个地址范围是 4G-8M 到 4G-4M 之间。这个空间起叫”内核永久映射空间”或者”永久内核映射空间”。这个空间和其它空间使用同样的页目录表，对于内核来说，就是 swapper_pg_dir，对普通进程来说，通过 CR3 寄存器指向。通常情况下，这个空间是 4M 大小，因此仅仅需要一个页表即可，内核通过来 pkmap_page_table 寻找这个页表。通过 kmap()，可以把一个 page 映射到这个空间来。由于这个空间是 4M 大小，最多能同时映射 1024 个 page。因此，对于不使用的的 page，及应该时从这个空间释放掉（也就是解除映射关系），通过 kunmap() ，可以把一个 page 对应的线性地址从这个空间释放出来。

**临时映射（temporary kernel mapping）**
内核在 FIXADDR_START 到 FIXADDR_TOP 之间保留了一些线性空间用于特殊需求。这个空间称为”固定映射空间”在这个空间中，有一部分用于高端内存的临时映射。

这块空间具有如下特点：
（1）每个 CPU 占用一块空间
（2）在每个 CPU 占用的那块空间中，又分为多个小空间，每个小空间大小是 1 个 page，每个小空间用于一个目的，这些目的定义在 kmap_types.h 中的 km_type 中。

当要进行一次临时映射的时候，需要指定映射的目的，根据映射目的，可以找到对应的小空间，然后把这个空间的地址作为映射地址。这意味着一次临时映射会导致以前的映射被覆盖。通过 kmap_atomic() 可实现临时映射。



**常见问题：**

1、用户空间（进程）是否有高端内存概念？

用户进程没有高端内存概念。只有在内核空间才存在高端内存。用户进程最多只可以访问3G物理内存，而内核进程可以访问所有物理内存。

 

2、64位内核中有高端内存吗？

目前现实中，64位Linux内核不存在高端内存，因为64位内核可以支持超过512GB内存。若机器安装的物理内存超过内核地址空间范围，就会存在高端内存。

 

3、用户进程能访问多少物理内存？内核代码能访问多少物理内存？

32位系统用户进程最大可以访问3GB，内核代码可以访问所有物理内存。

64位系统用户进程最大可以访问超过512GB，内核代码可以访问所有物理内存。

 

4、高端内存和物理地址、逻辑地址、线性地址的关系？

高端内存只和逻辑地址有关系，和逻辑地址、物理地址没有直接关系。

 

5、为什么不把所有的地址空间都分配给内核？

若把所有地址空间都给内存，那么用户进程怎么使用内存？怎么保证内核使用内存和用户进程不起冲突？

（1）让我们忽略Linux对段式内存映射的支持。 在保护模式下，我们知道无论CPU运行于用户态还是核心态，CPU执行程序所访问的地址都是虚拟地址，MMU 必须通过读取控制寄存器CR3中的值作为当前页面目录的指针，进而根据分页内存映射机制（参看相关文档）将该虚拟地址转换为真正的物理地址才能让CPU真 正的访问到物理地址。

（2）对于32位的Linux，其每一个进程都有4G的寻址空间，但当一个进程访问其虚拟内存空间中的某个地址时又是怎样实现不与其它进程的虚拟空间混淆 的呢？每个进程都有其自身的页面目录PGD，Linux将该目录的指针存放在与进程对应的内存结构task_struct.(struct mm_struct)mm->pgd中。每当一个进程被调度（schedule()）即将进入运行态时，Linux内核都要用该进程的PGD指针设 置CR3（switch_mm()）。

（3）当创建一个新的进程时，都要为新进程创建一个新的页面目录PGD，并从内核的页面目录swapper_pg_dir中复制内核区间页面目录项至新建进程页面目录PGD的相应位置，具体过程如下：
do_fork() --> copy_mm() --> mm_init() --> pgd_alloc() --> set_pgd_fast() --> get_pgd_slow() --> memcpy(&PGD + USER_PTRS_PER_PGD, swapper_pg_dir + USER_PTRS_PER_PGD, (PTRS_PER_PGD - USER_PTRS_PER_PGD) * sizeof(pgd_t))
这样一来，每个进程的页面目录就分成了两部分，第一部分为“用户空间”，用来映射其整个进程空间（0x0000 0000－0xBFFF FFFF）即3G字节的虚拟地址；第二部分为“系统空间”，用来映射（0xC000 0000－0xFFFF FFFF）1G字节的虚拟地址。可以看出Linux系统中每个进程的页面目录的第二部分是相同的，所以从进程的角度来看，每个进程有4G字节的虚拟空间， 较低的3G字节是自己的用户空间，最高的1G字节则为与所有进程以及内核共享的系统空间。

（4）现在假设我们有如下一个情景：
在进程A中通过系统调用sethostname(const char *name,seze_t len)设置计算机在网络中的“主机名”.
在该情景中我们势必涉及到从用户空间向内核空间传递数据的问题，name是用户空间中的地址，它要通过系统调用设置到内核中的某个地址中。让我们看看这个 过程中的一些细节问题：系统调用的具体实现是将系统调用的参数依次存入寄存器ebx,ecx,edx,esi,edi（最多5个参数，该情景有两个 name和len），接着将系统调用号存入寄存器eax，然后通过中断指令“int 80”使进程A进入系统空间。由于进程的CPU运行级别小于等于为系统调用设置的陷阱门的准入级别3，所以可以畅通无阻的进入系统空间去执行为int 80设置的函数指针system_call()。由于system_call()属于内核空间，其运行级别DPL为0，CPU要将堆栈切换到内核堆栈，即 进程A的系统空间堆栈。我们知道内核为新建进程创建task_struct结构时，共分配了两个连续的页面，即8K的大小，并将底部约1k的大小用于 task_struct（如#define alloc_task_struct() ((struct task_struct *) __get_free_pages(GFP_KERNEL,1))）,而其余部分内存用于系统空间的堆栈空间，即当从用户空间转入系统空间时，堆栈指针 esp变成了（alloc_task_struct()+8192），这也是为什么系统空间通常用宏定义current（参看其实现）获取当前进程的 task_struct地址的原因。每次在进程从用户空间进入系统空间之初，系统堆栈就已经被依次压入用户堆栈SS、用户堆栈指针ESP、EFLAGS、 用户空间CS、EIP，接着system_call()将eax压入，再接着调用SAVE_ALL依次压入ES、DS、EAX、EBP、EDI、ESI、 EDX、ECX、EBX，然后调用sys_call_table+4*%EAX，本情景为sys_sethostname()。

（5）在sys_sethostname()中，经过一些保护考虑后，调用copy_from_user(to,from,n），其中to指向内核空间 system_utsname.nodename，譬如0xE625A000，from指向用户空间譬如0x8010FE00。现在进程A进入了内核，在 系统空间中运行，MMU根据其PGD将虚拟地址完成到物理地址的映射，最终完成从用户空间到系统空间数据的复制。准备复制之前内核先要确定用户空间地址和 长度的合法性，至于从该用户空间地址开始的某个长度的整个区间是否已经映射并不去检查，如果区间内某个地址未映射或读写权限等问题出现时，则视为坏地址， 就产生一个页面异常，让页面异常服务程序处理。过程如 下：copy_from_user()->generic_copy_from_user()->access_ok()+__copy_user_zeroing().

（6）小结：
*进程寻址空间0~4G  
*进程在用户态只能访问0~3G，只有进入内核态才能访问3G~4G  
*进程通过系统调用进入内核态
*每个进程虚拟空间的3G~4G部分是相同的  
*进程从用户态进入内核态不会引起CR3的改变但会引起堆栈的改变



Linux 简化了分段机制，使得虚拟地址与线性地址总是一致，因此，Linux的虚拟地址空间也为0～4G。Linux内核将这4G字节的空间分为两部分。将最高的 1G字节（从虚拟地址0xC0000000到0xFFFFFFFF），供内核使用，称为“内核空间”。而将较低的3G字节（从虚拟地址 0x00000000到0xBFFFFFFF），供各个进程使用，称为“用户空间）。因为每个进程可以通过系统调用进入内核，因此，Linux内核由系统 内的所有进程共享。于是，从具体进程的角度来看，每个进程可以拥有4G字节的虚拟空间。
    Linux使用两级保护机制：0级供内核使用，3级供用户程序使用。从图中可以看出（这里无法表示图），每个进程有各自的私有用户空间（0～3G），这个空间对系统中的其他进程是不可见的。最高的1GB字节虚拟内核空间则为所有进程以及内核所共享。
1．虚拟内核空间到物理空间的映射
  内核空间中存放的是内核代码和数据，而进程的用户空间中存放的是用户程序的代码和数据。不管是内核空间还是用户空间，它们都处于虚拟空间中。读者会问，系 统启动时，内核的代码和数据不是被装入到物理内存吗？它们为什么也处于虚拟内存中呢？这和编译程序有关，后面我们通过具体讨论就会明白这一点。
虽 然内核空间占据了每个虚拟空间中的最高1GB字节，但映射到物理内存却总是从最低地址（0x00000000）开始。对内核空间来说，其地址映射是很简单 的线性映射，0xC0000000就是物理地址与线性地址之间的位移量，在Linux代码中就叫做PAGE_OFFSET。


我们来看一下在include/asm/i386/page.h中对内核空间中地址映射的说明及定义：
```c
/*
* This handles the memory map.. We could make this a config
* option, but too many people screw it up, and too few need
* it.
*
* A __PAGE_OFFSET of 0xC0000000 means that the kernel has
* a virtual address space of one gigabyte, which limits the
* amount of physical memory you can use to about 950MB. 
*
* If you want more physical memory than this then see the CONFIG_HIGHMEM4G
* and CONFIG_HIGHMEM64G options in the kernel configuration.
*/

#define __PAGE_OFFSET           (0xC0000000)
……
#define PAGE_OFFSET             ((unsigned long)__PAGE_OFFSET)
#define __pa(x)                 ((unsigned long)(x)-PAGE_OFFSET)
#define __va(x)                 ((void *)((unsigned long)(x)+PAGE_OFFSET))
```
源 代码的注释中说明，如果你的物理内存大于950MB，那么在编译内核时就需要加CONFIG_HIGHMEM4G和CONFIG_HIGHMEM64G选 项，这种情况我们暂不考虑。如果物理内存小于950MB，则对于内核空间而言，给定一个虚地址x，其物理地址为“x- PAGE_OFFSET”，给定一个物理地址x，其虚地址为“x+ PAGE_OFFSET”。
这里再次说明，宏__pa()仅仅把一个内核空间的虚地址映射到物理地址，而决不适用于用户空间，用户空间的地址映射要复杂得多。
2．内核映像
  在下面的描述中，我们把内核的代码和数据就叫内核映像（kernel image）。当系统启动时，Linux内核映像被安装在物理地址0x00100000开始的地方，即1MB开始的区间(第1M留作它用)。然而，在正常 运行时， 整个内核映像应该在虚拟内核空间中，因此，连接程序在连接内核映像时，在所有的符号地址上加一个偏移量PAGE_OFFSET，这样，内核映像在内核空间 的起始地址就为0xC0100000。
例如，进程的页目录PGD（属于内核数据结构）就处于内核空间中。在进程切换时，要将寄存器CR3设置成指 向新进程的页目录PGD，而该目录的起始地址在内核空间中是虚地址，但CR3所需要的是物理地址，这时候就要用__pa()进行地址转换。在 mm_context.h中就有这么一行语句：
asm volatile(“movl %0,%%cr3”: :”r” (__pa(next-&gt;pgd));
这是一行嵌入式汇编代码，其含义是将下一个进程的页目录起始地址next_pgd，通过__pa()转换成物理地址，存放在某个寄存器中，然后用mov指令将其写入CR3寄存器中。经过这行语句的处理，CR3就指向新进程next的页目录表PGD了。

 



# 线程可以共享进程里的哪些资源



线程**共享**的环境包括：**进程代码段**、**进程的公有数据**(利用这些共享的数据，线程很容易的实现相互之间的通讯)、**进程打开的文件描述符**、**信号的处理器**、**进程的当前目录**和**进程用户ID**与**进程组ID**。

 

**非共享**的包括：**线程ID，寄存器组的值，线程的堆栈，错误返回码， 线程的信号屏蔽码， 线程的优先级**



# 并发和并行的区别



所有的并发处理都有排队等候，唤醒，执行至少三个这样的步骤.所以并发肯定是宏观概念，在微观上他们都是序列被处理的，只不过资源不会在某一个上被阻塞 (一般是通过时间片轮转)，所以在宏观上看多个几乎同时到达的请求同时在被处理。如果是同一时刻到达的请求也会根据优先级的不同，而先后进入队列排队等候 执行。

并发与并行是两个既相似而又不相同的概念：并发性，又称共行性，是指能处理多个同时性活动的能力；**并行是指同时发生的两个并发事件，具有并发的含义，而并发则不一定并行，也亦是说并发事件之间不一定要同一时刻发生**。

**并发的实质是一个物理CPU(也可以多个物理CPU) 在若干道程序之间多路复用，并发性是对有限物理资源强制行使多用户共享以提高效率。**

**并行性指两个或两个以上事件或活动在同一时刻发生。在多道程序环境下，并行性使多个程序同一时刻可在不同CPU上同时执行。**

 

![img](https://images2015.cnblogs.com/blog/609046/201608/609046-20160809185916168-581222779.jpg)

并发，是在**同一个cpu**上同时（不是真正的同时，而是看来是同时，因为cpu要在多个程序间切换）运行多个程序。

![img](https://images2015.cnblogs.com/blog/609046/201608/609046-20160809185927496-1309008591.jpg)

并行，是**每个cpu**运行一个程序。

 

打个比方。并发，就像一个人（cpu）喂2个孩子（程序），轮换着每人喂一口，表面上两个孩子都在吃饭。并行，就是2个人喂2个孩子，两个孩子也同时在吃饭。





# 缓冲区溢出以及缓冲区溢出攻击



缓冲区溢出是指当计算机程序向缓冲区内填充的数据位数超过了缓冲区本身的容量。溢出的数据覆盖在合法数据上。理想情况是，程序检查数据长度并且不允许输入超过缓冲区长度的字符串。但是绝大多数程序都会假设数据长度总是与所分配的存储空间相匹配，这就为缓冲区溢出埋下隐患。

操作系统所使用的缓冲区又被称为堆栈，在各个操作进程之间，指令被临时存储在堆栈当中，堆栈也会出现缓冲区溢出。 当一个超长的数据进入到缓冲区时，超出部分就会被写入其他缓冲区，其他缓冲区存放的可能是数据、下一条指令的指针，或者是其他程序的输出内容，这些内容都被覆盖或者破坏掉。可见一小部分数据或者一套指令的溢出就可能导致一个程序或者操作系统崩溃。

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
    #include <stdio.h>  
    #include <string.h>  
    #include <iostream>  
      
    using namespace std;  
      
    int main(int argc, char *argv[])  
    {  
        char buf[10];  
        strcpy(buf, argv[1]);  
        cout<<buf;  
        return 0;  
    }  
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

连续输入20个字符就产生了溢出。

C语言常用的strcpy、sprintf、strcat 等函数都非常容易导致缓冲区溢出问题。

程序运行时，其内存里面一般都包含这些部分：

(1)程序参数和程序环境；

(2)**程序堆栈(****堆栈则比较特殊，主要是在调用函数时来****保存现场，以便函数返回之后能继续运行****)，它通常在程序执行时增长，一般情况下，它向下朝堆增长**。

(3)堆，它也在程序执行时增长，相反，它向上朝堆栈增长；

(4)BSS 段，它包含未初始化的全局可用的数据（例如，全局变量）；

(5)数据段，它包含初始化的全局可用的数据（通常是全局变量）；

(6)文本段，它包含只读程序代码。 

BSS、数据和文本段组成静态内存：在程序运行之前这些段的大小已经固定。程序运行时虽然可以更改个别变量，但不能将数据分配到这些段中。

以下面的程序为例：

 

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
    #include <stdio.h>  
      
    char buf[3] = "abc";  
    int i;  
      
    int main()  
    {  
        i = 1;  
        return 0;  
    }  
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

其中，**i属于BBS段，而buf属于数据段。两者都属于静态内存**，因为他们在程序中虽然可以改变值，但是其分配的内存大小是固定的，如buf的数据大于三个字符，将会覆盖其他数据。 

**与静态内存形成对比，堆和堆栈是动态的，可以在程序运行的时候改变大小**。堆的程序员接口因语言而异。在C语言中，堆是经由malloc()和其它相关函数来访问的，而C++中的new运算符则是堆的程序员接口。**堆栈则比较特殊，主要是在调用函数时来****保存现场，以便函数返回之后能继续运行。**

 

------

 

缓冲区溢出攻击

------

缓冲区溢出攻击简单介绍：

缓冲区溢出的一个致命的使用就是**让程序执行它本来不愿意执行的函数**。这是一种常见的通过计算机网络攻击系统安全的方法。通常，**输入给程序一个字符串，这个字符串包含一些可执行代码的字节编码，成为攻击代码**。另外，还有一些字节会**用一个指向攻击代码的指针覆盖返回地址**。那么，**执行ret指令的效果就是跳转到攻击代码**。My god, 黑客顺利侵入。

 

一种攻击形式，攻击代码会使用系统调用启动一个外壳程序，给攻击者提供一组操作系统函数。

另一种攻击形式，攻击代码会执行一些未授权的任务，修复对栈的破坏，然后第二次执行ret指令，（表面上正常返回给调用者）。

------

那么如何防护/对抗缓冲区溢出攻击？

（1）**栈随机化（主要受linux系统版本限制，老版本不支持栈随机化）：使得栈的位置在程序每次运行时都有变化**。为了在系统插入攻击代码，攻击者不但要插入代码，**还需要插入指向这段代码的指针（指向攻击代码的首地址/栈地址）**，这个指针也是攻击字符串的一部分。产生这个指针需要知道这个字符串放置的栈地址。老的系统版本，如果在相同的系统运行相同的程序，栈的位置是相当固定的。所以黑客可以在一台机器上研究透系统上的栈是如何分配地址的，就可以入侵其它主机。

**实现的方式**：程序开始时，在栈上分配一段**0~n字节之间**的**随机**大小的空间。分配的范围n必须足够大，才能获得足够多样的栈地址变化，但是又要足够小，不至于浪费程序太多的空间。**t****radeoff**。

 

（2）**栈破坏检测（主要受GCC版本的限制，老的GCC版本不支持栈破坏检测）：检测到何时栈被破坏**。从strcpy等函数我们可以看到，破坏通常发生在当超越局部缓冲区的边界时。在C语言中，**没有可靠的方法来防止对数组的越界写**。但是，我们能够在发生了越界写的时候，并且，在其还没有造成任何有害结果之前，尝试检测到它，并且把程序终止。

**实现的方式**：**金丝雀，加入一种栈保护机制**。 在栈帧中，紧接着局部缓冲区的位置放置一个哨兵（金丝雀），哨兵值是随机产生的，攻击者没有简单的方法能够知道它是什么。在恢复寄存器状态和函数返回之 前，程序检查这个金丝雀的值是否发生改变，如果发生改变立即终止程序。《深入理解操作系统》P182页，有一个特别好的例子。

 

（3）**限制可执行代码区域（主要受硬件版本的限制，需要硬件支持）**：消除攻击者向系统插入可执行代码的能力，一种方法是：限制那些能够存放可执行代码的存储器区域。在典型的系统中，**只有保存编译器产生的代码的那部分存储器才需要是可执行的，其它部分可以被限制为只允许读和写。**

一般的系统允许三种访问的形式：**读（从存储器读数据）、写（存储数据到存储器）和执行（将存储器的内容看作是机器级代码）**。以前，**x86体系结构将读和执行访问控制合并为1位的标志**，这样任何被标记为可读的页都是可执行的。栈又要求必须是既可以读又可以写的，所以x86体系结构栈上的字节都是可执行的。也有一些体制，能够限制一些页是可读但是不可执行，但是这些体制一般都会带来严重的性能损失。

**实现的方式**：AMD为它的64位存储器的内容保护引入了“NX”（No-eXecute，不执行）位，将读和执行访问模式分开，intel也跟进了。从这开始，栈可以被标记为可读、可写，但是不可执行。**检查页是否可执行由硬件来完成，效率上没有损失。**



# 函数调用与系统调用的区别



 

 

| 函数库调用                                      | 系统调用                                           |
| ----------------------------------------------- | -------------------------------------------------- |
| 在所有的ANSI C编译器版本中，C库函数是**相同**的 | 各个操作系统的系统调用是**不同**的                 |
| 它调用**函数库**中的一段程序（或函数）          | 它调用**系统内核**的服务                           |
| 与**用户程序**相联系                            | 是**操作系统**的一个入口点                         |
| **在用户地址空间执行**                          | **在内核地址空间执行**                             |
| 它的运行时间属于“**用户时间**”                  | 它的运行时间属于“**系统时间**”                     |
| 属于**过程调用，调用开销较小**                  | 需要在**用户空间和内核上下文环境间切换，开销较大** |
| 在C函数库libc中有大约300个函数                  | 在UNIX中大约有90个系统调用                         |
| 典型的C函数库调用：system fprintf malloc        | 典型的系统调用：chdir fork write brk；             |



# [函数调用过程栈帧变化详解](https://www.cnblogs.com/zlcxbb/p/5759776.html)




函数调用另一个词语表示叫作**过程**。一个过程调用包括将**数据（以过程参数和返回值的形式）**和**控制**从代码的一部分传递到另一部分。另外，它还必须在进入时为过程的局部变量分配空间，并在退出时释放这些空间。

 

大多数机器，包括IA32,只提供转移控制到过程和从过程中转移出控制这种简单的指令。**数据传递、局部变量的分配和释放通过操纵程序栈来实现。**

 

在了解本文章之前，您需要先对程序的进程空间有所了解，即对进程如何使用内存？如果你知道这些，下面的内 容将是很easy的事情了。为了您的回顾还是将简单的分布图贴出来，便于您的回顾。

![img](https://images2015.cnblogs.com/blog/609046/201608/609046-20160811093750949-1069261245.jpg)

我们先来了解一个概念，栈帧(stack frame)，机器用栈来**传递过程参数，存储返回信息，保存寄存器用于以后恢复，以及本地存储**。为单个过程(函数调用)分配的那部分栈称为栈帧。**栈帧其实 是两个指针寄存器，寄存器%ebp为帧指针（指向该栈帧的最底部），而寄存器%esp为栈指针****（指向该栈帧的最顶部）****，当程序运行时，栈指针可以移动(大多数的信息的访问都是通过帧指针的，换句话说，就是如果该栈存在，%ebp帧指针是不移动的，访问栈里面的元素可以用-4(%ebp）或者8(%ebp)访问%ebp指针下面或者上面的元素)。**总之简单 一句话，栈帧的主要作用是用来控制和保存一个过程的所有信息的。栈帧结构如下所示：

![img](https://images2015.cnblogs.com/blog/609046/201608/609046-20160811093847590-1225480550.jpg)

![img](file:///C:/Users/DDliu/AppData/Local/Temp/enhtmlclip/Image(7).jpg)

**此处注意：这里面有一个错误，即：“保存的寄存器、局部变量和临时值”处应该是ebp-4。**

**栈是从高地址向低地址存储。所以越是低的地址，越是靠后入栈。**

如果你已经对这个图已经非常了解了，那么就没有必要再看下去了。因为下面的内容都是对这幅图的讲解。

　　假设过程P（调用者）调用过程Q（被调用者），则Q的参数放在P的栈帧中。另外，当P调用Q时，P中的返回地址被压入栈中，形成P的栈帧的末尾 （返回地址就是当程序从Q返回时应该继续执行的地方）。Q的栈帧从保存的帧指针的值开始，后面到新的栈指针之间就是该过程的部分了。

　　过程实例讲解：

下面以这个程序为例进行简要说明函数调用的基本过程。

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
int swap_add(int* xp,int* yp) {
    int x = *xp;
    int y = *yp;
    *xp = y;
    *yp = x;
    return x+y;
}
int caller(){
    int arg1 = 534;
    int arg2 = 1057;
    int sum = swap_add(&arg1,&arg2);
    int diff = arg1 - arg2;
    
    return sum * diff;
} 
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

 

经过汇编之后caller部分的代码如下：

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
caller:
    pushl %ebp   //保存%ebp 
    movl %esp,%ebp    //设置新的帧指针为旧的栈指针
    subl $24,%esp  //分配24子节的栈空间
    movl $534,-4(%ebp) //设置arg1=534
    movl $1057,-8(%ebp) //设置arg2=1057
    leal -8(%ebp),%eax //计算&arg2
    movl %eax,4(%esp) //将&arg2存入栈中
    leal -4(%ebp),%eax //计算&arg1
    movl %eax,(%esp) //将&arg1存入栈中
    call swap_add //调用swap_add-------------------》过程调用
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

这段代码先保存了%ebp的一个副本，将新的过程（该函数的ebp）的ebp设置为栈帧的开始位置。然后将栈指针减去24，从而在栈上分配了24字 节的空间（你应该思考一下为什么是24字节），然后是初始化两个局部变量，计算两个局部变量的地址并存入栈中，形成了函数swap_add的参数。将这些 参数存储到相对于栈指针偏移量为0和+4的地方，留待稍后的swap_add调用访问。然后调用swap_add.

接下的代码是swap_add的函数部分：

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
swap_add:
    pushl %ebp //save old %ebp
    movl %esp,%ebp  //set %ebp as frame pointer
    pushl %ebx     //save %ebx
     
    movl 8(%ebp),%edx   //Get xp
    movl 12(%ebp),%ecx   //Get yp
    movl (%edx),%ebx   //Get x
    movl (%ecx),%eax    //Get u
    movl %eax,(%edx)    //Store y as xp
    movl %ebx,(%ecx)      //Sotre x as yp
    addl %ebx,%eax         //return value = x + y
     
    popl %ebx        //restore  %ebx
    popl %ebp        //restore %ebp
    ret        //从过程调用中返回, 将控制转移回caller
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

代码分为3部分 建立部分：

初始化栈帧

；主体部分：

执行过程的实体计算

；结束部分：

回复栈帧的状态，以及过程返回

。这一部分的代码比较简单，就不在一一介绍，根据以上的3 部分，划分的已经很清晰了。(说明一点程序在执行到swap_add的代码之前，也就是在执行call语句已经把返回地址压入栈中)值得注意的是最后一部 分的popl %ebx   popl %ebp。它的作用是恢复了之前存储的栈帧指针的值，也就是调用程序的原始栈帧指针。从而程序就可以得到返回(有些细心的人会问那返回值咋么办？呵呵，

返 回值是存入了%eax中

，在接下来的调用程序caller中直接访问该寄存器就可以了)。

 

**正如前面所讲的那样，栈向低地址方向增长，而栈指针%esp指向栈顶元素，可以利用pushl将数据存入栈中并利用popl指令从栈中取出。将栈指针的值减小适当的值可以分配没有指定初始值的数据的空间，例如：**subl $24,%esp**。类似的，通过增加栈指针来释放空间。**

下面就是返回之后继续执行的部分代码了：

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
movl -4(%ebp),%edx
subl -8(%ebp),%edx
imull %edx,%eax   //为了计算diff, 
leave          //为返回准备栈，GCC 产生的代码有时候会使用leave指令来释放栈帧，
　　　　　　　　 //而有时会使用一个或者两个popl指令。两个方法都可行。
ret             //从过程调用中返回
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

 为了计算diff，从栈中取出arg1,和arg2的值，并将寄存器%eax当做swap_add的返回值。

整个过程的栈变化如下所示：

![img](https://images2015.cnblogs.com/blog/609046/201608/609046-20160811094146043-721266853.jpg)





# 字节对齐问题



文章最后本人做了一幅图，一看就明白了，这个问题网上讲的不少，但是都没有把问题说透。

32位机器上各种数据类型的长度如下:
char:1(有符号无符号同) 
short:2(有符号无符号同) 
int:4(有符号无符号同) 
long:4(有符号无符号同) 
float:4 double:8

　　一、概念 
　　 
　　 对齐跟数据在内存中的位置有关。如果一个**变量的内存地址正好位于它长度的整数倍**，他就被称做**自然对齐**。比如在32位cpu下，假设一个整型变量的地址为0x00000004，那它就是自然对齐的。
　　 
　　二、为什么要字节对齐
　　 
　　 需要字节对齐的根本原因在于CPU访问数据的效率问题。假设上面整型变量的地址不是自然对齐，比如为0x00000002，则CPU如果取它的值的话需要访问两次内存，第一次取从0x00000002-0x00000003的一个short，第二次取从0x00000004-0x00000005的一个short然后组合得到所要的数据，如果变量在0x00000003地址上的话则要访问三次内存，第一次为char，第二次为short，第三次为char，然后组合得到整型数据。而如果变量在自然对齐位置上，则只要一次就可以取出数据。一些系统对对齐要求非常严格，比如sparc系统，如果取未对齐的数据会发生错误，举个例：
　　 
　　char ch[8];
　　char *p = &ch[1];
　　int i = *(int *)p;
　　 
　　
　　运行时会报segment error，而在x86上就不会出现错误，只是效率下降。
　　
　　三、正确处理字节对齐
　　
　　 对于标准数据类型，它的地址只要是它的长度的整数倍就行了，而非标准数据类型按下面的原则对齐：
　　
　　数组 ：按照**基本数据类型**对齐，第一个对齐了后面的自然也就对齐了。 
　　联合 ：按其包含的**长度最大的数据类型**对齐。 
　　结构体： 结构体中**每个数据类型**都要对齐。
　　比如有如下一个结构体：
　　
　　struct stu{
　　 char sex;
　　 int length;
　　 char name[10];
　　};
　　struct stu my_stu;
　　 
　　
　　由于**在x86下，GCC默认按4字节对齐**，它会在sex后面跟name后面分别填充三个和两个字节使length和整个结构体对齐。于是我们sizeof(my_stu)会得到长度为20，而不是15.
　　
　　四、__attribute__选项
　　
　　我们可以按照自己设定的对齐大小来编译程序，GNU使用__attribute__选项来设置，比如我们想让刚才的结构按一字节对齐，我们可以这样定义结构体
　　
　　struct stu{
　　 char sex;
　　 int length;
　　 char name[10];
　　}__attribute__ ((aligned (1))); 
　　
　　struct stu my_stu;
　　 
　　
　　则sizeof(my_stu)可以得到大小为15。
　　
　　上面的定义等同于
　　
　　struct stu{
　　 char sex;
　　 int length;
　　 char name[10];
　　}__attribute__ ((packed)); 
　　struct stu my_stu;
　　 
　　
　　__attribute__((packed))得变量或者结构体成员使用最小的对齐方式，即对变量是一字节对齐，对域（field）是位对齐.
　　
　　五、什么时候需要设置对齐
　　
　　 在设计不同CPU下的通信协议时，或者编写硬件驱动程序时寄存器的结构这两个地方都需要按一字节对齐。即使看起来本来就自然对齐的也要使其对齐，以免不同的编译器生成的代码不一样.

 

一、快速理解

\1. 什么是字节对齐？

在C语言中，结构是一种复合数据类型，其构成元素既可以是基本数据类型（如int、long、float等）的变量，也可以是一些复合数据类型（如数组、结构、联合等）的数据单元。在结构中，编译器为结构的每个成员按其自然边界（alignment）分配空间。各个成员按照它们被声明的顺序在内存中顺序存储，第一个成员的地址和整个结构的地址相同。

**为了使CPU能够对变量进行快速的访问,变量的起始地址应该具有某些特性,即所谓的”对齐”**. 比如4字节的int型,其起始地址应该位于4字节的边界上,即起始地址能够被4整除.

\2. 字节对齐有什么作用？

字节对齐的作用不仅是**便于cpu快速访问**，同时合理的利用字节对齐可以有效地**节省存储空间**。

对于32位机来说，4字节对齐能够使cpu访问速度提高，比如说一个long类型的变量，如果跨越了4字节边界存储，那么cpu要读取两次，这样效率就低了。但是在32位机中使用1字节或者2字节对齐，反而会使变量访问速度降低。所以这要考虑处理器类型，另外还得考虑编译器的类型。在vc中默认是4字节对齐的，GNU gcc 也是默认4字节对齐。

\3. 更改C编译器的缺省字节对齐方式

在缺省情况下，C编译器为每一个变量或是数据单元按其自然对界条件分配空间。一般地，可以通过下面的方法来改变缺省的对界条件：
· 使用伪指令#pragma pack (n)，C编译器将按照n个字节对齐。
· 使用伪指令#pragma pack ()，取消自定义字节对齐方式。

另外，还有如下的一种方式：
· __attribute((aligned (n)))，让所作用的结构成员对齐在n字节自然边界上。如果结构中有成员的长度大于n，则按照最大成员的长度来对齐。
· __attribute__ ((packed))，取消结构在编译过程中的优化对齐，按照实际占用字节数进行对齐。

\4. 举例说明

例1

struct test
{
char x1;
short x2;
float x3;
char x4;
};

由于编译器默认情况下会对这个struct作自然边界（有人说“自然对界”我觉得边界更顺口）对齐，结构的第一个成员x1，其偏移地址为0，占据了第1个字节。第二个成员x2为short类型，其起始地址必须2字节对界，因此，编译器在x2和x1之间填充了一个空字节。结构的第三个成员x3和第四个成员x4恰好落在其自然边界地址上，在它们前面不需要额外的填充字节。在test结构中，成员x3要求4字节对界，是该结构所有成员中要求的最大边界单元，因而test结构的自然对界条件为4字节，编译器在成员x4后面填充了3个空字节。整个结构所占据空间为12字节。

例2

\#pragma pack(1) //让编译器对这个结构作1字节对齐
struct test
{
char x1;
short x2;
float x3;
char x4;
};
\#pragma pack() //取消1字节对齐，恢复为默认4字节对齐

这时候sizeof(struct test)的值为8。

例3

\#define GNUC_PACKED __attribute__((packed))
struct PACKED test
{
char x1;
short x2;
float x3;
char x4;
}GNUC_PACKED;

这时候sizeof(struct test)的值仍为8。

二、深入理解

什么是字节对齐,为什么要对齐?
TragicJun 发表于 2006-9-18 9:41:00 现代**计算机中内存空间都是按照byte划分的，从理论上讲似乎对任何类型的变量的访问可以从任何地址开始，但实际情况是在访问特定类型变量的时候经常在特定的内存地址访问，这就需要各种类型数据按照一定的规则在空间上排列，而不是顺序的一个接一个的排放，这就是对齐**。
对齐的作用和原因：各个硬件平台对存储空间的处理上有很大的不同。**一些平台对某些特定类型的数据只能从某些特定地址开始存取**。比如有些架构的CPU在访问一个没有进行对齐的变量的时候会发生错误,那么在这种架构下编程必须保证字节对齐.其他平台可能没有这种情况，但是最常见的是如果不按照适合其平台要求对数据存放进行对齐，会在存取效率上带来损失。**比如有些平台每次读都是从偶地址开始**，如果一个int型（假设为32位系统）如果存放在偶地址开始的地方，那么一个读周期就可以读出这32bit，而如果存放在奇地址开始的地方，就需要2个读周期，并对两次读出的结果的高低字节进行拼凑才能得到该32bit数据。显然在读取效率上下降很多。
二.字节对齐对程序的影响:

先让我们看几个例子吧(32bit,x86环境,gcc编译器):
设结构体如下定义：
struct A
{
int a;
char b;
short c;
};
struct B
{
char b;
int a;
short c;
};
现在已知32位机器上各种数据类型的长度如下:
char:1(有符号无符号同) 
short:2(有符号无符号同) 
int:4(有符号无符号同) 
long:4(有符号无符号同) 
float:4 double:8
那么上面两个结构大小如何呢?
结果是:
sizeof(strcut A)值为8
sizeof(struct B)的值却是12

结构体A中包含了4字节长度的int一个，1字节长度的char一个和2字节长度的short型数据一个,B也一样;按理说A,B大小应该都是7字节。
之所以出现上面的结果是因为编译器要对数据成员在空间上进行对齐。上面是按照编译器的默认设置进行对齐的结果,那么我们是不是可以改变编译器的这种默认对齐设置呢,当然可以.例如:
#pragma pack (2) /*指定按2字节对齐*/
struct C
{
char b;
int a;
short c;
};
#pragma pack () /*取消指定对齐，恢复缺省对齐*/
sizeof(struct C)值是8。
修改对齐值为1：
#pragma pack (1) /*指定按1字节对齐*/
struct D
{
char b;
int a;
short c;
};
#pragma pack () /*取消指定对齐，恢复缺省对齐*/
sizeof(struct D)值为7。
后面我们再讲解#pragma pack()的作用.

三.编译器是按照什么样的原则进行对齐的?

先让我们看四个重要的基本概念：

**自身对齐值**——就是数据自身的长度值  ； **指定对齐值**——就是通过#pragma pack (i)指定进行i字节的对齐

**有效对齐值**——自身对齐值和指定对齐值中小的那个值。


1.数据类型自身的对齐值：
对于char型数据，其自身对齐值为1，对于short型为2，对于int,float,double类型，其自身对齐值为4，单位字节。
2.结构体或者类的自身对齐值：其成员中自身对齐值最大的那个值。
3.指定对齐值：#pragma pack (value)时的指定对齐值value。
4.数据成员、结构体和类的有效对齐值：自身对齐值和指定对齐值中小的那个值。
有了这些值，我们就可以很方便的来讨论具体数据结构的成员和其自身的对齐方式。**有效对齐值N是最终用来决定数据存放地址方式的值，最重要。有效对齐N，就是表示“对齐在N上”，也就是说该数据的"存放起始地址%N=0".**而数据结构中的数据变量都是按定义的先后顺序来排放的。第一个数据变量的起始地址就是数据结构的起始地址。结构体的成员变量要对齐排放，结构体本身也要根据自身的**有效对齐值圆整(就是结构体成员变量占用总长度需要是对结构体有效对齐值的整数倍**，结合下面例子理解)。这样就不能理解上面的几个例子的值了。
例子分析：
分析例子B；
struct B
{
char b;
int a;
short c;
};
假设B从地址空间0x0000开始排放。该例子中没有定义指定对齐值，在笔者环境下，该值默认为4。第一个成员变量b的自身对齐值是1，比指定或者默认指定对齐值4小，所以其有效对齐值为1，所以其存放地址0x0000符合0x0000%1=0.第二个成员变量a，其自身对齐值为4，所以有效对齐值也为4，所以只能存放在起始地址为0x0004到0x0007这四个连续的字节空间中，复核0x0004%4=0,且紧靠第一个变量。第三个变量c,自身对齐值为2，所以有效对齐值也是2，可以存放在0x0008到0x0009这两个字节空间中，符合0x0008%2=0。所以从0x0000到0x0009存放的都是B内容。再看数据结构B的自身对齐值为其变量中最大对齐值(这里是b）所以就是4，所以结构体的有效对齐值也是4。根据结构体圆整的要求，0x0009到0x0000=10字节，（10＋2）％4＝0。所以0x0000A到0x000B也为结构体B所占用。故B从0x0000到0x000B共有12个字节,sizeof(struct B)=12;其实如果就这一个就来说它已将满足字节对齐了,因为它的起始地址是0,因此肯定是对齐的,之所以在后面补充2个字节,是因为编译器为了实现结构数组的存取效率,试想如果我们定义了一个结构B的数组,那么第一个结构起始地址是0没有问题,但是第二个结构呢?按照数组的定义,数组中所有元素都是紧挨着的,如果我们不把结构的大小补充为4的整数倍,那么下一个结构的起始地址将是0x0000A,这显然不能满足结构的地址对齐了,因此我们要把结构补充成有效对齐大小的整数倍.其实诸如:对于char型数据，其自身对齐值为1，对于short型为2，对于int,float,double类型，其自身对齐值为4，这些已有类型的自身对齐值也是基于数组考虑的,只是因为这些类型的长度已知了,所以他们的自身对齐值也就已知了.
同理,分析上面例子C：
\#pragma pack (2) /*指定按2字节对齐*/
struct C
{
char b;
int a;
short c;
};
\#pragma pack () /*取消指定对齐，恢复缺省对齐*/
第一个变量b的自身对齐值为1，指定对齐值为2，所以，其有效对齐值为1，假设C从0x0000开始，那么b存放在0x0000，符合0x0000%1=0;第二个变量，自身对齐值为4，指定对齐值为2，所以有效对齐值为2，所以顺序存放在0x0002、0x0003、0x0004、0x0005四个连续字节中，符合0x0002%2=0。第三个变量c的自身对齐值为2，所以有效对齐值为2，顺序存放
在0x0006、0x0007中，符合0x0006%2=0。所以从0x0000到0x00007共八字节存放的是C的变量。又C的自身对齐值为4，所以C的有效对齐值为2。又8%2=0,C只占用0x0000到0x0007的八个字节。所以sizeof(struct C)=8.

 

typedef struct Stu1{
char c;
char *name;
int id;
short k1;
char m;
short k2;
char number[12];
}Stu1;


typedef struct Stu2{
char c;
char name[20];  //基本数据类型为char ,所以看成20个char 类型值进行存储，每个有效对齐值都为1 -------与上面的char c 放在一起
int id;
char m;
char number[12];//同上，与上面的m 放在一起，因为总长度要为4 的整数倍，所以最后一个的地址若不为4的倍数，一样要填补到4
}Stu2;

printf("Stu1:%d Stu2:%d\n",sizeof(Stu1),sizeof(Stu2));

输出结果为：Stu1:32Stu2:44

四.如何修改编译器的默认对齐值?

1.在VC IDE中，可以这样修改：[Project]|[Settings],c/c++选项卡Category的Code Generation选项的Struct Member Alignment中修改，默认是8字节。
2.在编码时，可以这样动态修改：#pragma pack .注意:是pragma而不是progma.

**五.针对字节对齐,我们在编程中如何考虑?**
如果在编程的时候要考虑节约空间的话,那么我们只需要假定结构的首地址是0,然后各个变量按照上面的原则进行排列即可,基本的原则就是把结构中的变量按照类型大小从小到大声明,尽量减少中间的填补空间.还有一种就是为了以空间换取时间的效率,我们显示的进行填补空间进行对齐,比如:有一种使用空间换时间做法是显式的插入reserved成员：
struct A{
char a;
char reserved[3];//使用空间换时间
int b;
}

reserved成员对我们的程序没有什么意义,它只是起到填补空间以达到字节对齐的目的,当然即使不加这个成员通常编译器也会给我们自动填补对齐,我们自己加上它只是起到显式的提醒作用.

六.字节对齐可能带来的隐患:

代码中关于对齐的隐患，很多是隐式的。比如在强制类型转换的时候。例如：
unsigned int i = 0x12345678;
unsigned char *p=NULL;
unsigned short *p1=NULL;

p=&i;
*p=0x00;
p1=(unsigned short *)(p+1);
*p1=0x0000;
最后两句代码，从奇数边界去访问unsignedshort型变量，显然不符合对齐的规定。
在x86上，类似的操作只会影响效率，但是在MIPS或者sparc上，可能就是一个error,因为它们要求必须字节对齐.

七.如何查找与字节对齐方面的问题:

如果出现对齐或者赋值问题首先查看
\1. 编译器的big little端设置
\2. 看这种体系本身是否支持非对齐访问
\3. 如果支持看设置了对齐与否,如果没有则看访问时需要加某些特殊的修饰来标志其特殊访问操作

举例：

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
#include <stdio.h>
main()
{
    struct A {
        int a;
        char b;
        short c;
    };
    struct B {
        char b;
        int a;
        short c;
    };
    #pragma pack (2) /*指定按2字节对齐*/
    struct C {
        char b;
        int a;
        short c;
    };
    #pragma pack () /*取消指定对齐，恢复缺省对齐*/
    #pragma pack (1) /*指定按1字节对齐*/
    struct D {
        char b;
        int a;
        short c;
    };
    #pragma pack ()/*取消指定对齐，恢复缺省对齐*/
    int s1=sizeof(struct A);
    int s2=sizeof(struct B);
    int s3=sizeof(struct C);
    int s4=sizeof(struct D);
    printf("%d\n",s1);
    printf("%d\n",s2);
    printf("%d\n",s3);
    printf("%d\n",s4);
}
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
#include <stdio.h>  
main()  
{  
    struct A {  
        int a;  
        char b;  
        short c;  
    };  
    
    struct B {  
        char b;  
        int a;  
        short c;  
    };  
    
    #pragma pack (2) /*指定按2字节对齐*/  
    struct C {  
        char b;  
        int a;  
        short c;  
    };  
    #pragma pack () /*取消指定对齐，恢复缺省对齐*/  
    #pragma pack (1) /*指定按1字节对齐*/  
    struct D {  
        char b;  
        int a;  
        short c;  
    };  
    #pragma pack ()/*取消指定对齐，恢复缺省对齐*/  
    
    int s1=sizeof(struct A);  
    int s2=sizeof(struct B);  
    int s3=sizeof(struct C);  
    int s4=sizeof(struct D);  
    printf("%d\n",s1);  
    printf("%d\n",s2);  
    printf("%d\n",s3);  
    printf("%d\n",s4);  
}  
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

 

输出：

8

12

8

7

 

修改代码：

struct A {
// int a;
char b;
short c;
};

struct B {
char b;
// int a;
short c;
};

输出：

4

4

输出都是4，说明之前的int影响对齐！

 

![img](http://hi.csdn.net/attachment/201108/29/0_1314609020rbP8.gif)









# [进程调度算法](https://www.cnblogs.com/zlcxbb/p/5901974.html)



# 一、先来先服务和短作业(进程)优先调度算法

## 1．先来先服务调度算法

先来先服务(FCFS)调度算法是一种最简单的调度算法，该算法既可用于作业调度，也可用于进程调度。当在作业调度中采用该算法时，每次调度都是从后备作业队列中选择一个或多个最先进入该队列的作业，将它们调入内存，为它们分配资源、创建进程，然后放入就绪队列。在进程调度中采用FCFS算法时，则每次调度是从就绪队列中选择一个最先进入该队列的进程，为之分配处理机，使之投入运行。该进程一直运行到完成或发生某事件而阻塞后才放弃处理机。

## 2．短作业(进程)优先调度算法

短作业(进程)优先调度算法SJ(P)F，是指对短作业或短进程优先调度的算法。它们可以分别用于作业调度和进程调度。短作业优先(SJF)的调度算法是从后备队列中选择一个或若干个估计运行时间最短的作业，将它们调入内存运行。而短进程优先(SPF)调度算法则是从就绪队列中选出一个估计运行时间最短的进程，将处理机分配给它，使它立即执行并一直执行到完成，或发生某事件而被阻塞放弃处理机时再重新调度。

# 二、高优先权优先调度算法

## 1．优先权调度算法的类型

为了照顾紧迫型作业，使之在进入系统后便获得优先处理，引入了最高优先权优先(FPF)调度算法。此算法常被用于批处理系统中，作为作业调度算法，也作为多种[操作系统](http://www.wypblog.com/archives/category/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F)中的进程调度算法，还可用于实时系统中。当把该算法用于作业调度时，系统将从后备队列中选择若干个优先权最高的作业装入内存。当用于进程调度时，该算法是把处理机分配给就绪队列中优先权最高的进程，这时，又可进一步把该算法分成如下两种。

1) 非抢占式优先权算法

在这种方式下，系统一旦把处理机分配给就绪队列中优先权最高的进程后，该进程便一直执行下去，直至完成；或因发生某事件使该进程放弃处理机时，系统方可再将处理机重新分配给另一优先权最高的进程。这种调度算法主要用于批处理系统中；也可用于某些对实时性要求不严的实时系统中。

2) 抢占式优先权调度算法

在这种方式下，系统同样是把处理机分配给优先权最高的进程，使之执行。但在其执行期间，只要又出现了另一个其优先权更高的进程，进程调度程序就立即停止当前进程(原优先权最高的进程)的执行，重新将处理机分配给新到的优先权最高的进程。因此，在采用这种调度算法时，是每当系统中出现一个新的就绪进程i 时，就将其优先权Pi与正在执行的进程j 的优先权Pj进行比较。如果Pi≤Pj，原进程Pj便继续执行；但如果是Pi>Pj，则立即停止Pj的执行，做进程切换，使i 进程投入执行。显然，这种抢占式的优先权调度算法能更好地满足紧迫作业的要求，故而常用于要求比较严格的实时系统中，以及对性能要求较高的批处理和分时系统中。

## 2．高响应比优先调度算法

在批处理系统中，短作业优先算法是一种比较好的算法，其主要的不足之处是长作业的运行得不到保证。如果我们能为每个作业引入前面所述的动态优先权，并使作业的优先级随着等待时间的增加而以速率a 提高，则长作业在等待一定的时间后，必然有机会分配到处理机。该优先权的变化规律可描述为：
![操作系统](http://s1.homezz.com/201304/5190/34849_o.jpg)
由于等待时间与服务时间之和就是系统对该作业的响应时间，故该优先权又相当于响应比RP。据此，又可表示为：
![操作系统](http://s3.homezz.com/201304/5190/34850_o.jpg)
由上式可以看出：

(1) 如果作业的等待时间相同，则要求服务的时间愈短，其优先权愈高，因而该算法有利于短作业。

(2) 当要求服务的时间相同时，作业的优先权决定于其等待时间，等待时间愈长，其优先权愈高，因而它实现的是先来先服务。

(3) 对于长作业，作业的优先级可以随等待时间的增加而提高，当其等待时间足够长时，其优先级便可升到很高，从而也可获得处理机。简言之，该算法既照顾了短作业，又考虑了作业到达的先后次序，不会使长作业长期得不到服务。因此，该算法实现了一种较好的折衷。当然，在利用该算法时，每要进行调度之前，都须先做响应比的计算，这会增加系统开销。

# 三、基于时间片的轮转调度算法

## 1．时间片轮转法

1) 基本原理

在早期的时间片轮转法中，系统将所有的就绪进程按先来先服务的原则排成一个队列，每次调度时，把CPU 分配给队首进程，并令其执行一个时间片。时间片的大小从几ms 到几百ms。当执行的时间片用完时，由一个计时器发出时钟中断请求，调度程序便据此信号来停止该进程的执行，并将它送往就绪队列的末尾；然后，再把处理机分配给就绪队列中新的队首进程，同时也让它执行一个时间片。这样就可以保证就绪队列中的所有进程在一给定的时间内均能获得一时间片的处理机执行时间。换言之，系统能在给定的时间内响应所有用户的请求。

## 2．多级反馈队列调度算法

前面介绍的各种用作进程调度的算法都有一定的局限性。如短进程优先的调度算法，仅照顾了短进程而忽略了长进程，而且如果并未指明进程的长度，则短进程优先和基于进程长度的抢占式调度算法都将无法使用。而多级反馈队列调度算法则不必事先知道各种进程所需的执行时间，而且还可以满足各种类型进程的需要，因而它是目前被公认的一种较好的进程调度算法。在采用多级反馈队列调度算法的系统中，调度算法的实施过程如下所述。

(1) 应设置多个就绪队列，并为各个队列赋予不同的优先级。第一个队列的优先级最高，第二个队列次之，其余各队列的优先权逐个降低。该算法赋予各个队列中进程执行时间片的大小也各不相同，在优先权愈高的队列中，为每个进程所规定的执行时间片就愈小。例如，第二个队列的时间片要比第一个队列的时间片长一倍，……，第i+1个队列的时间片要比第i个队列的时间片长一倍。

(2) 当一个新进程进入内存后，首先将它放入第一队列的末尾，按FCFS原则排队等待调度。当轮到该进程执行时，如它能在该时间片内完成，便可准备撤离系统；如果它在一个时间片结束时尚未完成，调度程序便将该进程转入第二队列的末尾，再同样地按FCFS原则等待调度执行；如果它在第二队列中运行一个时间片后仍未完成，再依次将它放入第三队列，……，如此下去，当一个长作业(进程)从第一队列依次降到第*n*队列后，在第*n* 队列便采取按时间片轮转的方式运行。

(3) 仅当第一队列空闲时，调度程序才调度第二队列中的进程运行；仅当第1～(i-1)队列均空时，才会调度第i队列中的进程运行。如果处理机正在第i队列中为某进程服务时，又有新进程进入优先权较高的队列(第1～(i-1)中的任何一个队列)，则此时新进程将抢占正在运行进程的处理机，即由调度程序把正在运行的进程放回到第i队列的末尾，把处理机分配给新到的高优先权进程。

 





