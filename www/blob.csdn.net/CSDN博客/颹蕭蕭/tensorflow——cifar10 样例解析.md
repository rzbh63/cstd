
# tensorflow——cifar10 样例解析 - 颹蕭蕭 - CSDN博客


2019年03月19日 19:54:36[颹蕭蕭](https://me.csdn.net/itnerd)阅读数：103


从 tensorflow 提供的 cifar10 分类程序样例学习程序的主要框架
最外层结构：
利用 tf.app.flags 解析命令行参数
利用 tf.app.run 启动主函数，在主函数中训练
```python
import
```
```python
tensorflow
```
```python
as
```
```python
tf

FLAGS
```
```python
=
```
```python
tf
```
```python
.
```
```python
app
```
```python
.
```
```python
flags
```
```python
.
```
```python
FLAGS
tf
```
```python
.
```
```python
app
```
```python
.
```
```python
flags
```
```python
.
```
```python
DEFINE_string
```
```python
(
```
```python
'train_dir'
```
```python
,
```
```python
'/tmp/cifar10_train'
```
```python
,
```
```python
"""Directory where to write event logs """
```
```python
"""and checkpoint."""
```
```python
)
```
```python
tf
```
```python
.
```
```python
app
```
```python
.
```
```python
flags
```
```python
.
```
```python
DEFINE_integer
```
```python
(
```
```python
'max_steps'
```
```python
,
```
```python
100000
```
```python
,
```
```python
"""Number of batches to run."""
```
```python
)
```
```python
tf
```
```python
.
```
```python
app
```
```python
.
```
```python
flags
```
```python
.
```
```python
DEFINE_boolean
```
```python
(
```
```python
'log_device_placement'
```
```python
,
```
```python
False
```
```python
,
```
```python
"""Whether to log device placement."""
```
```python
)
```
```python
tf
```
```python
.
```
```python
app
```
```python
.
```
```python
flags
```
```python
.
```
```python
DEFINE_integer
```
```python
(
```
```python
'log_frequency'
```
```python
,
```
```python
10
```
```python
,
```
```python
"""How often to log results to the console."""
```
```python
)
```
```python
def
```
```python
train
```
```python
(
```
```python
)
```
```python
:
```
```python
pass
```
```python
def
```
```python
main
```
```python
(
```
```python
argv
```
```python
=
```
```python
None
```
```python
)
```
```python
:
```
```python
# pylint: disable=unused-argument
```
```python
cifar10
```
```python
.
```
```python
maybe_download_and_extract
```
```python
(
```
```python
)
```
```python
if
```
```python
tf
```
```python
.
```
```python
gfile
```
```python
.
```
```python
Exists
```
```python
(
```
```python
FLAGS
```
```python
.
```
```python
train_dir
```
```python
)
```
```python
:
```
```python
tf
```
```python
.
```
```python
gfile
```
```python
.
```
```python
DeleteRecursively
```
```python
(
```
```python
FLAGS
```
```python
.
```
```python
train_dir
```
```python
)
```
```python
tf
```
```python
.
```
```python
gfile
```
```python
.
```
```python
MakeDirs
```
```python
(
```
```python
FLAGS
```
```python
.
```
```python
train_dir
```
```python
)
```
```python
train
```
```python
(
```
```python
)
```
```python
if
```
```python
__name__
```
```python
==
```
```python
'__main__'
```
```python
:
```
```python
tf
```
```python
.
```
```python
app
```
```python
.
```
```python
run
```
```python
(
```
```python
)
```
下面来看训练过程：搭建计算流图，计算 loss，选择合适的优化器以减小 loss 为目标来更新权重，周期性的记录日志。
```python
def
```
```python
train
```
```python
(
```
```python
)
```
```python
:
```
```python
"""Train CIFAR-10 for a number of steps."""
```
```python
with
```
```python
tf
```
```python
.
```
```python
Graph
```
```python
(
```
```python
)
```
```python
.
```
```python
as_default
```
```python
(
```
```python
)
```
```python
:
```
```python
global_step
```
```python
=
```
```python
tf
```
```python
.
```
```python
train
```
```python
.
```
```python
get_or_create_global_step
```
```python
(
```
```python
)
```
```python
# 强制使用 CPU
```
```python
with
```
```python
tf
```
```python
.
```
```python
device
```
```python
(
```
```python
'/cpu:0'
```
```python
)
```
```python
:
```
```python
images
```
```python
,
```
```python
labels
```
```python
=
```
```python
cifar10
```
```python
.
```
```python
distorted_inputs
```
```python
(
```
```python
)
```
```python
# 这里的 logits 是计算图中的计算 softmax 之前的节点
```
```python
logits
```
```python
=
```
```python
cifar10
```
```python
.
```
```python
inference
```
```python
(
```
```python
images
```
```python
)
```
```python
# 这里的 loss 是计算 loss 的节点
```
```python
loss
```
```python
=
```
```python
cifar10
```
```python
.
```
```python
loss
```
```python
(
```
```python
logits
```
```python
,
```
```python
labels
```
```python
)
```
```python
# 这个是利用反向传播更新网络权值的计算节点
```
```python
train_op
```
```python
=
```
```python
cifar10
```
```python
.
```
```python
train
```
```python
(
```
```python
loss
```
```python
,
```
```python
global_step
```
```python
)
```
```python
# 这里通过重载 SessionRunHook 这个运行时的回调函数，实现周期写日志的功能
```
```python
class
```
```python
_LoggerHook
```
```python
(
```
```python
tf
```
```python
.
```
```python
train
```
```python
.
```
```python
SessionRunHook
```
```python
)
```
```python
:
```
```python
"""Logs loss and runtime."""
```
```python
def
```
```python
begin
```
```python
(
```
```python
self
```
```python
)
```
```python
:
```
```python
self
```
```python
.
```
```python
_step
```
```python
=
```
```python
-
```
```python
1
```
```python
self
```
```python
.
```
```python
_start_time
```
```python
=
```
```python
time
```
```python
.
```
```python
time
```
```python
(
```
```python
)
```
```python
def
```
```python
before_run
```
```python
(
```
```python
self
```
```python
,
```
```python
run_context
```
```python
)
```
```python
:
```
```python
self
```
```python
.
```
```python
_step
```
```python
+=
```
```python
1
```
```python
return
```
```python
tf
```
```python
.
```
```python
train
```
```python
.
```
```python
SessionRunArgs
```
```python
(
```
```python
loss
```
```python
)
```
```python
# Asks for loss value.
```
```python
def
```
```python
after_run
```
```python
(
```
```python
self
```
```python
,
```
```python
run_context
```
```python
,
```
```python
run_values
```
```python
)
```
```python
:
```
```python
if
```
```python
self
```
```python
.
```
```python
_step
```
```python
%
```
```python
FLAGS
```
```python
.
```
```python
log_frequency
```
```python
==
```
```python
0
```
```python
:
```
```python
current_time
```
```python
=
```
```python
time
```
```python
.
```
```python
time
```
```python
(
```
```python
)
```
```python
duration
```
```python
=
```
```python
current_time
```
```python
-
```
```python
self
```
```python
.
```
```python
_start_time
          self
```
```python
.
```
```python
_start_time
```
```python
=
```
```python
current_time
          loss_value
```
```python
=
```
```python
run_values
```
```python
.
```
```python
results
          examples_per_sec
```
```python
=
```
```python
FLAGS
```
```python
.
```
```python
log_frequency
```
```python
*
```
```python
FLAGS
```
```python
.
```
```python
batch_size
```
```python
/
```
```python
duration
          sec_per_batch
```
```python
=
```
```python
float
```
```python
(
```
```python
duration
```
```python
/
```
```python
FLAGS
```
```python
.
```
```python
log_frequency
```
```python
)
```
```python
format_str
```
```python
=
```
```python
(
```
```python
'%s: step %d, loss = %.2f (%.1f examples/sec; %.3f '
```
```python
'sec/batch)'
```
```python
)
```
```python
print
```
```python
(
```
```python
format_str
```
```python
%
```
```python
(
```
```python
datetime
```
```python
.
```
```python
now
```
```python
(
```
```python
)
```
```python
,
```
```python
self
```
```python
.
```
```python
_step
```
```python
,
```
```python
loss_value
```
```python
,
```
```python
examples_per_sec
```
```python
,
```
```python
sec_per_batch
```
```python
)
```
```python
)
```
```python
with
```
```python
tf
```
```python
.
```
```python
train
```
```python
.
```
```python
MonitoredTrainingSession
```
```python
(
```
```python
checkpoint_dir
```
```python
=
```
```python
FLAGS
```
```python
.
```
```python
train_dir
```
```python
,
```
```python
# 一系列回调函数
```
```python
hooks
```
```python
=
```
```python
[
```
```python
tf
```
```python
.
```
```python
train
```
```python
.
```
```python
StopAtStepHook
```
```python
(
```
```python
last_step
```
```python
=
```
```python
FLAGS
```
```python
.
```
```python
max_steps
```
```python
)
```
```python
,
```
```python
#达到最大步长限制
```
```python
tf
```
```python
.
```
```python
train
```
```python
.
```
```python
NanTensorHook
```
```python
(
```
```python
loss
```
```python
)
```
```python
,
```
```python
# loss 发散
```
```python
_LoggerHook
```
```python
(
```
```python
)
```
```python
]
```
```python
,
```
```python
# 周期写日志
```
```python
config
```
```python
=
```
```python
tf
```
```python
.
```
```python
ConfigProto
```
```python
(
```
```python
log_device_placement
```
```python
=
```
```python
FLAGS
```
```python
.
```
```python
log_device_placement
```
```python
)
```
```python
)
```
```python
as
```
```python
mon_sess
```
```python
:
```
```python
while
```
```python
not
```
```python
mon_sess
```
```python
.
```
```python
should_stop
```
```python
(
```
```python
)
```
```python
:
```
```python
mon_sess
```
```python
.
```
```python
run
```
```python
(
```
```python
train_op
```
```python
)
```
上面的代码中使用回调函数来写日志，看起来比较高级。对于初学者来说，可能更习惯于把 log 的代码直接加在循环里，向下面这样，就不用多写一个内部类_LoggerHook：
```python
def
```
```python
train
```
```python
(
```
```python
)
```
```python
:
```
```python
"""Train CIFAR-10 for a number of steps."""
```
```python
with
```
```python
tf
```
```python
.
```
```python
Graph
```
```python
(
```
```python
)
```
```python
.
```
```python
as_default
```
```python
(
```
```python
)
```
```python
:
```
```python
global_step
```
```python
=
```
```python
tf
```
```python
.
```
```python
train
```
```python
.
```
```python
get_or_create_global_step
```
```python
(
```
```python
)
```
```python
# 强制使用 CPU
```
```python
with
```
```python
tf
```
```python
.
```
```python
device
```
```python
(
```
```python
'/cpu:0'
```
```python
)
```
```python
:
```
```python
images
```
```python
,
```
```python
labels
```
```python
=
```
```python
cifar10
```
```python
.
```
```python
distorted_inputs
```
```python
(
```
```python
)
```
```python
# 这里的 logits 是计算图中的计算 softmax 之前的节点
```
```python
logits
```
```python
=
```
```python
cifar10
```
```python
.
```
```python
inference
```
```python
(
```
```python
images
```
```python
)
```
```python
# 这里的 loss 是计算 loss 的节点
```
```python
loss
```
```python
=
```
```python
cifar10
```
```python
.
```
```python
loss
```
```python
(
```
```python
logits
```
```python
,
```
```python
labels
```
```python
)
```
```python
# 这个是利用反向传播更新网络权值的计算节点
```
```python
train_op
```
```python
=
```
```python
cifar10
```
```python
.
```
```python
train
```
```python
(
```
```python
loss
```
```python
,
```
```python
global_step
```
```python
)
```
```python
with
```
```python
tf
```
```python
.
```
```python
train
```
```python
.
```
```python
MonitoredTrainingSession
```
```python
(
```
```python
checkpoint_dir
```
```python
=
```
```python
FLAGS
```
```python
.
```
```python
train_dir
```
```python
,
```
```python
hooks
```
```python
=
```
```python
[
```
```python
tf
```
```python
.
```
```python
train
```
```python
.
```
```python
StopAtStepHook
```
```python
(
```
```python
last_step
```
```python
=
```
```python
FLAGS
```
```python
.
```
```python
max_steps
```
```python
)
```
```python
,
```
```python
tf
```
```python
.
```
```python
train
```
```python
.
```
```python
NanTensorHook
```
```python
(
```
```python
loss
```
```python
)
```
```python
]
```
```python
,
```
```python
# 这里把写日志的回调函数删除了
```
```python
config
```
```python
=
```
```python
tf
```
```python
.
```
```python
ConfigProto
```
```python
(
```
```python
log_device_placement
```
```python
=
```
```python
FLAGS
```
```python
.
```
```python
log_device_placement
```
```python
)
```
```python
)
```
```python
as
```
```python
mon_sess
```
```python
:
```
```python
step
```
```python
=
```
```python
-
```
```python
1
```
```python
start_time
```
```python
=
```
```python
time
```
```python
.
```
```python
time
```
```python
(
```
```python
)
```
```python
while
```
```python
not
```
```python
mon_sess
```
```python
.
```
```python
should_stop
```
```python
(
```
```python
)
```
```python
:
```
```python
step
```
```python
+=
```
```python
1
```
```python
lss
```
```python
,
```
```python
_
```
```python
=
```
```python
mon_sess
```
```python
.
```
```python
run
```
```python
(
```
```python
[
```
```python
loss
```
```python
,
```
```python
train_op
```
```python
]
```
```python
)
```
```python
# 直接在 while 循环里写日志， 效果和回调函数是一样的
```
```python
if
```
```python
step
```
```python
%
```
```python
FLAGS
```
```python
.
```
```python
log_frequency
```
```python
==
```
```python
0
```
```python
:
```
```python
current_time
```
```python
=
```
```python
time
```
```python
.
```
```python
time
```
```python
(
```
```python
)
```
```python
duration
```
```python
=
```
```python
current_time
```
```python
-
```
```python
start_time
                start_time
```
```python
=
```
```python
current_time
                examples_per_sec
```
```python
=
```
```python
FLAGS
```
```python
.
```
```python
log_frequency
```
```python
*
```
```python
FLAGS
```
```python
.
```
```python
batch_size
```
```python
/
```
```python
duration
                sec_per_batch
```
```python
=
```
```python
float
```
```python
(
```
```python
duration
```
```python
/
```
```python
FLAGS
```
```python
.
```
```python
log_frequency
```
```python
)
```
```python
format_str
```
```python
=
```
```python
(
```
```python
'%s: step %d, loss = %.2f (%.1f examples/sec; %.3f '
```
```python
'sec/batch)'
```
```python
)
```
```python
print
```
```python
(
```
```python
format_str
```
```python
%
```
```python
(
```
```python
datetime
```
```python
.
```
```python
now
```
```python
(
```
```python
)
```
```python
,
```
```python
step
```
```python
,
```
```python
lss
```
```python
,
```
```python
examples_per_sec
```
```python
,
```
```python
sec_per_batch
```
```python
)
```
```python
)
```
记录的日志如下：
`2019-03-19 19:04:37.806384: step 0, loss = 4.67 (260.6 examples/sec; 0.491 sec/batch)
2019-03-19 19:04:42.597658: step 10, loss = 4.62 (267.2 examples/sec; 0.479 sec/batch)
2019-03-19 19:04:47.308927: step 20, loss = 4.49 (271.7 examples/sec; 0.471 sec/batch)
...`最后深入到计算流图的细节，看看每一个节点是怎么搭建的（[cifar10.py](http://cifar10.py)）：
（源代码中关于summary，use_fp16 等细枝末节已被剔除，不影响主干程序）
```python
"""Builds the CIFAR-10 network.
Summary of available functions:
 # Compute input images and labels for training. If you would like to run
 # evaluations, use inputs() instead.
 inputs, labels = distorted_inputs()
 # Compute inference on the model inputs to make a prediction.
 predictions = inference(inputs)
 # Compute the total loss of the prediction with respect to the labels.
 loss = loss(predictions, labels)
 # Create a graph to run one step of training with respect to the loss.
 train_op = train(loss, global_step)
"""
```
```python
import
```
```python
os
```
```python
import
```
```python
re
```
```python
import
```
```python
sys
```
```python
import
```
```python
tarfile
```
```python
from
```
```python
six
```
```python
.
```
```python
moves
```
```python
import
```
```python
urllib
```
```python
import
```
```python
tensorflow
```
```python
as
```
```python
tf
```
```python
import
```
```python
cifar10_input
FLAGS
```
```python
=
```
```python
tf
```
```python
.
```
```python
app
```
```python
.
```
```python
flags
```
```python
.
```
```python
FLAGS
```
```python
# Basic model parameters.
```
```python
tf
```
```python
.
```
```python
app
```
```python
.
```
```python
flags
```
```python
.
```
```python
DEFINE_integer
```
```python
(
```
```python
'batch_size'
```
```python
,
```
```python
128
```
```python
,
```
```python
"""Number of images to process in a batch."""
```
```python
)
```
```python
tf
```
```python
.
```
```python
app
```
```python
.
```
```python
flags
```
```python
.
```
```python
DEFINE_string
```
```python
(
```
```python
'data_dir'
```
```python
,
```
```python
'/tmp/cifar10_data'
```
```python
,
```
```python
"""Path to the CIFAR-10 data directory."""
```
```python
)
```
```python
# Global constants describing the CIFAR-10 data set.
```
```python
IMAGE_SIZE
```
```python
=
```
```python
24
```
```python
NUM_CLASSES
```
```python
=
```
```python
10
```
```python
NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN
```
```python
=
```
```python
50000
```
```python
NUM_EXAMPLES_PER_EPOCH_FOR_EVAL
```
```python
=
```
```python
10000
```
```python
# Constants describing the training process.
```
```python
MOVING_AVERAGE_DECAY
```
```python
=
```
```python
0.9999
```
```python
# The decay to use for the moving average.
```
```python
NUM_EPOCHS_PER_DECAY
```
```python
=
```
```python
350.0
```
```python
# Epochs after which learning rate decays.
```
```python
LEARNING_RATE_DECAY_FACTOR
```
```python
=
```
```python
0.1
```
```python
# Learning rate decay factor.
```
```python
INITIAL_LEARNING_RATE
```
```python
=
```
```python
0.1
```
```python
# Initial learning rate.
```
```python
# If a model is trained with multiple GPUs, prefix all Op names with tower_name
```
```python
# to differentiate the operations. Note that this prefix is removed from the
```
```python
# names of the summaries when visualizing a model.
```
```python
TOWER_NAME
```
```python
=
```
```python
'tower'
```
```python
DATA_URL
```
```python
=
```
```python
'https://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz'
```
```python
def
```
```python
_variable_on_cpu
```
```python
(
```
```python
name
```
```python
,
```
```python
shape
```
```python
,
```
```python
initializer
```
```python
)
```
```python
:
```
```python
"""Helper to create a Variable stored on CPU memory.
  Args:
    name: name of the variable
    shape: list of ints
    initializer: initializer for Variable
  Returns:
    Variable Tensor
  """
```
```python
with
```
```python
tf
```
```python
.
```
```python
device
```
```python
(
```
```python
'/cpu:0'
```
```python
)
```
```python
:
```
```python
dtype
```
```python
=
```
```python
tf
```
```python
.
```
```python
float16
```
```python
if
```
```python
FLAGS
```
```python
.
```
```python
use_fp16
```
```python
else
```
```python
tf
```
```python
.
```
```python
float32
    var
```
```python
=
```
```python
tf
```
```python
.
```
```python
get_variable
```
```python
(
```
```python
name
```
```python
,
```
```python
shape
```
```python
,
```
```python
initializer
```
```python
=
```
```python
initializer
```
```python
,
```
```python
dtype
```
```python
=
```
```python
dtype
```
```python
)
```
```python
return
```
```python
var
```
```python
def
```
```python
_variable_with_weight_decay
```
```python
(
```
```python
name
```
```python
,
```
```python
shape
```
```python
,
```
```python
stddev
```
```python
,
```
```python
wd
```
```python
)
```
```python
:
```
```python
"""Helper to create an initialized Variable with weight decay.
  Note that the Variable is initialized with a truncated normal distribution.
  A weight decay is added only if one is specified.
  Args:
    name: name of the variable
    shape: list of ints
    stddev: standard deviation of a truncated Gaussian
    wd: add L2Loss weight decay multiplied by this float. If None, weight
        decay is not added for this Variable.
  Returns:
    Variable Tensor
  """
```
```python
dtype
```
```python
=
```
```python
tf
```
```python
.
```
```python
float16
```
```python
if
```
```python
FLAGS
```
```python
.
```
```python
use_fp16
```
```python
else
```
```python
tf
```
```python
.
```
```python
float32
  var
```
```python
=
```
```python
_variable_on_cpu
```
```python
(
```
```python
name
```
```python
,
```
```python
shape
```
```python
,
```
```python
tf
```
```python
.
```
```python
truncated_normal_initializer
```
```python
(
```
```python
stddev
```
```python
=
```
```python
stddev
```
```python
,
```
```python
dtype
```
```python
=
```
```python
dtype
```
```python
)
```
```python
)
```
```python
if
```
```python
wd
```
```python
is
```
```python
not
```
```python
None
```
```python
:
```
```python
weight_decay
```
```python
=
```
```python
tf
```
```python
.
```
```python
multiply
```
```python
(
```
```python
tf
```
```python
.
```
```python
nn
```
```python
.
```
```python
l2_loss
```
```python
(
```
```python
var
```
```python
)
```
```python
,
```
```python
wd
```
```python
,
```
```python
name
```
```python
=
```
```python
'weight_loss'
```
```python
)
```
```python
tf
```
```python
.
```
```python
add_to_collection
```
```python
(
```
```python
'losses'
```
```python
,
```
```python
weight_decay
```
```python
)
```
```python
return
```
```python
var
```
```python
def
```
```python
distorted_inputs
```
```python
(
```
```python
)
```
```python
:
```
```python
"""Construct distorted input for CIFAR training using the Reader ops.
  Returns:
    images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.
    labels: Labels. 1D tensor of [batch_size] size.
  Raises:
    ValueError: If no data_dir
  """
```
```python
pass
```
```python
return
```
```python
images
```
```python
,
```
```python
labels
```
```python
def
```
```python
inputs
```
```python
(
```
```python
eval_data
```
```python
)
```
```python
:
```
```python
"""Construct input for CIFAR evaluation using the Reader ops.
  Args:
    eval_data: bool, indicating if one should use the train or eval data set.
  Returns:
    images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.
    labels: Labels. 1D tensor of [batch_size] size.
  Raises:
    ValueError: If no data_dir
  """
```
```python
pass
```
```python
return
```
```python
images
```
```python
,
```
```python
labels
```
```python
# CNN 的 核心结构
```
```python
def
```
```python
inference
```
```python
(
```
```python
images
```
```python
)
```
```python
:
```
```python
"""Build the CIFAR-10 model.
  Args:
    images: Images returned from distorted_inputs() or inputs().
  Returns:
    Logits.
  """
```
```python
# We instantiate all variables using tf.get_variable() instead of
```
```python
# tf.Variable() in order to share variables across multiple GPU training runs.
```
```python
# If we only ran this model on a single GPU, we could simplify this function
```
```python
# by replacing all instances of tf.get_variable() with tf.Variable().
```
```python
#
```
```python
# conv1
```
```python
with
```
```python
tf
```
```python
.
```
```python
variable_scope
```
```python
(
```
```python
'conv1'
```
```python
)
```
```python
as
```
```python
scope
```
```python
:
```
```python
kernel
```
```python
=
```
```python
_variable_with_weight_decay
```
```python
(
```
```python
'weights'
```
```python
,
```
```python
shape
```
```python
=
```
```python
[
```
```python
5
```
```python
,
```
```python
5
```
```python
,
```
```python
3
```
```python
,
```
```python
64
```
```python
]
```
```python
,
```
```python
stddev
```
```python
=
```
```python
5e
```
```python
-
```
```python
2
```
```python
,
```
```python
wd
```
```python
=
```
```python
None
```
```python
)
```
```python
conv
```
```python
=
```
```python
tf
```
```python
.
```
```python
nn
```
```python
.
```
```python
conv2d
```
```python
(
```
```python
images
```
```python
,
```
```python
kernel
```
```python
,
```
```python
[
```
```python
1
```
```python
,
```
```python
1
```
```python
,
```
```python
1
```
```python
,
```
```python
1
```
```python
]
```
```python
,
```
```python
padding
```
```python
=
```
```python
'SAME'
```
```python
)
```
```python
biases
```
```python
=
```
```python
_variable_on_cpu
```
```python
(
```
```python
'biases'
```
```python
,
```
```python
[
```
```python
64
```
```python
]
```
```python
,
```
```python
tf
```
```python
.
```
```python
constant_initializer
```
```python
(
```
```python
0.0
```
```python
)
```
```python
)
```
```python
pre_activation
```
```python
=
```
```python
tf
```
```python
.
```
```python
nn
```
```python
.
```
```python
bias_add
```
```python
(
```
```python
conv
```
```python
,
```
```python
biases
```
```python
)
```
```python
conv1
```
```python
=
```
```python
tf
```
```python
.
```
```python
nn
```
```python
.
```
```python
relu
```
```python
(
```
```python
pre_activation
```
```python
,
```
```python
name
```
```python
=
```
```python
scope
```
```python
.
```
```python
name
```
```python
)
```
```python
# pool1
```
```python
pool1
```
```python
=
```
```python
tf
```
```python
.
```
```python
nn
```
```python
.
```
```python
max_pool
```
```python
(
```
```python
conv1
```
```python
,
```
```python
ksize
```
```python
=
```
```python
[
```
```python
1
```
```python
,
```
```python
3
```
```python
,
```
```python
3
```
```python
,
```
```python
1
```
```python
]
```
```python
,
```
```python
strides
```
```python
=
```
```python
[
```
```python
1
```
```python
,
```
```python
2
```
```python
,
```
```python
2
```
```python
,
```
```python
1
```
```python
]
```
```python
,
```
```python
padding
```
```python
=
```
```python
'SAME'
```
```python
,
```
```python
name
```
```python
=
```
```python
'pool1'
```
```python
)
```
```python
# norm1
```
```python
norm1
```
```python
=
```
```python
tf
```
```python
.
```
```python
nn
```
```python
.
```
```python
lrn
```
```python
(
```
```python
pool1
```
```python
,
```
```python
4
```
```python
,
```
```python
bias
```
```python
=
```
```python
1.0
```
```python
,
```
```python
alpha
```
```python
=
```
```python
0.001
```
```python
/
```
```python
9.0
```
```python
,
```
```python
beta
```
```python
=
```
```python
0.75
```
```python
,
```
```python
name
```
```python
=
```
```python
'norm1'
```
```python
)
```
```python
# conv2
```
```python
with
```
```python
tf
```
```python
.
```
```python
variable_scope
```
```python
(
```
```python
'conv2'
```
```python
)
```
```python
as
```
```python
scope
```
```python
:
```
```python
kernel
```
```python
=
```
```python
_variable_with_weight_decay
```
```python
(
```
```python
'weights'
```
```python
,
```
```python
shape
```
```python
=
```
```python
[
```
```python
5
```
```python
,
```
```python
5
```
```python
,
```
```python
64
```
```python
,
```
```python
64
```
```python
]
```
```python
,
```
```python
stddev
```
```python
=
```
```python
5e
```
```python
-
```
```python
2
```
```python
,
```
```python
wd
```
```python
=
```
```python
None
```
```python
)
```
```python
conv
```
```python
=
```
```python
tf
```
```python
.
```
```python
nn
```
```python
.
```
```python
conv2d
```
```python
(
```
```python
norm1
```
```python
,
```
```python
kernel
```
```python
,
```
```python
[
```
```python
1
```
```python
,
```
```python
1
```
```python
,
```
```python
1
```
```python
,
```
```python
1
```
```python
]
```
```python
,
```
```python
padding
```
```python
=
```
```python
'SAME'
```
```python
)
```
```python
biases
```
```python
=
```
```python
_variable_on_cpu
```
```python
(
```
```python
'biases'
```
```python
,
```
```python
[
```
```python
64
```
```python
]
```
```python
,
```
```python
tf
```
```python
.
```
```python
constant_initializer
```
```python
(
```
```python
0.1
```
```python
)
```
```python
)
```
```python
pre_activation
```
```python
=
```
```python
tf
```
```python
.
```
```python
nn
```
```python
.
```
```python
bias_add
```
```python
(
```
```python
conv
```
```python
,
```
```python
biases
```
```python
)
```
```python
conv2
```
```python
=
```
```python
tf
```
```python
.
```
```python
nn
```
```python
.
```
```python
relu
```
```python
(
```
```python
pre_activation
```
```python
,
```
```python
name
```
```python
=
```
```python
scope
```
```python
.
```
```python
name
```
```python
)
```
```python
# norm2
```
```python
norm2
```
```python
=
```
```python
tf
```
```python
.
```
```python
nn
```
```python
.
```
```python
lrn
```
```python
(
```
```python
conv2
```
```python
,
```
```python
4
```
```python
,
```
```python
bias
```
```python
=
```
```python
1.0
```
```python
,
```
```python
alpha
```
```python
=
```
```python
0.001
```
```python
/
```
```python
9.0
```
```python
,
```
```python
beta
```
```python
=
```
```python
0.75
```
```python
,
```
```python
name
```
```python
=
```
```python
'norm2'
```
```python
)
```
```python
# pool2
```
```python
pool2
```
```python
=
```
```python
tf
```
```python
.
```
```python
nn
```
```python
.
```
```python
max_pool
```
```python
(
```
```python
norm2
```
```python
,
```
```python
ksize
```
```python
=
```
```python
[
```
```python
1
```
```python
,
```
```python
3
```
```python
,
```
```python
3
```
```python
,
```
```python
1
```
```python
]
```
```python
,
```
```python
strides
```
```python
=
```
```python
[
```
```python
1
```
```python
,
```
```python
2
```
```python
,
```
```python
2
```
```python
,
```
```python
1
```
```python
]
```
```python
,
```
```python
padding
```
```python
=
```
```python
'SAME'
```
```python
,
```
```python
name
```
```python
=
```
```python
'pool2'
```
```python
)
```
```python
# local3
```
```python
with
```
```python
tf
```
```python
.
```
```python
variable_scope
```
```python
(
```
```python
'local3'
```
```python
)
```
```python
as
```
```python
scope
```
```python
:
```
```python
# Move everything into depth so we can perform a single matrix multiply.
```
```python
reshape
```
```python
=
```
```python
tf
```
```python
.
```
```python
reshape
```
```python
(
```
```python
pool2
```
```python
,
```
```python
[
```
```python
images
```
```python
.
```
```python
get_shape
```
```python
(
```
```python
)
```
```python
.
```
```python
as_list
```
```python
(
```
```python
)
```
```python
[
```
```python
0
```
```python
]
```
```python
,
```
```python
-
```
```python
1
```
```python
]
```
```python
)
```
```python
dim
```
```python
=
```
```python
reshape
```
```python
.
```
```python
get_shape
```
```python
(
```
```python
)
```
```python
[
```
```python
1
```
```python
]
```
```python
.
```
```python
value
    weights
```
```python
=
```
```python
_variable_with_weight_decay
```
```python
(
```
```python
'weights'
```
```python
,
```
```python
shape
```
```python
=
```
```python
[
```
```python
dim
```
```python
,
```
```python
384
```
```python
]
```
```python
,
```
```python
stddev
```
```python
=
```
```python
0.04
```
```python
,
```
```python
wd
```
```python
=
```
```python
0.004
```
```python
)
```
```python
biases
```
```python
=
```
```python
_variable_on_cpu
```
```python
(
```
```python
'biases'
```
```python
,
```
```python
[
```
```python
384
```
```python
]
```
```python
,
```
```python
tf
```
```python
.
```
```python
constant_initializer
```
```python
(
```
```python
0.1
```
```python
)
```
```python
)
```
```python
local3
```
```python
=
```
```python
tf
```
```python
.
```
```python
nn
```
```python
.
```
```python
relu
```
```python
(
```
```python
tf
```
```python
.
```
```python
matmul
```
```python
(
```
```python
reshape
```
```python
,
```
```python
weights
```
```python
)
```
```python
+
```
```python
biases
```
```python
,
```
```python
name
```
```python
=
```
```python
scope
```
```python
.
```
```python
name
```
```python
)
```
```python
# local4
```
```python
with
```
```python
tf
```
```python
.
```
```python
variable_scope
```
```python
(
```
```python
'local4'
```
```python
)
```
```python
as
```
```python
scope
```
```python
:
```
```python
weights
```
```python
=
```
```python
_variable_with_weight_decay
```
```python
(
```
```python
'weights'
```
```python
,
```
```python
shape
```
```python
=
```
```python
[
```
```python
384
```
```python
,
```
```python
192
```
```python
]
```
```python
,
```
```python
stddev
```
```python
=
```
```python
0.04
```
```python
,
```
```python
wd
```
```python
=
```
```python
0.004
```
```python
)
```
```python
biases
```
```python
=
```
```python
_variable_on_cpu
```
```python
(
```
```python
'biases'
```
```python
,
```
```python
[
```
```python
192
```
```python
]
```
```python
,
```
```python
tf
```
```python
.
```
```python
constant_initializer
```
```python
(
```
```python
0.1
```
```python
)
```
```python
)
```
```python
local4
```
```python
=
```
```python
tf
```
```python
.
```
```python
nn
```
```python
.
```
```python
relu
```
```python
(
```
```python
tf
```
```python
.
```
```python
matmul
```
```python
(
```
```python
local3
```
```python
,
```
```python
weights
```
```python
)
```
```python
+
```
```python
biases
```
```python
,
```
```python
name
```
```python
=
```
```python
scope
```
```python
.
```
```python
name
```
```python
)
```
```python
# linear layer(WX + b),
```
```python
# We don't apply softmax here because
```
```python
# tf.nn.sparse_softmax_cross_entropy_with_logits accepts the unscaled logits
```
```python
# and performs the softmax internally for efficiency.
```
```python
with
```
```python
tf
```
```python
.
```
```python
variable_scope
```
```python
(
```
```python
'softmax_linear'
```
```python
)
```
```python
as
```
```python
scope
```
```python
:
```
```python
weights
```
```python
=
```
```python
_variable_with_weight_decay
```
```python
(
```
```python
'weights'
```
```python
,
```
```python
[
```
```python
192
```
```python
,
```
```python
NUM_CLASSES
```
```python
]
```
```python
,
```
```python
stddev
```
```python
=
```
```python
1
```
```python
/
```
```python
192.0
```
```python
,
```
```python
wd
```
```python
=
```
```python
None
```
```python
)
```
```python
biases
```
```python
=
```
```python
_variable_on_cpu
```
```python
(
```
```python
'biases'
```
```python
,
```
```python
[
```
```python
NUM_CLASSES
```
```python
]
```
```python
,
```
```python
tf
```
```python
.
```
```python
constant_initializer
```
```python
(
```
```python
0.0
```
```python
)
```
```python
)
```
```python
softmax_linear
```
```python
=
```
```python
tf
```
```python
.
```
```python
add
```
```python
(
```
```python
tf
```
```python
.
```
```python
matmul
```
```python
(
```
```python
local4
```
```python
,
```
```python
weights
```
```python
)
```
```python
,
```
```python
biases
```
```python
,
```
```python
name
```
```python
=
```
```python
scope
```
```python
.
```
```python
name
```
```python
)
```
```python
return
```
```python
softmax_linear
```
```python
def
```
```python
loss
```
```python
(
```
```python
logits
```
```python
,
```
```python
labels
```
```python
)
```
```python
:
```
```python
"""Add L2Loss to all the trainable variables.
  Add summary for "Loss" and "Loss/avg".
  Args:
    logits: Logits from inference().
    labels: Labels from distorted_inputs or inputs(). 1-D tensor
            of shape [batch_size]
  Returns:
    Loss tensor of type float.
  """
```
```python
# Calculate the average cross entropy loss across the batch.
```
```python
labels
```
```python
=
```
```python
tf
```
```python
.
```
```python
cast
```
```python
(
```
```python
labels
```
```python
,
```
```python
tf
```
```python
.
```
```python
int64
```
```python
)
```
```python
cross_entropy
```
```python
=
```
```python
tf
```
```python
.
```
```python
nn
```
```python
.
```
```python
sparse_softmax_cross_entropy_with_logits
```
```python
(
```
```python
labels
```
```python
=
```
```python
labels
```
```python
,
```
```python
logits
```
```python
=
```
```python
logits
```
```python
,
```
```python
name
```
```python
=
```
```python
'cross_entropy_per_example'
```
```python
)
```
```python
cross_entropy_mean
```
```python
=
```
```python
tf
```
```python
.
```
```python
reduce_mean
```
```python
(
```
```python
cross_entropy
```
```python
,
```
```python
name
```
```python
=
```
```python
'cross_entropy'
```
```python
)
```
```python
tf
```
```python
.
```
```python
add_to_collection
```
```python
(
```
```python
'losses'
```
```python
,
```
```python
cross_entropy_mean
```
```python
)
```
```python
# The total loss is defined as the cross entropy loss plus all of the weight
```
```python
# decay terms (L2 loss).
```
```python
return
```
```python
tf
```
```python
.
```
```python
add_n
```
```python
(
```
```python
tf
```
```python
.
```
```python
get_collection
```
```python
(
```
```python
'losses'
```
```python
)
```
```python
,
```
```python
name
```
```python
=
```
```python
'total_loss'
```
```python
)
```
```python
def
```
```python
_add_loss_summaries
```
```python
(
```
```python
total_loss
```
```python
)
```
```python
:
```
```python
"""Add summaries for losses in CIFAR-10 model.
  Generates moving average for all losses and associated summaries for
  visualizing the performance of the network.
  Args:
    total_loss: Total loss from loss().
  Returns:
    loss_averages_op: op for generating moving averages of losses.
  """
```
```python
# Compute the moving average of all individual losses and the total loss.
```
```python
loss_averages
```
```python
=
```
```python
tf
```
```python
.
```
```python
train
```
```python
.
```
```python
ExponentialMovingAverage
```
```python
(
```
```python
0.9
```
```python
,
```
```python
name
```
```python
=
```
```python
'avg'
```
```python
)
```
```python
losses
```
```python
=
```
```python
tf
```
```python
.
```
```python
get_collection
```
```python
(
```
```python
'losses'
```
```python
)
```
```python
loss_averages_op
```
```python
=
```
```python
loss_averages
```
```python
.
```
```python
apply
```
```python
(
```
```python
losses
```
```python
+
```
```python
[
```
```python
total_loss
```
```python
]
```
```python
)
```
```python
return
```
```python
loss_averages_op
```
```python
def
```
```python
train
```
```python
(
```
```python
total_loss
```
```python
,
```
```python
global_step
```
```python
)
```
```python
:
```
```python
"""Train CIFAR-10 model.
  Create an optimizer and apply to all trainable variables. Add moving
  average for all trainable variables.
  Args:
    total_loss: Total loss from loss().
    global_step: Integer Variable counting the number of training steps
      processed.
  Returns:
    train_op: op for training.
  """
```
```python
# Variables that affect learning rate.
```
```python
num_batches_per_epoch
```
```python
=
```
```python
NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN
```
```python
/
```
```python
FLAGS
```
```python
.
```
```python
batch_size
  decay_steps
```
```python
=
```
```python
int
```
```python
(
```
```python
num_batches_per_epoch
```
```python
*
```
```python
NUM_EPOCHS_PER_DECAY
```
```python
)
```
```python
# Decay the learning rate exponentially based on the number of steps.
```
```python
lr
```
```python
=
```
```python
tf
```
```python
.
```
```python
train
```
```python
.
```
```python
exponential_decay
```
```python
(
```
```python
INITIAL_LEARNING_RATE
```
```python
,
```
```python
global_step
```
```python
,
```
```python
decay_steps
```
```python
,
```
```python
LEARNING_RATE_DECAY_FACTOR
```
```python
,
```
```python
staircase
```
```python
=
```
```python
True
```
```python
)
```
```python
# Generate moving averages of all losses and associated summaries.
```
```python
loss_averages_op
```
```python
=
```
```python
_add_loss_summaries
```
```python
(
```
```python
total_loss
```
```python
)
```
```python
# Compute gradients.
```
```python
with
```
```python
tf
```
```python
.
```
```python
control_dependencies
```
```python
(
```
```python
[
```
```python
loss_averages_op
```
```python
]
```
```python
)
```
```python
:
```
```python
opt
```
```python
=
```
```python
tf
```
```python
.
```
```python
train
```
```python
.
```
```python
GradientDescentOptimizer
```
```python
(
```
```python
lr
```
```python
)
```
```python
grads
```
```python
=
```
```python
opt
```
```python
.
```
```python
compute_gradients
```
```python
(
```
```python
total_loss
```
```python
)
```
```python
# Apply gradients.
```
```python
apply_gradient_op
```
```python
=
```
```python
opt
```
```python
.
```
```python
apply_gradients
```
```python
(
```
```python
grads
```
```python
,
```
```python
global_step
```
```python
=
```
```python
global_step
```
```python
)
```
```python
# Track the moving averages of all trainable variables.
```
```python
variable_averages
```
```python
=
```
```python
tf
```
```python
.
```
```python
train
```
```python
.
```
```python
ExponentialMovingAverage
```
```python
(
```
```python
MOVING_AVERAGE_DECAY
```
```python
,
```
```python
global_step
```
```python
)
```
```python
with
```
```python
tf
```
```python
.
```
```python
control_dependencies
```
```python
(
```
```python
[
```
```python
apply_gradient_op
```
```python
]
```
```python
)
```
```python
:
```
```python
variables_averages_op
```
```python
=
```
```python
variable_averages
```
```python
.
```
```python
apply
```
```python
(
```
```python
tf
```
```python
.
```
```python
trainable_variables
```
```python
(
```
```python
)
```
```python
)
```
```python
return
```
```python
variables_averages_op
```
```python
def
```
```python
maybe_download_and_extract
```
```python
(
```
```python
)
```
```python
:
```
```python
"""Download and extract the tarball from Alex's website."""
```
```python
pass
```

