
# 深度学习“见顶”不等于AI寒冬 - 喜欢打酱油的老鸟 - CSDN博客


2019年01月25日 11:33:28[喜欢打酱油的老鸟](https://me.csdn.net/weixin_42137700)阅读数：153


[http://m.gmw.cn/toutiao/2019-01/25/content_122035283.htm](http://m.gmw.cn/toutiao/2019-01/25/content_122035283.htm)
尽管新的算法模型在推动AI向前发展，但并不意味着它们的前景可以预见，也不意味着深度学习“不可救药”。
**记者 赵广立 贡晓丽**
在当前的第三次人工智能（AI）浪潮之中，深度学习算法被认为是迄今为止“最为重大的AI革命”。此说法或许有所夸大，但深度学习对这一轮AI的大爆发而言的确功不可没。然而，最近以来，关于深度学习算法是否已经“见顶”“触底”的讨论逐渐增多，“AI或将再度进入寒冬”的说法也一度甚嚣尘上。果真如此吗？
《中国科学报》记者通过检索和采访了解到，类似上述说法可前溯至2018年6月初，多家行业媒体在移动互联网平台上转发了作者信息显示为“Koh Young Technology 公司首席AI 科学家Filip Piekniewski”的文章《AI的寒冬将来临》。该文从深度学习“声势已大幅减弱”“不具有扩展性”“自动驾驶事故不断”三个角度得出结论：“深度学习将大幅降温”“预测AI的冬天就像预测股市崩盘——不可能准确地预测何时发生，但几乎可以肯定的是，它会在某个时点发生。”
最近讨论“深度学习是否触底”的文章，则来自于一家名为“Towards Data Science”的媒体平台。1月中旬，一篇作者署名为Thomas Nield、题目被译作“历史总是在重演，AI寒冬或再来”的文章再提“AI寒冬”，论据再次指向“深度学习的天花板”。在此文中，作者认为“我们的确需要降低期望并停止宣传‘深度学习’的能力了。否则，我们可能会发现自己陷入另一个AI 寒冬”。
被推向神坛的深度学习，怎么突然“生”出这么多缺陷？
**深度学习确有先天缺陷**
相比盲目甩锅“自动驾驶事故不断”，人工智能科学家、地平线创始人兼首席执行官余凯在指出深度学习在自动驾驶领域的局限之前，首先肯定其贡献，“深度学习对于自动驾驶的作用，行业内已一目了然”。
“现在业内强调的是，深度学习已不是唯一。”余凯在接受《中国科学报》采访时表示，在自动驾驶领域，深度学习的局限在于，仅在感知方面发挥作用，而对于异常情况处理等方面的应用效果并不理想。
不仅是自动驾驶，在近两年大热的“AI+医疗”领域，深度学习算法也遭遇了难以再进一步的困境。
“现在深度学习解决临床问题的基本思路，没有太大突破。”科大讯飞医疗信息技术有限公司总经理陶晓东告诉《中国科学报》，这波人工智能过度依赖数据，忽略了很多数据之外的信息，“在医疗领域尤其如此”。
“许多医学理论，比如基本的解剖信息都没有用在深度学习的框架里。”陶晓东认为，这导致AI不能在数据不完全的情况下从更多维度逼近真相，“你不可能有像ImageNet那样地训练数据”。区别于上述行业应用中的问题，南京大学计算机科学与技术系主任、人工智能学院院长周志华认为从学术理论本身出发，深度学习（或深度神经网络）有其固有缺陷。
“神经网络有很多缺陷。”周志华在2018年的一次主题为“关于深度学习一点思考”的分享中明确提到，“凡是用过深度神经网络的人都知道，要花大量的精力来调参数，因为这是一个巨大的系统。这会带来很多问题，首先调参数时，经验是很难共享的；这带来第二个问题——不管是科学研究、技术发展，都希望结果可重复，而在整个机器学习领域里面，深度学习的可重复性是最弱的。”
他举例说，经常会遇到这样的情况：有一组研究人员报告了一个结果，但其他的研究人员很难重复——哪怕用同样的数据、同样的方法。
**可以不必是深度学习**
深度学习能够成功，对以下三个先决条件的满足不可忽视：更多的数据、更强力的计算设备以及很多有效的训练技巧——这帮助人们利用高复杂度的模型，深度神经网络恰恰就是一种便于实现的、高复杂度的模型。
周志华解释说，这背后的逻辑是，当选择使用一个深度模型的时候，得到的结果容易“过拟合”，因此就要使用足够大的数据来训练模型，使其得到的“规律”符合一般规律；而这不但需要训练技巧，还要考虑到如此做会导致系统计算开销非常大，因此要有强有力的计算设备，如GPU等。
“深度神经网络最本质的东西到底是什么？答案可能是表示学习的能力，这是真正重要的。”周志华认为，有了深度学习之后，人们不再需要手工设计特征，把数据从一端扔进去、另外一端出来，中间所有的特征完全通过“学习”来解决，就是所谓的特征学习或表示学习，“这和以往的机器学习技术相比是一个很大的进步，我们不再完全依赖人类专家去设计特征了”。
“表示学习或特征学习最关键的是什么？逐层的处理。”因此，周志华认为，这也是深度神经网络得以成功的内因：先是逐层处理，第二是“要有内部的特征变换”。“当我们考虑到这两件事时，会发现其实深度模型是一个非常自然的选择。有了这样的模型，我们很容易可以做上面两件事。”
算法模型能够逐层处理、具备特征的内部变化，加之有足够的复杂度，在周志华看来是深度神经网络“能够成功的关键原因”。从这个角度思考，周志华认为，如果满足这几个条件，就不一定只用深度神经网络，“神经网络是可选方案之一，只要同时做到这三点，别的模型也可以”。
“虽然神经网络很流行、很成功，但是，在很多的任务上性能最好的，不见得都是深度神经网络。”周志华举例说，比如备受关注的Kaggle 竞赛（全球最大机器学习竞赛社区），有各种各样的真实问题，订票、商品推荐等，许多获胜者并不是深度神经网络，而是类似于随机森林这样的模型。
“靠神经网络获胜的往往就是在图像、视频、声音这几类典型任务上，而涉及到混合建模、离散建模、符号建模的任务，神经网络的性能比其他模型还要差一些。”周志华介绍说，他所领导的研究组提出一个“深度森林”的算法，该算法模型在许多不同任务上得到与深度神经网络高度相似的结果，而在一些其他任务特别是跨任务的表现上非常好，可将同一套参数用在不同任务上，且该模型有自适应复杂度。
除此之外，记者了解到，最近涌现出的一些新的算法概念，如小数据学习、对抗网络（GAN）、胶囊网络技术等，也有望成为对深度学习短板的有效补充。
**“寒冬”之说不客观**
值得一提的是，尽管新的算法模型在推动AI向前发展，但并不意味着它们的前景可以预见，也不意味着深度学习“不可救药”。余凯就自动驾驶领域的应用向《中国科学报》举例说，下一步，深度学习要基于规则方式，同贝叶斯网络结合，“从感知到决策阶段，尤其是决策层面，贝叶斯网络规则的引入尤为重要”。
事实上，深度学习能够得以如此流行，也经历了长期的发展。周志华说，从卷积神经网络开始出现，到这个算法真正在工业界取得巨大成效，中间经过了30 年的发展。
“我们其实没有什么真正的颠覆性技术，所有的技术都是一步步发展的。今天我们有新的探索，能够解决一些问题，但从长远看，在经过很多年、很多人的进一步努力后，今天的探索应该是为未来技术打下一个更加重要的基础。”周志华表示。
从这个视角看来，AI寒冬之说显得毫无客观可言，至少余凯认为如此，“‘风口’或‘寒冬’是这几年不太真正从事人工智能的人大量参与产生的聒噪和炒作而已，真正的AI专家都知道深度学习是AI的一个重要课题，但远非全部”。
深度学习及其衍生技术，是一个机器识别、仿生模态感知与机器理解能力从无到有的进步，在这个进步过程中，有大量的科技公司投注、国家与政府跟进，打开了巨大的商业想象空间以及AI与各行各业结合的可能，尽管这些技术和市场需求相比渗透率还很低，但不能因其不是满分，就打零分。退一步讲，即使深度学习不再在技术端继续增长，要把产业潜力释放出来，也需要一个漫长的时间周期。
人工智能奠基人之一、有“深度学习之父”美誉的Geoffrey Hinton作为曾经的AI寒冬亲历者，对这波“AI寒冬论”的回应更为直接。他说：“不，不会有AI寒冬。因为AI 已经渗透到你生活中了。在之前寒冬中，AI 还不是你生活的一部分，但现在它是了。”（赵广立 贡晓丽）
《中国科学报》 (2019-01-24 第7版 信息技术)
来源： 中国科学报


