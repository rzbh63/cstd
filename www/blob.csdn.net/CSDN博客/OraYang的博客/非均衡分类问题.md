
# 非均衡分类问题 - OraYang的博客 - CSDN博客

2017年08月07日 20:56:08[OraYang](https://me.csdn.net/u010665216)阅读数：724所属专栏：[机器学习](https://blog.csdn.net/column/details/16605.html)



前言
在我们研究非均衡分类这个问题前，我们先来讨论下一个问题。众所周知，在我们一开始学习诸多分类算法(如k-近邻算法，决策树，朴素贝叶斯，logistic，支持向量机，AdaBoost)时，我们一般都假设所有类别的分类代价是一样的，坦白说，在大多数情况下，不同类别的分类代价并不相等。
其他分类性能度量指标：正确率、召回率及ROC曲线
在我们应用前言中提到的那些分类算法时，都是基于错误率来衡量分类器任务的成功程度的。实际上这样的度量错误掩盖了样例如何被分错的事实。在机器学习中，有一个叫作[混淆矩阵](https://en.wikipedia.org/wiki/Confusion_matrix)的工具，可以帮助我们更好的了解分类中的错误。在分类中，当某个类别的重要性高于其他类别时，我们就可以利用上述定义来定义出多个比错误率更好的新指标。
![](https://img-blog.csdn.net/20170807205608087)
另一个用于度量分类中的非均衡的工具是[ROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)曲线，ROC代表接收者操作特征
![](https://img-blog.csdn.net/20170807205608513)
基于代价函数的分类器决策控制
在分类算法中，我们有很多方法可以用来引入代价信息。在AdaBoost中，可以基于代价函数来调整错误权重向量D。在朴素贝叶斯中，可以选择具有最小期望代价而不是最大概率的类别作为最后的结果。在SVM中，可以在代价函数中对于不同的类别选择不同的参数C。上述做法就会给较小类更多的权重，即在训练的时候，小类当中只允许更少的错误。
处理非均衡分类问题的数据抽样方法
另一种针对非均衡问题调节分类器的方法，就是对分类器的训练数据进行改造。这可以通过欠抽样（undersampling）或者过抽样（oversampling）来实现。过抽样意味着复制样例，而欠抽样意味着删除样例。不管采用哪种方式，数据都会从原始形式改造为新形式。抽样过程则可以通过随机方式或者某个预定方式来实现。
总结
分均衡分类问题是指在分类器训练时正例数目与反例数目不相等（相差很大）。该问题在错分正例和反例的代价不同时也存在。







