
# 2.5 范数 - 蜗牛 - CSDN博客


2015年10月14日 18:05:51[会敲键盘的猩猩](https://me.csdn.net/u010182633)阅读数：589标签：[深度学习																](https://so.csdn.net/so/search/s.do?q=深度学习&t=blog)[麻省理工																](https://so.csdn.net/so/search/s.do?q=麻省理工&t=blog)[范数																](https://so.csdn.net/so/search/s.do?q=范数&t=blog)[
							](https://so.csdn.net/so/search/s.do?q=麻省理工&t=blog)[
																					](https://so.csdn.net/so/search/s.do?q=深度学习&t=blog)个人分类：[PRML																](https://blog.csdn.net/u010182633/article/category/3186993)
[
																								](https://so.csdn.net/so/search/s.do?q=深度学习&t=blog)


**声明：该文章翻译自MIT出版的《DEEP LEARNING》，博主会定期更新文章内容。由于博主能力有限，中间有过错之处希望大家给予批评指正，一起学习交流。**
有时候，我们需要度量向量的尺度。在机器学习中，我们通常用$\boldsymbol{L}^p$范数来度量向量的尺度：
$$
\Vert\boldsymbol{x}\Vert_p= \ ( \sum_{i}\Vert x_i\Vert ^p \ )^{1/p}
$$
其中$p\in {\rm R},p\geq 1$
范数，包括$\boldsymbol{L}^p$范数，是将向量映射到非负值的函数，并且满足下面的性质，使得他们类似于点之间的距离：
f(\boldsymbol{x})=0\Rightarrow\boldsymbol{x}=\boldsymbol{0}
f(\boldsymbol{x+y})\leq f(\boldsymbol{x})+f(\boldsymbol{y})(三角不等式)
\forall\alpha\in {\rm R},f(\alpha\boldsymbol{x})=\vert\alpha\vert  f(\boldsymbol{x})
$\boldsymbol{L}^2$范数是欧几里得范数。它仅仅是原点到点$\boldsymbol{x}$的欧几里德距离。它可能是机器学习中最常用的范数。并且也常用$\boldsymbol{x}$的平方来度量向量的尺度，通过$\boldsymbol{x^{\rm T}x}$就能计算出来。
$\boldsymbol{L}^2$范数的平方在数学上和计算上都比$\boldsymbol{L}^2$范数有效。例如，$\boldsymbol{L}^2$范数的平方对$\boldsymbol{x}$中每个元素的导数只依赖于$\boldsymbol{x}$的每个元素。而$\boldsymbol{L}^2$范数的导数依赖于整个向量。在许多情境中，$\boldsymbol{L}^2$范数的平方可能是不方便的，因为在原点附近增长非常慢。在一些机器学习应用中，区别零元素和极小元素是非常重要的，对于这些情况，我们转向在所有位置增长速率一样的函数，但是依然保持数学的简明特性：$\boldsymbol{L}^1$范数。$\boldsymbol{L}^1$范数可以简化为：
$$
\Vert\boldsymbol{x}\Vert_1=\sum_i\vert\boldsymbol{x}_i\vert
$$
当在机器学习中，当零和非零元素之间的区别非常重要时，我们通常使用$\boldsymbol{L}^1$范数。每次$\boldsymbol{x}$的一个元素从零移动到$e$,$\boldsymbol{L}^1$范数就增长$e$。
有时，我们通过计算向量中非零元素的数目来度量它的尺度（当我们用$\boldsymbol{L}^1$范数时，我们经常用它替代该函数）。一些作者将此函数参考为$l_0$范数，但是这个术语不正确，因为按比例改变向量没有改变非零项的数目。
另一个在机器学习中常见的范数是$l_\infty$范数，叫做最大范数。这个范数简化如下：
$$
\Vert\boldsymbol{x}\Vert_\infty={\rm max}_{i} \vert x_i\vert
$$
例如，向量中最大元素的值。
有时，我们可能希望度量矩阵的尺度。在深度学习的情景中，最常用的方式是Frobenius范数：
$$
\Vert A\Vert_F=\sqrt{\sum_{i,j}a_{i,j}^2}
$$
它和向量的$\boldsymbol{L}^2$范数是相似的。
两个向量的点乘可以重写成范数的形式。特别地，
$$
\boldsymbol{x^{\rm T}y}=\Vert\boldsymbol{x}\Vert_2\Vert\boldsymbol{y}\Vert_2cos\theta
$$
其中$\theta$是$\boldsymbol{x}$和$\boldsymbol{y}$之间的角度。

