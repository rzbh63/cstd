
# 多任务——损失函数 - 小花生的博客 - CSDN博客


2018年08月02日 22:41:21[Peanut_范](https://me.csdn.net/u013841196)阅读数：2581


《Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics》
**要解决的问题：**多任务的损失函数（2017）
**创新点：**之前的损失函数是根据不同任务的权重参数计算得来，这些权重的设置是困难的，而且需要花费大量时间和精力去进行验证，在实践中多任务学习望而却步。作者提出了一种考虑homoscedastic uncertainty 为不同的任务来计算损失。作者观察每个任务的最佳权重取决于测量尺度（如米、厘米或毫米）和最终的任务噪音的大小。（同质不确定性）
作者将同质不确定性解释为任务相关加权，并展示了如何导出一个原则的多任务损失函数
（回归和分类损失）。
**Homoscedastic uncertainty as task-dependent uncertainty:**
1）认知不确定性是模型中的不确定性，它捕获了我们的模型所不具备的特性。由于缺乏训练数据。它可以通过增加训练数据来解释。
2）偶然的不确定性捕捉我们对于我们的数据信息的不确定性，无法解释。
（1）数据依赖性或异方差的不确定性是偶然的不确定性，取决于输入数据并作为模型输出进行预测。
（2）任务依赖性或方差不确定性是偶然的不确定性，不依赖于输入数据。它不是一个模型输出，而是一个对所有任务都保持不变的量。输入数据并在不同任务之间变化。因此，它可以被描述为任务依赖的不确定性。
**网络结构：**
![这里写图片描述](https://img-blog.csdn.net/2018080222354352?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTM4NDExOTY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)[ ](https://img-blog.csdn.net/2018080222354352?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTM4NDExOTY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
**损失函数：**
作者根据homoscedastic uncertainty推导出一个基于最大高斯似然估计的多任务损失函数。
![这里写图片描述](https://img-blog.csdn.net/20180802223615830?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTM4NDExOTY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)[ ](https://img-blog.csdn.net/20180802223615830?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTM4NDExOTY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
![这里写图片描述](https://img-blog.csdn.net/20180802223901299?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTM4NDExOTY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)[ ](https://img-blog.csdn.net/20180802223901299?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTM4NDExOTY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
作者通过实验证明，这种损失函数的效果要优于网格搜索的效果
**原因：**
（1）网格搜索的精度取决于搜索的深度。
（2）优化任务权重使用方差噪声项允许在训练中动态配比权重参数。
---

###### 注：博众家之所长，集群英之荟萃。

