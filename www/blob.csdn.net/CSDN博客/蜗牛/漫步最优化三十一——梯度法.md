
# 漫步最优化三十一——梯度法 - 蜗牛 - CSDN博客


2017年10月25日 19:31:10[会敲键盘的猩猩](https://me.csdn.net/u010182633)阅读数：291



$\textbf{我拿起笔芯，}$
$\textbf{开始在心里慢慢书写回忆。}$
$\textbf{记录第一次遇见的你，}$
$\textbf{记录第一次牵手的你，}$
$\textbf{记录第一次亲吻的你，}$
$\textbf{。。。。。。}$
$\textbf{相爱或许像无法被安排的雨，}$
$\textbf{可能随时来袭。}$
$\textbf{我想我是个幸运儿，}$
$\textbf{因为我已经置身大雨滂沱中。}$
$\textbf{——畅宝宝的傻逼哥哥}$
前面几篇文章介绍的方法都是用于一维无约束问题的求解，接下里我们开始考虑多维无约束问题的求解。
类似一维优化问题，多维方法也有两大类，即搜索法与梯度法。对于搜索法，我们只需要知道函数值就能得到解，常用的方法是有组织的搜索参数空间，从而找到目标函数值下降的一条轨迹。最基本的就是从某个点开始，每次调整所有的参数，通过比较所有函数值选出新的点，然后重复这个过程。多维搜索法与一维搜索很类似，但是非常低效，所以这种方法只应用在无法获取梯度信息或者比较难获取梯度信息的问题上，例如目标函数不是连续的问题。
梯度法基于梯度信息，它被分为两大类，一阶法与二阶法。一阶法基于泰勒级数的线性近似，因此需要知道梯度$\mathbf{g}$。而二阶法基于泰勒级数的二次近似，所以既需要梯度$\mathbf{g}$又需要海森矩阵$\mathbf{H}$。
梯度法从简单的到高度复杂的都有，这里我们主要关注最基本的几个：
最速梯度下降法
牛顿法
高斯-牛顿法
一些更高级的梯度法会在后面讨论。

