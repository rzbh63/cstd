
# 《机器学习》周志华-CH1 绪论 - 喜欢打酱油的老鸟 - CSDN博客


2018年10月01日 16:23:03[喜欢打酱油的老鸟](https://me.csdn.net/weixin_42137700)阅读数：65


文章目录1.1 引言1.2 基本术语（极其重要）1.3 假设空间1.4 归纳偏好1.5 发展历程1.6 应用现状习题
1.1 引言
机器学习(machine learning)的定义：它致力于研究如何通过计算的手段，利用经验来改善系统自身的性能。
在计算机系统中，“经验”通常以“数据”的形式存在。
ML研究的主要内容：在计算机上、从数据中产生“模型model”的算法。即是：如何通过数据集产生模型？因此机器学习本质上，研究的是算法；而这种算法的作用是，从数据集中产生模型；而模型的作用是，当面对新的数据时，模型会给我们提供一定的判断，即是数据预测。
模型，可以看做是：从数据集中学得的结果。
机器学习，是研究算法的学问。
2017.1.17记录；
2017.2.5记录；
1.2 基本术语（极其重要）
本节讲述了ML领域诸多经典的基本术语，如果不明白这些术语的含义，那么ML的学习，将会寸步难行。下面，将这些入门术语都做个笔记，用浅显易懂的例子将它表述出来，从而加深自己的理解。
机器学习的根基，是数据，而且是大量的数据；通过将一系列的数据，提取它的规律，那么就能得到模型。注意，ML领域的“模型”，和三维建模的这个“模型”，是有本质上的区别的。后者是一种几何实体，而前者可以理解为一组方程。
本节的基本术语有：
数据集data set：机器学习的基础是数据，数据的集合；
示例instance/样本sample：每条数据描述了一个对象的信息，该对象称之为示例，一般用x表示；
属性attribute/特征feature：数据描述的是样本在某些方面的性质，称之为属性；
属性值attribute value：属性的取值；
属性空间attribute space/样本空间sample space/输入空间input space：对于一个样本而言，假如它有n种属性，则组成了一个n维空间，称之为样本空间；
特征向量feature vector：示例的别名；
学习learning/训练training：从数据集中学得模型的过程；
训练数据training data：学习过程中使用的数据；
训练样本training sample：训练数据中的样本；
训练集training set：数据集分为两部分，一部分用于训练模型；
假设hypothesis：学得的模型对应了数据集中某种潜在的规律，称之为假设；
真相/真实ground-truth：数据集本身的潜在的规律。学习的过程就是逼近真相的过程；
学习器learner：模型的别称；
标记label：有关示例结果的信息，一般用y表示；
样例example：具有标记信息的示例；
标记空间label space/输出空间：所有标记的集合构成的空间；
分类classification：一种典型的学习任务，将数据集按一定规律分为若干类；
回归regression：一种典型的学习任务，预测数据集对应的结果；
二分类binary classification：将数据集分为两类；
正类positive class：二分类任务其中的一类数据；
反类negative class：同上；
多分类multi-class classification：将数据集分为多类；
测试testing：学得模型后，对其进行预测的过程。机器学习是一个反复的过程，需要重复多次学习、测试、调整，才能得到准确率最高的模型；
测试样本testing sample：被预测的样本；
聚类clustering：无监督学习的一种，将训练集的数据分为若干组，而这些组事先是不知道的；
簇cluster：聚类得到的数据分类；
监督学习supervised learning：训练数据拥有标记信息；
无监督学习unsupervised learning：训练数据没有标记信息；
泛化generalization能力：学得模型适用于新样本的能力。或者说，模型预测数据的精准度；
独立同分布independent and identically distributed：简称i,i,d。假设样本是从一个很大的数据空间中，独立的从其内在分布上得到的；
大概20多个专有名词，一开始看的时候，不可能全部都理解的很透彻。因此，需要反复、多次的观看和理解。这些专有名词，是ML领域不可避免的重要内容。
1.3 假设空间
学习的目的是泛化，即通过训练，得到一个模型，而这个模型可以对新样例的标签进行精准的预测。
学习的过程，也可以看做，在所有假设组成的空间中，进行搜索的过程。假设，就是说该数据集对应的潜在规律；这个规律可能有很多种，学习的过程，就是找到最适合它的那一种。
1.4 归纳偏好
很多情况下，通过现有的有限的数据集，可以得到多个假设空间；但是我们必须得到一个最好的模型。这时候，就要从这若干个假设空间中，选择其中的一个，从这个空间中提取ML的模型。
尽管数据集无法从这若干个假设空间中选择最佳的那一个，但是我们可以使用另一个法宝：归纳偏好。机器学习算法在学习的过程中，对某种类型的假设的偏好，称之为归纳偏好。可以简单的理解为，对于上述不同的假设空间，在选择最优模型时，其权重不同。
对于归纳偏好，我们使用奥卡姆剃刀来作为一般的原则，用于引导算法确立“正确”的偏好。奥卡姆梯度是自然科学中最常见的法则之一：若有多个假设与观察一致，则选最简单的那个。
1.5 发展历程
本节讲述机器学习的发展历程，属于common knowledge的介绍。没有任何难度，了解即可。
机器学习是人工智能(artificial intelligence)研究发展到一定阶段的必然产物。下面总结ML的发展历程：
时间 | 流派 | 主要人物 | 成果
| :-: | -:
1950-1970 | 推理期 | A.Newell和H.Simon| 逻辑理论家、通用问题求解
1975-1995 | 知识期 | E.A. Feigenbaum    | 知识工程、专家系统
1980-1990 | 符号主义 | 诸多                     | 决策树、基于逻辑的学习
1950-1985 | 连接主义 | J.J.Hopfield         | BP神经网络
1995-1970 | 统计学习 | V.N.Vapnik          | SVM、核方法、VC维
2000-2015 |连接主义 | 诸多                    | 深度学习、大数据时代
1.6 应用现状
大数据时代的三大关键技术：机器学习、云计算、众包crowdsourcing
ML的应用领域：天气预报、环境监测、能源勘探、商业营销策划、互联网搜索、图片搜索、自动驾驶、奥巴马大选、脑科学研究等。
习题
1.1 表1.1中若只包含编号为1和4的两个样例，试给出相应的版本空间。
1.2 与试用单个合取式来进行假设表示相比，试用“析合范式”将使得假设空间具有更强的表示能力。例如：
好瓜<->(（色泽=）（根蒂=蜷缩）（敲声=）)
会把“ ”以及“ ”都分类为“好瓜”。若使得最多包含k个合取式的析合范式来表达表1.1西瓜分类问题的假设空间，试估算共有多少种可能的假设。
1.3 若数据包含噪声，则假设空间中有可能不存在与所有训练样本都一致的假设。在此情形下，试设计一种归纳偏好用于假设选择。
1.4 本章1.4节在论述“没有免费的午餐”定理时，默认使用了“分类错误率”作为性能度量来对分类器进行评估。若换用其他性能度量l，则式(1.1)将改为
试证明，“没有免费的午餐定理”仍成立。
1.5 试述机器学习能在互联网搜索的哪些环节起什么作用。
---------------------
本文来自 JasonYoung_2017 的CSDN 博客 ，全文地址请点击：[https://blog.csdn.net/qq_34100655/article/details/79122523?utm_source=copy](https://blog.csdn.net/qq_34100655/article/details/79122523?utm_source=copy)

