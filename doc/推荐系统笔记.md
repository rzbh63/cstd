# 推荐系统笔记



# 

版权声明：本文为博主原创文章，转载请附

http://blog.csdn.net/asd136912

https://blog.csdn.net/asd136912/article/details/78258564

​		

在推荐系统的系列笔记中预计将会简要记录这些：

一些推荐系统的基础应用：

- Content Based Recommendation System 基于内容的推荐系统
- Collaborative Filtering 协同过滤
- Low Rank Matrix Factorization 低阶矩阵分解

以及一些更加精确不过更为复杂的模型：

- LFM (Latent Factor Model) 隐因子模型
- SVD (Singular Value Decomposition) 奇异值分解 / SVD++
- Factorization Machines 因子分解机
- Field-aware Factorization Machine (FFM) 场感知分解机
- Group Lasso (least absolute shrinkage and selection operation) 分组最小角回归算法

### 综述

现在常见的推荐系统可以分为以下两种形式：

- Rating prediction 评分预测
- Item recommendation (基于历史记录的) 物品推荐

评分预测是比较简单的一种模型，比如某个用户给定某个物品的评分，在对比其他用户对该用户的评分相似度来判断该用户对其他物品的喜爱程度，从而进行推荐。最典型的就是IMDB与豆瓣，都需要用户主动评分才能进行下一步推荐。其中CBRS基于内容的推荐系统，Collaborative  Filtering 协同过滤，SVD奇异值分解就是评分预测的典型模型。

然而评分预测在大部分场景中并不适用，比如在许多电商购物网站，许多用户并不会主动给某个物品进行评分，而且每个物品的attribute差距都很大，不能像电影那样对每个电影的不同属性进行分类从而进行推荐。这个时候只能通过用户的历史记录，点击，购买记录，评论对用户进行合适的推荐。其中有LSA(Latent  Semantic Analysis)  隐语义模型：分析用户评论的语义进行推荐；Curiosity Based  Model基于好奇心的心理学模型；或是使用数据挖掘的频繁项物品进行推荐(bundle recommendation)等等。

基于此，大概可以归纳出以下三类模型。在这三类中，每一类又包含很多方法，无法绝对的说哪一类模型最好，依照具体的数据形式以及内容而定。

> 1. 基于聚类的推荐 
> 2. 基于协同过滤的推荐 
> 3. 基于模型学习的推荐 

#### 1.基于聚类的推荐

第一类的模型可以使用到的方法： 

> 1. 全局均值 
> 2. 物品均值 
> 3. 用户均值 
> 4. 用户分类-物品均值 
> 5. 物品分类-用户均值 
> 6. 用户活跃度 
> 7. 物品活跃度 
> 8. 改进的用户活跃度 
> 9. 改进的物品活跃度 

这类模型的共同特征是通过设计聚类方法来对用户和物品分类，利用同类用户对同类物品的评分均值来预测用户对物品的评分。另外通过该模型的实现对用户和商品的特征有一个基本的了解。

#### 2.基于协同过滤的推荐

第二类的模型主要使用的方法是基于物品的协同过滤，它的核心思想是当预测用户对一个物品评分时，主要考虑与该物品最相似且用户已打过分的若干物品。所以在这其中相似度的度量方法尤其重要，包括欧氏距离、皮尔逊相似度度量、余弦相似度度量、改进的余弦相似度度量。（之所以不使用基于用户的协同过滤，是由于建立用户-用户的相似度矩阵过于巨大）

#### 3.基于模型学习的推荐

第三类的模型使用的方法有： 

> 1. SVD 
> 2. NMF 
> 3. RSVD 
> 4. SVD++ 
> 5. SVDfeature 
> 6. Libmf 
> 7. Libfm 

这一类模型的共同特点是矩阵分解。即对用户-物品评分矩阵分解成若干个小矩阵，目的是分解之后的矩阵乘积接近原始矩阵，于是也实现了对原始矩阵为空的值的预测。在这些方法中，比较重要的几个参数有：隐特征个数，随机梯度下降中的学习率，正则化参数，总迭代次数。具体在每个方法中这些参数的最优值也不尽相同。  



### 参考文献

1. [sigir17-Embedding Factorization Models for Jointly Recommending 
    Items and User Generated Lists.pdf](http://www.comp.nus.edu.sg/~xiangnan/papers/sigir17-EmbeddingMF.pdf)
2. <http://blog.csdn.net/u010414589/article/details/52185257>



​				

### 基于内容的推荐系统 (CBRS)

首先介绍一下最简单的一个推荐算法模型CBRS。在这个模型中我们用线性回归的基本思路拟合出每个用户对每个电影的评分向量，预测出用户没有评分的电影并进行推荐。

假设我们有4个Users和5个Movies，有一些用户给电影打了分，有一些没有打。电影的评分是从0-5，没有评分的项在表格中将用？来表示。我们设定每个电影有$X_1$和$X_2$两个属性，分别是浪漫和动作，并手动给每个电影进行$X_1$和$X_2$的设置。

| Movies\User | User 1 | User 2 | User 3 | User 4 | $X_1$(romance) | $X_2$(action) |
| ----------- | ------ | ------ | ------ | ------ | -------------- | ------------- |
| Movie 1     | 5      | 5      | 0      | 0      | 0.9            | 0             |
| Movie 2     | 5      | ？     | ？     | 0      | 1              | 0.01          |
| Movie 3     | ？     | 4      | 0      | ？     | 0.99           | 0             |
| Movie 3     | 0      | 0      | 5      | 4      | 0.1            | 1             |
| Movie 3     | 0      | 0      | 5      | ？     | 0              | 0.9           |

------

接下来引入一些标记： 
 $n_u​$ 表示User的数量 

$n_m​$ 表示Movie的数量 

 $r(i,j)$ 表示User i 是否给 Movie j 评过分，有则=1，无则=0 

$y^{(i,j)}$ 表示User i 给 Movie j 的评分 

$m_j​$ 表示User j 评过分的电影总数

我们对以上特征来构建一个线性回归模型的算法，针对每个用户j都有一个$θ^j​$参数向量（可以理解为对电影的各个属性喜爱程度），并用$x^i​$表示电影i的特征向量。对于用户j对电影i的评分，预测值为$(θ^j)^Tx^i​$。

根据以上我们可以构建出代价函数Cost function J = $\sum_{i:r(i,j)=1}  ((θ^j)^Tx^i-y^{(i,j)})^2​$

  根据线性回归模型，我们需要最小化代价函数，并加上正则化项: $min\frac{1}{2} \sum_{i:r(i,j)=1}  ((θ^j)^Tx^i-y^{(i,j)})^2 + \frac{λ}{2}\sum_{k=1}^n(θ^j_k)^2$

  其中 $i:r(i,j)$表示我们只计算那些用户 j 评过分的电影。在一般的线性回归模型中，误差项和正则项应该都是乘以 1/2m，在这里我们将 m 去掉。并且我们不对方差项 $θ_0$ 进行正则化处理。 

 上面的操作都是对单个用户线性回归模型，对于所有用户，我们有： 

$min_{θ_1..θ_{n^u}}\frac{1}{2} \sum_{j=1}^{n^u}\sum_{i:r(i,j)=1}  ((θ^j)^Tx^i-y^{(i,j)})^2 + \frac{λ}{2}\sum_{j=1}^{n^u}\sum_{k=1}^n(θ^j_k)^2$

 如果使用梯度下降来求解，根据Cost function代价函数求偏导可以得出θ的更新公式,其中a表示学习速率： 

$θ^j_k:=θ^j_k - a\sum_{i:r(i,j)=1} ((θ^j)^Tx^i-y^{(i,j)})x_k^i (k=0)$

$θ^j_k:=θ^j_k - a(\sum_{i:r(i,j)=1} ((θ^j)^Tx^i-y^{(i,j)})x_k^i +λ θ^j_k) (k!=0)$

> 当然此模型可能过于简单，除了每个电影的属性很少，而且人们喜爱一个电影的因素也不只是因为电影的分类，电影的演员，导演，甚至是上映时间都可以成为观众喜爱一部电影的重要因素。

### Collaborative Filtering 协同过滤算法

在之前基于内容的推荐系统中，我们必须要有电影的特征向量才能求出每个用户的参数向量，但是这样会带来很大的麻烦，原因是每个人对电影的分类概念都不同，而且需要手动定义每个电影的特征向量将会降低许多效率。 
 不如我们换个思路，可否通过用户参数向量来拟合出电影的特征向量呢？当然是可以的: 

$min_{x_1..x_{n^m}}\frac{1}{2} \sum_{i=1}^{n^u}\sum_{j:r(i,j)=1}  ((θ^j)^Tx^i-y^{(i,j)})^2 + \frac{λ}{2}\sum_{i=1}^{n^m}\sum_{k=1}^n(x^i_k)^2$

   和之前作对比两个最小化代价函数都如此相近，那么将用户参数与电影的向量都作为代价函数J的输入值，再分别对x于θ分别求偏导就可以解决实际应用中用户评分与电影特征向量都不全的问题了。 

$Cost Function J(x,θ) = \frac{1}{2}\sum_{(i,j):r(i,j)=1}  ((θ^j)^Tx^i-y^{(i,j)})^2 + \frac{λ}{2}\sum_{i=1}^{n^m}\sum_{k=1}^n(x^i_k)^2  + \frac{λ}{2}\sum_{j=1}^{n^u}\sum_{k=1}^n(θ^j_k)^2$

   再对x与θ分别求偏导，并用梯度下降求局部最小值 

$θ^j_k:=θ^j_k - a(\sum_{i:r(i,j)=1} ((θ^j)^Tx^i-y^{(i,j)})x_k^i +λ θ^j_k)$

$x^i_k:=x^i_k - a(\sum_{j:r(i,j)=1} ((θ^j)^Tx^i-y^{(i,j)})θ_k^j +λ x^i_k)$

 注：在协同过滤从算法中，我们通常不使用方差项，如果需要的话，算法会自动学得。



> 协同过滤算法使用步骤如下：
>
> 1. 初始 $x(1),x(2),…,x(n_m)，θ(1),θ(2),…,θ(n_u)$为一些随机小值
> 2. 使用梯度下降算法最小化代价函数
> 3. 在训练完算法后，我们预测$(θ(j))^Tx(i)$为用户 j 给电影 i 的评分从而进行推荐

- 均值化处理（Mean Normalization）

   现在假设新来了一名用户，她从来没有看过任何电影，我们该如何给该用户推荐电影呢？首先我们可以先得出矩阵Y表示用户与评分：最有一列为该用户的评分 

$$
Y=\begin{bmatrix} 
5 & 5 & 0 & 0 & ?\\ 
5 & ? & ? & 0 & ?\\ 
? & 4 & 0 & ? & ?\\ 
0 & 0 & 5 & 4 & ?\\ 
0 & 0 & 5 & 0 & ? 
\end{bmatrix}
$$

 我们首先需要对结果 Y 矩阵进行均值归一化处理，将每一个用户对某一部电影的评分减去所有用户对该电影评分的平均值： 

$$
Y=\begin{bmatrix} 
2.5 & 2.5 & -2.5 & -2.5 & ?\\ 
2.5 & ? & ? & -2.5 & ?\\ 
? & 2 & -2 & ? & ?\\ 
-2.25 & -2.25 & 2.75 & 1.75 & ?\\ 
-1.25 & -1.25 & 3.75 & -1.25 & ? 
\end{bmatrix}
$$
 然后我们利用这个新的 Y 矩阵来训练算法。如果我们要用新训练出的算法来预测评分，则需要将平均值重新加回去，预测$(θ(j))^T(x(i))+μi$对于新用户，我们的新模型会认为她给每部电影的评分都是该电影的平均分。

### Matlab代码参考

cofiCostFunc.m

```matlab
function [J, grad] = cofiCostFunc(params, Y, R, num_users, num_movies, ...
                                  num_features, lambda)
% Collaborative filtering cost function

% Unfold the U and W matrices from params
X = reshape(params(1:num_movies*num_features), num_movies, num_features);
Theta = reshape(params(num_movies*num_features+1:end), ...
                num_users, num_features);
J = 0;
X_grad = zeros(size(X));
Theta_grad = zeros(size(Theta));

M=(X*Theta'-Y).^2;
J=1/2*sum(sum(R.*M));
J=J+lambda/2*sum(sum(Theta.^2))+lambda/2*sum(sum(X.^2));

for k=1:num_features
    for i=1:num_movies   
        for j=1:num_users
               X_grad(i,k)=X_grad(i,k)+(X(i,:)*Theta(j,:)'-Y(i,j))*Theta(j,k).*R(i,j);
        end
    end
end
X_grad=X_grad+lambda*X;

for k=1:num_features
    for j=1:num_users
        for i=1:num_movies
               Theta_grad(j,k)=Theta_grad(j,k)+(X(i,:)*Theta(j,:)'-Y(i,j))*X(i,k).*R(i,j);
        end
    end
end
Theta_grad=Theta_grad+lambda*Theta;

grad = [X_grad(:); Theta_grad(:)];

end
```





### Low Rank Matrix Factorization低阶矩阵分解

在上一篇[笔记之二](http://blog.csdn.net/asd136912/article/details/78262145)里面说到我们有五部电影，以及四位用户，每个用户对电影的评分如下，？表示未评分。

| Movies\User | User 1 | User 2 | User 3 | User 4 |
| ----------- | ------ | ------ | ------ | ------ |
| Movie 1     | 5      | 5      | 0      | 0      |
| Movie 2     | 5      | ？     | ？     | 0      |
| Movie 3     | ？     | 4      | 0      | ？     |
| Movie 4     | 0      | 0      | 5      | 4      |
| Movie 5     | 0      | 0      | 5      | ？     |

那么我们可以把第一个表格里的内容转化成一个矩阵R： 
$$
R=\begin{bmatrix} 
5 & 5 & 0 & 0\\ 
5 & ? & ? & 0\\ 
? & 4 & 0 & ?\\ 
0 & 0 & 5 & 4\\ 
0 & 0 & 5 & 0 
\end{bmatrix}
$$
 把参数θ和特征变量x也都表示成向量的形式： 
$$
X=\begin{bmatrix} 
---(x^{(1)})^{T}---\\ 
---(x^{(2)})^{T}---\\ 
...\\ 
---(x^{(n_{m})})^{T}--- 
\end{bmatrix}
$$

$$
\Theta=\begin{bmatrix} 
---(\theta^{(1)})^{T}---\\ 
---(\theta^{(2)})^{T}---\\ 
...\\ 
---(\theta^{(n_{u})})^{T}--- 
\end{bmatrix}
$$



 那么我们有：$R =\Theta^{T}X$，这种方法被称为：低秩矩阵分解（Low Rank Matrix Factorization）。



> 相关应用：
>
> - 找电影i相似的电影j：可以计算$\left \| x^{(i)} - x^{(j)} \right \|$两个特征向量的距离，其中距离最小的就是最相似的电影。



### LFM (Latent Factor Model) 隐因子模型

接下来引申到LFM (Latent Factor Model)  隐因子模型，其中隐因子可以理解为一个用户喜欢一个电影的隐形原因，比如电影里面有他喜欢的romantic和action元素，还有他喜欢的某个演员或者导演编剧。如果另外一个电影有类似的元素跟演员，那么他很有可能会也喜欢这部电影。LFM的核心思路就是求出用户的θ向量和电影的x向量。 

 在评分矩阵$R_{m,n}$中，LFM中认为评分矩阵可以表示为$R_{m,n}=P_{m,F}\cdot{Q_{F,n}}$即两个矩阵的乘积，其中F为隐因子的个数。我们设$\hat {r}_{ui}$为用户u对物品i的评分。 
$$
\hat{r}_{ui}=\sum_{f=1}^{F}{P_{uf}Q_{fi}}
$$
 我们的目标是减少$\hat {r}_{ui}$与${r}_{ui}$之间的差距，并且为了防止过拟合加入了正则项。 
$$
min: Cost Function J=\sum_{\color{red}{r_{ui}\ne0}}{(r_{u,i}-\hat{r}_{ui})^2}+\lambda(\sum{P_{uf}^2}+\sum{Q_{fi}^2})
$$
 通过梯度下降对代价函数求偏导，可以得出： 
$$
\frac{\partial{J}}{\partial{P_{uf}^{(t)}}}=\sum_{\color{red}{i,r_{ui}\ne0}}{-2(r_{u,i}-\hat{r}_{ui})Q_{fi}^{(t)}}+2\lambda{P_{uf}^{(t)}}
$$

$$
\frac{\partial{J}}{\partial{Q_{fi}^{(t)}}}=\sum_{\color{red}{u,r_{ui}\ne0}}{-2(r_{u,i}-\hat{r}_{ui})P_{uf}^{(t)}}+2\lambda{Q_{fi}^{(t)}}
$$

 在上一步可以使用随机梯度下降方法(SGD,Stochastic Gradient Descent)，它比传统的梯度下降法需要更少的迭代次数就可以收敛，这里就不详细阐述了。



### SVD (singular value decomposition) 奇异值分解

SVD的数学意义和理解可以参考这篇[博客](https://blog.csdn.net/asd136912/article/details/79864576) 

这里的SVD推荐本质上是model-based，跟传统数学意义的SVD没有太大关系，只不过借鉴了SVD分解*R*=*U*∗*S*∗*V*

这个形式，通过最优化方法进行模型拟合，求得$R=U∗V$。

我们在刚刚上面提到的$\hat{r}_{ui}$中加入偏置项： 
$$
\hat{r}_{ui}=\sum_{f=1}^{F}{P_{uf}Q_{fi}}+\mu+b_u+b_i
$$
 其中$μ$表示训练集中物品的所有评分的平均值。$b_u$是用户偏置项，表示一个用户评分的平均值。$b_i$是物品偏置项，表示一个物品被评分的平均值。偏置项是固有属性，每个用户和物品都有自己的值，代表该物品是否被大众喜爱程度或某个用户对物品苛刻程度。 

 带偏置的LFM又被称为SVD。加入偏置项之后我们可以得到新的代价函数： 
$$
J=\sum_{\color{red}{r_{ui}\ne0}}{(r_{u,i}-\hat{r}_{ui})^2}+\lambda(\sum{P_{uf}^2}+\sum{Q_{fi}^2}+\sum{b_u^2}+\sum{b_i^2})
$$
 通过随机梯度下降可以求得： 
$$
b_u^{(t+1)}:=b_u^{(t)}+\alpha*(r_{u,i}-\hat{r}_{ui}-\lambda*b_u^{(t)}) \\
b_i^{(t+1)}:=b_i^{(t)}+\alpha*(r_{u,i}-\hat{r}_{ui}-\lambda*b_i^{(t)})
$$


### SVD++ / TIME SVD ++

我们从上一步的BiasLFM(即SVD)继续演化就可以得到SVD++。 
 SVD++：User对Item i 有评分，则反映他对各个隐因子的喜好程度$y_i=(y_{i1},y_{i2},...,y_{iF})$，是物品所携带的属性。 
$$
\hat{r}_{ui}=\sum_{f=1}^{F}{(P_{uf}+\frac{\sum_{j\in{N(u)}}{Y_{jf}}}{\sqrt{|N(u)|}})Q_{fi}}+\mu+b_u+b_i
$$
 其中$N_u$为User u 评价过的物品集合。 

 使用随机梯度下降可以求得Q与Y的偏导 
$$
\frac{\partial{\hat{r_{ui}}}}{\partial{Q_{fi}}}=P_{uf}+\frac{\sum_{j\in{N(u)}}{Y_{jf}}}{\sqrt{|N(u)|}}\\
\frac{\partial{\hat{r_{ui}}}}{\partial{Y_{jf}}}=\frac{Q_{fi}}{\sqrt{|N(u)|}}
$$
 其他偏导于SVD的一样，收缩因子取集合大小的根号是一个经验公式，并没有理论依据。 

 TIME SVD ++: 添加了时间动态，这里就不详细阐述了~



### 矩阵分解优劣势

主要的优势如下：

- 比较容易编程实现，随机梯度下降方法依次迭代即可训练出模型。
- 预测的精度比较高，预测准确率要高于基于领域的协同过滤以及基于内容CBR等方法。
- 比较低的时间和空间复杂度，高维矩阵映射为两个低维矩阵节省了存储空间，训练过程比较费时，但是可以离线完成；评分预测一般在线计算，直接使用离线训练得到的参数，可以实时推荐。
- 非常好的扩展性，如由SVD拓展而来的SVD++和 TIME SVD++。

矩阵分解的不足主要有：

- 训练模型较为费时。
- 推荐结果不具有很好的可解释性，无法用现实概念给分解出来的用户和物品矩阵的每个维度命名，只能理解为潜在语义空间。





​				

### Factorization Machines 因子分解机



Factorization Machines(FM) 因子分解机是Steffen Rendle于2010年提出，而Field-aware  Factorization Machine (FFM) 场感知分解机最初的概念来自于Yu-Chin  Juan与其比赛队员，它们借鉴了辣子Michael Jahrer的论文中field概念，提出了FM的升级版模型。 
 FM的paper中主要对比对象是SVM支持向量机，与SVM相比，有如下几个优势 

- FM可以实现对于输入数据是非常稀疏（比如自动推荐系统），而SVM会效果很差，因为训出的SVM模型会面临较高的bias。 
- FMs拥有线性的复杂度, 可以通过 primal 来优化而不依赖于像SVM的支持向量机。

在推荐系统和计算广告领域，点击率CTR（click-through rate）和转化率CVR（conversion  rate）是衡量广告流量的两个关键指标。准确的估计CTR、CVR对于提高流量的价值，增加广告收入有重要的指导作用。FM和FFM近年来表现突出，分别在由[Criteo](https://www.baidu.com/s?wd=Criteo&tn=24004469_oem_dg&rsv_dl=gh_pl_sl_csd)和[Avazu](https://www.baidu.com/s?wd=Avazu&tn=24004469_oem_dg&rsv_dl=gh_pl_sl_csd)举办的CTR预测竞赛中夺得冠军。

假如在某个电影播放网站有这么一组实时数据：

| MoviesClass | Actor | Director | MoviesIsPlay? |
| ----------- | ----- | -------- | ------------- |
| Action      | A     | AA       | 1             |
| Romantic    | B     | BB       | 0             |
| Action      | A     | BB       | 1             |

其中MoviesIsPlay?是label，MoviesClass 、UserType、Actor、Director是特征。以上这四种特征都是categorical类型的，需要经过独热编码（One-Hot Encoding）转换成数值型特征。

| MoviesClass = Action | MoviesClass = Romantic | Actor = A | Actor = B | Director = AA | Director = BB | MoviesIsPlay = 1 | MoviesIsPlay = 0 |
| -------------------- | ---------------------- | --------- | --------- | ------------- | ------------- | ---------------- | ---------------- |
| 1                    | 0                      | 1         | 0         | 1             | 0             | 1                | 0                |
| 0                    | 1                      | 0         | 1         | 0             | 1             | 0                | 1                |
| 1                    | 0                      | 1         | 0         | 0             | 1             | 1                | 0                |

从该独热编码表可以看出矩阵许多值都为0，数据十分稀疏，而且会导致数据维度增大，数量级从$n$增大到$n^2$

。

而我们的目的是从该矩阵中**获取到特征的某些关联**，比如MovieClass=action 与 actor=A 关联比较大，电影播放量可很客观，从而对用户进行推荐。

先从线性回归和多项式回归开始建模，这里我们以二阶多项式模型（degree = 2时）为例：  $x_ix_j$

表示特征$x_i$和$x_j$的组合，当$x_i$和$x_j$都非零时，组合特征$x_ix_j$才有意义。 
$$
\hat{y}(x) := \underbrace {w_0 + \sum_{i=1}^{n} w_i x_i }_{\text{线性回归}} + \underbrace {\sum_{i=1}^{n} \sum_{j=i+1}^{n} w_{ij} x_i x_j}_{\text{交叉项（组合特征）}}
$$
 其中，n 代表样本的特征数量，$x_i$是第 i 个特征的值，$w_0、w_i、w_{ij}$ 是模型参数。

从此公式可以看出组合特征一共有n(n-1)/2个，如果特征n上百个，组合特征上万个，就是任意两个$w_{ij}$相互独立，样本数据很稀疏，$x_ix_j$为非零的项会非常的少，导致训练样本的不足，很容易导致参数 $w_{ij}$不准确，最终将严重影响模型的性能和稳定性。

那么如何解决这些问题呢？上一篇博客的矩阵分解提供了思路。在一个rating矩阵可以分解为user矩阵和item矩阵，每个user和item都可以采用一个隐向量表示，两个向量的点积就是矩阵中user对item的打分。

类似地，所有二次项参数 $w_{ij}$ 可以组成一个对称阵 W，可以分解为$W=V^TV$，V  的第 j 列便是第 j 维特征的隐向量，也就是说每个参数 $w_{ij}=⟨v_i,v_j⟩$，**这就是FM模型的核心思想（不讨论高阶形式）**。所以可以得到：  
$$
\hat{y}(\mathbf{x}) := w_0 + \sum_{i=1}^{n} w_i x_i + \sum_{i=1}^{n} \sum_{j=i+1}^{n} \langle \mathbf{v}_i, \mathbf{v}_j \rangle x_i x_j
$$
 其中<>表示两个向量的点积
$$
\langle \mathbf{v}_i, \mathbf{v}_j \rangle := \sum_{f=1}^{k} v_{i,f} \cdot v_{j,f}
$$
 直观上看，FM的复杂度是 $O(kn^2)$。但是，通过下列等式，FM的二次项可以化简，其复杂度可以优化到 $O(kn)$。由此可见，FM可以在线性时间对新样本作出预测。 
$$
\sum_{i=1}^n \sum_{j=i+1}^n \langle \mathbf{v}_i, \mathbf{v}_j \rangle x_i x_j = \frac{1}{2} \sum_{f=1}^k \left(\left( \sum_{i=1}^n v_{i, f} x_i \right)^2 - \sum_{i=1}^n v_{i, f}^2 x_i^2 \right)
$$
 下面给出详细证明过程：



> $$
> \begin{align} & \sum_{i=1}^{n} \sum_{j=i+1}^{n} {\langle \mathbf{v}_i, \mathbf{v}_j \rangle} x_i x_j \qquad\qquad\qquad\qquad\qquad\qquad(1)\\
> = & \frac{1}{2} \sum_{i=1}^{n} \sum_{j=1}^{n} {\langle \mathbf{v}_i, \mathbf{v}_j \rangle} x_i x_j - \frac{1}{2} \sum_{i=1}^{n} {\langle \mathbf{v}_i, \mathbf{v}_i \rangle} x_i x_i \qquad\qquad\;\;(2)\\
> = & \frac{1}{2} \left(\sum_{i=1}^{n} \sum_{j=1}^{n} \sum_{f=1}^{k} v_{i,f} v_{j,f} x_i x_j - \sum_{i=1}^{n} \sum_{f=1}^{k} v_{i,f} v_{i,f} x_i x_i \right) \qquad\,(3) \\
> = & \frac{1}{2} \sum_{f=1}^{k} {\left \lgroup \left(\sum_{i=1}^{n} v_{i,f} x_i \right) \cdot \left(\sum_{j=1}^{n} v_{j,f} x_j \right) - \sum_{i=1}^{n} v_{i,f}^2 x_i^2 \right \rgroup} \quad\;\;\,(4) \\
> = & \frac{1}{2} \sum_{f=1}^{k}  {\left \lgroup \left(\sum_{i=1}^{n} v_{i,f} x_i \right)^2 - \sum_{i=1}^{n} v_{i,f}^2 x_i^2\right \rgroup} \qquad\qquad\qquad\;\;(5) \end{align}
> $$
>
>    其中第（1）步到第（2）步，这里用AA表示系数矩阵VV的上三角元素，BB表示对角线上的交叉项系数。由于系数矩阵VV是一个对称阵，所以下三角与上三角相等，有下式成立： 
> $$
> A = \frac{1}{2} (2A+B) - \frac{1}{2} B.  \quad \underline{ A=\sum_{i=1}^{n} \sum_{j=i+1}^{n} {\langle \mathbf{v}_i, \mathbf{v}_j \rangle} x_i x_j } ; \quad \underline{ B = \frac{1}{2} \sum_{i=1}^{n} {\langle \mathbf{v}_i, \mathbf{v}_i \rangle} x_i x_i }
> $$

之后采用随机梯度下降SGD（Stochastic Gradient Descent）训练模型参数。那么，模型各个参数的梯度如下: 
$$
\frac{\partial}{\partial \theta} y(\mathbf{x}) = \left \{ \begin{array}{ll} 1,         & \text{if}\; \theta\; \text{is}\; w_0 \qquad \text{(常数项)} \\ x_i     & \text{if}\; \theta\; \text{is}\; w_i \;\qquad \text{(线性项)} \\ x_i \sum_{j=1}^{n} v_{j,f} x_j - v_{i,f} x_i^2, & \text{if}\; \theta\; \text{is}\; v_{i,f} \qquad \text{(交叉项)} \end{array} \right.
$$
 其中，$v_j$,f是隐向量 $v_j$ 的第 f 个元素。由于$\sum_{j=1}^n v_{j, f} x_j$只与 f 有关，而与 i 无关，在每次迭代过程中，只需计算一次所有 f 的$\sum_{j=1}^n v_{j, f} x_j$就能够方便地得到所有 $v_i,f$ 的梯度。因此，FM参数训练的复杂度也是 O(kn)。



#### FM总结

首先是为什么使用向量的点积可以解决以上问题呢？

- 参数的数量大幅度缩减，从n×(n−1)/2降低到nk

- 隐向量的点积可以表示原本两个毫无相关的参数之间的关系

- 而稀疏数据下学习不充分的问题也能得到充分解决。比如原本的多项式回归的参数$w_{12}$的学习只能依赖于特征$x_1$和$x_2$；而对参数$⟨v_1,v_2⟩$ 而言就完全不一样了，它由$v_1$和$v_2$组成。而对于每个向量可以通过多个交叉组合

  特征学习得到，比如可以由$x1x2,x1x3,..$学习获得，这样可供学习的非零样本就大大增加了。

其次FM与矩阵分解MF与SVM有什么差别呢？

- FM是一种比较灵活的模型，通过合适的特征变换方式，FM可以[模拟](https://www.baidu.com/s?wd=%E6%A8%A1%E6%8B%9F&tn=24004469_oem_dg&rsv_dl=gh_pl_sl_csd)二阶多项式核的SVM模型、MF模型、SVD++模型等。
- 相比SVM的二阶多项式核而言，FM在样本稀疏的情况下是有优势的；而且，FM的训练/预测复杂度是线性的，而二项多项式核SVM需要计算核矩阵，核矩阵复杂度就是N平方。
- 相比MF而言，我们把MF中每一项的rating分改写为$r_{ui} \sim \beta_u + \gamma_i + x_u^T y_i$，从此公式中可以看出，这相当于只有两类特征 $β$ 和 $γ$ 的FM模型。对于FM而言，我们可以加任意多的特征，比如user的历史购买平均值，item的历史购买平均值等，但是MF只能局限在两类特征。SVD++与MF类似，在特征的扩展性上都不如FM。

### Field-aware Factorization Machine(FFM) 场感知分解机

场感知说白了可以理解为分类。通过引入field的概念，**FFM把相同性质的特征归于同一个field**。比如，  “MovieClass = romantic”、“MovieClass =  action”这2个特征值都是代表电影分类的，可以放到同一个field中。简单来说，同一个类别的特征经过One-Hot编码生成的数值特征都可以放到同一个field。在FFM中，每一维特征  *x**i*，针对其它特征的每一种field *f**j*，都会学习一个隐向量 *v**i*,*f**j*

。**因此，隐向量不仅与特征相关，也与field相关**。也就是说，“MovieClass”这个特征与“UserRate”特征和“PlayTimes”特征进行关联的时候使用不同的隐向量，也是FFM中“field-aware”的由来。 
 通过修改FM的公式，我们可以得出： 
$$
\hat{y}(\mathbf{x}) := w_0 + \sum_{i=1}^{n} w_i x_i + \sum_{i=1}^{n} \sum_{j=i+1}^{n} \langle \mathbf{v}_{i,\,f_j}, \mathbf{v}_{j,\,f_i} \rangle x_i x_j
$$
 其中，$f_j$是第j个特征所属的field。如果隐向量的长度为k，那么FFM的二交叉项参数就有nfk个，远多于FM模型的n**k个。此外，由于隐向量与field相关，FFM的交叉项并不能够像FM那样做化简，其预测复杂度为$O(kn^2)$。



> 为了使用FFM方法，所有的特征必须转换成“field_id:feat_id:value”格式，field_id代表特征所属field的编号，feat_id是特征编号，value是特征的值。数值型的特征比较容易处理，只需分配单独的field编号，如用户评论得分、商品的历史CTR/CVR等。categorical特征需要经过One-Hot编码成数值型，编码产生的所有特征同属于一个field，而特征的值只能是0或1，如用户的性别、年龄段，商品的品类id等。  
>     除此之外，还有第三类特征，如用户浏览/购买品类，有多个品类id且用一个数值衡量用户浏览或购买每个品类商品的数量。这类特征按照categorical特征处理，不同的只是特征的值不是0或1，而是代表用户浏览或购买数量的数值。按前述方法得到field_id之后，再对转换后特征顺序编号，得到feat_id，特征的值也可以按照之前的方法获得。

### 参考文献

1. <https://tech.meituan.com/deep-understanding-of-ffm-principles-and-practices.html>
2. <http://www.52caml.com/head_first_ml/ml-chapter9-factorization-family/>
3. <http://www.csie.ntu.edu.tw/~r01922136/slides/ffm.pdf>
4. <https://github.com/guestwalk/libffm> FFM C++实现