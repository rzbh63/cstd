
# 在人工智能领域，人工智能机器无法如人一样理解常识知识 - 喜欢打酱油的老鸟 - CSDN博客


2019年03月14日 09:44:22[喜欢打酱油的老鸟](https://me.csdn.net/weixin_42137700)阅读数：236


[https://www.toutiao.com/a6664721599637225987/](https://www.toutiao.com/a6664721599637225987/)
在人工智能领域，人工智能机器因为无法如人一样理解常识知识，而使人工智能机器表现出的智能程度极其有限。
因此，“常识问题或常识知识问题（common sense knowledge problem）是认知科学特别是人工智能中一个被称为‘真正的问题’的问题。”面对人工智能的发展，海斯指出：“我们需要把如何进行推理的知识加以形式化，还要把那个使推理成为可能的有关现实世界的知识加以形式化。这种元信息可自行参与推理过程，但是，它又与演绎式解释程序有着不同的和特殊的关系：它对自己的活动作出描述，而不仅仅为了有利。
![在人工智能领域，人工智能机器无法如人一样理解常识知识](http://p1.pstatp.com/large/pgc-image/1523243920788e48f51dcaf)
在另一个研究智能的科学中，认知科学目前最大的难题也是语言和常识知识（默会知识、背景知识）问题。符号主义范式早期在证明几何学定理、弈棋、定理再发现，以及运用逻辑演算和少量现实世界背景知识就可精确控制的一些领域取得了成功。但是，人们很快认识到，日常生活中要解决的大多数问题无法归入少数几种因素的形式组合。至少机器语言翻译的经验告诉我们，人类认知是与真实世界的大量背景知识相关的。
大部分认知科学工作者试图通过智能计算机的研究，发明一些解决日常生活实际问题的程序，致力于按照规则的观念阐明必要的背景知识，寻求最小知识系统。人们猜测，只要抽象出真实世界中那些对于求解问题非常重要的特征，机器就能给出这个抽象世界足够的背景信息，并智能地思考简化了的人工世界中的对象及其关系，从而实现模拟真实世界的目的。最初的努力是试图建构嵌入机器的“微型世界”，微型世界是对真实世界特征的极大简化。
![在人工智能领域，人工智能机器无法如人一样理解常识知识](http://p1.pstatp.com/large/pgc-image/1523243920986d4a606517c)
不幸的是，如休伯特·德雷福斯（H.Dreyfus）所说，“微型世界不是世界，而是孤立的，缺乏意义的不毛之地，不能指望这样的不毛之地生长出我们日常生活的多彩世界。”由于上述困难，人工智能科学家寄希望于从尽量少的知识集合出发，通过形式化手段演绎出整个知识系统。自1975至今，开始进入寻求极小常识知识集合的阶段。在这方面的工作中，已经取得初步成就的极小常识系统有明斯基的“框架”程序、尚克（R.Schank）的“脚本”程序、麦克德莫特（D.McDemott）和多伊尔（J.Doyle）和赖特（R.Reiter）的“非单调逻辑”、麦卡锡（J.McCarthy）的“化界系统”，以及麦克德莫特的“时态逻辑”等。
但事实上，这些常识理解程序实验结果表明，它们都只能完成某一范围的局域性特定任务，难以真正在实践中得到广泛通用。这项研究提醒我们，最重要的是，我们对于常识知识结构本身的复杂性还知之甚少，甚至是无知。1985年，德克萨斯奥斯丁微电子和计算机中心开始启动的常识知识数据库的重大项目，预计包含上亿条逻辑语句，由于难以摆脱用机器程序处理日常问题所遇到的“组合爆炸”问题，目前仍在艰难进行之中。
![在人工智能领域，人工智能机器无法如人一样理解常识知识](http://p1.pstatp.com/large/pgc-image/1523243920946c8cf1b57d3)
可以说，当前的智能研究所面临的意向性问题、范畴问题、常识化问题、对心灵的认识问题、人工智能的目标问题无疑已经成为了亟待解决的重要问题。很显然，**回避问题不是明智的做法，而解决问题才是必选之道**。问题是这些问题的解决又如何可能呢？在我们还不能直接解剖活生生的大脑时，哲学的探索无疑是一个最好的选择。如同古希腊的自然哲学一样，对智能的哲学分析也将促进人们对智能的科学认识。当然，这种哲学分析也需要适当的条件。**既需要来自科学的实证材料，又需要来自哲学的反思**。

