
# 均方差损失函数MSELoss详解及反向传播中的梯度求导 - BrightLamp的博客 - CSDN博客


2018年12月20日 20:21:36[BrightLampCsdn](https://me.csdn.net/oBrightLamp)阅读数：537



## 摘要
本文给出均方差损失函数 MSELoss 的定义并求解其在反向传播中的梯度.
## 相关
*系列文章索引 :*
[https://blog.csdn.net/oBrightLamp/article/details/85067981](https://blog.csdn.net/oBrightLamp/article/details/85067981)
## 正文
均方差损失函数 MSELoss 定义简洁, 梯度求导简单, 应用广泛.
## 1. 梯度
设向量 s 作为预测值, 向量 y 为实际值, 由 MSELoss 函数计算得出误差值 error (标量 e ), 求 e 关于 s 的梯度.
$$
e = MSELoss(s, y) =\frac{1}{n}\sum^{n}_{t=1} (s_t-y_t)^2
$$
求解过程 :
$$
\frac{de}{ds}=\frac{2}{n}((s_1-y_1),(s_2-y_2),(s_3-y_3),\cdots,(s_n-y_n))\\
\frac{de}{dy}=-\frac{de}{ds}
$$

## 2. 代码实现
```python
import
```
```python
torch
```
```python
import
```
```python
numpy
```
```python
as
```
```python
np
```
```python
class
```
```python
MSELoss
```
```python
:
```
```python
def
```
```python
__init__
```
```python
(
```
```python
self
```
```python
)
```
```python
:
```
```python
self
```
```python
.
```
```python
x
```
```python
=
```
```python
None
```
```python
self
```
```python
.
```
```python
y
```
```python
=
```
```python
None
```
```python
def
```
```python
__call__
```
```python
(
```
```python
self
```
```python
,
```
```python
x
```
```python
,
```
```python
y
```
```python
)
```
```python
:
```
```python
self
```
```python
.
```
```python
x
```
```python
=
```
```python
x
        self
```
```python
.
```
```python
y
```
```python
=
```
```python
y
```
```python
return
```
```python
np
```
```python
.
```
```python
sum
```
```python
(
```
```python
np
```
```python
.
```
```python
square
```
```python
(
```
```python
x
```
```python
-
```
```python
y
```
```python
)
```
```python
)
```
```python
/
```
```python
x
```
```python
.
```
```python
size
```
```python
def
```
```python
backward
```
```python
(
```
```python
self
```
```python
)
```
```python
:
```
```python
dx
```
```python
=
```
```python
2
```
```python
*
```
```python
(
```
```python
self
```
```python
.
```
```python
x
```
```python
-
```
```python
self
```
```python
.
```
```python
y
```
```python
)
```
```python
/
```
```python
self
```
```python
.
```
```python
x
```
```python
.
```
```python
size
```
```python
return
```
```python
dx
```
```python
,
```
```python
-
```
```python
dx

np
```
```python
.
```
```python
random
```
```python
.
```
```python
seed
```
```python
(
```
```python
123
```
```python
)
```
```python
np
```
```python
.
```
```python
set_printoptions
```
```python
(
```
```python
precision
```
```python
=
```
```python
6
```
```python
,
```
```python
suppress
```
```python
=
```
```python
True
```
```python
,
```
```python
linewidth
```
```python
=
```
```python
80
```
```python
)
```
```python
x_numpy
```
```python
=
```
```python
np
```
```python
.
```
```python
random
```
```python
.
```
```python
random
```
```python
(
```
```python
27
```
```python
)
```
```python
y_numpy
```
```python
=
```
```python
np
```
```python
.
```
```python
random
```
```python
.
```
```python
random
```
```python
(
```
```python
27
```
```python
)
```
```python
x_torch
```
```python
=
```
```python
torch
```
```python
.
```
```python
tensor
```
```python
(
```
```python
x_numpy
```
```python
,
```
```python
requires_grad
```
```python
=
```
```python
True
```
```python
)
```
```python
y_torch
```
```python
=
```
```python
torch
```
```python
.
```
```python
tensor
```
```python
(
```
```python
y_numpy
```
```python
,
```
```python
requires_grad
```
```python
=
```
```python
True
```
```python
)
```
```python
loss_func_numpy
```
```python
=
```
```python
MSELoss
```
```python
(
```
```python
)
```
```python
loss_func_torch
```
```python
=
```
```python
torch
```
```python
.
```
```python
nn
```
```python
.
```
```python
MSELoss
```
```python
(
```
```python
)
```
```python
.
```
```python
float
```
```python
(
```
```python
)
```
```python
loss_numpy
```
```python
=
```
```python
loss_func_numpy
```
```python
(
```
```python
x_numpy
```
```python
,
```
```python
y_numpy
```
```python
)
```
```python
loss_torch
```
```python
=
```
```python
loss_func_torch
```
```python
(
```
```python
x_torch
```
```python
,
```
```python
y_torch
```
```python
)
```
```python
loss_torch
```
```python
.
```
```python
backward
```
```python
(
```
```python
)
```
```python
dx_numpy
```
```python
,
```
```python
dy_numpy
```
```python
=
```
```python
loss_func_numpy
```
```python
.
```
```python
backward
```
```python
(
```
```python
)
```
```python
print
```
```python
(
```
```python
loss_numpy
```
```python
)
```
```python
print
```
```python
(
```
```python
loss_torch
```
```python
.
```
```python
data
```
```python
.
```
```python
numpy
```
```python
(
```
```python
)
```
```python
)
```
```python
print
```
```python
(
```
```python
"----------"
```
```python
)
```
```python
print
```
```python
(
```
```python
dx_numpy
```
```python
)
```
```python
print
```
```python
(
```
```python
x_torch
```
```python
.
```
```python
grad
```
```python
.
```
```python
numpy
```
```python
(
```
```python
)
```
```python
)
```
```python
print
```
```python
(
```
```python
"----------"
```
```python
)
```
```python
print
```
```python
(
```
```python
dy_numpy
```
```python
)
```
```python
print
```
```python
(
```
```python
y_torch
```
```python
.
```
```python
grad
```
```python
.
```
```python
numpy
```
```python
(
```
```python
)
```
```python
)
```
```python
"""
0.116960116566
0.1169601165663142
----------
[ 0.034682 -0.000561 -0.029935  0.034016  0.021168 -0.000575  0.03608   0.019185
  0.012494 -0.002536 -0.040756 -0.015934 -0.004686 -0.041798  0.02092   0.031164
 -0.01721  -0.051175  0.020822  0.003614 -0.026012  0.02444   0.008264  0.036326
 -0.007696 -0.020748 -0.013576]
[ 0.034682 -0.000561 -0.029935  0.034016  0.021168 -0.000575  0.03608   0.019185
  0.012494 -0.002536 -0.040756 -0.015934 -0.004686 -0.041798  0.02092   0.031164
 -0.01721  -0.051175  0.020822  0.003614 -0.026012  0.02444   0.008264  0.036326
 -0.007696 -0.020748 -0.013576]
----------
[-0.034682  0.000561  0.029935 -0.034016 -0.021168  0.000575 -0.03608  -0.019185
 -0.012494  0.002536  0.040756  0.015934  0.004686  0.041798 -0.02092  -0.031164
  0.01721   0.051175 -0.020822 -0.003614  0.026012 -0.02444  -0.008264 -0.036326
  0.007696  0.020748  0.013576]
[-0.034682  0.000561  0.029935 -0.034016 -0.021168  0.000575 -0.03608  -0.019185
 -0.012494  0.002536  0.040756  0.015934  0.004686  0.041798 -0.02092  -0.031164
  0.01721   0.051175 -0.020822 -0.003614  0.026012 -0.02444  -0.008264 -0.036326
  0.007696  0.020748  0.013576]
"""
```

