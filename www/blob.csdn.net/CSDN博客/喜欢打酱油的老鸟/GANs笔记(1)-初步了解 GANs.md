
# GANs笔记(1) - 初步了解 GANs - 喜欢打酱油的老鸟 - CSDN博客


2019年04月05日 12:11:35[喜欢打酱油的老鸟](https://me.csdn.net/weixin_42137700)阅读数：8标签：[GAN																](https://so.csdn.net/so/search/s.do?q=GAN&t=blog)个人分类：[人工智能																](https://blog.csdn.net/weixin_42137700/article/category/7820233)


[https://www.toutiao.com/a6675315277808271884/](https://www.toutiao.com/a6675315277808271884/)

# 1. 生成模型与判别模型
理解对抗网络，首先要**了解生成模型和判别模型**。
判别模型比较好理解，就像分类一样，有一个判别界限，通过这个判别界限去区分样本。从概率角度分析就是获得样本 x 属于类别y 的概率，是一个条件概率 P（y|x）。
而生成模型是需要在整个条件内去产生数据的分布，就像高斯分布一样，需要去拟合整个分布，从概率角度分析就是样本 x 在整个分布中的产生的概率，即联合概率 P（xy）。
# 2. 对抗网络思想
理解了生成模型和判别模型后，再来理解对抗网络就很直接了，对抗网络只是提出了一种网络结构，总体来说， GANs 简单的想法就是用两个模型，**一个生成模型，一个判别模型。**
判别模型用于判断一个给定的图片是不是真实的图片（从数据集里获取的图片），生成模型的任务是去创造一个看起来像真的图片一样的图片。而在开始的时候这两个模型都是没有经过训练的，这两个模型一起对抗训练，生成模型产生一张图片去欺骗判别模型，然后判别模型去判断这张图片是真是假，最终在这两个模型训练的过程中，两个模型的能力越来越强，最终达到稳态。（本书仅介绍 GANs 在计算机视觉方面的应用，但是 GANs 的用途很广，不单单是图像，其他方面，譬如文本、语音，或者任何只要含有规律的数据合成，都能用 GANs 实现。）
# 3. 详细实现过程
假设我们现在的数据集是手写体数字的数据集 mnist，生成模型的输入可以是二维高斯模型中一个随机的向量，生成模型的输出是一张伪造的 fake image，同时通过索引获取数据集中的真实手写数字图片 real image，然后将 fake image 和 real image 一同传给判别模型，由判别模型给出 real 还是 fake 的判别结果。于是，一个简单的 GANs 模型就搭建好了。
值得注意的是，生成模型 G 和判别模型 D 可以是各种各样的神经网络，对抗网络的生成模型和判别模型没有任何限制。
![GANs笔记(1) -  初步了解 GANs](http://p3.pstatp.com/large/pgc-image/b2e19777a2454e3883ec9a389a8524db)
**3.1 前向传播阶段**
**1. 模型输入**
1 、我们随机产生一个随机向量作为生成模型的数据，然后经过生成模型后产生一个新
的向量，作为 Fake Image，记作 D(z)。
2 、从数据集中随机选择一张图片，将图片转化成向量，作为 Real Image,记作 x。
**2. 模型输出**
将由 1 或者 2 产生的输出，作为判别网络的输入，经过判别网络后输出值为一个 0 到 1之间的数，用于表示输入图片为 Real Image 的概率，real 为 1，fake 为 0。使用得到的概率值计算损失函数，解释损失函数之前，我们先解释下判别模型的输入。根据输入的图片类型是 Fake Image 或 Real Image 将判别模型的输入数据的 label 标记为 0或者 1。即判别模型的输入类型为(Xfake ,0)或者(Xreal ,1)。
**3.2 反向传播阶段**
**1. 优化目标**
原文给了这么一个优化函数：
![GANs笔记(1) -  初步了解 GANs](http://p3.pstatp.com/large/pgc-image/b9187beb82c848a88930d302ddc4cbd5)
我们来理解一下这个目标公式，先优化 D，再优化 G，拆解之后即为如下两步：
**第一步：优化 D**
![GANs笔记(1) -  初步了解 GANs](http://p3.pstatp.com/large/pgc-image/1bacce7da43041a9b732977b33754a33)
优化 D，即优化判别网络时，没有生成网络什么事，后面的 G(z)就相当于已经得到的假样本。优化 D 的公式的第一项，使得真样本 x 输入的时候，得到的结果越大越好，因为真样本的预测结果越接近1越好；对于假样本G(z)，需要优化的是其结果越小越好，也就是D(G(z))越小越好，因为它的标签为 0。但是第一项越大，第二项越小，就矛盾了，所以把第二项改为 1-D(G(z))，这样就是越大越好。
**第二步：优化 G**
![GANs笔记(1) -  初步了解 GANs](http://p3.pstatp.com/large/pgc-image/a5a296cc9f314eb2ba8f087e412e9962)
在优化 G 的时候，这个时候没有真样本什么事，所以把第一项直接去掉，这时候只有假样本，但是这个时候希望假样本的标签是 1，所以是 D(G(z))越大越好，但是为了统一成 1-D(G(z))的形式，那么只能是最小化 1-D(G(z))，本质上没有区别，只是为了形式的统一。之后这两个优化模型可以合并起来写，就变成最开始的最大最小目标函数了。我们依据上面的优化目标函数，便能得到如下模型最终的损失函数。
**2. 判别模型的损失函数**
![GANs笔记(1) -  初步了解 GANs](http://p1.pstatp.com/large/pgc-image/a10b87e94412460c8fbf0336f710c17b)
当输入的是从数据集中取出的 real Image 数据时，我们只需要考虑第二部分，D(x)为判别模型的输出，表示输入 x 为 real 数据的概率，我们的目的是让判别模型的输出 D（x）的输出尽量靠近 1。
当输入的为 fake 数据时，我们只计算第一部分，G（z）是生成模型的输出，输出的是一张 Fake Image。我们要做的是让 D(G(z))的输出尽可能趋向于 0。这样才能表示判别模型是有区分力的。
相对判别模型来说，这个损失函数其实就是交叉熵损失函数。计算 loss，进行梯度反传。这里的梯度反传可以使用任何一种梯度修正的方法。当更新完判别模型的参数后，我们再去更新生成模型的参数。
**3. 生成 模型的损失函数**
![GANs笔记(1) -  初步了解 GANs](http://p3.pstatp.com/large/pgc-image/f0e53a45766f432291eb4fce2ebaa6d0)
对于生成模型来说，我们要做的是让 G（z）产生的数据尽可能的和数据集中的数据一样。就是所谓的同样的数据分布。那么我们要做的就是最小化生成模型的误差，即只将由 G(z)产生的误差传给生成模型。
但是针对判别模型的预测结果，要对梯度变化的方向进行改变。当判别模型认为 G（z）输出为真实数据集的时候和认为输出为噪声数据的时候，梯度更新方向要进行改变。
即最终的损失函数为：
![GANs笔记(1) -  初步了解 GANs](http://p3.pstatp.com/large/pgc-image/d0902a53393a4366a8176dcd04a74757)
其中D̅ 表示判别模型的预测类别，对预测概率取整，为 0 或者 1.用于更改梯度方向，阈值可以自己设置，或者正常的话就是 0.5。
**4. 反向传播**
我们已经得到了生成模型和判别模型的损失函数，这样分开看其实就是两个单独的模型，针对不同的模型可以按照自己的需要去是实现不同的误差修正，我们也可以选择最常用的BP 做为误差修正算法，更新模型参数。
其实说了这么多，生成对抗网络的生成模型和判别模型是没有任何限制，生成对抗网络提出的只是一种网络结构，我们可以使用任何的生成模型和判别模型去实现一个生成对抗网络。当得到损失函数后就安装单个模型的更新方法进行修正即可。
# 4. GANs 大家族分类
随着 GANs 的火热，相关的衍伸模型出现了至少有上百种，在下面这个博客
https://deephunt.in/the-gan-zoo-79597dc8c347
中整理了非常多的 GANs 变种。本书仅选择与计算机视觉相关的 GANs 作介绍，简要地介绍其核心思想和算法原理。本书共涉及到 29种经典的 GANs 架构，现在将其按不同类型进行分类，并按时间排列列表如下。发表时间 名称 中文名称 论文地址
```python
14 年 06 月 GANs 生成对抗网络 https://arxiv.org/pdf/1406.2661.pdf
14 年 11 月 CGAN 条件生成对抗网络 https://arxiv.org/pdf/1411.1784.pdf
15 年 06 月 LAPGAN 拉普拉斯金字塔 GAN https://arxiv.org/pdf/1506.05751.pdf
15 年 11 月 DCGAN 深度卷积生成对抗网络 https://arxiv.org/pdf/1511.06434.pdf
15 年 12 月 VAEGAN 变分自编码器 GAN https://arxiv.org/pdf/1512.09300.pdf
16 年 05 月 BiGAN 双向生成对抗网络 https://arxiv.org/pdf/1605.09782.pdf
16 年 06 月 CoGAN 耦合生成对抗网络 https://arxiv.org/pdf/1606.07536.pdf
16 年 06 月 fGAN f-散度生成对抗网络 https://arxiv.org/pdf/1606.00709.pdf
16 年 06 月 ImprovedDCGAN 提升的 DCGAN https://arxiv.org/pdf/1606.03498.pdf
16 年 06 月 InfoGAN 互信息生成对抗网络 https://arxiv.org/pdf/1606.03657.pdf
16 年 09 月 EBGAN 基于能量的生成对抗网络 https://arxiv.org/pdf/1609.03126.pdf
16 年 09 月 SRGAN 超分辨率生成对抗网络 https://arxiv.org/pdf/1609.04802.pdf
16 年 11 月 LSGAN 最小二乘生成对抗网络 https://arxiv.org/pdf/1611.04076.pdf
16 年 12 月 StackGAN 堆栈式生成对抗网络 https://arxiv.org/pdf/1612.03242.pdf
17 年 01 月 WGAN Was 距离生成对抗网络 https://arxiv.org/pdf/1701.07875.pdf
17 年 03 月 BEGAN 边界均衡生成对抗网络 https://arxiv.org/pdf/1703.10717.pdf
17 年 03 月 CycleGAN 循环生成对抗网络 https://arxiv.org/pdf/1703.10593.pdf
17 年 03 月 TripleGAN 三部分生成对抗网络 https://arxiv.org/pdf/1703.02291.pdf
17 年 04 月 WGAN-GP 加强版 WGAN https://arxiv.org/pdf/1704.00028.pdf
17 年 05 月 DRAGAN 深度回归分析 GAN https://arxiv.org/pdf/1705.07215.pdf
17 年 10 月 PGGAN 渐进生成对抗网络 https://arxiv.org/pdf/1710.10196.pdf
17 年 10 月 StackGAN++ 提升的堆栈式 GAN https://arxiv.org/pdf/1710.10916.pdf
17 年 11 月 StarGAN 星型结构 GAN https://arxiv.org/pdf/1711.09020.pdf
17 年 11 月 XGAN X 型结构 GAN https://arxiv.org/pdf/1711.05139.pdf
17 年 12 月 ComboGAN 合一式生成对抗网络 https://arxiv.org/pdf/1712.06909.pdf
18 年 02 月 SNGAN 频谱归一化生成对抗网络 https://arxiv.org/pdf/1802.05957.pdf
18 年 05 月 SAGAN 自注意力生成对抗网络 https://arxiv.org/pdf/1805.08318.pdf
18 年 07 月 RGAN 相对生成对抗网络 https://arxiv.org/pdf/1807.00734.pdf
18 年 09 月 BigGAN 大规模生成对抗网络 https://arxiv.org/pdf/1809.11096.pdf
```
后续将会逐一介绍这些 GANs 变种的实现原理。

