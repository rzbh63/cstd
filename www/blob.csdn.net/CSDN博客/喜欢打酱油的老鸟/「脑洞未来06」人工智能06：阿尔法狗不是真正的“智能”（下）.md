
# 「脑洞未来06」人工智能06：阿尔法狗不是真正的“智能”（下） - 喜欢打酱油的老鸟 - CSDN博客


2019年01月28日 08:56:19[喜欢打酱油的老鸟](https://me.csdn.net/weixin_42137700)阅读数：28标签：[AlphaGo																](https://so.csdn.net/so/search/s.do?q=AlphaGo&t=blog)个人分类：[人工智能																](https://blog.csdn.net/weixin_42137700/article/category/7820233)


[https://www.toutiao.com/a6650072315826536974/](https://www.toutiao.com/a6650072315826536974/)
2019-01-24 22:36:57
【观点】在引爆世界第三次人工智能热潮的时候，“AlphaGo”的主人DeepMind 和东家谷歌，看着世间疯狂地传颂着、领悟着“人工智能将战胜、淘汰、替代人类”“将让99%的人类变成无用阶级”……可能高兴得都合不拢嘴了！基于巨大的商业炒作与利益诉求，他们是再怎么也不会出来澄清：AlphaGo所涉及“深度神经网络”“卷积神经网络”和“增强学习网络”，对应的“深度学习”“增强学习”等技术（确实属于技术突破），实际上就是一个个超级比喻，根本不是什么“智能”，更不是像人一样的“智力”……《新未来简史》如是说。
![「脑洞未来06」人工智能06：阿尔法狗不是真正的“智能”（下）](http://p9.pstatp.com/large/pgc-image/ed2ef722245e4cd08e692a17ad63a29c)
（上接《代表如今人工智能最高水准的阿尔法狗，不是真正的智能，为何？》原名：【脑洞未来5】人工智能篇5：阿尔法狗不是真正的“智能”（上） ）
> 作者：王骥

> 来自：《新未来简史：区块链、人工智能、大数据陷阱与数字化生活》，2018年4月版
曾经引爆人工智能第二次热潮的IBM深蓝这种（暴力搜索法或穷举搜索法，即穷尽一切走棋法后，选择最好的那一种）办法行不通，得另辟蹊径。有人想到了结合“概率”的算法。于是“蒙特卡罗方法”（Monte Carlo method）出场了。
这一方法也称统计模拟方法，是20世纪40年代美国在第二次世界大战 “曼哈顿计划”成员S.M.乌拉姆和J.冯·诺伊曼首先提出，并以驰名世界的赌城—摩纳哥的Monte Carlo来命名的。该算法就是以某种事件出现的频率估计这一随机事件的概率，或者得到这个随机变量的某些数字特征，并将其作为问题的解。
蒙地卡罗方法首先被人在国际象棋上运算，似乎根本行不通，直到2006年，有人发展了蒙地卡罗方法，即在此方法上加了树枝状搜索，从此探索出电脑围棋编程的另一条通途。这一改进的方法就是“蒙地卡罗树搜索”。
该搜索法面世后，那时就有人惊奇地预言说，未来不久，电脑将在围棋上击败人类顶级选手。而此之前，人们一直相信围棋是不可战胜。这一预言只经历了十年，即2016年就变成了现实。所以，技术是改变一切的真正神器。
![「脑洞未来06」人工智能06：阿尔法狗不是真正的“智能”（下）](http://p1.pstatp.com/large/pgc-image/678abc1ea8ec433ea5a735993d72d4bb)
根据谷歌曾在《自然》杂志上公布阿尔法狗的运作的基本原理，分别为：
走棋网络（Policy Network），给定当前局面，预测和采样下一步的走棋；快速走子（Fast rollout），在适当牺牲走棋质量的条件下提高速度；价值网络（Value Network），给定当前局面，估计双方胜率；蒙特卡罗树搜索，就是把以上三个部分串联成一个完整的系统。
该搜索法并没有穷尽所有的走法，而是先完成大约数十步计算以后，剩下的便靠机率模拟算法（传统的局部特征匹配与线性回归两种方法演算出可能胜负作为依据）来推算获胜可能，并据以选择棋步。
其中，阿尔法狗所计算的那数十步很重要，用到了三个重要的概念和算法，即“深度神经网络”、“卷积神经网络”和“增强学习网络”。这三个概念非常重要，并由此很好地体现“深度学习”与“增强学习（也称加强学习）”的概念。这数十步到底是如何计算的呢？
![「脑洞未来06」人工智能06：阿尔法狗不是真正的“智能”（下）](http://p1.pstatp.com/large/pgc-image/9001e556ba794dc4b2df1528ed031cfd)
阿尔法狗在比赛之前便通过“深度神经网络”开始“学习”（形象的比喻，实际上就是计算机的反复计算与修正）。深度神经网络是一种模拟人类脑神经系统的运算流程，有资料输入端与输出端，中间则是运算神经元（由无数晶体管组成），透过一次次“学习”，比对输出资料与正确资料的差异，反馈调整神经元的运算参数，便能“学习”某种运算技能。
这里输入的资料便是数以亿计的历史棋谱，包括所有顶尖高手曾经下过的棋谱，输出资料便是这些高手在各种棋局下获胜的走法，反复调参，使得计算机输出的资料与获胜的资料尽可能的相同，这些信息便储存在计算机里，相当于人们记住了某些繁琐的操作一样。
![「脑洞未来06」人工智能06：阿尔法狗不是真正的“智能”（下）](http://p1.pstatp.com/large/pgc-image/5bd332c4a3bd451aacba01458bcc2b6b)
注意，深度神经网络的“深度”，就是运算神经元有许多层，每一层处理原始资料的一种特征，多层汇总，以达成强大的运算能力。
但是，像围棋棋谱这样的原始资料非常复杂，这么多的资料（棋盘上所有方格）都传输到神经元上的话，那么电脑就会破表，所以，输入资料需要有所选择，于是“卷积神经网络”出场了。
卷积神经网络的运算神经元，接受的并不是棋盘上的全部资料，而只是来自棋盘上邻近方格的资料，这样就大大简化了处理程序。比如阿尔法狗从棋盘上选取四十八种布局方式的特征，利用十三层神经网络予以分层处理，反覆“学习”、反复调参，这样就实现对当前棋局的辨认，就像人们学会了某种复杂事项的处理一样。
于是，在实战中，只要一遇到某种棋局，阿尔法狗便能对照储存库中庞大现成棋谱及其最接近胜利（如选择顶级高手的下法）的走法予以辨认，好像顶级棋手亲自到场一样，步步胜算。
![「脑洞未来06」人工智能06：阿尔法狗不是真正的“智能”（下）](http://p1.pstatp.com/large/pgc-image/78542d1076484cb38d9973767931fc53)
此外，为了增强对战能力，还需要用到“增强学习网络”，让阿尔法狗跟先前下过的棋局对战，或者干脆让其自己跟自己下棋，好像金庸笔下周伯通在桃花岛开创的“左右互搏”术一样，以累积更多实战经验。
增强学习网络是一种半监督式学习（下一章将详细解读），没有标准答案，通过程序设计，下赢了棋局，收获正向回馈，下输了便会被扣分。由此慢慢累积学习经验，越学习越厉害。当然，这种学习是需要一些时间的。
不过，对于计算机来说，高速计算与不知疲倦就是它的长项和特色，比如全人类几百年来下过的全部棋谱，对阿尔法狗来说，“学习”分析一遍只需要花费几天时间而已。又比如阿尔法狗自己左右互博2000万盘，一个人，按15分钟练一盘来算，也需要600年。
![「脑洞未来06」人工智能06：阿尔法狗不是真正的“智能”（下）](http://p3.pstatp.com/large/pgc-image/5f04cb86de3e4277be1befaff107aff6)
阿尔法狗的奇迹就是，仅仅用上几个月的时间，通过“学习”，就能模拟了人类围棋招式的几百年进化历程，同时优胜劣汰，形成的自己的棋风。所以，当阿尔法狗在与李世石对弈时，还输了一盘，但在一年后再与柯洁对战时，却把柯洁下到哭泣。也就是这半年时间后，阿尔法狗通过增强的“学习”使其的功力至少提升了数十倍了。
由上，阿尔法狗原理中所用到“蒙地卡罗树搜索”根本就算不上传统的人工智能。当然，上述被认为最可能像人一样智能的“机器学习”、“深度学习”和“增强学习”，也是对计算机通过输入资料到输出资料反复测试以达到最佳效果的这些编程，其自发运行过程的一个拟人化的比喻。
不仅如此，这些“学习”所涉及的“深度神经网络”和“卷积神经网络”更是个美丽的比喻，不过仅仅就是一大推模仿大脑用的晶体管、储存器与无数传导线等元件组成的系统而已。
虽然，我们每一个人心中都有个自己的“人工智能”，但是，更多的民众或许真的就把这些比喻当成了现实，以为机器真的可以像人那样有意识、自觉地去学习、思考了。实际上它们仅仅只是按照人类的编程运行，交互式自动控制的机器，跟本章开篇所说的复印机的故事有很多相似的地方，只不过绝大多数挂名为人工智能的器械、系统要比复印技术高级、复杂得多得多。
![「脑洞未来06」人工智能06：阿尔法狗不是真正的“智能”（下）](http://p1.pstatp.com/large/pgc-image/66f3cf284c8a4af5ab6d5f955fefd944)
或许，神秘得人气爆棚的人工智能就是：
主流倡导者们相信机器未来会有意识（现实中连边缘都未触及），在推动各类计算机技术飞速发展的过程中，创造了“智能”、“神经”和“学习”这些比喻性的词汇与概念，同时制造了可怕的预测。而局外的广大民众混淆了这些概念的“比喻性”，忽视了机器“智能”、“神经”和“学习”的真相以及和人类的真正差别，进而相信并传播了这些可怕的预测，从而制造了恐怖。
当然，这些预测和恐怖与人工智能改变世界的巨大实用价值和前景是两件不同的事情。

