
# 漫步最优化九——泰勒级数 - 蜗牛 - CSDN博客


2017年07月07日 18:24:56[会敲键盘的猩猩](https://me.csdn.net/u010182633)阅读数：375



$\textbf{感受停在我胸口的纤手，}$
$\textbf{记住望着我坚定的双眼。}$
$\textbf{为了你，我竟然会疯狂掉，}$
$\textbf{没有你，即便山崩海啸，也不想逃。}$
$\textbf{也许未来很遥远，}$
$\textbf{但是我愿在未知的等待中为你守候。}$
$\qquad\qquad\quad\textbf{——畅宝宝的傻逼哥哥}$
一些非线性规划过程与方法利用了目标函数与等式、不等式约束为线性或二次近似这个策略，即$f(\textbf{x}),a_i(\textbf{x}),c_j(\textbf{x})$为线性或二次近似，这样的近似通过使用泰勒级数就能得到。如果$f(\textbf{x})$是两个变量$x_1,x_2$的函数，使得$f(\textbf{x})\in C^P$，其中$P\to\infty$，即$f(\textbf{x})$有任意阶的连续偏导数，那么函数$f(\textbf{x})$在$[x_1+\delta_1,x_2+\delta_2]$上的函数值由泰勒级数可得

$$
\begin{align*}
f(x_1+\delta_1,x_2+\delta_2)
=&f(x_1,x_2)+\frac{\partial f}{\partial x_1}\delta_1+\frac{\partial f}{\partial x_2}\delta_2\\
&+\frac{1}{2}\left(\frac{\partial^2f}{\partial x_1^2}\delta_1^2+\frac{2\partial^2f}{\partial x_1\partial x_2}\delta_1\delta_2+\frac{\partial^2f}{\partial x_2^2}\delta_2^2\right)\\
&+O(\Vert\boldsymbol{\delta}\Vert^3)
\end{align*}
$$
其中

$$
\boldsymbol{\delta}=[\delta_1\ \delta_2]^T
$$
$O(\Vert\boldsymbol{\delta}\Vert^3)$是余项，$\Vert\boldsymbol{\delta}\Vert$是$\boldsymbol{\delta}$的欧几里得范数

$$
\Vert\boldsymbol{\delta}=\sqrt{\boldsymbol{\delta}^T\boldsymbol{\delta}}
$$
符号$\phi(x)=O(x)$表示当$x$趋近零时，$\phi(x)$至少与$x$趋近零的速度一样快，即存在常数$K\geq 0$使得

$$
\left|\frac{\phi(x)}{x}\right|\leq K\quad as\quad x\to 0
$$
其实余项也可以表示成$o(\Vert\boldsymbol{\delta}\Vert^2)$其中符号$phi(x)=o(x)$表示当$x$接近零时，$\phi(x)$接近零的属于比$x$要快，即

$$
\left|\frac{\phi(x)}{x}\right|\to 0\quad as\ x\to 0
$$
如果$f(\textbf{x})$是$n$个变量的函数，那么$f(\textbf{x})$在点$[x_1+\delta_1,x_2+\delta_2,\ldots]$上的泰勒级数为

$$
\begin{align*}
f(x_1+\delta_1,x_2+\delta_2,\ldots)
=&f(x_1,x_2,\ldots)+\sum_{i=1}^n\frac{\partial f}{\partial x_i}\delta_i\\
&+\frac{1}{2}\sum_{i=1}^n\sum_{j=1}^n\delta_i\frac{\partial^2f}{\partial x_i\partial x_j}\delta_j\\
&+o(\Vert\boldsymbol{\delta}\Vert^2)
\end{align*}
$$
用矩阵符号表示为：

$$
f(\textbf{x}+\boldsymbol{\delta})=f(\textbf{x})+\textbf{g}(\textbf{x})^T\boldsymbol{\delta}+\frac{1}{2}\boldsymbol{\delta}^T\textbf{H}(\textbf{x})\boldsymbol{\delta}+o(\Vert\boldsymbol{\delta}\Vert^2)
$$
其中$\textbf{g}(\textbf{x})$是点$\textbf{x}$处的梯度，$\textbf{H(x)}$是海森矩阵。
当$\Vert\boldsymbol{\delta}\Vert\to 0$时，可以忽略二阶或更高阶的项，这时候就得到$f(\textbf{x}+\boldsymbol{\delta})$的线性近似

$$
f(\textbf{x}+\boldsymbol{\delta})\approx f(\textbf{x})+\textbf{g}(\textbf{x})^T\boldsymbol{\delta}
$$
同样的，$f(\textbf{x}+\boldsymbol{\delta})$的二次近似为

$$
f(\textbf{x}+\boldsymbol{\delta})\approx f(\textbf{x})+\textbf{g}(\textbf{x})^T\boldsymbol{\delta}+\frac{1}{2}\boldsymbol{\delta}^T\textbf{H(x)}\boldsymbol{\delta}
$$
泰勒级数还有另一种形式，包含余项

$$
\begin{align*}
f(\textbf{x}+\boldsymbol{\delta})
=&f(\textbf{x})\\
&+\sum_{1\leq k_1+k_2+\cdots+k_n\leq P}\frac{\partial^{k_1+k_2+\cdots+k_n}f(\textbf{x})}{\partial x_1^{k_1}\partial x_2^{k_2}\cdots\partial x_n^{k_n}}\prod_{i=1}^n\frac{\delta_i^{k_i}}{k_i!}\\
&+\sum_{k_1+k_2+\cdots+k_n=P+1}\frac{\partial^{P+1}f(\textbf{x}+\alpha\boldsymbol{\delta})}{\partial x_i^{k_1}\partial x_2^{k_2}\cdots\partial x_n^{k_n}}\prod_{i=1}^n\frac{\delta_i^{k_i}}{k_i!}
\end{align*}
$$
其中$0\leq\alpha\leq 1$且

$$
\sum_{1\leq k_1+k_2+\cdots+k_n\leq P}\frac{\partial^{k_1+k_2+\cdots+k_n}f(\textbf{x})}{\partial x_1^{k_1}\partial x_2^{k_2}\cdots\partial x_n^{k_n}}\prod_{i=1}^n\frac{\delta_i^{k_i}}{k_i!}
$$
所有$k_1,k_2,\ldots,k_n$可能组合的求和，这个泰勒级数的表示是最一般的，因此可以得到$f(\textbf{x}+\boldsymbol{\delta})$的三次和更高次近似，进一步，还可以用来求线性，二次，三次或更高次的精确封闭形式表达式。如果$f(\textbf{x})\in C^1$且$P=0$，那么我们得到

$$
f(\textbf{x}+\boldsymbol{\delta})=f(\textbf{x})+\textbf{g}(\textbf{x}+\alpha\boldsymbol{\delta})^T\boldsymbol{\delta}
$$
如果$f(\textbf{x})\in C^2,P=1$，那么

$$
f(\textbf{x}+\boldsymbol{\delta})=f(\textbf{x})+\textbf{g}(\textbf{x})^T\boldsymbol{\delta}+\frac{1}{2}\boldsymbol{\delta}^T\textbf{H}(\textbf{x}+\alpha\boldsymbol{\delta})\boldsymbol{\delta}
$$
其中$0\leq\alpha\leq 1$，上面那个等式我们通常称为微分中值定理。
通过重组泰勒级数，我们可以得到下面的形式：

$$
\begin{align*}
f(\textbf{x}+\boldsymbol{\delta}
=&f(\textbf{x})+\textbf{g}(\textbf{x})^T\boldsymbol{\delta}+\frac{1}{2}\boldsymbol{\delta}^T\textbf{H(x)}\boldsymbol{\delta}+\frac{1}{3!}D^3f(\textbf{x})\\
&+\cdots+\frac{1}{(r-1)!}D^{r-1}f(\textbf{x})+\cdots
\end{align*}
$$
其中

$$
D^rf(\textbf{x})=\sum_{i_1=1}^n\sum_{i_2=1}^n\cdots\sum_{i_r=1}^n\left\{\delta_{i_1}\delta_{i_2}\cdots\delta_{i_r}\frac{\partial^rf(\textbf{x})}{\partial x_{i_1}\partial x_{i_2}\cdots\partial x_{i_r}}\right\}
$$


