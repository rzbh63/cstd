
# 推荐系统(5)—隐语义模型(LFM) - 喜欢打酱油的老鸟 - CSDN博客


2019年03月09日 17:03:10[喜欢打酱油的老鸟](https://me.csdn.net/weixin_42137700)阅读数：75


[https://www.toutiao.com/a6663676280782717454/](https://www.toutiao.com/a6663676280782717454/)
2019-03-02 14:27:17
# 基本概念
LFM(latent factor model)隐语义模型，这也是在推荐系统中应用相当普遍的一种模型。那这种模型跟ItemCF或UserCF有什么不同呢？这里可以做一个对比：
对于UserCF，我们可以先计算和目标用户兴趣相似的用户，之后再根据计算出来的用户喜欢的物品给目标用户推荐物品。
而ItemCF，我们可以根据目标用户喜欢的物品，寻找和这些物品相似的物品，再推荐给用户。
我们还有一种方法，先对所有的物品进行分类，再根据用户的兴趣分类给用户推荐该分类中的物品，LFM就是用来实现这种方法。
如果要实现最后一种方法，需要解决以下的问题：
(1)给物品分类
(2)确定用户兴趣属于哪些类及感兴趣程度
(3)对于用户感兴趣的类，如何推荐物品给用户
对分类，很容易想到人工对物品进行分类，但是人工分类是一种很主观的事情，比如一部电影用户可能因为这是喜剧片去看了，但也可能因为他是周星驰主演的看了，也有可能因为这是一部属于西游类型的电影，不同的人可以得到不同的分类。
而且对于物品分类的粒度很难控制，究竟需要把物品细分到个程度，比如一本线性代数，可以分类到数学中，也可以分类到高等数学，甚至根据线性代数主要适用的领域再一次细分，但对于非专业领域的人来说，想要对这样的物品进行小粒度细分无疑是一件费力不讨好的事情。
而且一个物品属于某个类，但是这个物品相比其他物品，是否更加符合这个类呢？这也是很难人工确定的事情。
对于上述需要解决的问题，我们的隐语义模型就派上用场了。隐语义模型，可以基于用户的行为自动进行聚类，并且这个类的数量，即粒度完全由可控。对于某个物品是否属与一个类，完全由用户的行为确定，我们假设两个物品同时被许多用户喜欢，那么这两个物品就有很大的几率属于同一个类。而某个物品在类所占的权重，也完全可以由计算得出。
# LFM算法思想
每个用户（**user**）都有自己的偏好，比如A喜欢带有**小清新的**、**吉他伴奏的**、**王菲**等元素（**latent factor**），如果一首歌（**item**）带有这些元素，那么就将这首歌推荐给该用户，也就是用元素去连接用户和音乐。每个人对不同的元素偏好不同，而每首歌包含的元素也不一样。我们希望能找到这样两个矩阵：
一.**用户-潜在因子矩阵Q**，
表示不同的用户对于不用元素的偏好程度，1代表很喜欢，0代表不喜欢。比如下面这样：
![推荐系统(5)—隐语义模型(LFM)](http://p9.pstatp.com/large/pgc-image/be83138fb1ec44e1936734fe5e4d678f)
二.**潜在因子-音乐矩阵P**
表示每种音乐含有各种元素的成分，比如下表中，音乐A是一个偏小清新的音乐，含有小清新这个Latent Factor的成分是0.9，重口味的成分是0.1，优雅的成分是0.2……
![推荐系统(5)—隐语义模型(LFM)](http://p3.pstatp.com/large/pgc-image/221f7a02e2034ca8a8bb60399425fb57)
利用这两个矩阵，我们能得出张三对音乐A的喜欢程度是：张三对**小清新**的偏好*音乐A含有**小清新**的成分+对**重口味**的偏好*音乐A含有**重口味**的成分+对**优雅**的偏好*音乐A含有**优雅**的成分+……
![推荐系统(5)—隐语义模型(LFM)](http://p9.pstatp.com/large/pgc-image/62e127e0f54e4105a1c802c48f5914a5)
即：0.6*0.9+0.8*0.1+0.1*0.2+0.1*0.4+0.7*0=0.69
每个用户对每首歌都这样计算可以得到不同用户对不同歌曲的评分矩阵R'。（注，这里的破浪线表示的是估计的评分，接下来我们还会用到不带波浪线的R表示实际的评分）：
![推荐系统(5)—隐语义模型(LFM)](http://p9.pstatp.com/large/pgc-image/f5e561ac5d6842ddb787e4f52d5810f1)
因此我们队张三推荐四首歌中得分最高的B，对李四推荐得分最高的C，王五推荐B。
如果用矩阵表示即为：
![推荐系统(5)—隐语义模型(LFM)](http://p3.pstatp.com/large/pgc-image/eeacd50b85d34611971043c688e28cb5)
下面问题来了，**这个潜在因子（latent factor）是怎么得到的呢？**
由于面对海量的让用户自己给音乐分类并告诉我们自己的偏好系数显然是不现实的，事实上我们能获得的数据只有用户行为数据。我们沿用一般量化标准：单曲循环=5, 分享=4, 收藏=3, 主动播放=2 , 听完=1, 跳过=-2 , 拉黑=-5，在分析时能获得的实际评分矩阵**R**，也就是输入矩阵大概是这个样子：
![推荐系统(5)—隐语义模型(LFM)](http://p3.pstatp.com/large/pgc-image/218fc8cb549f45db9089616060c01bac)
事实上这是个非常非常稀疏的矩阵，因为大部分用户只听过全部音乐中很少一部分。如何利用这个矩阵去找潜在因子呢？这里主要应用到的是矩阵的UV分解。也就是将上面的评分矩阵分解为两个低维度的矩阵，用Q和P两个矩阵的乘积去估计实际的评分矩阵，而且我们希望估计的评分矩阵R'
![推荐系统(5)—隐语义模型(LFM)](http://p9.pstatp.com/large/pgc-image/a0b56ad6f5dc4d619913d239a34a6271)
和实际的评分矩阵不要相差太多，也就是求解下面的目标函数：
以下公式便是隐语义模型计算用户u对物品i兴趣的公式：
![推荐系统(5)—隐语义模型(LFM)](http://p1.pstatp.com/large/pgc-image/a0219690844b4cd7a127d825a27fc5f9)
其中，p为用户兴趣和第k个隐类的关系，q为第k个隐类和物品i的关系，F为隐类的数量，r便是用户对物品的兴趣度。
接下的问题便是如何计算这两个参数p和q了，对于这种线性模型的计算方法，这里使用的是梯度下降法，大概的思路便是使用一个数据集，包括用户喜欢的物品和不喜欢的物品，根据这个数据集来计算p和q。
下面给出公式，对于正样本，我们规定r=1，负样本r=0：
![推荐系统(5)—隐语义模型(LFM)](http://p9.pstatp.com/large/pgc-image/78367d21e28946dfbdaa94b6ac22511b)
这里涉及到最优化理论，在实际应用中，往往还要在后面加上2范数的罚项，然后利用梯度下降法就可以求得这**P,Q**两个矩阵的估计值。
例如我们上面给出的那个例子可以分解成为这样两个矩阵：
![推荐系统(5)—隐语义模型(LFM)](http://p1.pstatp.com/large/pgc-image/e7418f1af2f04ffd9d81d9dcae458557)
这两个矩阵相乘就可以得到估计的得分矩阵：
![推荐系统(5)—隐语义模型(LFM)](http://p1.pstatp.com/large/pgc-image/737a20e22ccf40ea915e9b59e26bbba2)
将用户已经听过的音乐剔除后，选择分数最高音乐的推荐给用户。这就是LFM的思想，这种算法理解起来比较简单。

