
# 人工智能浪潮下的语音交互——VUI设计（基础篇） - 喜欢打酱油的老鸟 - CSDN博客


2019年01月07日 08:01:13[喜欢打酱油的老鸟](https://me.csdn.net/weixin_42137700)阅读数：144


[https://www.toutiao.com/a6642089383191118350/](https://www.toutiao.com/a6642089383191118350/)
2019-01-03 10:19:06
摘要：本文内容一部分来源于阿里设计师王一行翻译的《语音用户界面设计》一书，一部分为工作中所学习的。感兴趣的可以去买书看看。VUI的第一个时期20世纪50年代，贝尔实验室建立了一个单人语音...
> 本文内容一部分来源于阿里设计师王一行翻译的《语音用户界面设计》一书，一部分为工作中所学习的。感兴趣的可以去买书看看。
**VUI的第一个时期**
20世纪50年代，贝尔实验室建立了一个单人语音数字识别系统。这些早期系统的词汇量非常少，在实验室之外并没有什么用户。20世纪六七十年代，关于语音数字系统的这项研究仍在不断拓展可识别的词汇，并且至力于实现“连续语音”的识别（不需要在词与词之间暂停）。
20世纪90年代，IVR交互式语音应答系统出现（我们打10086客服出现的语音服务系统）。它可以通过电话线路理解人们的话，并执行相应任务。在21世纪初期，IVR系统成为了主流，任何人都可以通过一个普通的电话和语音进行股票的询价、机票预定、银行转账、处方药品预定、本地电影排片查询以及收听交通信息等。
![人工智能浪潮下的语音交互——VUI设计（基础篇）](http://p3.pstatp.com/large/pgc-image/354a9b386a794cba808d3b5608e32d42)
**VUI的第二个时期**
我们现在所处的时期被称为VUI的第二个时期。像Siri、Google new、和Cortana这类集成了视觉和语音信息的app，以及Amazon Echo、Google Home这类纯语音的设备逐渐成为主流。Google报告称其搜索请求中有20%是通过语音完成。
当下百度退出新的产品简单搜索，干脆将语音作为搜索入口，有兴趣的同学可以去试试。
![人工智能浪潮下的语音交互——VUI设计（基础篇）](http://p99.pstatp.com/large/pgc-image/f2149b1eb8f34f5cbb5d366c91dbabc0)
下面会给大家介绍一些VUI的基本术语
唤醒词设定
国内的四大音箱品牌，如小爱同学（小米）、小度小度（百度）、天猫精灵（阿里）、小艺小艺（华为）
那么为什么要设定唤醒词呢？
一个原因是遵从现实的人际交往关系，比如在学校宿舍，我让你帮我带东西，我会说小明，回来时帮我带桶泡面。而小明同学识别到“小明”，就知道你在呼唤他，是对他在说话。也会针对性地进行回答。
第二个原因你的设备在工作中是一直处于倾听状态的，如果音箱在用户非使用时间记录用户的话，还将听到的语音传到云端，这样就侵犯了用户的隐私。所以音箱需要一个唤醒词来唤醒音箱。（音箱在通电状态下，唤醒词是做本地处理的，不管是否连接网络都能响应，响应速度也更及时。）
至于怎么命名唤醒词，此处不做说明。
![人工智能浪潮下的语音交互——VUI设计（基础篇）](http://p99.pstatp.com/large/pgc-image/ff6a4724c94a4889892da96f386dd372)
**超时**
一般唤醒音箱后，音箱的倾听时间为7～10秒，各个厂家的都不同。当用户的输入超出限定世界，一般采取的做法是识别时限内的内容，进行相应的回答。
**延迟**
延迟发生的场景很难去预估，通常由以下几个原因产生的，但实际上未知的更多
1. 糟糕的连接性能
2. 系统处理进程
3. 数据库访问
当你去查询一个球队的比赛时，并且想知道他现在的积分，下一轮的对手是谁，你应该就会知道这需要进行云端数据查询，需要一定的时间，这个时候音箱上的呼吸灯就会告诉你他正在为你工作中。
但有时候，延迟会比较长（一般在0～10秒内），如果延迟会达到一个节点，比如说7秒，这个时候音箱如果给一个响应，说：请稍等，正在为您查询，那么用户的耐心是否会变长，消除焦虑呢？
![人工智能浪潮下的语音交互——VUI设计（基础篇）](http://p1.pstatp.com/large/pgc-image/e835898dc3f44c69a0b177fe722a0423)
**消歧**
很多时候用户只会提供执行命令所需要的部分信息，而没有提供所有细节。比如对音箱说，“打电话”，但这个时候音箱并不知道打给谁。但如果你说打电话给张三丰，这个时候音箱会发起呼叫来执行当前指令。
再举个例子，比如说查询天气，这个时候音箱是不知道你查询的是什么地方的天气，但可以根据当前的地理位置来判断，告诉你当地的天气。
消歧就是明确各种指令，然后让音箱能顺利的理解并执行命令。一般消歧会涉及到多轮对话，此处不做具体说明。
![人工智能浪潮下的语音交互——VUI设计（基础篇）](http://p9.pstatp.com/large/pgc-image/192e543a78d14fffb0257ce0336cbfc6)
下面从一段对话来说明显性确认、置信度、N-Best列表、多轮对话
1. 你问：Hey google 勇⼠队获胜了吗？
2. 助手：是的 上周⽇对阵鹈鹕，勇⼠队赢了118:92
3. 你问：很好，他们下⼀场⽐赛是什么时候
4. 助手：勇⼠的下⼀场⽐赛是今天下午7:30，他们将再打鹈鹕队
5. 你问：当我回家时 提醒我找到我的凯⽂杜兰特球⾐
6. 助手：当然 当你回家时我会提醒你
**隐性确认**
隐性确认策略就是将答案连同原始问题的一部分一同回复给用户，让用户知道知道他的话接收到了，但不需要他们确认。
**示例：**
1. 你问：他们的下一场比赛是什么时候吗？
2. 助手：勇⼠的下⼀场⽐赛是今天下午7:30，他们将再打鹈鹕队 。
从这，可以看出它知道“他们”指的是勇⼠，能根据上下⽂理解这些代词的意思。且在答复中从将勇士反馈给用户，让用户知道“他”知道“他们”指的是勇士。
置信度低的显现确认
如果置信度不高，Google可能这样回复：你是问勇士的下一场比赛是什么时候吗？
1. 你问：他们的下一场比赛是什么时候吗？
2. 助手：你是问勇士的下一场比赛是什么时候吗？
**置信度高**
1. 你问：他们的下一场比赛是什么时候吗？
2. 助手：他们下⼀场⽐赛是今天下午7:30，将再打鹈鹕队 。
这种对话更加自然没有痕迹，但对置信度的要求也更高，当前只能对简单的对话进行这种回答。对于场景的要求较高，最好是单一的，变量小的。
**多轮对话**
很显然，当前对话示例是多轮对话。多轮对话很明显的一个特征就是无须重复唤醒助手，能够持续的对话。助手也能根据上下文来理解并给出相应的回答，就像人一样，更加自然的对话。（当前各大厂商的助手只能在某单一场景进行多轮对话）
**N-Best列表**
其实助手每一次回复都会从用户说的话返回个N-Best列表，然后从中选取一个置信度最高的进行回复，而持续性对话，在于N-Best列表关联着向下文而生成，形成了一个对话场景。（VUI设计师在设计的时候，每个对话都会提供多个TTS对助手进行训练）
对话式标识（对话礼仪，如：谢谢、好的、⼲得好等）
当⽤户在对话中使⽤了⼀些基本的礼仪后，系统也会给予相应的回复，显的更加人性化，⽤户的参与度也会更⾼。
比如你对助手说谢谢，助手会回答不客气。很有意思的对话。
**TTS**
TTS简单的来说就是语音播报，即助手说出来的话。
**声纹识别**
现在一些厂商已经加入了声纹识别技术，根据声音来识别用户，从而根据用户的习惯进行不同的回答，而不是千篇一律的回答。
**ASR**
ASR（自动语音识别引擎），ASR就是能将用户语音转换成文本的技术。
**语音打断**
和字面的意思一样，就是在助手播报过程中，用户可以打断，根据自己的意愿进行选择。可以想象一下我们在打10086客服是，是不是经常打断，提前选择自己需要的服务。
**语料泛化**
语料泛化指，设计师提供一些语料后（3-5个），再进行细化。直到覆盖到全部场景。比如查询天气就有多种预料，可以是查看天气、看看天气、天气咋样，进一步还可以指定时间与地点。
**垂类**
垂类可以理解为类别，举例说明：比如闹钟和天气就是两个垂类，用户在设定闹钟的路径中，突然对助手说查询天气。这个就是跨垂类的场景，需要设计师考虑让不让跨垂类。
**意图**
意图一样是字面上的意思，简单点来说就是给助手一个明确的指令。意图可以往下拆分成多个子意图。比如查询天气就是主意图，查询深圳的天气就是子意图。很多主意图助手是无法直接回答，需要进行进一步的确认才能回答。当然天气不在此列，毕竟我们可以根据地理位置，来回答你。
中文环境下的特殊要求，多音字、同音字
在语音设计中，我们不得不考虑多音字、同音字的设计，比如说打电话给王行，如果只有一个叫“王行”的，不管“一行”还是“行走”，我们都指定同一个路径就行了，但是如果有两个、三个的同音字呢？而且可能同音不同字，比如说“张”与“章”。这个时候音箱该怎么处理？音箱没有屏幕来呈现一个列表，让你进行区分，音箱只能通过语音来告诉你。可能已经有人想到这么处理了，此处就不做具体讨论，欢迎大家的发言。
**小结**
关于音箱还有非常多的细节可以写，比如在语音识别下，可以分为识别到声音但没有语义（无效的声音）；没有识别到任何声音；识别到了声音有语义但没有理解。此类还可以继续去拆分距离等因素。
当前音箱产品对于大部分指令都能及时且正确的响应，但距离与人相似的交流还有很长的路要走。我们需要更快的响应速度，更贴近自然的声音，更丰富的多轮对话场景，以及更鲜明的“人格”，更加聪明的“ta”。

