
# 一文读懂对抗生成网络的3种模型 - 喜欢打酱油的老鸟 - CSDN博客


2019年01月07日 08:01:07[喜欢打酱油的老鸟](https://me.csdn.net/weixin_42137700)阅读数：25标签：[对抗生成网络																](https://so.csdn.net/so/search/s.do?q=对抗生成网络&t=blog)个人分类：[人工智能																](https://blog.csdn.net/weixin_42137700/article/category/7820233)


[https://www.toutiao.com/i6635851641293636109/](https://www.toutiao.com/i6635851641293636109/)
2018-12-17 14:53:28
![一文读懂对抗生成网络的3种模型](http://p3.pstatp.com/large/pgc-image/c09df7d24b284c27944903e7739cad9b)

基于对抗生成网络技术的在线工具edges2cats，
可以为简笔画涂色
**前言**
**在GAN系列课程中分别讲解了对抗生成网络的三种模型，从Goodfellow最初提出的原始的对抗生成网络，到改进型的DC GAN，再到解决了原始GAN存在问题，从而生成效果更好的WGAN。**
生成模型不同于分类聚类等传统的机器学习任务，要做的是从无序中生成有序，从输入的随机数出发，生成有意义的数据，例如图片，文字，时间序列等。课堂中讨论的生成模型主要应用在计算机图形学中。
生成模型本身可以分成三类，一类是基于概率的，比如用传统统计非线性ICA或变分自编码器（VAE），第二类是自动化生成的，主要是使用RNN产生的图片，或者写出的诗，而GAN这一类是基于对抗性取样（adversial sample）。

# 一、传统GAN模型
**GAN**（Generative Adversarial Networks对抗生成网络）模型使用一组真实的图片作为输入，试图生成能够以假乱真的类似图片。方法是先由生成器随机的生成图片，之后由判别器判定图片是否为真实的。由于在所有的GAN模型，都可以分为生成器和判别器两个部分，训练的过程是先训练生成器，等到训练一定时间后再固定生成器训练判别器，这使得GAN不同与传统的机器学习的训练过程，更加不稳定，而这也是GAN模型之后的改进版要优化的部分。
![一文读懂对抗生成网络的3种模型](http://p3.pstatp.com/large/pgc-image/b34a4d17c7c242ba885d134b208efa55)

在传统的GAN模型中，图像的处理使用的是全连接层，训练的方法是随机梯度下降，优化的目标是真实数据的概念分布与生成数据概念分布的差距。根据理论推导，在无限的训练时间，无穷的模型容量，以及可以直接修改生成器的概率分布的假设时，模型一点可以训练达到最优解。但实际中，上述的假设都不满足，这也成了之后GAN模型改进的基础。

![一文读懂对抗生成网络的3种模型](http://p9.pstatp.com/large/pgc-image/fb4c11910d574945a48ec969622e15ad)

相比VAE这样的生成模型，GAN生成的图片不会是模糊的，会有清晰的边缘，但可能会出现塌缩，即生成器生成的图像都是类似的，不具有多样性。从理论的角度来看，GAN模型提出了一种全新的生成模型的范式，不依赖马尔可夫链这样的类线性模型，可以捕捉到全局的关联，但无法显式的导出生成器的概率分布。

# 二、改进版：DCGAN模型
接下来看看GAN的改进版**DCGAN**（Deep Convolutional Generative Adversarial Networks 深度卷积对抗生成网络），这篇文章讲原来判别器和生成器中的全连接层的结构改为了更适合处理图像的卷积层和反卷积层，引入了批量正则化，将训练的策略改为了Adam，在像素间进行了插值，同时进行了GAN模型标配的黑科技向量运算，即通过对生成器所需的随机分布进行向量运行，控制生成的图像，例如下图所示，通过戴眼镜的男生减去不戴眼镜的男生，再加上不戴眼镜的女生，生成出戴眼镜的女生。

![一文读懂对抗生成网络的3种模型](http://p99.pstatp.com/large/pgc-image/3a5548b6f99e4424a85f0f4be6352671)

为了加速训练，**DCGAN还改变了优化目标**，对于判别器和生成器，逐个对于卷积层分别进行优化，同时对判别器和生成器单独使用mini batch的方式，使用一组图像进行训练，从而隐式的对缺乏多样性的生成结果予以惩罚。
**DCGAN还引入了一些小技巧**，例如在损失函数中加入之前项的均值，例如Label smooth，将判别器判定的较小概率的值，例如0.1等价于0，从而避免了判别器的过渡训练，由于最初生成器的训练要难于判别器，Label smooth可以看成是对判别器加上了early stopping（提早停止）的正则化操作。
DCGAN的另一个创新点是**通过inception这样成熟的分类器去判别生成图片的质量，**从而不必由人类去判定。如果模型生成的图片是类似真实图片的，那通过inception的分类器，总会被分为一类，而如果模型生成的图片是四不像，那分类生成的标签就会有较大的不确定性，即较大的相对信息熵。同时为了评价网络生成图片的多样性，DCGAN的作者提出以一个可以计量的标准，即通过比较真实图片与生成图片的差异（计算KL散度的积分）来完成。
![一文读懂对抗生成网络的3种模型](http://p9.pstatp.com/large/pgc-image/832fe75d4ef943ad8ce3d5628235d296)

DCGAN 生成器的一种架构
有了新生成的数据，就可以用来做半监督学习，即交新增的生成数据当成是带标签的，从而提升训练集的数量。在做半监督学习时，需要修改分类器的损失函数，将所有生成图片看成新的一类，这里新加项类似与GAN模型待优化的函数。
DCGAN生成的图片缺乏全局的统一性，可能生成的猫有头有耳朵，但是其位置是不对的，可能耳朵长到了腿上。

# 三、WGAN模型
![一文读懂对抗生成网络的3种模型](http://p99.pstatp.com/large/pgc-image/df6e394d3e80448f8c1269d7df9df036)

接着说**WGAN**（Wasserstein GAN）这个偏数理的模型，该文章先指出了原始GAN模型的缺陷，通过将训练的目标函数的拆分，找出其中内部相互矛盾的方向，指出了为什么GAN的训练是不稳定的。通过导入Wasserstein 距离，通过向判别器引入连续噪音，对判别器的概念分布进行钝化（smooth），同时使用模拟退火的思路，随着训练降低引入的随机性。WGAN相比DCGAN，训练的过程更为稳定，生成的图像更为清晰。

# 四、小结
总结一下，GAN是一类脱胎于监督学习的生成模型，可以用在特征提取的评价，半监督学习，也可以用在强化学习的模拟环境构建中。GAN的发展很快，例如基于GAN的风格迁移让机器具有了想象力，GAN中相互博弈的猫鼠游戏类似于找到博弈论中的纳什均衡，而这在理论上属于一个还没有解决的开放问题。
> 本文为郭瑞东老师关于《深入浅出GAN-原理与应用》的学习心得
原创： 郭瑞东 集智AI学园

