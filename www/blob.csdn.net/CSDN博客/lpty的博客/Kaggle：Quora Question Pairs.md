
# Kaggle：Quora Question Pairs - lpty的博客 - CSDN博客

2018年06月11日 19:00:31[lpty](https://me.csdn.net/sinat_33741547)阅读数：1556



## 一、概要
[Quora Question Pairs](https://www.kaggle.com/c/quora-question-pairs)是kaggle上一个关于文本匹配的问题，主要目的是判断两个问题是不是同一个意思。
## 二、数据简介
数据结构相对比较简单，如下：
`"id","qid1","qid2","question1","question2","is_duplicate"`共有6个字段，比较有用的便是question字段代表一个序列文本，is_duplicate代表两个文本是否为相同的意思。
## 三、数据预处理
作为文本数据，到手之后常用操作就是预处理，笔者这里将数据进行简单清洗，大致分为以下步骤：
`1、将文本转为小写
2、对于文本中一些“不规范”表述，统一为一种形式，如：1000g——>1kg等
3、词干提取`预处理这里仔细考虑可以做出几层，比如：提取名词性短语、翻译模型、去除共现词等等，但出于时间考虑，这里只是简单的做了一层的处理。
## 四、特征工程
对于传统机器学习模型，重头戏就来自特征工程，这里将本项目中的特征工程分为以下几种：
### 1、统计特征
对于文本的统计特征，项目中提取了以下几种：
##### （1）共现词
共现词代表同一个词在两个文本同时出现，这是一个比较形象的特征，同时出现的词越多代表相似度越高，这里如果单纯使用名词性的词语可能效果会更好，因为这种问题形式的文本，其核心内容都会在名词短语中体现出来，具体计算方式如下：
`(共现词的在q1中出现的次数+共现词在q2中出现的次数)/文本总次数`
##### （2）加权共现词
加权其实就是用文本的TFIDF值作为权重，计算共现词概率
##### （3）特殊共现词
特殊共现的做法利用了训练数据里面的标签，通过计算每一个词，在文本重复时出现的次数，在文本不重复时出现的次数得到这个词的一个监督权重；
`词在文本重复时出现的次数/词出现的总次数 = 词的监督权重`在得到每一个词的监督权重之后，对于文本只需要对每一个词的权重进行概率连乘就可以了。
`词A的监督权重*词B的监督权重*... = 特殊共现概率`
##### （4）其他
其他还有StrikeAMatch、编辑距离等，实际使用中效果也挺不错的，详细的特征可以参考代码。
### 2、表示特征
表示特征主要是一些跟word Embedding相关的特征提取，
##### （1）Word2Vec
基于清洗后的文本训练了一个300维的词向量，之后计算两个文本之间的cosine、euclidean、manhattan距离作为特征，这里的词向量也可以考虑利用预训练的模型如Glove等。
还有基于word2vec的n-gram特征，这个特征效果也还可以。
##### （2）wordMoverDistance
词移距离，详细可以参考我的博文，一种基于词向量计算文本相似度的方法，实践中效果相当不错。
##### （3）DocVector
上述词向量也是用了某些方式转化为句向量，之后再计算相似度。这里直接使用句向量模型，生成向量提取cosine特征。
### 3、NLP特征
##### （1）关键词特征
利用TFIDF算法，提取出文本的关键词，再结合词向量计算距离特征。
##### （2）TFIDF距离
这个直接使用TFIDF矩阵进行计算，有点暴力，因为这个矩阵有点大。后续基于这个特征还可以进行扩充，比如PAC后的50、100、300维的向量距离，还有其他的如LDA等等，但降维过程占用资源过大，笔者只有一台空置服务器可以使用，就放弃了。
##### （3）其他
后续还有一些想法没有实现，比如进行句法分析，基于句法的特征等等。
### 4、图特征
quora的数据集一个比较有意思的点是，这是一个社交网络状态下的数据集，对于这种数据，它很有可能并不是全部手动标注的，有可能是基于问题搜索后，用户对搜搜推荐的问题有没有点击来加权衡量出来，那么，这里其实存在一种很强的图联系。
基于问题与问题是否同时出现构建了一个网络，而多次出现的问题变成独立连接之间的桥梁，构成一个庞大的问题关系网。
##### （1）图的统计特征
统计特征计量了每一个问题得最大连接度，及问题的最大连通长度。
##### （2）图的结构特征
结构特征提取了每个问题的最大团，问题同时出现的最大团等，很有意思的是，这种出现重复的问题，很多时候会聚集在一个团中或者周围。
##### （3）图的传播特征
基于问题网络，还可以进行传播特征计算，如pagerank、hits等等，但笔者用python简单构建的模型占用资源过大，没法进一步计算，如果有时间，可以考虑在图数据库中重新构建一个，再进行相应的传播计算。
## 五、模型
### 1、传统模型
传统模型这里使用了xgboost，这个模型参数简单，且效果也不错，作为快速验证想法的工具很值得推荐。
其他还有随机森林也是一个不错的选择，两个模型相比较，xgboost会好一点，随机森林表现出来过拟合严重一些，但也要可能是笔者没有花时间进行仔细的调参所致。
### 2、深度模型
关于深度学习的模型，笔者实现了两个，一个基于CNN，一个基于LSTM-RNN，但效果都没有达到论文所说的预期，不知是论文中用了一些小trick没有注意到，还是在某些方面出了偏差，最后都弃之不用了。
### 3、融合模型
融合模型作为最后提升分数的利器，很值得一用。但前期在深度模型处花了不少时间，GPU渣。。后面就没时间了&没心情继续调了，就此作罢。
## 六、其他
最终只提交了一个单模型的xgboost的结果上去，分数0.17574，由于比赛已经结束，自行算了一个大概的位置，应该是 600/3300 Top 20%，以后有时间再优化吧
![这里写图片描述](https://img-blog.csdn.net/20180611185933404?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NpbmF0XzMzNzQxNTQ3/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)[ ](https://img-blog.csdn.net/20180611185933404?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NpbmF0XzMzNzQxNTQ3/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
具体代码已经开源，可以在我的github上找到：[https://github.com/lpty/kaggle](https://github.com/lpty/kaggle)
[            ](https://img-blog.csdn.net/20180611185933404?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NpbmF0XzMzNzQxNTQ3/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

