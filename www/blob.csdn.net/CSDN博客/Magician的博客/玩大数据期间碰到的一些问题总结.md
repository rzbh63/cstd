
# 玩大数据期间碰到的一些问题总结 - Magician的博客 - CSDN博客


2018年09月26日 09:25:40[春雨里de太阳](https://me.csdn.net/qq_16633405)阅读数：173



### 文章目录
[问题一：Zookeeper节点数量为什么建议是奇数个？](#Zookeeper_1)
[问题二：HA机制的Hadoop集群中Journal Node 作用](#HAHadoopJournal_Node__15)
[问题三：两个datanode节点互相排斥怎么解决（集群无法识别新加入的Datanode）？](#datanodeDatanode_32)
[问题四：如何修改Zookeeper日志 zookeeper.out输出路径](#Zookeeper_zookeeperout_49)
[问题五：HDFS block丢失过多进入安全模式（safe mode）的解决方法](#HDFS_blocksafe_mode_57)
[问题六：datanode数据存放位置研究](#datanode_70)

# 问题一：Zookeeper节点数量为什么建议是奇数个？
原因是：“Zookeeper集群，**当有一半以上的节点数在工作中的时候，集群才对外服务”。**
怎么理解上面这句话呢，用实验数据说话：
**实验一：**
设置节点数量为偶数 4， 启动 2 个节点。观察结果：集群不对外服务启动 3 个节点。观察结果：集群开始对外服务
**实验二：**
设置节点数量为奇数个 5启动3个节点。观察结果：集群开始对外服务
**总结：**
Zookeeper的算法逻辑里面，“一半以上的节点”，是不包括等于一半的。所以无论设置集群总数量为 2n+1 个节点 或者 2n 个节点，最少都需要依赖 n+1 个节点，分别可以**容纳**n 个 或 n-1 个节点挂掉（**也就是说就算挂n个节点ZK系统照样运行**）。 （相比之下，设置为 2n+1， 可以比设置为 2n 多挂掉一个节点）。所以这里说的是建议奇数个而不是一定是奇数个节点
# 问题二：HA机制的Hadoop集群中Journal Node 作用
两个NameNode为了数据同步，会通过一组称作JournalNodes的独立进程进行相互通信。当active状态的NameNode的命名空间有任何修改时，会告知大部分的JournalNodes进程。standby状态的NameNode有能力读取JNs中的变更信息，并且一直监控edit log的变化，把变化应用于自己的命名空间。standby可以确保在集群出错时，命名空间状态已经完全同步了。
集群启动时，可以同时启动2个NameNode。这些NameNode只有一个是active的，另一个属于standby状态。active状态意味着提供服务，standby状态意味着处于休眠状态，只进行数据同步，时刻准备着提供服务，如图所示：
![在这里插入图片描述](https://img-blog.csdn.net/20180925175212733?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzE2NjMzNDA1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
在一个典型的HA集群中，每个NameNode是一台独立的服务器。在任一时刻，只有一个NameNode处于active状态，另一个处于standby状态。其中，active状态的NameNode负责所有的客户端操作，standby状态的NameNode处于从属地位，维护着数据状态，随时准备切换。
[
](https://img-blog.csdn.net/20180925175212733?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzE2NjMzNDA1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)两个NameNode为了数据同步，会通过一组称作JournalNodes的独立进程进行相互通信（**JournalNodes依赖于Zookeeper来实现两个NameNode之间数据的同步功能**）。当active状态的NameNode的命名空间有任何修改时，会告知大部分的JournalNodes进程。standby状态的NameNode有能力读取JNs中的变更信息，并且一直监控edit log的变化，把变化应用于自己的命名空间。standby可以确保在集群出错时，命名空间状态已经完全同步了，如图所示
![在这里插入图片描述](https://img-blog.csdn.net/20180925175540986?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzE2NjMzNDA1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
为了确保快速切换，standby状态的NameNode有必要知道集群中所有数据块的位置。为了做到这点，所有的datanodes必须配置两个NameNode的地址，发送数据块位置信息和**心跳**给他们两个。
对于HA集群而言，确保同一时刻只有一个NameNode处于active状态是至关重要的。否则，两个NameNode的数据状态就会产生分歧，可能丢失数据，或者产生错误的结果。为了保证这点，JNs必须确保同一时刻只有一个NameNode可以向自己写数据。
JournalNode服务器：运行的JournalNode进程非常轻量，可以部署在其他的服务器上。注意：必须允许至少3个节点。当然可以运行更多，**但是必须是奇数个，如3、5、7、9个等等。当运行N个节点时，系统可以容忍至少(N-1)/2(N至少为3)个节点失败而不影响正常运行**。
在HA集群中，standby状态的NameNode可以完成checkpoint操作，因此**没必要配置Secondary NameNode、CheckpointNode、BackupNode**。如果真的配置了，还会报错。
# 问题三：两个datanode节点互相排斥怎么解决（集群无法识别新加入的Datanode）？
之前有两个datanode节点，这里新添加了一个datanode节点，但是在集群中却未表现出来。
到对应的管理界面只看到两个存活的节点
Live Nodes 为 2,
Dead Nodes 为 0
然后我切换到Datanodes界面查看:
发现mini2和mini3存活, 我就刷新了几下, 发现变成了mini3和mini4存活了, 我一直刷呀刷,发现有mini2就没有mini4,有mini4就没有mini2, mini2与mini4互相排斥,
然后我上传了一个文件,结果mini2挂掉了 ,  经过排查发现是我的
/root/apps/hadoop/tmp/dfs/data/current目录下了VERSION文件里:
![在这里插入图片描述](https://img-blog.csdn.net/2018092518073586?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzE2NjMzNDA1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
![在这里插入图片描述](https://img-blog.csdn.net/20180925180746183?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzE2NjMzNDA1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
mini2和mini4的 datanodeUuid是一样的（在虚拟机中玩集群添加节点的时候直接克隆虚拟机，虽然将新增的节点配置好后，但是由于对应datanode的配置信息（如版本信息）依旧是别的的节点的配置信息，所以才会出现这种情况，这时候只需要将之前节点生成的datanode的配置信息删除，让该节点重新生成配置信息即可），原来是datanode的Uuid冲突了。
**解决方法：**
把mini4的VERSION文件删除，重启datanode即可
停止:[hadoop-daemon.sh](http://hadoop-daemon.sh)stop datanode
启动:[hadoop-daemon.sh](http://hadoop-daemon.sh)start datanode
# 问题四：如何修改Zookeeper日志 zookeeper.out输出路径
如果不做修改，默认zookeeper的日志输出信息都打印到了zookeeper.out文件中，这样输出路径和大小没法控制，因为日志文件没有轮转。所以需要修改日志输出方式。
具体操作如下：
1、修改$ZOOKEEPER_HOME/bin目录下的zkEnv.sh文件，ZOO_LOG_DIR指定想要输出到哪个目录，ZOO_LOG4J_PROP，指定INFO,ROLLINGFILE的日志APPENDER.
2、修改$ZOOKEEPER_HOME/conf/log4j.properties文件的：
zookeeper.root.logger的值与前一个文件的ZOO_LOG4J_PROP 保持一致，该日志配置是以日志文件大小轮转的，如果想要按照天轮转，可以修改为DaliyRollingFileAppender
# 问题五：HDFS block丢失过多进入安全模式（safe mode）的解决方法
因磁盘空间不足，内存不足，系统掉电等其他原因导致dataNode datablock丢失。
解决办法(Solution)*
安装HDFS客户端，并执行如下命令：
`步骤 1     执行命令退出安全模式：hadoop dfsadmin -safemode leave
步骤 2     执行健康检查，删除损坏掉的block。  hdfs fsck  /  -delete`注意: 这种方式会出现数据丢失，损坏的block会被删掉。
# 问题六：datanode数据存放位置研究
Datanode中数据实际存放位置：
自定义路径+dfs/data/current/BP-190247797-192.168.10.220-1460040893538/current/finalized
一、curren
/home/zjsd/hadoopdata/dfs/data/current/BP-190247797-192.168.10.220-1460040893538/current/如图：
![在这里插入图片描述](https://img-blog.csdn.net/20180926092335511?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzE2NjMzNDA1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
`dfsUsed：该文件中存放该DataNode容量被占有的大小&&DataNode总容量
Finalized：数据实际所在的位置
VERSION：数据块的版本信息
DataNode空间存储的ID
layoutVersion:软件所处的版本`二、Datanode的版本信息:
![在这里插入图片描述](https://img-blog.csdn.net/20180926092324435?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzE2NjMzNDA1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
参考：[https://blog.csdn.net/wbzhang2594/article/details/53893275](https://blog.csdn.net/wbzhang2594/article/details/53893275)
参考：[https://blog.csdn.net/kiwi_kid/article/details/53514314](https://blog.csdn.net/kiwi_kid/article/details/53514314)
参考：
[https://blog.csdn.net/csdm_admin/article/details/63253538?utm_source=itdadao&utm_medium=referral](https://blog.csdn.net/csdm_admin/article/details/63253538?utm_source=itdadao&utm_medium=referral)
参考：[https://blog.csdn.net/wangshuminjava/article/details/79306358](https://blog.csdn.net/wangshuminjava/article/details/79306358)
参考：[https://blog.csdn.net/czp11210/article/details/76695745](https://blog.csdn.net/czp11210/article/details/76695745)
参考：[https://blog.csdn.net/xiaoshunzi111/article/details/51239679](https://blog.csdn.net/xiaoshunzi111/article/details/51239679)

