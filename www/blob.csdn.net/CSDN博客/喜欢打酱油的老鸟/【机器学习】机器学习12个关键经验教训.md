
# 【机器学习】机器学习12个关键经验教训 - 喜欢打酱油的老鸟 - CSDN博客


2018年08月16日 08:46:23[喜欢打酱油的老鸟](https://me.csdn.net/weixin_42137700)阅读数：107


https://blog.csdn.net/ChenVast/article/details/81482361
机器学习算法可以通过概括示例来确定如何执行重要任务。在手动编程不是这样的情况下，这通常是可行且成本有效的。随着更多数据的出现，可以解决更加雄心勃勃的问题。因此，机器学习被广泛应用于计算机真诚等领域。然而，开发成功的机器学习应用程序需要大量的“黑色艺术”，这在教科书中很难找到。
我最近阅读了华盛顿大学Pedro Domingos教授的一篇惊人的技术论文，题为“**关于机器学习的一些有用的事情。**“它总结了机器学习研究人员和从业人员学到的12个关键经验教训，包括要避免的陷阱，要关注的重要问题以及常见问题的答案。我想在本文中分享这些课程，因为它们在考虑解决您的下一个机器学习问题时非常有用。

## 1、学习 = 表示 + 评估 + 优化
![](https://cdn-images-1.medium.com/max/1000/1*AsfkdCyNlXqdp4gHiqxkCQ.png)
所有机器学习算法通常只包含3个组件：
表示：分类器必须以计算机可以处理的某种形式语言表示。相反，为学习者选择表示等同于选择它可能学习的分类器集。该集合称为学习者的假设空间。如果分类器不在假设空间中，则无法学习。一个相关的问题是如何表示输入，即使用哪些功能。
评估：需要评估函数来区分好的分类器和坏的分类器。算法内部使用的评估函数可能与我们希望分类器优化的外部评估函数不同，以便于优化，并且由于下一节中讨论的问题。
优化：最后，我们需要一种方法在语言中的分类器中搜索得分最高的分类器。优化技术的选择是学习者效率的关键，也有助于确定评估函数具有多个最优值时产生的分类器。新学员开始使用现成的优化器是很常见的，后者后来被定制设计的优化器取代。

## 2、计算的概括
![](https://cdn-images-1.medium.com/max/800/1*ud-ZL2LwBRQO_vznuC33RQ.jpeg)
机器学习的基本目标是**概括****超出训练集中的示例**。这是因为，无论我们拥有多少数据，我们都不太可能在测试时再次看到这些确切的示例。在训练集上做得很好很容易。机器学习初学者中最常见的错误是测试训练数据并具有成功的假象。如果所选分类器随后在新数据上进行测试，则通常不会比随机猜测更好。因此，如果您雇用某人来构建分类器，请务必将一些数据保留给自己并测试他们为您提供的分类器。相反，如果您已经被雇用来构建分类器，那么从一开始就设置一些数据，并且仅使用它来测试最终选择的分类器，然后在整个数据上学习最终分类器。

## 3、单独的数据不够
![](https://cdn-images-1.medium.com/max/1000/1*78SqTXRXtDgc4rlrnmJzaA.png)
作为目标的概括具有另一个主要结果：**仅凭数据是不够的，无论你拥有多少数据。**
这似乎是令人沮丧的新闻。那么我们怎么能希望学到什么呢？幸运的是，我们想要在现实世界中学习的功能并不是从所有数学上可能的函数集中统一绘制的！实际上，非常一般的假设 - 如平滑性，具有相似类的类似示例，有限的依赖性或有限的复杂性 - 通常足以做得很好，这也是机器学习如此成功的主要原因。像演绎一样，归纳（学习者所做的）是知识杠杆：它将少量的输入知识转化为大量的输出知识。归纳是一种比推论更强大的杠杆，需要更少的输入知识来产生有用的结果，但它仍然需要超过零输入知识才能工作。而且，与任何杠杆一样，我们投入的越多，回想起来，对学习知识的需求应该不足为奇。机器学习并不神奇; 它无法从无到有。它的作用是从更少的东西中获得更多。与所有工程一样，编程需要做很多工作：我们必须从头开始构建所有东西。学习更像是农业，让大自然完成大部分工作。农民将种子与营养物质结合起来种植作物。学习者将知识与数据相结合，以发展计划。

## 4、过度拟合有很多形式
如果我们拥有的知识和数据不足以完全确定正确的分类器怎么办？然后我们冒着将幻觉分类器（或其中的一部分）幻觉的风险，这种分类器在现实中并非基础，并且只是在数据中编码随机怪癖。这个问题叫做*过度拟合，*是机器学习的问题。当你的学习者输出一个对训练数据100％准确但对测试数据只有50％准确的分类器时，实际上它可以输出一个对两者都准确率为75％的分类器，它就会过度拟合。
机器学习中的每个人都知道过度拟合，但它有多种形式，并不是很明显。**理解过度拟合的一种方法是将泛化误差分解为****偏差****和****方差。****偏差**是学习器一直学习同样错误的倾向。无论真实信号如何，**方差**都是学习随机事物的倾向。线性学习器具有较高的偏差，因为当两个类之间的边界不是超平面时，学习器无法诱导它。决策树没有这个问题，因为它们可以代表任何布尔函数，但另一方面它们可能遭受高度变化：在同一现象产生的不同训练集上学习的决策树通常是非常不同的，实际上它们应该是相同的。
**交叉验证可以帮助对抗过度拟合**，例如通过使用它来选择要学习的决策树的最佳大小。但它并不是灵丹妙药，因为如果我们用它来做太多参数选择，它本身就会开始过度拟合。
除了交叉验证之外，还有许多方法可以对抗过度拟合。
**最受欢迎的是为评估函数添加正则化项**。例如，这可以惩罚具有更多结构的分类器，从而有利于较小的分类器具有较少的过度拟合空间。
另一种选择是在**添加新结构之前执行像卡方的统计显着性检验，以确定在具有和不具有该结构的情况下类的分布是否确实不同。**当**数据非常稀缺**时，这些技术特别有用。然而，你应该对特定技术“解决”过度拟合问题的说法持怀疑态度。通过陷入欠拟合（偏差）的相反误差，很容易避免过度拟合（方差）。
同时避免这两者需要学习一个完美的分类器，并且事先不知道它没有一种技术总能做到最好（没有免费的午餐）。

## 5、直觉在高维度上失败
![](https://cdn-images-1.medium.com/max/1000/1*co8lvlGGtrYmLDqteORm6A.png)
过度拟合后，机器学习中最大的问题是**维数***诅咒**。*这个表达式是由贝尔曼于1961年创造的，指的是当输入是高维的时，许多在低维度上工作良好的算法变得难以处理。但在机器学习方面，它指的更多。由于固定大小的训练集覆盖了输入空间的减少部分，因此随着实例的维度（特征的数量）的增长，正确推广变得指数级更难。
高维度的一般问题是我们的直觉来自三维世界，通常不适用于高维度的。在高维度上，多变量高斯分布的大部分质量并非接近均值，而是在其周围越来越远的“壳”中; 并且大部分高维度橙色的体积在皮肤中，而不是纸浆中。如果在高维超立方体中均匀分布恒定数量的示例，则超出某些维度，大多数示例更接近超立方体的面而不是其最近的邻域。如果我们通过将其刻在超立方体中来近似超球面，则在高维度上，超立方体的几乎所有体积都在超球面之外。这对于机器学习来说是个坏消息，其中一种类型的形状通常由另一种形状近似。
建立2维或3维分类器很容易; 我们可以**通过视觉检查找到不同类别的例子之间的合理前沿**。
但在高维度上，很难理解发生了什么。这反过来又使得设计好的分类器变得困难。天真地，人们可能会认为收集更多功能永远不会受到伤害，因为在最坏的情况下，他们没有提供有关该课程的新信息。但实际上，维度的诅咒可能会超过它们的好处。

## 6、理论上的保证不是他们所看到的
![](https://cdn-images-1.medium.com/max/800/1*K9wPLf21MuJ04bhO-To_yg.png)
机器学习论文充满理论保证。最常见的类型是确保良好泛化所需的示例数量的界限。你应该对这些保证做些什么？首先，它们甚至是可能的，这是非常了不起的。归纳传统上与演绎形成对比：在演绎中，你可以保证结论是正确的; 在归纳中，所有投注都已关闭。或许这是几个世纪以来的传统智慧。最近几十年的一个主要发展是认识到事实上我们可以对归纳的结果有所保证，特别是如果我们愿意接受概率保证。
我们必须小心这样的约束意味着什么。例如，它没有说，如果你的学习者返回了与特定训练集一致的假设，那么这个假设可能很好地推广。所说的是，给定足够大的训练集，学习器很可能会返回一个概括得很好或无法找到一致假设的假设。这个界限也没有说明如何选择一个好的假设空间。它只告诉我们，如果假设空间包含真实的分类器，则学习者输出不良分类器的概率随训练集大小而减小。如果我们缩小假设空间，则边界会改善，但它包含真实分类器的可能性也会缩小。
另一种常见的理论保证类型是渐近：给定无限数据，学习者可以保证输出正确的分类器。这是令人放心的，但由于其渐近保证，选择一个学习者而不是另一个学习者会很轻率。在实践中，我们很少处于渐近状态（也称为“asymptopia”）。并且，由于上面讨论的偏差 - 方差权衡，如果学习者A比给定无限数据的学习者B更好，则B通常优于给定的有限数据。
**理论保证在机器学习中的主要作用不是作为实际决策的标准，而是作为算法设计的理解和推动力的源泉。**在这方面，它们非常有用; 事实上，理论与实践的密切相互作用是机器学习多年来取得如此巨大进步的主要原因之一。但*需要注意的是：***学习是一种复杂的现象，只是因为学习者有理论上的理由并且在实践中工作并不意味着前者是后者的原因。**

## 7、特征工程是关键
![](https://cdn-images-1.medium.com/max/1000/1*7n6g6yeEIOrXL6HnybmZdA.jpeg)
在一天结束时，一些机器学习项目成功，一些失败。有什么区别？很容易，最重要的因素是使用的功能。如果您有许多独立的功能，每个功能都与课程相关，那么学习很容易。另一方面，如果类是功能的一个非常复杂的功能，您可能无法学习它。通常，原始数据的形式不适合学习，但您可以从中构建特征。这通常是机器学习项目中的大部分工作。它通常也是最有趣的部分之一，直觉，创造力和“黑色艺术”与技术的东西一样重要。
初学者经常会惊讶于机器学习项目在实际进行机器学习时花费的时间很少。但是，如果考虑收集数据，集成数据，清理数据并对其进行预处理以及在功能设计中可以进行多少试验和错误，这是多么有意义。此外，机器学习不是构建数据集和运行学习器的一次性过程，而是运行学习器，分析结果，修改数据 和/或 学习器以及重复的迭代过程。**学习往往是最快的部分，但那是因为我们已经掌握了很好的知识！****特征工程更加困难，因为它是特定领域的，而学习器可以在很大程度上是通用的。**但是，两者之间没有明显的边界，

## 8、更多数据击败更聪明的算法
![](https://cdn-images-1.medium.com/max/600/1*KHLUDcJY4Iii_LhHHf6ciw.jpeg)
在大多数计算机科学中，2个主要的有限资源是时间和记忆。在机器学习中，还有第三个：训练数据。哪个瓶颈已经从十年变为十年。在20世纪80年代，它往往是数据。今天通常是时间。可以获得大量数据，但没有足够的时间来处理它，因此它未被使用。这导致了一个悖论：尽管**原则上更多的数据意味着可以学习更复杂的分类器，但实际上更简单的分类器最终被使用，因为复杂的分类器需要花费太长时间才能学习。**部分答案是提出快速学习复杂分类器的方法，实际上在这方面取得了显着进展。
使用更聪明的算法的部分原因是收益比您预期的要小，对于第一个近似值，它们都做同样的事情。当您将表示视为不同的规则和神经网络时，这是令人惊讶的。但事实上，命题规则很容易编码为神经网络，其他表征之间也存在类似的关系。所有学习者基本上都是通过将附近的例子分组到同一个班级来工作; 关键区别在于“附近”的含义。对于非均匀分布的数据，学习者可以产生广泛不同的边界，同时仍然在重要的区域进行相同的预测（具有大量训练样例的那些，因此也在哪里大多数文本示例都可能出现）。
通常，首先尝试最简单的学习者是有好处的（例如，逻辑回归之前的朴素贝叶斯，支持向量机之前的k-最近邻居）。更复杂的学习者是诱人的，但他们通常更难使用，因为他们需要更多的旋钮来获得良好的结果，并且因为他们的内部更不透明）。
学习者可分为两种主要类型：表示具有**（1）固定大小**的那些，如线性分类器，以及其表示**（2）可随数据一起增长**的那些，如决策树。**固定大小的学习者只能利用如此多的数据。可变大小的学习者原则上可以在给定足够数据的情况下学习任何函数**，但实际上由于算法的限制或计算成本，它们可能不会。此外，由于维度的诅咒，没有现有数据量可能就足够了。出于这些原因，聪明的算法 - 那些充分利用数据和计算资源的算法 - 最终会得到回报，前提是您愿意付出努力。设计学习者和学习分类器之间没有明显的前沿; 相反，任何给定的知识都可以在学习者中编码或从数据中学习。因此，**机器学习项目往往最终成为学习器设计的重要组成部分，从业者需要掌握一些专业知识。**

## 9、学习许多模型，而不只是一个
![](https://cdn-images-1.medium.com/max/600/1*aIhEa8hFYYK9ertRsiWsUw.jpeg)
在机器学习的早期，每个人都有他们最喜欢的学习者，以及一些*先验*理由相信它的优越性。大多数努力都尝试了很多变化并选择了最好的变体。然后系统的实证比较表明，最佳学习者因应用程序而异，并且包含许多不同学习者的系统开始出现。现在努力尝试了许多学习者的许多变化，并且仍然选择最好的学习者。但是后来研究人员注意到，如果不是选择找到的最佳变化，我们会结合很多变化，结果会更好 - 通常要好得多 - 并且对用户来说只需要额外的努力。
**创建这样的****模型集合****现在是标准的。在最简单的技术中，称为****装袋，****我们只需通过重新采样生成训练集的随机变体，在每个上学习分类器，并通过投票组合结果。**这是有效的，因为它大大减少了方差，而只是略微增加了偏差。在*提升中，*训练样例具有权重，并且这些权重是变化的，因此每个新分类器都关注于先前的分类器往往出错的示例。在*堆叠中，*各个分类器的输出成为“更高级别”学习者的输入，该学习者将如何最好地组合它们。
存在许多其他技术，趋势是越来越大的集合。在Netflix奖项中，来自世界各地的团队参与竞争，以构建最佳的视频推荐系统。随着比赛的进行，团队发现他们通过将学习者与其他团队相结合获得了最佳成绩，并且合并为越来越大的团队。获胜者和亚军都是超过100名学习者的叠加合奏，两个合奏的结合进一步改善了结果。毫无疑问，我们将来会看到更大的。

## 10、简单并不意味着准确性
![](https://cdn-images-1.medium.com/max/1000/1*PcM3TF0_kjYHHTnFD1u2iQ.png)
奥卡姆的剃刀着名地说，**实体不应该超越必要性**。在机器学习中，这通常意味着，给定两个具有相同训练误差的分类器，两者中较简单的可能具有最低的测试误差。这种主张的声称证据经常出现在文献中，但实际上有许多反例，“无免费午餐”定理意味着它不可能是真的。
我们在上一节中看到了一个反例：模型集合。即使在训练误差达到零之后，通过添加分类器，增强系综的泛化误差也会继续改善。因此，与直觉相反，模型的参数数量与其过度拟合倾向之间没有必然的联系。
更复杂的观点将复杂性等同于假设空间的大小，其基础是较小的空间允许假设由较短的代码表示。上面关于理论保证的部分中的界限可能被视为暗示较短的假设更好地概括。这可以通过在我们具有*先验*偏好的空间中为假设分配较短的代码来进一步细化。但是将其视为准确性和简单性之间权衡的“证据”是循环推理：**我们假设我们更喜欢设计更简单，如果它们是准确的，那是因为我们的偏好是准确的，而不是因为假设在我们选择的表示中是“简单的”。**

## 11、可代表性并不意味着可以学习
![](https://cdn-images-1.medium.com/max/600/1*y7QB6PLoF5ZgKVwuCkI98A.jpeg)
基本上，在可变大小的学习器中使用的所有表示都具有相关的定义形式“每个函数都可以使用这种表示来表示或任意近似地接近。”由此可以保证，表示的粉丝经常忽略所有其他函数。然而，**仅仅因为可以表示函数并不意味着它可以被学习**。例如，标准决策树学习者无法学习叶子多于训练样例的树木。在连续空间中，使用固定的基元组表示甚至简单的函数通常需要无限数量的组件。
此外，如果假设空间具有评估函数的许多局部最优，通常情况下，即使可表示，学习器也可能找不到真正的函数。给定有限的数据，时间和记忆，标准学习者只能学习所有可能功能的一小部分，并且这些子集对于具有不同表示的学习者是不同的。因此，关键问题不是“它能表现出来吗？”，答案通常是微不足道的，但是“可以学习吗？”并且**尝试不同的学习者（并且可能将它们结合起来）是值得的。**

## 12、相关并不意味着因果关系
![](https://cdn-images-1.medium.com/max/600/1*sxROjgnxj6eMp6li4h-efw.png)
**关联并不意味着因果关系这一点经常发生，以至于它可能不值得怀疑。**但是，尽管我们讨论的那种学习者只能学习相关性，但他们的结果往往被视为代表因果关系。这不对吗？如果是这样，为什么人们这样做呢？
通常，学习预测模型的目标是将它们用作行动指南。如果我们发现啤酒和尿布经常在超市一起买，那么也许在尿布部分旁边放啤酒会增加销量。但实际上没有进行实验，很难说。**机器学习通常应用于****观察****数据，其中预测变量不受学习者的控制，而不是****实验****数据。**一些学习算法可能会从观测数据中提取因果信息，但其适用性相当有限。另一方面，相关性是潜在因果关系的标志，我们可以将其作为进一步调查的指南。

## 结论
像任何学科一样，机器学习有很多“民间智慧”，很难获得，但对成功至关重要。多明戈斯教授的论文总结了一些你需要知道的最重要的项目。
原文：https://medium.com/cracking-the-data-science-interview/12-useful-things-to-know-about-machine-learning-c599be92c98d

