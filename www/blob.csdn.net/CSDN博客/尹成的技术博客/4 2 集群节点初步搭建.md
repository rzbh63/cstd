
# 4.2 集群节点初步搭建 - 尹成的技术博客 - CSDN博客

2018年11月15日 13:56:01[尹成](https://me.csdn.net/yincheng01)阅读数：49个人分类：[区块链](https://blog.csdn.net/yincheng01/article/category/7618299)



CentOS下搭建hadoop伪分布式
1．打开配置好JDK的CentOS7，输入 mkdir /usr/local/hadoop 创建一个hadoop的文件夹
2．将hadoop的tar包放到刚创建好的目录
3．进入hadoop目录，输入 tar -zxvf hadoop-2.7.3.tar.gz 解压tar包
4.输入 java -version 检查JDK是否配置成功，自己配置，不要用系统自带的openJDK
5.输入 ssh-keygen -t dsa -P ‘’ -f ~/.ssh/id_dsa 创建一个无密码的公钥，-t是类型的意思，dsa是生成的密钥类型，-P是密码，’’表示无密码，-f后是密要生成后保存的位置
6.输入 cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys 将公钥id_dsa.pub添加进keys，这样就可以实现无密登陆ssh
7.输入 ssh localhost 验证，第一次登陆有询问，输入 yes ，登陆成功且不需要密码
8.输入 vi /etc/hostname 修改主机名
9.将localhost.localdomain修改为localhost，保存并退出
10．创建3个之后要用到的文件夹，分别如下：
mkdir /usr/local/hadoop/tmp
`mkdir -p /usr/local/hadoop/hdfs/name
mkdir /usr/local/hadoop/hdfs/data`11.输入 vi ~/.bash_profile 修改环境变量，这个和之前配JDK那个不同，profile是超级用户所有，这个是每个用户独立所有的，就在 ~ 目录下，是隐藏文件，可以用 ll -a 查看
12.根据hadoop的解压位置，配置环境变量如下所示
13．按ESC切换到命令模式，然后输入 :wq! 保存并退出
14.输入 source ~/.bash_profile 使环境变量生效，将source简写为 . 也可以
15．进入hadoop解压后的 /etc/hadoop 目录，里面存放的是hadoop的配置文件，接下来要修改这里面一些配置文件
16.有2个.sh文件，需要指定一下JAVA的目录，首先输入 vi[hadoop-env.sh](http://hadoop-env.sh)修改配置文件
17.将原有的JAVA_HOME注释掉，根据自己的JDK安装位置，精确配置JAVA_HOME如下
18.按ESC，输入 :wq! 保存并退出，这里和之后的保存并退出就不再截图
19.输入 vi[yarn-env.sh](http://yarn-env.sh)修改配置文件
20.在如下位置添加 export JAVA_HOME=/usr/local/java/jdk1.8.0_102 指定JAVA_HOME，保存并退出
21.输入 vi core-site.xml 修改配置文件
22.在configuration标签中，添加如下内容，保存并退出，注意这里配置的hdfs:localhost:9000是不能在网页访问的，可以在本机访问，等配好并启动hadoop后，可以输入 hadoop fs -ls hdfs:localhost:9000 命令进行访问，查看hdfs的文件目录及文件
fs.defaultFS
hdfs://localhost:9000
HDFS的URI

hadoop.tmp.dir
/usr/local/hadoop/tmp
namenode上本地的hadoop临时文件夹
23．输入 vi hdfs-site.xml 修改配置文件
24．在configuration标签中，添加如下内容，保存并退出
dfs.namenode.name.dir
file:/usr/local/hadoop/hdfs/name
namenode上存储hdfs名字空间元数据

dfs.datanode.data.dir
file:/usr/local/hadoop/hdfs/data
datanode上数据块的物理存储位置

dfs.replication
1
副本个数，默认是3,应小于datanode机器数量
输入 cp mapred-site.xml.template mapred-site.xml 将mapred-site.xml.template文件复制到当前目录，并重命名为mapred-site.xml
26.输入 vi mapred-site.xml 修改配置文件
27.在configuration标签中，添加如下内容，保存并退出
mapreduce.framework.name
yarn
指定mapreduce使用yarn框架
28．输入 vi yarn-site.xml 修改配置文件
在configuration标签中，添加如下内容，保存并退出
yarn.resourcemanager.hostname
master
指定resourcemanager所在的hostname

yarn.nodemanager.aux-services
mapreduce_shuffle
NodeManager上运行的附属服务。
需配置成mapreduce_shuffle，才可运行MapReduce程序

30.进入hadoop的bin目录，输入 ./hdfs namenode -format 格式化namenode，第一次使用需格式化一次，之后就不用再格式化，如果改一些配置文件了，可能还需要再次格式化
31.格式化完成
32.进入hadoop的sbin目录，输入 ./start-all.sh 启动hadoop
33.输入 yes
34．输入 jps 查看当前java的进程，该命令是JDK1.5开始有的，作用是列出当前java进程的PID和Java主类名，除了JPS，有5个进程都是hadoop启动的进程，启动成功
35．虚拟机内打开网页，输入localhost:8088，查看hadoop进程管理界面
36.虚拟机内打开网页，输入localhost:50070，查看hdfs的界面
37.能访问8088和50070两个端口看到如上两个界面，说明hadoop搭建完成，接下来通过本地web访问这两个端口，IP输入虚拟机的IP
38.如上所示，访问失败，这是因为没有关闭虚拟机的防火墙，输入 systemctl stop firewalld.service 关闭防火墙，
39.若想重启后，防火墙不再开启，输入 systemctl disable firewalld.service
40.继续在本地网页访问hadoop的8088和50070端口，访问成功
学院Go语言视频主页
[https://edu.csdn.net/lecturer/1928](https://edu.csdn.net/lecturer/1928)
[清华团队带你实战区块链开发](https://ke.qq.com/course/344443?tuin=3d17195d)
扫码获取海量视频及源码   QQ群：721929980
![在这里插入图片描述](https://img-blog.csdnimg.cn/20181114143613461.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lpbmNoZW5nMDE=,size_16,color_FFFFFF,t_70)

