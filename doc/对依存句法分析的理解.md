# 对依存句法分析的理解

2018年04月19日 19:50:33 [zcancandice](https://me.csdn.net/weixin_38889448) 阅读数：2541



# 1.概念

​      依存句法分析通常通过依存弧连接句子中的两两词语，以表示其句法关系，最终形成能表示整个句子句法关系的依存树。

​      {h,m,l}表示一条连接弧，h(head)表示核心词，m(modifier)表示修饰词。l表示连接弧类型（修饰关系）。h--->m表明m修饰h

​       对于每个句子，只有一个词语是总核心词（根节点）,定义一个伪词w0作为总核心词s的父节点，w0--->s

依存句法分析通常满足3个约束：

1.单核心，即句子中每个词语都只依存于一个核心词

2.弱联通

3.无环（每个连接弧是单向的）

# 2.依存句法分析的两个基本问题

​      依存句法分析主要是对输入的句子，给出分值最高的依存树。因此包含两个基本问题（1）评分（score）（2）解码：即基于句子特征权重，构造满足约束的依存树

# 3.依存句法准确率指标

UAS=核心节点正确的词数/总词数*100%

LAS=核心节点正确且依存关系也正确的词数/总词数*100%

CM=依存树完全正确的句子数/总句子数*100%

RA=根节点正确的句子数/总句子数*100%

# 4.解码

**4.1. 基于图的依存句法分析方法**——从完全有向图中寻找最大生成树的问题

**4.2. 基于转移的依存句法分析方法**——通过一系列移进、规约等转移动作构建一棵依存句法树，学习的目标是寻找最优动作序列

两种方式对比：与基于图的方法相比，基于转移的方法时间复杂度更低，且能采用更丰富的特征，分析准确率与图方法相当

# 5.基于转移的依存句法分析

转移系统：初始状态---（状态转移动作）--->n个中间状态----（状态转移动作）---->接受状态，将一个状态表示为<栈，缓存，已分析好的依存弧>

初始状态：栈中只有伪词w0,整个词语都在缓存中，没有依存弧

接受状态：栈中只有伪词，缓存清空，所有的依存弧

状态转移动作：移进，左规约，右规约。

移进表示将缓存中的第一个词移入栈中

**栈中词从左往右排序【...,X3,X2,X1】,栈顶词为X1，后进先出**

左规约表示栈顶的第一个词与第二个词产生了左指向依存弧，即第一个词依存于第二个词，将栈顶第二个词（核心词）下栈

右规约表示栈顶第一个词与第二个词产生了右指向依存弧，即第二个次依存于第一个词，将栈顶第一个词下栈

![img](https://img-blog.csdn.net/20180420093353390)

# 6.解码算法

**贪心解码算法：**要学习一个分类器，其输入为一个状态，输出为该状态下最可能的动作。贪心算法存在错误级联问题，即前期动作选择错误会导致后面更多的错误，且无法回溯。

**通过特征来表示状态，通过分类器判断要采取的转移动作。**如栈顶的词、词性，缓存中的第一个词、词性，已生成部分依存树的最左或最右词，这些又被称为核心特征。为了提高分类的精度，还需要人工定义各种组合特征。如Zhang and Nivre (2011) 曾给出了一套准优化的特征及特征组合模板，共有20种核心特征，72种组合特征。

**柱搜索算法：**使用agenda来组织搜索过程，保存了相同数目的K个状态，遍历所有状态选择分值最大的K个，形成新的K个状态，更新agenda。

**柱搜索算法举例**

​      首先需要确定一个`Beam Size`，这里设置为2，意思是每个`word`后面的分支考虑概率最大的那两个`words`。比如下面的例子，从下往上首先分成A、B两个words，然后继续往上传播，句子变成是AA/AB/BA/BB这四种情况（绿色虚线）。考虑到`Beam Size=2`，选择概率最大的两个，假设是AB/BA（橙色大箭头）。然后以选择的AB/BA继续向上传播，又出现了四种情况ABA/ABB/BBA/BBB，依然是选择综合概率最大的两个ABB/BBB。以此类推，直至句子结束。只要可以调整好`Beam Size`，就能够使用最小的计算量，得到最优的结果。

![img](https://img-blog.csdn.net/20180420111027540)

作者：知乎用户
链接：https://www.zhihu.com/question/54356960/answer/293804923
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

# 7.基于深度学习技术的贪心解码算法

​       CMU的Dyer等人 (2015) 提出使用长短时记忆循环神经网络（LSTM-RNN）来表示栈和缓存，并使用递归神经网络来表示部分依存树，另外还额外地使用一个LSTM表示历史的转移动作序列，最终将这些网络输出的向量进行拼接来表示一个状态，从而达到无需进行任何人工特征提取和组合的操作，即可更完备地表示状态的目的。Ballesteros等人 (2015) 后来又进一步拓展他们自己上述的工作，使用字符序列的双向LSTM来表示单词，从而更好地对单词进行泛化表示，克服低频词或未登录词表示不精确等问题。Dyer等人的一系列工作虽然无需人工提取任何特征，但是网络过于复杂，不便于学习。Kiperwasser and Goldberg (2016) 提出了一个非常简单的特征表示和学习方法，他们使用双向LSTM来对句子中的每个词进行表示，然后将该词表示作为依存句法分析系统的输入，在仅使用少量核心特征的情况下，取得了较高的准确率。

# 8.基于深度学习技术的柱搜索解码算法

​     hou等人 (2015) 直接计算完整转移动作序列的似然函数，然而对整个句子来说，其可能的转移动作序列太多以至于无法枚举，所以无法精确地计算似然函数。为解决该问题，他们引入了对照学习（Contrastive Learning）方法来近似求解似然函数，即在进行全局归一化时，只考虑Beam中的有限结果。Google的Andor等人 (2016) 也采用了类似的思想，经过细致的参数调节，使得他们的句法分析系统获得了目前文献中报告的最高准确率，Google于今年5月份开源了他们的系统 – SyntaxNet 



# 参考来源：

1.车万翔.基于深度学习的依存句法分析进展         http://www.cipsc.org.cn/qngw/?p=885

2.Andor, D., Alberti, C., Weiss, D., Severyn, A., Presta, A., Ganchev, K., Collins, M. (2016). Globally Normalized Transition-Based Neural Networks. ACL.

3.Kiperwasser, E., & Goldberg, Y. (2016). Simple and Accurate Dependency Parsing Using Bidirectional LSTM Feature Representations. TACL.

4.Ballesteros, M., Dyer, C., & Smith, N. A. (2015). Improved Transition-Based Parsing by Modeling Characters instead of Words with LSTMs. EMNLP.

5.Dyer, C., Ballesteros, M., Ling, W., Matthews, A., & Smith, N. A. (2015). Transition-Based Dependency Parsing with Stack Long Short-Term Memory. ACL.

6.李正华. 汉语依存句法分析关键技术研究[D].哈尔滨工业大学,2013.

7.周浩. 基于神经网络的句法分析研究[D].南京大学,2017.

