# 夜深人静写算法（八）- 朴素贝叶斯分类

2018年01月04日 21:21:22

英雄哪里出来

阅读数：125971

更多

 								所属专栏： 																[夜深人静写算法](https://blog.csdn.net/column/details/21195.html) 																 							

 									

 **目录**  

 

**一、引例**

​      **1、旅游问题**

**二、贝叶斯理论**

​      **1、事件和概率**

​      **2、联合概率**

​      **3、条件概率**

​      **4、全概率公式**

​      **5、贝叶斯定理**

**三、朴素贝叶斯分类实例**

​      **1、回到旅游问题**

​      **2、朴素**

​      **3、特征和类别**

​      **4、拉普拉斯平滑**

​      **5、概率修正**

**四、朴素贝叶斯分类算法**

​      **1、分类问题**

​      **2、朴素贝叶斯分类算法原理**

**五、参考资料**

 

 

 **一、引例**

 **1、旅游问题**

 今天要讲的这个算法很有意思，看了好多资料，打算整理一下。一开始就讲概念，则读者减半。所以我打算从大家都感兴趣的话题开始聊，神不知鬼不觉的让大家领会这个算法的真谛。

公司一般都会组织旅游，那么去不去是我们自己决定的，天气、心情、工作等等的外在原因都会影响我们的选择。我收集了一些数据，如图一-1-1所示。来看看大家在不同情况下对旅游是如何选择的。

 ![img](https://img-blog.csdn.net/20180104212458440)

 图一-1-1

 我们看到这些数据可以大致分析一下，比如：“真的想出去的玩的时候风雨无阻”、“有时候宅是没有任何理由的”等等。

 那么现在我问你，如果下雨、心情好、工作忙，去还是不去？这条数据在上述的表中是找不到的，然而或许你会脱口而出：“不去”。那么我就要问了：“你是怎么想出来的？”你可能想都不用想就能告诉我：“第三条数据，下雨、心情好、工作闲”的时候都不去，工作忙了怎么可能还会去？

 你如果要这么说，那我可以说：“忙的时候我就想出去走走，放松下心情，为什么不可以？”

 这个问题争论下去没有什么意义，还是要拿数据说话。其实我们只要能够证明这样一个事实，即：下雨、心情好、工作忙的前提下，“不去旅游”的概率大于“去旅游”的概率。这样就能做出决定了：“不去”。反之亦然。

 这就是我们今天要讲的---朴素贝叶斯分类算法。

 

 **二、贝叶斯理论**

 这是一个基于概率的算法，所以有必要复习一下大学概率论的相关知识。

 **1、事件和概率**

 简单扫一遍事件的概念，完全可以略过，只需要瞄一眼图二-1-1的文氏图就行：

​         a.包含事件：A⊂B，即事件A发生则必然导致事件B发生；

​         b.和事件：A∪B，即事件A和事件B至少一个发生，事件A∪B发生；

​         c.积事件：A∩B（或AB），即事件A和事件B同时发生，则事件A∩B发生；

​         d.互斥事件：A∩B=∅，即事件A和B不能同时发生；

​         e.对立事件：A∩B=∅且A∪B=Ω，即事件A和B必定并且仅有一个发生，A的对立事件记为A'（数学中是上划线）；

​         f.差事件：A-B，即当且仅当A发生而B不发生时，事件A-B发生；

 ![img](https://img-blog.csdn.net/20180104213029680)

 图二-1-1

 概率则是对事件发生可能性大小的客观度量。事件A的概率记为*P*(A)。

 **2、联合概率**

 联合概率是指事件A和事件B同时发生的概率，记为P(A∩B)或P(AB)。

 ![img](https://img-blog.csdn.net/20180104213305062)

 图二-2-1

 用S(x)表示图二2-1的文氏图中x块代表的面积，用面积的比值来代表概率是最直观的了：

 ![img](https://img-blog.csdn.net/20180104213908638)

 图二-2-2

 **3、条件概率**

 条件概率是指已知事件B发生的条件下，事件A发生的概率，记为*P*(A|B)。由于事件A和B之间可能会有一定联系，因而事件B发生以后，事件A的概率可能会发生变化。即P(A|B)不一定等于P(A)。

 从图二-2-1可以看出，*P*(A|B)=S(A∩B)/S(B)，分子分母同时除上S(Ω)，则：

 ![img](https://img-blog.csdn.net/20180104214457147)

 图二-3-1

 同理可得：

 ![img](https://img-blog.csdn.net/20180104214722711)

 图二-3-2

 将分母移到等式左边，则有如下乘法等式：

 ![img](https://img-blog.csdn.net/20180104215041787)

 图二-3-3

 这个就是乘法公式。

 最后将P(B)移到等式右边成为分子，得到条件概率的计算公式如下：

 ![img](https://img-blog.csdn.net/20180104215219289)

 图二-3-4

 这时候有人可能会问*P*(A|B)和*P*(B|A)有什么区别？在数学思维里，当一个量不容易求的时候总是将它转换成等价的好求的量，这里也是如此。接下来的这个例子中，你会发现*P*(A|B)不好求而P(B|A)是显而易见的例子。

 **【例题1】假设人口中有1%的人携带SB病毒。进行检查时，由于技术和操作不完善的原因，携带者未必呈阳性，而不携带者也可能呈阳性。在不清楚是否携带的情况下，检测呈阳性概率为10%；明确携带病毒的情况下，检测呈阳性概率为98%。**

 **请问，现在某人检查结果呈阳性，那么他携带SB病毒的概率有多大？**

 为了简化问题，我们令人群中携带SB病毒的事件为A，检测呈阳性的事件为B。那么需要求的就是*P*(A|B)。

 *P*(B|A)表示携带病毒者检测呈阳性的概率，是个已知量，为0.98；*P*(A)表示携带SB病毒的概率为0.01；*P*(B)为0.10。

 所以*P*(A|B)=*P*(B|A)*P*(A)/*P*(B)=0.98*0.01/0.10=9.8%

 我们发现，即使检验结果为阳性，携带病毒的概率也不是很大，这是因为有误报率的存在。对于这个病毒问题，下文还会继续探讨，目前只是作为抛砖引玉的作用。

 **4、全概率公式**

 ![img](https://img-blog.csdn.net/20180104215647006)

 图二-4-1

 如图二-4-1所示，B代表全集，并且被切分成B1、B2、B3三部分，那么A可以表示成如下：

 ![img](https://img-blog.csdn.net/20180104215723499)

 图二-4-2

 然后计算A的概率就可以转换成计算A和B的积事件的概率之和，利用乘法公式，有如下等式：

 ![img](https://img-blog.csdn.net/20180104220011869)

 图二-4-3

 以上就是划分为3的全概率公式，接下来看下更一般的情况：

 ![img](https://img-blog.csdn.net/20180104220256455)

 图二-4-4

 还是以病毒携带为例说一说全概率公式。

 **【例题2】假设人口中有1%的人携带SB病毒。进行检查时，由于技术和操作不完善的原因，携带者未必呈阳性，而不携带者也可能呈阳性。****不携带病毒的情况下****，检测呈阳性概率为9%；携带病毒的情况下，检测呈阳性概率为98%。**

 **请问，在不清楚是否携带病毒的情况下，检测呈阳性的概率为多少？**

 该问题对例题1进行了扩展，红字部分是两道题的区别，沿着上个问题的思路，*P*(A)代表携带病毒的概率，*P*(B)代表检测呈阳性的概率。那么*P*(B)就是我们需要求的量。有全概率公式，我们可以将事件按照是否携带病毒分成两类：A表示携带，A'表示不携带。根据全概率公式，有：

 ![img](https://img-blog.csdn.net/20180104220517007)

 图二-4-5

​     其中*P*(B|A)和*P*(B|A')分别代表携带病毒和不携带病毒时，检测呈阳性的概率，题中已经给出；*P*(A)和*P*(A')也都是已知量；所以*P*(B)可以轻松计算得出：*P*(B) = 0.98*0.01 + 0.09*(1-0.01) = 9.89%

 

 **5、贝叶斯定理**

 贝叶斯公式看起来复杂，其实很简单，将条件概率的推算公式的分母P(B)用全概率公式替换，就有了贝叶斯公式：

 ![img](https://img-blog.csdn.net/20180104220827799)

 图二-5-1

 好了，贝叶斯相关的理论部分到这里就结束了，接下来我们看一个SB病毒的完整例题。

 **【例题3】假设人口中有1%的人携带SB病毒。进行检查时，由于技术和操作不完善的原因，携带者未必呈阳性，而不携带者也可能呈阳性。不携带病毒的情况下，检测呈阳性概率为9%；携带病毒的情况下，检测呈阳性概率为98%。**

 **请问，现在某人检查结果呈阳性，那么他携带SB病毒的概率有多大？**

 沿用【例题2】的题面和【例题1】的提问，就有了【例题3】。为了套用贝叶斯公式，我们用A1和A2代表携带病毒和不携带病毒，那么A1和A2构成一个全集Ω，*P*(B)代表检测呈阳性的概率。需要求的就是*P*(A1|B)。直接套用贝叶斯公式：

 ![img](https://img-blog.csdn.net/20180104221116857)

 图二-5-2

 我们发现，携带病毒的的情况下检测呈阳性的概率高达98%。然而反过来，检查结果为阳性，携带病毒的概率不到10%，单纯从图二-5-2的公式就能看出一些端倪，98%和1%都是确定的，99%也是从1%通过反算取得，所以影响最后的概率的最大因素就是那个9%（不携带病毒时检查呈阳性的概率），也就是误报率。误报率越大，公式的分母越大，最后的概率就越小。

 再来分析一下条件概率的计算公式，*P*(A)被称为“先验概率”，它是事件B发生前对事件A概率的一个判断，有的资料上也叫 “古典概率”，往往通过大量的数据估算得出（最经典的是抛一枚硬币，正面朝上的概率为1/2）；*P*(A|B)被称为“后验概率”，即在事件B发生后，对事件A概率的一个再判断；而*P*(B|A)/*P*(B)作为调整因子，用于加强或减弱先验概率。

 ![img](https://img-blog.csdn.net/20180104221609235)

 图二-5-3

 这样讲可能不是很直观，那么我们现在把A和B用具体的事件来表示，用A表示加班，用B表示身体被掏空。则有如下等式：

 ![img](https://img-blog.csdn.net/20180104221805699)

 图二-5-4

 我们需要求的是：想知道某个人“身体被掏空”，是因为“加班”呢还是别的什么原因?属于加班的概率有多少？等式右边的三项都可以通过大量数据统计得出。

 P(加班)：该员工从入职到现在加班的天数/总天数；

 P(身体被掏空)：请假的天数/总天数；

 P(身体被掏空|加班)：当晚加班后次日请假的天数/总加班数；

 （以上的计算方法只是一个参考方案，并且和样本数量有关。比如入职越久的老员工数据越准确，因为采样次数越多频率越接近概率）

 当然，“身体被掏空”这个结果发生的原因还有其它的，读者可以发挥自己的想象，比较各个原因发生的概率，抽丝剥茧，逐步找到“身体被掏空”的真正原因。

 

 **三、朴素贝叶斯分类算法**

 **1、回到旅游问题**

 回到之前的问题，下雨、心情好、工作忙的前提下，“去旅游”还是“不去旅游”？我们先把这个问题用公式来描述出来：

 ![img](https://img-blog.csdn.net/20180104223039863)

 图三-1-1

 那么，如果我们能够计算*P*1和*P*2的值，然后比较两者的大小，就能做出决定了。先计算P1。根据条件概率的推算公式，有：

 ![img](https://img-blog.csdn.net/20180104223253471)

 图三-1-2

 还是那句话，当一个量不容易求的时候，总是可以将它转换成等价的好求的量，那么为什么这三个量好求呢？这样看来貌似还不是很好求，我们需要把等式进行再一次变形。

 接下来我们看下朴素贝叶斯分类算法是如何将上式进行变形的。

 **2、朴素**

 “朴素”的意思就是简单，为了让问题足够简单，我们需要假定影响结果（这里特指“去旅游”这件事）的各个因素相互独立。相互独立意味着什么？意味着事件B发生与否，并不会影响事件A发生的概率，即：*P*(A|B) = *P*(A)。则根据乘法公式，有：

 *P*(AB) = *P*(A|B)*P*(B) = *P*(A)*P*(B)

 可以推广到n个独立事件的情况。那么就有：

 ![img](https://img-blog.csdn.net/20180104223617237)

 图三-2-1

 同理，再加上“去旅游”这个事件的前提下，原本独立的事件还是满足如下等式：

 P(BC|A) = P(B|A)P(C|A)

 ![img](https://img-blog.csdn.net/20180104223822031)

 图三-2-2

 然而，问题来了，有人说天气可能影响我的心情，它们之间并不是相互独立的。没错，这也是为何称之为“朴素”的一个原因，这里的相互独立这个假设往往是理想化的，这也是朴素贝叶斯分类的一个缺点，所以这个算法适用于各个决定因素之间相关性较小的实际问题。但是这并不影响我们学习这个算法的思维。

   最后我们把上述*P*1的连等式进行一番整理，有：

 ![img](https://img-blog.csdn.net/20180104224050842)

 图三-2-3

 **3、特征和类别**

 仔细观察最后的连等式，我们可以将这些概率分成几类，天气、心情、工作可以认为是一些“特征”，而去不去旅游作为我们需要分类的“类别”（这里为去和不去两类），那么我们需要统计的就是*P*(特征)、*P*(类别)、*P*(特征|类别)这三类概率。

 朴素贝叶斯分类算法的含义就是根据一些给定的“特征”进行“分类”。

 统计的数据越多，事情发生的频率越接近事情发生的概率（我们现在为了把事情简单化，所以数据量比较小，这样更方便说明问题）。

​     a)*P*(特征)：如图三-3-1，以“下雨”为例，10条样本数据中“下雨”的数据占据了3条，所以*P*(下雨)=3/10=0.3

 ![img](https://img-blog.csdn.net/20180104224252606)

 图三-3-1

​     b)*P*(类别)：如图三-3-2，以“去旅游”为例，10条样本数据中“去旅游”的数据占据了5条，所以P(去旅游)=5/10=0.5

 ![img](https://img-blog.csdn.net/20180104224412173)

 图三-3-2

​     c)*P*(特征|类别)：如图三-3-3，以“去旅游”的情况下“心情好”为例，5条“去旅游”的样本数据中“心情好”占据了1条，所以*P*(心情好|去旅游)=1/5=0.2

 ![img](https://img-blog.csdn.net/20180104224542478)

 图三-3-3

 按照上述方式进行统计，就能计算出下雨、心情好、工作忙的情况下“去旅游”和“不去旅游”的概率了。

 ![img](https://img-blog.csdn.net/20180104224952011)

 图三-3-4

 计算完*P*1和*P*2，仔细一看！哇靠！不去旅游的概率还能大于1？这是为什么呢？难道是为了替公司节省资金，所以竭力阻止我们去旅游？

 当然不是啦...

 真正的原因是因为我们的数据样本太少，所以其实频率并不等于概率，为了缓解这个问题，需要引入拉普拉斯平滑使得概率的计算更为精确。

​      **4、拉普拉斯平滑**

 （百度拉普拉斯平滑，你可以看到一个比较牛逼的图，我就不贴了。免得贴完图，导致又一批祖国的花朵对数学失去信心）。

 拉普拉斯平滑又被称为加1平滑，是比较常用的平滑方法。平滑方法的存在主要是为了解决零概率问题。

 还是以抛硬币来举例，硬币出现正面的概率为p，已知前m次出现正面的次数为n。当m足够大的时候，p=n/m；然而，当m很小时，这个结果显然是不成立的，试想m=4的时候，4次都是反面，那么p=0这肯定是不合理的。

 为了解决这个零概率问题，我们在分母加上取值范围的大小，并且在分子加1。概率计算公式变为p=(n + 1)/(m + 2)。其中分母的2代表正面、反面两种情况，分子的1则代表“1”次正面，当m足够大的时候，极限为n/m符合概率的计算；当m较小时，则认为正面这个事件至少发生一次。

 更加一般的情况，对于一个随机变量x，取值范围为[1, n]内的整数。进行m次取值试验后，记录第i次取出的结果为a(i)，那么取到j的概率为：

 ![img](https://img-blog.csdn.net/20180104225256280)

 图三-4-1

 加入拉普拉斯平滑以后，计算公式变为：

 ![img](https://img-blog.csdn.net/20180104225359772)

 图三-4-2

 分子加1是为了避免零概率问题，分母加n是为了公平，让每个能取到的值都加1。

 **5、概率修正**

 然后，通过拉普拉斯平滑对特征、类别概率进行修正。以P(下雨)为例，10次天气样本数据中，3次为下雨，然后对分母加上3（天气的种类数），分子加上1，得到最后的概率P(下雨) = (3 + 1) / (10 + 3) = 4/13。继续把P1和P2带入进行计算：

 ![img](https://img-blog.csdn.net/20180104225655123)

 图三-5-1

 选择不去旅游的概率还是大于1（真的很后悔选了这么个例子...）。这对于作者来说简直就是晴天霹雳，感觉有种编不下去了的感觉。但是，作者还是倾向于把产生这个的原因归结为样本数据太少引起的。

 然而，其实我们并不需要纠结这个问题，我们要做的只是需要比较P1和P2哪个大，我们发现P1和P2的分母是一样的，换言之只要比较两者的分子即可，因为引入了拉普拉斯平滑，所以这里涉及的所有概率都是大于0的，也就是说如果拿P1或P2作为除数不会产生除零异常。那么，令k = P1/P2，如果k>1，则说明P1>P2；反之，则P1<=P2。

 实际情况是P1<P2，不去旅游的概率远大于去旅游的概率。所以我们选择不去旅游。

 

 **四、朴素贝叶斯分类算法**

 **1、分类问题**

 **所谓分类问题，就是根据事物的特征，对事物的类别进行划分。上文描述的旅游问题就是一个分类问题，其中天气、心情、工作的忙或闲就是特征量，根据这些特征，分为去旅游和不去旅游两类。**

 **从数学的角度来阐述分类问题：**

 

 

 **定义待分类集合X和类别集合Y，其中X = {x1, x2, ...}，Y = {y1, y2,...yn}。 需要找到一种映射规则y = F(x)，使得对于任何一个特征xi**∈X有且仅有一个yj∈Y使得yj  = F(xi)成立。

 分类问题的实质就是构造这个分类器F。其实你在遇到一个问题，然后思考用什么算法来解决这个问题的时候，就是一个分类的过程。分类的准确率与你学过的算法多少（构造方式）、问题本身适合什么算法的特性（特征量）以及你对每个算法的经验（样本数量）有关。

 **2、朴素贝叶斯分类算法原理**

 1、x = {a1, a2,...am}为一个待分类项，其中ai代表x的第i条特征（例如：x  = {下雨，心情好，工作忙}）；

 **2、类别集合Y  = {y1, y2,...yn}（例如：Y = {去旅游，不去旅游}）；**

 **3、分别计算P(y1|x)、P(y2|x)、...、P(yn|x)；**

 **4、找出满足P(y1|x),P(y2|x),...,P(yn|x)中值最大的yk，那么x属于类别yk；**

 

 **朴素贝叶斯算法要求各个特征量ai相互独立，其中第3条的计算可以通过贝叶斯公式进行转换：**

 ![img](https://img-blog.csdn.net/20180104225943455)

 图四-2-1

 **在找满足P(yi|x)最大的yk时，分母P(x)是确定的，所以只需要计算分子即可。分子的计算可以通过大量样本训练统计得出。**





 **五、参考资料**

 a.阮一峰的贝叶斯定理，解释的很到位

 <http://www.ruanyifeng.com/blog/2011/08/bayesian_inference_part_one.html>

b.贝叶斯的理论知识

<http://mindhacks.cn/2008/09/21/the-magical-bayesian-method/>

c.算法杂货铺——分类算法之朴素贝叶斯分类

<https://www.cnblogs.com/leoo2sk/archive/2010/09/17/naive-bayesian-classifier.html>

 d.拉普拉斯平滑，一个比较好的解释

 <http://blog.csdn.net/stdcoutzyx/article/details/9285001>