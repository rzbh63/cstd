
# ReLU函数详解及反向传播中的梯度求导 - BrightLamp的博客 - CSDN博客


2018年11月21日 20:33:18[BrightLampCsdn](https://me.csdn.net/oBrightLamp)阅读数：546所属专栏：



## 摘要
本文给出 ReLU 函数的定义, 并求解其在反向传播中的梯度
## 相关
*配套代码, 请参考文章 :*
Python和PyTorch对比实现ReLU函数及反向传播
*系列文章索引 :*
[https://blog.csdn.net/oBrightLamp/article/details/85067981](https://blog.csdn.net/oBrightLamp/article/details/85067981)
## 正文
## 1. 定义
ReLU函数, 即线性整流函数(Rectified Linear Unit), 是神经网络结构中常用的非线性激活函数.
其定义如下:
$$
ReLU(x) = 
\left\{
             \begin{array}{rr} 
             0, &amp;  x  \leqslant 0\\
             x, &amp; x  &gt; 0
             \end{array}
\right.
$$
函数图像 :
![在这里插入图片描述](https://img-blog.csdnimg.cn/20181121174755337.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L29CcmlnaHRMYW1w,size_16,color_FFFFFF,t_70)
## 2. 反向传播
ReLU 函数是逐个处理输入值的, 并不需要写成向量的形式.
但为了方便编程实现, 这里将其进行改编成向量的形式.
考虑一个输入向量 x , 经 ReLU 函数变换后得到向量 r, 往前 forward 传播得到误差值 error (标量 e ),  求 e 对 x 的梯度.
$$
x =( x_1,x_2,x_3,\cdots,x_k) \\
\;\\
r = ReLU(x)\\
\;\\
e=forward(r)
$$
求解过程 :
$$
\frac{d r_i}{d x_i}   = 
\left\{
             \begin{array}{rr} 
             0, &amp;  x_i  \leqslant 0\\
             1 , &amp; x_i  &gt; 0
             \end{array}
\right.\\
\;\\
m = (\frac{\partial r_1}{\partial x_1},\frac{\partial r_2}{\partial x_2},\frac{\partial r_3}{\partial x_3}, \cdots ,\frac{\partial r_k}{\partial x_k})  \\
\;\\
\nabla e_{(r)} = (\frac{\partial e}{\partial r_1},\frac{\partial e}{\partial r_2},\frac{\partial e}{\partial r_3}, \cdots ,\frac{\partial e}{\partial r_k})  \\
\;\\
\frac{\partial e}{\partial x_i} = \frac{\partial e}{\partial r_i}\frac{\partial r_i}{\partial x_i} \\
\;\\
\nabla e_{(x)} = (\frac{\partial e}{\partial x_1},\frac{\partial e}{\partial x_2},\frac{\partial e}{\partial x_3}, \cdots ,\frac{\partial e}{\partial x_k})  =\nabla e_{(r)} \odot m
\;\\
$$
向量$\nabla e_{(r)}$由上游负责计算, 是已知的, x 确定时 m 也是已知的,$\odot$表示元素积, 即同位元素相乘.
## 3. ReLU 函数的作用
为了理解 ReLU 函数的作用, 我们引入一种在电子电路中广泛应用的电子元器件 :
![在这里插入图片描述](https://img-blog.csdnimg.cn/2018112117513488.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L29CcmlnaHRMYW1w,size_16,color_FFFFFF,t_70)
二极管 (英语：Diode)，电子元件当中, 一种具有两个电极的装置, 只允许电流由单一方向流过, 用于整流电路，可以把交流电变换成脉动的直流电, 即整流二极管 (rectifier diode).
![在这里插入图片描述](https://img-blog.csdnimg.cn/20181121180448899.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L29CcmlnaHRMYW1w,size_16,color_FFFFFF,t_70)
上图左边是整流二极管的特性曲线, 右边是整流二极管在电路图中的表示符号.
左边$\triangle U$部分是击穿电压, 很容易烧毁二极管, 不是整流二极管的正常工作范围.
可以看到, 正常工作范围的特性曲线和 ReLU 函数的图像非常相似.
![在这里插入图片描述](https://img-blog.csdnimg.cn/20181121181356236.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L29CcmlnaHRMYW1w,size_16,color_FFFFFF,t_70)
上图是常见的整流电路, 利用电流只能在二极管中单向传播的特性, 通过四只二极管组合, 就可以很方便将来自 T 的交流电转换为$R_L$使用的直流电.
使用 Python 模拟整流电路 :
```python
import
```
```python
numpy
```
```python
as
```
```python
np
```
```python
import
```
```python
matplotlib
```
```python
.
```
```python
pyplot
```
```python
as
```
```python
plt
```
```python
def
```
```python
relu
```
```python
(
```
```python
signal
```
```python
)
```
```python
:
```
```python
return
```
```python
np
```
```python
.
```
```python
maximum
```
```python
(
```
```python
0
```
```python
,
```
```python
signal
```
```python
)
```
```python
def
```
```python
relu_reverse
```
```python
(
```
```python
signal
```
```python
)
```
```python
:
```
```python
return
```
```python
-
```
```python
np
```
```python
.
```
```python
minimum
```
```python
(
```
```python
0
```
```python
,
```
```python
signal
```
```python
)
```
```python
x
```
```python
=
```
```python
np
```
```python
.
```
```python
linspace
```
```python
(
```
```python
-
```
```python
10
```
```python
,
```
```python
10
```
```python
,
```
```python
2000
```
```python
)
```
```python
y
```
```python
=
```
```python
np
```
```python
.
```
```python
sin
```
```python
(
```
```python
x
```
```python
)
```
```python
plt
```
```python
.
```
```python
axhline
```
```python
(
```
```python
color
```
```python
=
```
```python
"black"
```
```python
)
```
```python
plt
```
```python
.
```
```python
axvline
```
```python
(
```
```python
color
```
```python
=
```
```python
"black"
```
```python
)
```
```python
plt
```
```python
.
```
```python
plot
```
```python
(
```
```python
x
```
```python
,
```
```python
y
```
```python
)
```
```python
plt
```
```python
.
```
```python
show
```
```python
(
```
```python
)
```
```python
y
```
```python
=
```
```python
relu
```
```python
(
```
```python
y
```
```python
)
```
```python
+
```
```python
relu_reverse
```
```python
(
```
```python
y
```
```python
)
```
```python
plt
```
```python
.
```
```python
axhline
```
```python
(
```
```python
color
```
```python
=
```
```python
"black"
```
```python
)
```
```python
plt
```
```python
.
```
```python
axvline
```
```python
(
```
```python
color
```
```python
=
```
```python
"black"
```
```python
)
```
```python
plt
```
```python
.
```
```python
plot
```
```python
(
```
```python
x
```
```python
,
```
```python
y
```
```python
)
```
```python
plt
```
```python
.
```
```python
show
```
```python
(
```
```python
)
```
整流前 :
![在这里插入图片描述](https://img-blog.csdnimg.cn/2018112120053137.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L29CcmlnaHRMYW1w,size_16,color_FFFFFF,t_70)
整流后 :
![在这里插入图片描述](https://img-blog.csdnimg.cn/20181121200659664.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L29CcmlnaHRMYW1w,size_16,color_FFFFFF,t_70)
可以看到, 经过整流后, 所有的反向信号都调整为正向信号了.
[
](https://img-blog.csdnimg.cn/20181121200659664.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L29CcmlnaHRMYW1w,size_16,color_FFFFFF,t_70)
## 4. ReLU + 线性组合
[
](https://img-blog.csdnimg.cn/20181121200659664.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L29CcmlnaHRMYW1w,size_16,color_FFFFFF,t_70)在常见的神经网络结构中, ReLU 经常和线性变换一起使用.
[
](https://img-blog.csdnimg.cn/20181121200659664.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L29CcmlnaHRMYW1w,size_16,color_FFFFFF,t_70)
$$
a_i = a_ix_i + b_i\\
\;\\
y = \sum_{k = 1}^{k} ReLU(a_i)
$$
[
](https://img-blog.csdnimg.cn/20181121200659664.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L29CcmlnaHRMYW1w,size_16,color_FFFFFF,t_70)
```python
import
```
```python
numpy
```
```python
as
```
```python
np
```
```python
import
```
```python
matplotlib
```
```python
.
```
```python
pyplot
```
```python
as
```
```python
plt
```
```python
def
```
```python
relu
```
```python
(
```
```python
signal
```
```python
)
```
```python
:
```
```python
return
```
```python
np
```
```python
.
```
```python
maximum
```
```python
(
```
```python
0
```
```python
,
```
```python
signal
```
```python
)
```
```python
x
```
```python
=
```
```python
np
```
```python
.
```
```python
linspace
```
```python
(
```
```python
-
```
```python
10
```
```python
,
```
```python
10
```
```python
,
```
```python
2000
```
```python
)
```
```python
b1
```
```python
=
```
```python
0.00
```
```python
*
```
```python
np
```
```python
.
```
```python
pi
b2
```
```python
=
```
```python
0.25
```
```python
*
```
```python
np
```
```python
.
```
```python
pi
b3
```
```python
=
```
```python
0.50
```
```python
*
```
```python
np
```
```python
.
```
```python
pi
b4
```
```python
=
```
```python
0.75
```
```python
*
```
```python
np
```
```python
.
```
```python
pi
b5
```
```python
=
```
```python
1.00
```
```python
*
```
```python
np
```
```python
.
```
```python
pi
b6
```
```python
=
```
```python
1.25
```
```python
*
```
```python
np
```
```python
.
```
```python
pi
b7
```
```python
=
```
```python
1.50
```
```python
*
```
```python
np
```
```python
.
```
```python
pi
b8
```
```python
=
```
```python
1.75
```
```python
*
```
```python
np
```
```python
.
```
```python
pi
y1
```
```python
=
```
```python
np
```
```python
.
```
```python
sin
```
```python
(
```
```python
x
```
```python
+
```
```python
b1
```
```python
)
```
```python
y2
```
```python
=
```
```python
np
```
```python
.
```
```python
sin
```
```python
(
```
```python
x
```
```python
+
```
```python
b2
```
```python
)
```
```python
y3
```
```python
=
```
```python
np
```
```python
.
```
```python
sin
```
```python
(
```
```python
x
```
```python
+
```
```python
b3
```
```python
)
```
```python
y4
```
```python
=
```
```python
np
```
```python
.
```
```python
sin
```
```python
(
```
```python
x
```
```python
+
```
```python
b4
```
```python
)
```
```python
y5
```
```python
=
```
```python
np
```
```python
.
```
```python
sin
```
```python
(
```
```python
x
```
```python
+
```
```python
b5
```
```python
)
```
```python
y6
```
```python
=
```
```python
np
```
```python
.
```
```python
sin
```
```python
(
```
```python
x
```
```python
+
```
```python
b6
```
```python
)
```
```python
y7
```
```python
=
```
```python
np
```
```python
.
```
```python
sin
```
```python
(
```
```python
x
```
```python
+
```
```python
b7
```
```python
)
```
```python
y8
```
```python
=
```
```python
np
```
```python
.
```
```python
sin
```
```python
(
```
```python
x
```
```python
+
```
```python
b8
```
```python
)
```
```python
y
```
```python
=
```
```python
relu
```
```python
(
```
```python
y1
```
```python
)
```
```python
+
```
```python
relu
```
```python
(
```
```python
y2
```
```python
)
```
```python
+
```
```python
relu
```
```python
(
```
```python
y3
```
```python
)
```
```python
+
```
```python
relu
```
```python
(
```
```python
y4
```
```python
)
```
```python
y
```
```python
+=
```
```python
relu
```
```python
(
```
```python
y5
```
```python
)
```
```python
+
```
```python
relu
```
```python
(
```
```python
y6
```
```python
)
```
```python
+
```
```python
relu
```
```python
(
```
```python
y7
```
```python
)
```
```python
+
```
```python
relu
```
```python
(
```
```python
y8
```
```python
)
```
```python
plt
```
```python
.
```
```python
plot
```
```python
(
```
```python
x
```
```python
,
```
```python
y
```
```python
)
```
```python
plt
```
```python
.
```
```python
axhline
```
```python
(
```
```python
color
```
```python
=
```
```python
"black"
```
```python
)
```
```python
plt
```
```python
.
```
```python
axvline
```
```python
(
```
```python
color
```
```python
=
```
```python
"black"
```
```python
)
```
```python
plt
```
```python
.
```
```python
show
```
```python
(
```
```python
)
```
[
](https://img-blog.csdnimg.cn/20181121200659664.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L29CcmlnaHRMYW1w,size_16,color_FFFFFF,t_70)![在这里插入图片描述](https://img-blog.csdnimg.cn/20181121202745526.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L29CcmlnaHRMYW1w,size_16,color_FFFFFF,t_70)
只需要有限的几个 ReLU 进行组合, 就可以将交流信号调整到不错的直流信号.
[
](https://img-blog.csdnimg.cn/20181121202745526.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L29CcmlnaHRMYW1w,size_16,color_FFFFFF,t_70)ReLU 函数虽然很简单, 但和其他函数组合后却有神奇的非线性拟合能力.
[
            ](https://img-blog.csdnimg.cn/20181121202745526.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L29CcmlnaHRMYW1w,size_16,color_FFFFFF,t_70)
[
](https://img-blog.csdnimg.cn/20181121200659664.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L29CcmlnaHRMYW1w,size_16,color_FFFFFF,t_70)
