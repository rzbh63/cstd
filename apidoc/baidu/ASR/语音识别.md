# 语音识别 



# 语音识别 API

## 简介

百度语音识别通过 REST API 的方式给开发者提供一个通用的 HTTP 接口。 上传需要完整的录音文件，录音文件时长不超过60s。

## 语音识别

百度语音提供2种普通话及英语、粤语、四川话识别模型。

- 搜索模型： 效果同手机百度搜索的语音输入。适合于短语识别，没有逗号。
- 输入法模型：效果同百度输入法的语音输入。适合于长句识别，有逗号。

普通话搜索模型同时能识别简单的常用英语语句，效果同手机百度。

## 语音识别极速版

语音识别极速版支持普通话识别，采用最新识别模型，响应速度更快。按调用量计费，免费赠送5万次调用。

- 极速版输入法模型：使用在线语音领域全球首创的流式多级截断注意力模型SMLTA，拥有更快的响应时间，极大减少识别的耗时。适合于长句识别，有逗号。

## 适用范围

任意操作系统，任意编程语言，只要可以对百度语音服务器发起http请求的，均可以使用本接口。

**示例代码见： https://github.com/Baidu-AIP/speech-demo**

浏览器由于无法跨域请求百度语音服务器的域名，因此无法使用本接口。

## 语音格式

格式支持：pcm（不压缩）、wav（不压缩，pcm编码）、amr（压缩格式）。推荐pcm 采样率 ：16000 固定值。 编码：16bit 位深的单声道。

百度服务端会将非pcm格式，转为pcm格式，因此使用wav、amr会有额外的转换耗时。

- [16k 采样率pcm文件样例下载](http://speech-doc.gz.bcebos.com/rest-api-asr/public_audio/16k.pcm)
- [16k 采样率wav文件样例下载](http://speech-doc.gz.bcebos.com/rest-api-asr/public_audio/16k.wav)
- [16k 采样率amr文件样例下载](http://speech-doc.gz.bcebos.com/rest-api-asr/public_audio/16k-23850.amr)

音频文件格式转换请参见文档[【语音识别小工具\音频文件转码】](http://ai.baidu.com/docs#/ASR-Tool-convert/top)

## 自定义词库

自定义词库在您网页申请的应用内设置（具体位置参见下图）。 ![img](https://ai.bdstatic.com/file/35F8B9776A684CEEA94AFD550C770B10)

自定义词库适合短句，保证词库中一模一样的短句可以被识别出，词库中的分词优先级较高。 自定义词库仅对dev_pid = 1536生效，并且原始音频的采用率为16K。

最好在1万行以内。

副作用：如果用户的测试集中包含大量非自定义词表的query，整体上准确率下降。

### 举例

词库定义了1个短句： 1 . 摆渡船来了 百度内部处理的可能的分词结果： 摆渡船 来 了

以下录音的结果

1. 原始音频：摆渡船来了 =>识别结果： 摆渡船来了 【保证结果】
2. 原始音频：摆渡船来了么 =>识别结果： 百度传来了么 【可能结果，不保证】
3. 原始音频：摆渡船来 => 识别结果： 百度传来 【可能结果，不保证】
4. 原始音频：百度传来了喜讯 => 识别结果： 摆渡船传来了喜讯 【不保证，词库内的分词优先级高】

## SDK

目前对识别和合成的REST API，均封装了 Java、Python、PHP、C#、NodeJs、C++ 共6种开发语言的SDK。功能等同于REST API。SDK中 识别使用JSON方式提交本地文件。

# 调用流程

## 流程

1. 使用appKey secretKey 访问 https://openapi.baidu.com 换取 token ，详细见“鉴权认证机制”
2. 选择一种HTTP POST 请求格式，参见下一节 ”请求方式“
3. 填写您的参数 ，详细见 ”API请求方式及参数基本说明“

## 请求方式

如果您的音频在本地，需要将音频数据放在body中。（推荐方式） 音频在本地，有JSON和raw两种方式提交。这两种提交方式，均不是浏览器表单的提交

### json 方式，上传本地文件

- 音频文件，读取二进制内容后， base64 放在speech参数内。
- 音频文件的原始大小, 即二进制内容的字节数，填写“len”字段

由于使用json格式， header为：

```
   Content-Type:application/json
```

注意 由于base64编码后，数据会增大1/3。

### raw方式，上传本地文件

- 音频文件，读取二进制内容后，直接放在body中。
- Content-Length的值即为音频文件的大小。（一般代码会自动生成）。

由于使用raw方式， 采样率和文件格式需要填写在Content-Type中

```
   Content-Type: audio/pcm;rate=16000
```

## 测试demo

您可以下载我们的官方rest api示例查看。 测试demo请在申请应用后，从<http://ai.baidu.com/sdk>上下载

- 语音REST API示例代码 :: 一些简单的demo 有JAVA PHP 和C++
- RestApi SDK 下载 :: rest api 的完整封装，有 JAVA PHP Python Nodejs 和 C# 语言。使用JSON方式上传本地音频文件。**同rest api的功能一致，没有额外功能。**

# 鉴权认证机制

## 获取 Access Token

获取AccessToken 需要您在应用管理界面中新建应用，应用列表中即可查看。 开放平台上： ![img](https://ai.bdstatic.com/file/37CE2413CD57429D8BE68E6D3226464D)

使用语音识别及合成REST API 需要获取 Access Token。Access Token 是用户身份验证和授权的凭证，语音识别采用的是Client Credentials授权方式，即采用应用公钥（Api Key）、密钥获取Access Token，适用于任何带server类型应用，通过此授权方式获取Access Token仅可访问平台授权类的接口，

使用Client Credentials获取Access Token需要应用在其服务端发送请求（推荐用POST方法）到百度OAuth2.0授权服务的“ https://openapi.baidu.com/oauth/2.0/token ”地址上，并带上以下参数：

- grant_type：必须参数，固定为“client_credentials”；
- client_id：必须参数，应用的 API Key；
- client_secret：必须参数，应用的 Secret Key;

** 例如：**

```
https://openapi.baidu.com/oauth/2.0/token?grant_type=client_credentials&client_id=Va5yQRHl********LT0vuXV4&client_secret= 0rDSjzQ20XUj5i********PQSzr5pVw2&
```

响应数据包如下所示，其中 “access_token” 字段即为请求 REST API 所需的令牌, 默认情况下，Access Token 有效期为一个月，开发者需要对 Access Token的有效性进行判断，如果Access Token过期可以重新获取。

**例如：**

```
HTTP/1.1 200 OK
Content-Type: application/json
Cache-Control: no-store

{
"access_token": "1.a6b7dbd428f731035f771b8d********.86400.1292922000-2346678-124328",
"expires_in": 86400,
"refresh_token": "2.385d55f8615fdfd9edb7c4b********.604800.1293440400-2346678-124328",
"scope": "public audio_voice_assistant_get 。。。",
"session_key": "ANXxSNjwQDugf8615Onqeik********CdlLxn",
"session_secret": "248APxvxjCZ0VEC********aK4oZExMB",
}
```

scope中含有audio_voice_assistant_get 表示有语音识别能力，没有该audio_tts_post 的token调用识别接口会有3302错误 具体代码示例可以参见：http://ai.baidu.com/docs#/Auth/top。 注意语音服务的调用地址是https://openapi.baidu.com/oauth/2.0/token

# 参数说明

- 格式支持：pcm（不压缩）、wav（不压缩，pcm编码）、amr（压缩格式）；固定16k 采样率；
- 系统支持语言种类 普通话

## 识别语言及模型选择

**dev_pid 参数列表**

- 语音识别

| dev_pid | 语言                       | 模型       | 是否有标点 | 备注             | 请求地址                        |
| :------ | :------------------------- | :--------- | :--------- | :--------------- | :------------------------------ |
| 1536    | 普通话(支持简单的英文识别) | 搜索模型   | 无标点     | 支持自定义词库   | http://vop.baidu.com/server_api |
| 1537    | 普通话(纯中文识别)         | 输入法模型 | 有标点     | 不支持自定义词库 | http://vop.baidu.com/server_api |
| 1737    | 英语                       |            | 无标点     | 不支持自定义词库 | http://vop.baidu.com/server_api |
| 1637    | 粤语                       |            | 有标点     | 不支持自定义词库 | http://vop.baidu.com/server_api |
| 1837    | 四川话                     |            | 有标点     | 不支持自定义词库 | http://vop.baidu.com/server_api |
| 1936    | 普通话远场                 | 远场模型   | 有标点     | 不支持自定义词库 | http://vop.baidu.com/server_api |

- 语音识别极速版

| dev_pid | 语言   | 模型             | 是否有标点 | 备注           | 请求地址                     |
| :------ | :----- | :--------------- | :--------- | :------------- | :--------------------------- |
| 80001   | 普通话 | 极速版输入法模型 | 有标点     | 支持自定义词库 | http://vop.baidu.com/pro_api |

## 简介

目前 API 仅支持**整段语音**识别的模式，即需要上传完整语音文件进行识别。文件大小不超过10M，时长不超过60s。 语音数据上传POST方式有2种：

1. JSON格式POST上传本地文件。
2. raw格式POST上传本地文件。

- 请求地址

| 语音识别模型   | 请求地址                                                     |
| :------------- | :----------------------------------------------------------- |
| 语音识别       | http://vop.baidu.com/server_api https://vop.baidu.com/server_api http://vop.baidubce.com/server_api (服务端部署在百度云时，调用该地址可免外网流量费用，且返回识别结果速度更快) |
| 语音识别极速版 | https://vop.baidu.com/pro_api                                |

## 文件样例

推荐16K采样率 pcm文件

- [16k 采样率pcm文件样例下载](http://speech-doc.gz.bcebos.com/rest-api-asr/public_audio/16k.pcm)
- [16k 采样率wav文件样例下载](http://speech-doc.gz.bcebos.com/rest-api-asr/public_audio/16k.wav)
- [16k 采样率amr文件样例下载](http://speech-doc.gz.bcebos.com/rest-api-asr/public_audio/16k-23850.amr)

------

## JSON方式上传

语音数据和其他参数通过标准 JSON 格式串行化 POST 上传， JSON 里包括的参数：

| 字段名  | 类型   | 可需           | 描述                                                         |
| :------ | :----- | :------------- | :----------------------------------------------------------- |
| format  | string | 必填           | 语音文件的格式，pcm 或者 wav 或者 amr。不区分大小写。推荐pcm文件 |
| rate    | int    | 必填           | 采样率，16000，固定值                                        |
| channel | int    | 必填           | 声道数，仅支持单声道，请填写固定值 1                         |
| cuid    | int    | 必填           | 用户唯一标识，用来区分用户，计算UV值。建议填写能区分用户的机器 MAC 地址或 IMEI 码，长度为60字符以内。 |
| token   | string | 必填           | 开放平台获取到的开发者[[access_token\]](http://ai.baidu.com/docs#/Auth/top)获取 Access Token "access_token") |
| dev_pid | int    | 选填           | 不填写lan参数生效，都不填写，默认1537（普通话 输入法模型），dev_pid参数见本节开头的表格 |
| lan     | string | 选填，废弃参数 | 历史兼容参数，请使用dev_pid。如果dev_pid填写，该参数会被覆盖。语种选择,输入法模型，默认中文（zh）。 中文=zh、粤语=ct、英文=en，不区分大小写。 |
| speech  | string | 选填           | 本地语音文件的的二进制语音数据 ，需要进行base64 编码。与len参数连一起使用。 |
| len     | int    | 选填           | 本地语音文件的的字节数，单位字节                             |

- (speech, len)： 开发者可以将语音文件进行 base64编码，放在 “speech”字段中。并将语音数据的原始长度，填写“len”字段；

### 上传示例(speech, len 参数)

即：JSON格式POST上传本地文件

#### 固定头部header

```
Content-Type:application/json
```

#### 请求示例

4K大小的pcm文件（普通话录音）请求：

```
POST http://vop.baidu.com/server_api 
```

speech 参数填写为 文件内容base64后的结果：

```
{
    "format":"pcm",
    "rate":16000,
    "dev_pid":1536,
    "channel":1,
    "token":xxx,
    "cuid":"baidu_workshop",
    "len":4096,
    "speech":"xxx", // xxx为 base64（FILE_CONTENT）
}
```

#### 返回示例

```
{"corpus_no":"6433214037620997779","err_msg":"success.","err_no":0,"result":["北京科技馆，"],"sn":"371191073711497849365"}
```

#### 注意事项

len 字段表示原始语音大小字节数，不是 base64 编码之后的长度。

## Raw 方式上传

即 raw格式POST上传本地文件 语音数据直接放在 HTTP BODY 中，控制参数以及相关统计信息通过 header和url里参数传递。

### Header 参数说明

| 字段名 | 数据类型                 | 可需 | 描述                                                         |
| :----- | :----------------------- | :--- | :----------------------------------------------------------- |
| format | string（格式见下面示例） | 必填 | 语音格式，pcm 或者 wav 或者 amr。不区分大小写，推荐使用pcm文件 |
| rate   | int（格式见下面示例）    | 必填 | 采样率 16000， 固定值                                        |

语音数据的采样率和压缩格式在 HTTP-HEADER 里的Content-Type 表明，例：

```
Content-Type: audio/pcm;rate=16000
```

### url参数说明

| 字段名  | 可需           | 描述                                                         |
| :------ | :------------- | :----------------------------------------------------------- |
| cuid    | 必填           | 用户唯一标识，用来区分用户，计算UV值。建议填写能区分用户的机器 MAC 地址或 IMEI 码，长度为60字符以内。 |
| token   | 必填           | 开放平台获取到的开发者[[access_token\]](http://ai.baidu.com/docs#/Auth/top)获取 Access Token "access_token") |
| dev_pid | 选填           | 不填写lan参数生效，都不填写，默认1537（普通话 输入法模型），dev_pid参数见本节开头的表格 |
| lan     | 选填，废弃参数 | 历史兼容参数，请使用dev_pid。如果dev_pid填写，该参数会被覆盖。语种选择,输入法模型，默认中文（zh）。 中文=zh、粤语=ct、英文=en，不区分大小写。 |

URL 示例：

```
POST http://vop.baidu.com/server_api?dev_pid=1536&cuid=******&token=1.a6b7dbd428f731035f771b8d********.86400.1292922000-2346678-124328
```

## 接口返回参数

两种上传方式都返回统一的结果，采用 JSON 格式封装，如果识别成功，识别结果放在 JSON的“result”字段中，统一采用 utf-8 方式编码。 （如果使用POST方式的（url,callback）方式，百度服务器会回调用户服务器的callback地址, 返回如下结果）

| 字段名  | 数据类型                   | 可需 | 描述                                                         |
| :------ | :------------------------- | :--- | :----------------------------------------------------------- |
| err_no  | int                        | 必填 | 错误码                                                       |
| err_msg | string                     | 必填 | 错误码描述                                                   |
| sn      | string                     | 必填 | 语音数据唯一标识，系统内部产生。如果反馈及debug请提供sn。    |
| result  | array ( [string,string,…]) | 选填 | 识别结果数组，提供1-5 个候选结果， 优先使用第一个结果。utf-8 编码。 |

### 识别成功返回 case

```
{"err_no":0,"err_msg":"success.","corpus_no":"15984125203285346378","sn":"481D633F-73BA-726F-49EF-8659ACCC2F3D","result":["北京天气"]}
```

### 识别错误返回 case

```
{"err_no":2000,"err_msg":"data empty.","sn":"481D633F-73BA-726F-49EF-8659ACCC2F3D"}
```

### raw 方式测试说明

```
curl -i -X POST -H "Content-Type: audio/pcm;rate=16000" "http://vop.baidu.com/server_api?dev_pid=1536&cuid=xxxxx&token=1.a6b7dbd428f731035f771b8d********.86400.1292922000-2346678-124328" --data-binary "@/home/test/test.pcm"
```

## 错误码解释

见错误码及常见原因部分

# 错误码及常见原因

## 错误码列表

| 错误码 | 用户输入/服务端 | 含义                             | 一般解决方法                                                 |
| :----- | :-------------- | :------------------------------- | :----------------------------------------------------------- |
| 3300   | 用户输入错误    | 输入参数不正确                   | 请仔细核对文档及参照demo，核对输入参数                       |
| 3301   | 用户输入错误    | 音频质量过差                     | 请上传清晰的音频                                             |
| 3302   | 用户输入错误    | 鉴权失败                         | token字段校验失败。请用appkey 和 app secret生成。或者QPS超限。 |
| 3303   | 服务端问题      | 百度服务器后端繁忙               | 有可能是原始音频质量过差。可以请将api返回结果和原始音频反馈至论坛或者QQ群 |
| 3304   | 用户请求超限    | 用户的请求QPS超限                | 请降低识别api请求频率 （qps以appId计算，移动端如果共用则累计） |
| 3305   | 用户请求超限    | 用户的日pv（日请求量）超限       | 请开通付费，购买调用量资源（账号内所有应用APPID共用调用量限额） |
| 3307   | 服务端问题      | 语音服务器后端识别出错问题       | 有可能是原始音频质量过差。可以将api返回结果和原始音频反馈至工单、论坛或者QQ群 |
| 3308   | 用户输入错误    | 音频过长                         | 音频时长不超过60s，请将音频时长截取为60s以下，特别是amr格式  |
| 3309   | 用户输入错误    | 音频数据问题                     | 服务端无法将音频转为pcm格式，可能是长度问题，音频格式问题等。 请将输入的音频时长截取为60s以下，并核对下音频的编码，采样率16000，单声道，小端序，16bits。 |
| 3310   | 用户输入错误    | 输入的音频文件过大 或len参数过大 | 文件内容过大，音频时长不能超过60s                            |
| 3311   | 用户输入错误    | 采样率rate参数不在选项里         | 目前rate参数仅支持16000，填写其他值即会有此错误。            |
| 3312   | 用户输入错误    | 音频格式format参数不在选项里     | 目前格式仅仅支持pcm，wav或amr，如填写mp3即会有此错误         |
| 3313   | 服务端问题      | 语音服务器解析超时               | 请将api返回结果反馈至工单、论坛或者QQ群                      |
| 3314   | 用户输入错误    | 音频长度过短                     | 用户的lan参数小于等于4                                       |
| 3315   | 服务端问题      | 语音服务器处理超时               | 请将api返回结果反馈至工单、论坛或者QQ群                      |
| 3316   | 用户输入错误    | 音频转为pcm失败                  | 使用pcm格式，或者确认wav和amr的采样率16000，单声道。 wav是否是pcm编码，小端序，16bits |

## 错误码常见问题及具体分析

### 3300 错误

语音识别api使用的是HTTP POST方法， BODY里直接放置json， Content-Type头部为 application/json。 并非常见的浏览器表单请求（application/x-www-form-urlencoded或者multipart/x-www-form-urlencoded）。

必填字段：format rate channel 请勿漏填。此外 (speech, len) 及 (url, callback) 这两组参数必须二选一，如果都填，默认处理第一组。并确认 音频时长截取为60s以下。

### 3309错误

wav和amr的音频，服务端会自动转为pcm，这个过程中导致转码出错。请确认下format及rate参数与音频一致，并确认音频时长截取为60s以下。

### 3301 错误

识别结果实际为空。可能是音频质量过差，不清晰，或者是空白音频。 有时也可能是pcm填错采样率。如16K采样率的pcm文件，填写的rate参数为8000。

### 错误反馈

- 结果含有错误码：请提供： 1. 原始音频 2. 返回的完整json 3. 调用的时间点 4. 识别的参数
- 识别结果与期望不符： 请提供 ： 1.原始音频 2. 返回的完整json 3.期望结果 4. 识别的参数 5. 是否偶发
- 调用官方的rest sdk demo报错： 如果是rest sdk的报错，请提供完整报错信息。如果是上述两项，请按上面的说明。

## 反馈渠道

1. ai.baidu.com 底部查找QQ群
2. 网页里的应用发送工单
3. [论坛](http://ai.baidu.com/forum/topic/list/166)



# Android SDK





# 简介及运行环境

## 概述

本文档是百度语音开放平台Android SDK的用户指南，描述了**语音识别、长语音识别、离线自定义命令词识别、远场语音识别、语音唤醒、语义解析与对话管理**等相关接口的使用说明。SDK内部均为采用流式协议，即用户边说边处理。区别于Restapi需要上传整个录音文件。

## 兼容性

| 类别     | 兼容范围                                                     |
| :------- | :----------------------------------------------------------- |
| 系统     | 支持Android 4.0.3 以上版本 API LEVEL 15                      |
| 机型     | 上市的android手机和平板。对其它android设备及订制系统不做官方支持 |
| 硬件要求 | 要求设备上有麦克风                                           |
| 网络     | 支持移动网络（包括2G等）、WIFI等网络环境                     |
| 开发环境 | 建议使用最新版本Android Studio 进行开发                      |

1. 语音识别： 将录音转为文字。目前在线识别支持普通话、英文、粤语和四川话。
   - 在线长语音：任意时长的音频识别
   - 离线命令词：断网时识别固定的预定义短语（定义在bsg文件中）。SDK强制优先使用在线识别。
   - 唤醒词：识别预定义的“关键词”。 这个“关键词”必须在一句话的开头。
   - 离线命令词和唤醒词功能首次使用必须联网，SDK自动更新授权，失效前必须再次联网。
2. 语义理解： 将语音识别出的文字，进行分词及找出意图和词槽。

## DEMO压缩包说明

DEMO压缩包下载即可运行，其中DEMO内已经附带了SDK的库。

- bdasr_V3_xxx_xxx.jar 位于 core/libs 目录下。
- armeabi，armeabi-v7a，arm64-v8a，x86，x86_64 5个架构目录位于core/src/main/jniLibs 目录下

**demo 根目录下有readme_README_IMPORTANT.txt，使用前请先读完。** **demo 根目录下有doc_integration_DOCUMENT目录，里面有demo的测试图文教程和集成图文教程。**

## 版本更新

| jar 文件名                    | 日期       | 更新内容                                   |
| :---------------------------- | :--------- | :----------------------------------------- |
| bdasr_V3_20180801_d6f298a.jar | 2018-08-13 | 修复本地语义无法在线时使用；修复长语音回调 |

其它更新请看DEMO中的changlog文件

## SDK库文件

| 资源名称             | 资源大小 | 资源描述 |
| :------------------- | :------- | :------- |
| bdasr_V3_xxx_xxx.jar | 约130KB  | jar 库   |

## NDK so库架构

共计5个架构目录：armeabi，armeabi-v7a，arm64-v8a，x86，x86_64，每个架构下均有以下5个so库文件。

| 资源名称                                   | 资源大小 |
| :----------------------------------------- | :------- |
| libBaiduSpeechSDK.so                       | 700K     |
| libbd_easr_s1_merge_normal_20151216.dat.so | 2.2M     |
| libbdEASRAndroid.so                        | 400K     |
| libbdSpilWakeup.so                         | 1.3M     |
| libvad.dnn.so                              | 40K      |

## NDK so库精简

如果为了节省安装包体积，可以只使用armeabi目录，性能损失微小。

如果只需要在线识别功能，仅需要2个so文件：

| 资源名称             | 资源大小 |
| :------------------- | :------- |
| libBaiduSpeechSDK.so | 687K     |
| libvad.dnn.so        | 39K      |

# 接口使用及调用流程

DEMO在SDK的基础上，封装了输入和输出格式，您可以直接使用SDK，或者使用DEMO封装好SDK接口的类。 使用SDK方式的话，比较底层，需要自行实现一部分逻辑。可以参考DEMO中对SDK的调用封装。**基于SDK集成和基于DEMO集成方式2选1即可。**

SDK调用过程如下：

1. 初始化

   1.1.初始化EventManager类

   1.2.自定义输出事件类

   1.3.注册自己的输出事件类

1.4.加载离线资源（如果需要离线命令词功能）

1. 开始识别/唤醒

   2.1. 设置识别/唤醒输入参数

   2.2. 发送start开始事件

2. 回调事件

3.1. 开始回调事件

1. 控制识别/唤醒

4.1. 控制停止识别/唤醒，可以向SDK发送停止事件

4.2. 取消本次识别，可以向SDK发送取消事件

1. 事件管理器退出

5.1. 卸载离线资源(如果1.4加载离线资源)

5.2. 释放资源

## 在线识别

SDK 的调用过程可以参见DEMO中的ActivityMiniRecog类

DEMO的调用过程可以参考DEMO中的ActivityAbstractRecog类

**1** **初始化**

**1.1** **初始化EventManager对象**

SDK中，通过工厂创建语音识别的事件管理器。注意识别事件管理器只能维持一个，请勿同时使用多个实例。即创建一个新的识别事件管理器后，之前的那个置为null，并不再使用。

```
EventManager asr = EventManagerFactory.create(this, "asr"); 
// this是Activity或其它Context类
```

> *详见ActivityMiniRecog类中”基于sdk集成1.1 初始化EventManager对象"*

**1.2** **自定义输出事件类**

SDK中，需要实现EventListener的输出事件回调接口。该类需要处理SDK在识别过程中的回调事件。可以参考DEMO中对SDK的调用封装。

```
EventListener yourListener = new EventListener() {
@Override
public void onEvent(String name, String params, byte [] data, int offset, int length) {
if(name.equals(SpeechConstant.CALLBACK_EVENT_ASR_READY)){
// 引擎就绪，可以说话，一般在收到此事件后通过UI通知用户可以说话了
     }
if(name.equals(SpeechConstant.CALLBACK_EVENT_ASR_FINISH)){
// 识别结束
     }
// ... 支持的输出事件和事件支持的事件参数见“输入和输出参数”一节
   }
};
```

> *详见ActivityMiniRecog类中”基于sdk集成1.2 自定义输出事件类"*

**1.3 注册自己的输出事件类**

```
asr.registerListener(yourListener);
```

> *详见ActivityMiniRecog类中”基于sdk集成1.3 注册自己的输出事件类”*

DEMO中，以上两步合并为

```
IRecogListener listener = new MessageStatusRecogListener(handler);

// 可以传入IRecogListener的实现类，也可以如SDK，传入EventListener实现类
//如果传入IRecogListener类，在RecogEventAdapter为您做了大多数的json解析。

MyRecognizer myRecognizer = new MyRecognizer(this, listener); 
//this是Activity或其它Context类
```

> *详见ActivityAbstractRecog类中”基于DEMO集成第1.1, 1.2, 1.3 步骤 初始化EventManager类并注册自定义输出事件*

**2** **开始识别**

开始事件的参数可以参见"输入和输出参数"。

**2.1** **设置识别输入参数**

SDK中，您需要根据文档或者demo确定您的输入参数。DEMO中有UI界面简化选择和测试过程。demo中，在点击“开始录音”按钮后，您可以在界面或者日志中看见ASR_START事件的json格式的参数。

```
// asr.params(反馈请带上此行日志):{"accept-audio-data":false,"disable-punctuation":false,"accept-audio-volume":true,"pid":1736}

//其中{"accept-audio-data":false,"disable-punctuation":false,"accept-audio-volume":true,"pid":1736}为ASR_START事件的参数

String json ="{\"accept-audio-data\":false,\"disable-punctuation\":false,\"accept-audio-volume\":true,\"pid\":1736}"
```

> *详见ActivityMiniRecog类中”基于SDK集成2.1 设置识别参数‘’*

**2.2** **发送start开始事件**

```
asr.send(SpeechConstant.ASR_START, json, null, 0, 0);
```

> *详见ActivityMiniRecog类中”基于SDK集成2.2 发送开始事件*

DEMO中， 您需要传递Map<String,Object>的参数，会将Map自动序列化为json

```
Map<String, Object> params;
... // 设置识别参数
// params ="accept-audio-data":false,"disable-punctuation":false,"accept-audio-volume":true,"pid":1736
myRecognizer.start(params);
```

> *详见ActivityAbstractRecog类中"基于DEMO集成2.1, 2.2 设置识别参数并发送开始事件"*

**3 收到回调事件**

**3.1开始回调事件**

回调事件在您实现的EventListener中获取。OnEvent方法中， name是输出事件名，params该事件的参数，(data,offset, length)三者一起组成额外数据。如回调的音频数据，从data[offset]开始至data[offset + length] 结束，长度为length。

```
public void onEvent(String name, String params, byte [] data, int offset, int length);
```

> *详见ActivityMiniRecog类中”基于SDK集成3.1 开始回调事件"*

DEMO中， 回调事件在您实现的IRecogListener中获取。

> *详见RecogEventAdapter类中”基于DEMO集成3.1 开始回调事件"*

**4控制识别**

**4.1 控制停止识别 **

```
asr.send(SpeechConstant.ASR_STOP, null, null, 0, 0); 
//发送停止录音事件，提前结束录音等待识别结果
```

> *详见ActivityMiniRecog类中”基于SDK集成4.1 发送停止事件"*

**4.2 控制取消识别**

```
asr.send(SpeechConstant.ASR_CANCE, null, null, 0, 0);
 //取消本次识别，取消后将立即停止不会返回识别结果
```

> *详见ActivityMiniRecog类中”基于SDK集成4.2 发送取消事件"*

DEMO 中：

```
myRecognizer.stop(); 
// 发送停止录音事件，提前结束录音等待识别结果
```

> *详见ActivityAbstractRecog类中”基于DEMO集成4.1 发送停止事件"*

```
myRecognizer.cancel(); 
// 取消本次识别，取消后将立即停止不会返回识别结果
```

> *详见ActivityAbstractRecog类中”基于DEMO集成4.2 发送取消事件"*

**5** **事件管理器退出**

5.1 在线不需要卸载离线命令词

先启动取消，避免有还在运行的识别。 之后需要将之前的listener卸载，不卸载的话，可能有内存溢出

asr.send(SpeechConstant.ASR_CANCE, null, null, 0, 0); // 取消识别

**5.2** **释放资源**

```
asr.unregisterListener(this);
```

> *详见ActivityMiniRecog类中基于SDK集成5.2 退出事件管理器"*

DEMO中，

```
myRecognizer.release(); 
// 含有离线引擎卸载
```

> *详见ActivityAbstractRecog类中基于DEMO的5.2 退出事件管理器"*

## 离线命令词

离线命令词功能需要首先实现之前的在线识别功能的代码。离线引擎加载需要在EventManager初始化之后，识别事件之前。 在SDK中，

```
HashMap map = new HashMap();
map.put(SpeechConstant.DECODER, 2); 
// 0:在线 2.离在线融合(在线优先)
map.put(SpeechConstant.ASR_OFFLINE_ENGINE_GRAMMER_FILE_PATH, "/sdcard/yourpath/baidu_speech_grammar.bsg");
 //设置离线命令词文件路径
```

// 下面这段可选，用于生成SLOT_DATA参数， 用于动态覆盖ASR_OFFLINE_ENGINE_GRAMMER_FILE_PATH文件的词条部分

```
JSONObject json = new JSONObject();
json.put("name", new JSONArray().put("王自强").put("叶问")).put("appname", new
JSONArray().put("手百").put("度秘"));
map.put(SpeechConstant.SLOT_DATA, json.toString());
// SLOT_DATA 参数添加完毕
```

**1.1 到1.3同在线**

**1.4 加载离线资源**

```
asr.send(SpeechConstant.ASR_KWS_LOAD_ENGINE,new
JSONObject(map).toString());
```

//加载离线引擎，使用离线命令词时使用，请在整个离线识别任务结束之后卸载离线引擎

> *详见ActivityMiniRecog类中”基于SDK离线命令词1.4 加载离线资源(离线时使用)"*

//离线引擎加载完毕事件后，开始你的识别流程，此处开始你的识别流程，注意离线必须断网生效或者SDK无法连接百度服务器时生效，只能识别bsg文件里定义的短语。

**2.1-4.2 步骤同在线**

**5.1 卸载离线资源**

//不再需要识别功能后，卸载离线引擎。再次需要识别功能的话，可以重复以上步骤。即依旧需要EventManager初始化之后，识别事件之前加载离线引擎。

```
asr.send(SpeechConstant.ASR_KWS_UNLOAD_ENGINE, null, null, 0, 0);
```

> *详见ActivityMiniRecog类中”基于SDK集成5.1 卸载离线资源步骤(离线时使用)"*

在demo中，

```
HashMap&lt;String, Object&gt; map = new HashMap&lt;String, Object&gt;();
map.put(SpeechConstant.DECODER, 2); 
// 0:在线 2.离在线融合(在线优先)
map.put(SpeechConstant.ASR_OFFLINE_ENGINE_GRAMMER_FILE_PATH, "/sdcard/yourpath/baidu_speech_grammar.bsg"); 
//设置离线命令词文件路径
```

// 下面这段可选，用于生成SLOT_DATA参数， 用于动态覆盖ASR_OFFLINE_ENGINE_GRAMMER_FILE_PATH文件的词条部分

```
JSONObject json = new JSONObject();
json.put("name", new
JSONArray().put("王自强").put("叶问")).put("appname", new
JSONArray().put("手百").put("度秘"));
map.put(SpeechConstant.SLOT_DATA, json.toString());
// SLOT_DATA 参数添加完毕
myRecognizer.loadOfflineEngine(map);
//加载离线引擎，使用离线命令词时使用，请在整个离线识别任务结束之后卸载离线引擎 
```

> *详见ActivityAbstractRecog类中”基于DEMO集成1.4 加载离线资源步骤(离线时使用)"*

//离线引擎加载完毕事件后，开始你的识别流程，注意离线必须断网生效或者SDK无法连接百度服务器时生效，只能识别bsg文件里定义的短语。

//不再需要识别功能后，卸载离线引擎。再次需要识别功能的话，可以重复以上步骤, 新建MyRecognizer类即可。

```
myRecognizer.release();
```

> *详见ActivityAbstractRecog类中”基于DEMO5.1 卸载离线资源(离线时使用)"*

## 唤醒词功能

SDK 的调用过程可以参见DEMO中的ActivityMiniWakeUp类

DEMO的调用过程可以参考DEMO中的ActivityWakeUp类

**1** **初始化**

**1.1** **初始化EventManager对象**

SDK中，通过工厂创建语音唤醒词的事件管理器。注意唤醒词事件管理器同识别事件管理器一样只能维持一个，请勿同时使用多个实例。即创建一个新的唤醒词事件管理器后，之前的那个设置为null。并不再使用。

```
EventManager wp= EventManagerFactory.create(this,"wp");
 //this是Activity或其它Context类
```

> *详见ActivityMiniWakeUp类中”基于SDK唤醒词集成1.1 初始化EventManager"*

**1.2** **自定义输出事件类**

DEMO中，初始化过程合并到下一步。注意SDK和DEMO调用方式2选1即可。 注册用户自己实现的输出事件类

```
EventListener yourListener = new EventListener() {
@Override
public void onEvent(String name, String params, byte [] data, int
offset, int length) {
Log.d(TAG, String.format("event: name=%s, params=%s", name, params));
//唤醒事件
if(name.equals("wp.data")){
try {
JSONObject json = new JSONObject(params);
int errorCode = json.getInt("errorCode");
if(errorCode == 0){
//唤醒成功
   } else {
//唤醒失败
   }
 } catch (JSONException e) {
     e.printStackTrace();
   }
  } else if("wp.exit".equals(name)){
//唤醒已停止
  }
 }
}；
```

> *详见ActivityMiniWakeUp类中”基于SDK唤醒词集成1.2 自定义输出事件类"*

**1.3** **注册自己的输出事件类**

```
wp.registerListener(yourListener);
```

> *详见ActivityMiniWakeUp类中”基于SDK唤醒词集成1.3 注册输出事件"*

DEMO中，以上两步合并为

```
IWakeupListener listener = new SimpleWakeupListener();
myWakeup = new MyWakeup(this,listener);
// this是Activity或其它Context类
```

> *详见ActivityWakeUp类中”基于DEMO唤醒词集成第1.1, 1.2, 1.3步骤"*

**2** **开始唤醒**

**2.1** **设置唤醒输入参数**

SDK中，您需要根据文档或者demo确定您的输入参数。DEMO中有UI界面简化选择和测试过程。demo中，在点击“开始”按钮后，您可以在界面或者日志中看见WAKEUP_START事件的json格式的参数。

wakeup.params(反馈请带上此行日志):{"kws-file":"assets:\/\/\/WakeUp.bin"} // 其中{"kws-file":"assets:\/\/\/WakeUp.bin"}为WAKEUP_START事件的参数

```
HashMap map = new HashMap();
map.put(SpeechConstant.WP_WORDS_FILE, "assets://WakeUp.bin");
```

> *详见ActivityMiniWakeUp类中”基于SDK唤醒词集成第2.1 设置唤醒的输入参数"* 唤醒词文件请去http://ai.baidu.com/tech/speech/wake#tech-demo设置并下载

**2.2** **发送start开始事件**

```
wp.send(SpeechConstantWAKEUP_START, json, null, 0, 0);
```

> *详见ActivityMiniWakeUp类中”基于SDK唤醒词集成第2.2 发送开始事件开始唤醒"*

DEMO中， 您需要传递Map 的参数，会将Map自动序列化为json

```
HashMap<String,Object> params = new
HashMap<String,Object>();
params.put(SpeechConstant.WP_WORDS_FILE, "assets://WakeUp.bin");
myWakeup.start(params);
```

> *详见ActivityWakeUp类中”基于DEMO唤醒词集成第2.1, 2.2 发送开始事件开始唤醒"*

**3** **收到回调事件**

**3.1** **开始回调事件**

SDK中，回调事件在您实现的EventListener中获取。OnEvent中， name是输出事件名，params该事件的参数，(data,offset, length)三者一起组成额外数据。如回调的音频数据，从data[offset]开始至data[offset + length] 结束，长度为length。

```
public void onEvent(String name, String params, byte [] data, int offset, int length);
```

> *详见ActivityMiniWakeUp类中”基于SDK唤醒3.1 开始回调事件"*

DEMO中， 回调事件在您实现的IWakeupListener中获取。

> *详见WakeupEventAdapter类中”基于DEMO唤醒3.1 开始回调事件"*

**4** **控制唤醒**

SDK中，

**4.1** **控制停止唤醒**

```
wp.send(SpeechConstant.WAKEUP_STOP, null, null, 0, 0);
```

> *详见ActivityMiniWakeUp类中”基于SDK唤醒词集成第4.1 发送停止事件"*

DEMO中，

```
myWakeup.stop();
```

> *详见ActivityWakeUp类中”基于DEMO唤醒词集成第4.1 发送停止事件"*

**5** **事件管理器退出**

SDK中无需调用任何逻辑，但需要创建一个新的唤醒词事件管理器的话，之前的事件管理器请设置为null，并不再使用。

DEMO中，

```
myWakeup.release();
```

> *详见ActivityWakeUp类中”基于DEMO唤醒词集成第5 退出事件管理器"*

# SDK 功能简介及参数设置

语音识别Android SDK 功能 主要分为语音识别 及 语义理解与对话管理

1. 语音识别： 将录音转为文字。目前在线识别支持普通话、英文、粤语和四川话。
2. 语义理解与对话管理： 提取语音识别出的文字的意图与关键信息，并做出回应。

如果需要了解更多详细参数及其功能，请参见本文后段。

**音频格式要求:**

默认为麦克风输入，可以设置参数为**pcm**格式**16k**采样率，**16bit，小端序，单声道**的音频流输入。

## 语音识别

语音识别，可以分为在线识别，离线命令词，及唤醒词

1. 在线识别： 即联网使用的识别功能。
2. 离线命令词： 断网时激活，只能识别预定义的短语。联网时，强制使用在线识别。固定短语的语法需要从控制台“离线词&本地语义”模块预定义并下载为baidu_speech_grammar.bsg文件
3. 唤醒词： 本地功能，不需要网络。唤醒词即识别“关键词”，当SDK的识别引擎“听到”录音中的关键词后，立即告知用户。与android系统的锁屏唤醒完全无关。关键词和离线命令词一样，需要预定义并下载为WakeUp.bin文件

**目前没有公开版本的离线任意语句识别及声纹识别**

### 在线识别

在线是指手机联网时(2G 3G 4G wifi)，

在线识别，可以分为：

1. 在线普通识别： 流式识别出识别用户输入的录音音频流，支持普通话、英文、粤语和四川话。限制60s时长。
2. 在线长语音识别： 在线普通识别的基础上，没有60s时长的限制。 在线识别可以测试DEMO中的第一个按钮“在线识别”。

在线识别的三种模型：

1. 远场模型：针对离麦克风较远的音频输入。
2. 搜索模型： 适合短语输入，模型及识别效果类似手机百度，中文搜索模型同时也能识别常用 英语。
3. 输入法模型： 适合长句输入，模型及识别效果类似百度输入法。

**支持自定义词库**

设置方法：

登录百度云-管理中心“管理应用”“选择应用”“语音识别词库设置”右侧“进行设置”；

设置效果：

1. 可以自定义识别词，提升准确率。
2. 仅在搜索、输入法模型下生效。
3. 自定义词库适合短句，保证词库中一模一样的短句可以被识别出。
4. 词库中的分词优先级较高。

**举例** 词库定义了1个短句 :1 .“摆渡船来了”百度内部处理的可能的分词结果：摆渡船来 了。

以下录音的结果

1. 原始音频：摆渡船来了 =》识别结果： 摆渡船来了 【保证结果】
2. 原始音频：摆渡船来了么 =》识别结果： 百度传来了么 【可能结果，不保证】
3. 原始音频：摆渡船来 =》 识别结果： 百度传来 【可能结果，不保证】
4. 原始音频：百度传来了喜讯 =》 识别结果： 摆渡船传来了喜讯 ， 【不保证，词库内的分词优先级高】

最好在1万行以内。

副作用：如果用户的测试集中包含大量非自定义词表的query，整体上准确率下降。

### 在线识别具体功能参数

#### 设置语言、模型、自定义词库、语义

**描述:PID参数决定了语言，模型，及是否支持自定义词库和在线语义解析。**

1. 语言共有4种：中文普通话、英语、粤语及四川话。
2. 输入法模型/搜索模型/远场模型：分别适用于长句输入/短句输入/离麦克风较远的音频输入。
3. 在搜索、输入法模型下自定义词库生效。
4. 只有普通话，搜索或者远场模型，才可以开启在线语义解析。(下节描述)

DEMO中测试方法：(具体可参见识别安卓SDK测试文档)

demo测试：点击 在线识别=>设置=>PID,语种

请求示例： 英语 输入法模型

```
{"pid":1737,"accept-audio-volume":false}
```

#### 长语音

**描述:**开启长语音识别功能，此时VAD参数不能设为touch；长语音可以识别数小时的音频。注意选输入法模型。

**VAD_ENDPOINT_TIMEOUT = 0开启长语音**

DEMO中测试方法：(具体可参见识别安卓SDK测试文档)

demo测试：点击 在线识别=>设置=>长语音及VAD时长设置

请求参数示例： 开启长语音，不能与VAD=touch联用

```
{"accept-audio-volume":false,"vad.endpoint-timeout":0}
```

#### 设置静音时长进行断句

**描述：**普通识别的录音限制60s。连续xxxms静音后，SDK认为一句话结束。**VAD_ENDPOINT_TIMEOUT> 0**，作用是静音断句的时长设置，值建议800ms-3000ms可以调节此参数。使用长语音功能时不能使用这个参数。

**VAD_ENDPOINT_TIMEOUT > 0设置静音时长**

DEMO中测试方法：(具体可参见识别安卓SDK测试文档)

demo测试：点击 在线识别=>设置=>长语音及VAD时长设置

请求示例： 连续800ms静音，表示一句话结束

```
{"accept-audio-volume":false,"vad.endpoint-timeout":800}
```

#### 开启/关闭根据静音时长切分句子

**描述：默认开启根据静音时长切分句子。通过设置VAD参数的值，当设置VAD=dnn**时，表示开启VAD，此时通过设置的静音时长进行断句；开启长语音功能时，VAD必然是开启的状态；当设置**VAD=touch**时，表示关闭VAD，不能使用长语音功能，限制录音时长60s，在60s内的只能点击停止按钮通过发送停止事件才能停止识别。

DEMO中测试方法：(具体可参见识别安卓SDK测试文档)

demo测试：点击 在线识别=>设置=>VAD是否开启dnn或touch

请求示例： 开启VAD，根据静音时长切分句子

```
{"accept-audio-volume":false,"vad":"dnn"}
```

请求示例： 关闭VAD，60s内音频，SDK等待调用stop事件结束录音

```
{"accept-audio-volume":false,"vad":"touch"}
```

### 离线命令词

离线命令词，联网时，强制使用在线识别，在断网时或在线请求超时时，使用离线命令词功能。离线命令词功能不支持任意语句的识别，只能识别预定义的固定短语。

**离线命令词的bsg文件设置：**

在语音控制台的左侧功能栏中，进入“离线词&语义设置”模块，根据页面上的引导自行定义词条和语法，并生成bsg文件。其中右侧“说法”部分，为固定语法，下载后不可更改。左侧“词条”部分，代码中可以动态定义覆盖。 ![img](http://agroup-bos.su.bcebos.com/9e92b00e8fe701852c89046802729ec8ec80880d)

离线命令词功能可以测试DEMO中的第二个按钮“离线命令词识别”

### 离线命令词常用功能参数设置

#### 设置纯在线或离在线融合模式

**描述：**设置纯在线功能和离在线融合识别

**DECODER 参数**

- DECODER = 0 ，表示禁用离线功能，只使用在线功能；
- DECODER = 2 ，表示启用离线功能，但是SDK强制在线优先。

DEMO中测试方法：(具体可参见识别安卓SDK测试文档)

demo测试：点击 离线命令词功能=>开始

请求示例：DECODET=2，表示断网时，使用离线识别固定短语；

```
{"accept-audio-volume":false,”decoder”:2}
```

#### 设定离线命令词文件路径

**描述：离线命令词只能识别bsg文件中预定义的固定短语，其中bsg文件必须在项目中设定路径，参数ASR_OFFLINE_ENGINE_GRAMMER_FILE_PATH**作用就是定义离线命令词识别的bsg文件路径;该参数需要在ASR_KWS_LOAD_ENGINE加载离线资源输入事件中初始化；

**ASR_OFFLINE_ENGINE_GRAMMER_FILE_PATH设置bsg文件路径**

DEMO中测试方法：(具体可参见识别安卓SDK测试文档)

demo测试：点击 离线命令词功能

请求示例：定义assets目录下的离线命令词文件

```
{"accept-audio-data":false,"grammar":"assets:\/\/\/baidu_speech_grammar.bsg","decoder":2}
```

- 扩展离线命令词的词条部分

**描述：离线命令词bsg文件的左侧词条部分内容可通过SLOT_DATA**参数进行动态覆盖，覆盖后原先的bsg文件中的左侧词条部分失效。和ASR_OFFLINE_ENGINE_GRAMMER_FILE_PATH一起使用。

- SLOT_DATA扩展词条

DEMO中测试方法：(具体可参见识别安卓SDK测试文档)

demo测试：点击全部识别=>设置=>纯在线或在线+离线命令词=>离线命令词及在线识别混合                                                       =>离线命令词及本地语义                                                       =>扩展词条

请求示例：动态修改离线命令词的词条部分

```
{"accept-audio-data":false,"grammar":"asset:\/\/\/baidu_speech_grammar.bsg","decoder":2, "slot-data":{"name":\["妈妈","老伍"\],"appname":\["手百","度秘”"\]}}
```

## 语义

语义包括理解与对话管理，可用于提取语音识别出的文字的意图与关键信息，并做出回应。目前,百度语音识别技术已和百度NLP实现了流程打通。NLP部分由百度语义理解与对话管理平台[UNIT](http://unit.baidu.com/)提供。语音识别Android SDK提供了3种对接语义的方式：

在线语义：

- 百度UNIT： 对话理解与交互技术平台，开发者可根据业务需要定制对话系统，也可以直接使用UNIT预置的对话能力。
- 通用场景语义解析： 基于百度UNIT搭建的常见场景的语义理解（不含对话管理能力）。

本地语义：

- 在任意网络下都可使用，android sdk内部根据设置的bsg文件的定义进行离线命令词语义解析。

### 语义参数设置

### 在线语义

### 百度UNIT

[UNIT](http://unit.baidu.com/)是百度最专业的语义理解和对话管理平台，为开发者预置可一键式接入的语义理解和对话管理服务，方便快捷的满足语义理解和对话管理需求。 如果需要更多的定制语义服务，可先在UNIT上进行语义解析的配置，配置说明点击这里（http://ai.baidu.com/docs#/UNIT-v2-guide/top）。

使用流程如下：1.登录[UNIT](http://unit.baidu.com/)；2.训练一个技能；3.拿到技能"bot_id":"xx"；4.通过语音SDK配置对应PID（15364，15374，19364）及参数进行调用。

UNIT支持单bot和多bot的接入，接入参数如下：

- 单bot接入就是发送一个bot_id，示例：

```
{"bot_session_list":"[{\"bot_id\":\"5\",\"bot_session_id\":\"\"}]}"
```

- 多bot接入就是发送多个bot_id,示例：

```
{"bot_session_list":"[{\"bot_id\":\"5\",\"bot_session_id\":\"\"},{\"bot_id\":\"6\",\"bot_session_id\":\"\"},\"bot_id\":\"1006\",\"bot_session_id\":\"\"}]}"
```

- 返回结果：

```
{
    "errno":"0",
    "error_msg":"ok",
    "bot_session_list":"[{\"bot_id\":\"xx\",\"bot_session_id\":\"xxx\"},{\"bot_id\":\"xx\",\"bot_session_id\":\"xxx\"}"}]",
    "unit_response":[
        ...
    ],
}
```

- 请求参数说明

| 字段                              | 是否必选 | 类型           | 备注                                                         |
| :-------------------------------- | :------- | :------------- | :----------------------------------------------------------- |
| bot_session_list                  | 是       | string（json） | 至少有1个元素                                                |
| bot_session_list[].bot_id         | 是       | string         | 当前账号在UNIT平台的创建的技能的ID                           |
| bot_session_list[].bot_session_id | 是       | string         | 技能的session信息，由系统自动生成，client从上轮resonpse中取出并直接传递。如果为空，则表示清空session（开发者判断用户意图已经切换且下一轮会话不需要继承上一轮会话中的词槽信息时可以把bot_session_id置空，从而进行新一轮的会话） |

- 响应参数说明

| 字段                                | 是否必选 | 类型           | 备注                                                         |
| :---------------------------------- | :------- | :------------- | :----------------------------------------------------------- |
| errno                               | 是       | int            | 0 是正常，非0为异常                                          |
| error_msg                           | 是       | string         | 错误信息，errno！=0时存在，具体错误码参考本文档UNIT错误码    |
| bot_session_list                    | 是       | string(json)   |                                                              |
| `bot_session_list[].bot_id`         | 是       | string         | bot_id                                                       |
| `bot_session_list[].bot_session_id` | 是       | string         |                                                              |
| unit_response                       | 是       | `List<Object>` |                                                              |
| unit_response[i]                    | 是       | Object         | [格式参考](https://ai.baidu.com/docs#/UNIT-v2-API/a9b22016/)UNIT响应参数里的response字段 |

- 更多UNIT问题可通过QQ群：805312106咨询沟通。

### 通用场景语义解析

描述: **PID**仅普通话并且选搜索或远场模型才可以开启在线语义；在线条件下，会将识别的文本进行解析，找出文本的意图

DEMO中测试方法：(具体可参见识别安卓SDK测试文档)

demo测试：点击 在线和本地语义=>设置=>PID,语种

请求示例： 普通话 搜索模型

{"pid":15363,"accept-audio-volume":false}

### 本地语义

描述：必须设置ASR_OFFLINE_ENGINE_GRAMMER_FILE_PATH参数生效，无论网络状况，都可以有本地语义结果。并且本地语义结果会覆盖在线语义结果。

**NLU= enable**表示开启本地语义

DEMO中测试方法：(具体可参见识别安卓SDK测试文档)

Demo测试：在线和本地语义=>设置=>本地语义解析enable                                                            =>本地语义文件                                                            =>扩展词条

请求示例：设置本地语义的bsg文件路径，例如在asset目录下；

```
{"accept-audio-data":false,"grammar":"assets:\/\/\/baidu_speech_grammar.bsg",”pid”:”1536”, "slot-data":{"name":\["妈妈","老伍"\],"appname":\["手百","度秘”"\]},”nlu”:”enable”}
```

- 设置本地语义文件路径

**描述：使用本地语义需要设置bsg文件的路径，本地语义共用离线命令词的参数和文件。使用本地语义功能的时候，不需要作为ASR_KWS_LOAD_ENGINE的输入参数。但是需要作为ASR_START事件的输入参数。使用ASR_OFFLINE_ENGINE_GRAMMER_FILE_PATH**参数是设置bsg文件路径。

**ASR_OFFLINE_ENGINE_GRAMMER_FILE_PATH**参数设置bsg文件路径。

DEMO中测试方法：(具体可参见识别安卓SDK测试文档)

Demo测试：在线和本地语义=>设置=>本地语义文件

请求示例：设置本地语义的bsg文件路径，例如在asset目录下；

```
{"accept-audio-data":false,"grammar":"assets:\/\/\/baidu_speech_grammar.bsg",”pid”:”1536”,”nlu”:”enable”}
```

- 扩展本地语义文件的词条部分内容

描述：bsg文件的左侧词条部分内容可通过**SLOT_DATA**参数进行动态覆盖，覆盖后原先的bsg文件中的左侧词条部分失效。和ASR_OFFLINE_ENGINE_GRAMMER_FILE_PATH一起使用。

**SLOT_DATA**参数动态覆盖bsg文件词条内容

DEMO中测试方法：(具体可参见识别安卓SDK测试文档)

Demo测试：在线和本地语义设置本地语义文件, 扩展词条

请求示例：动态覆盖bsg文件左侧词条内容

```
{"accept-audio-data":false,"grammar":"assets:\/\/\/baidu_speech_grammar.bsg",”pid”:”1536”, "slot-data":{"name":\["妈妈","老伍"\],"appname":\["手百","度秘”"\]},”nlu”:”enable”}
```

## 唤醒词

唤醒词： 唤醒词即识别预定义的“关键词”。与在线长语音识别不同，长语音识别会返回所有识别结果，唤醒词只会识别出您预先定义的关键词。与android本身的锁屏唤醒没有任何关系。

唤醒词是本地功能，正常使用时无需联网。 在**http://ai.baidu.com/tech/speech/wake**页面下方可以自行定义bin文件。百度语音提供了近15个预定义唤醒词，效果有优化。也可以自定义唤醒词，效果不如预定义唤醒词。bin文件中最多可以有10个唤醒词，其中自定义唤醒词不超过3个，并且2个字的预定义唤醒词不超过3个。

**进行唤醒词操作前必须要有相对静音**。

### 正式授权

唤醒词和离线命令词功能需要一个正式授权文件。正式授权由SDK内部管理，无对外接口。正式授权文件在第一次联网使用SDK识别功能下载，比如第一次在线联网使用唤醒词功能或第一次在线识别后，SDK自动下载正式授权文件。正式授权文件有效期为应用新建后的35个月，SDK一旦发现正式授权文件失效，会尝试更新授权文件。

注意，appId appKey appSecret包名（applicationId）4个必须完全正确，才能自动下载正式授权文件。

### 唤醒词常用功能参数设置

#### 设置唤醒词文件路径

**描述：唤醒词功能是本地功能使用时无需联网，只能唤醒bin文件中预定义的关键词，bin文件需要使用WP_WORDS_FILE**设置路径，支持android asset目录（如assets:///wakeUp.bin)；

**WP_WORDS_FILE设置bin文件路径**

DEMO中测试方法：(具体可参见识别安卓SDK测试文档)

demo测试：精简版唤醒

请求示例：使用唤醒功能加载唤醒词bin文件；

```
{"kws-file":"assets:\/\/\/WakeUp.bin","accept-audio-volume":false}
```

### 通用录音设置

下面2个参数设置识别和唤醒都可以使用；

#### 引入外部音频文件

描述：SDK默认麦克风的音频输入，可以改为用户自定义的音频文件或者自定义的音频流。**IN_FILE**该参数可以引入音频文件进行识别，适用于对于音频输入有定制化的情况。音频格式为pcm，16000采样率，16bit，单声道，小端序；

**IN_FILE引入外部音频文件(识别和唤醒都可使用)**

DEMO中测试方法：(具体可参见识别安卓SDK测试文档)

demo测试：点击 在线识别=>设置=>外部音频=>16k_test.pcm,16k采样的测试音频

请求示例： 使用本地音频文件16k_test.pcm识别

```
{"accept-audio-volume":false,"infile":"res:\/\/\/com\/baidu\/android\/voicedemo\/16k_test.pcm"}
```

#### 保存录音文件

描述：SDK在识别的同时，可以把识别的音频保存下来，比如用于复现。**OUT_FILE**该参数可以保存录音文件。该参数需要设置ACCEPT_AUDIO_DATA参数；反馈问题时，请先使用该参数保存音频文件，使用上面的IN_FILE参数复现。

**OUT_FILE 保存录音文件**

DEMO中测试方法：(具体可参见识别安卓SDK测试文档)

demo测试：点击 在线识别设置保存音频开启音频回调。

请求示例：保存音频到 /storage/emulated/0/baiduASR/outfile.pcm

```
{"accept-audio-data":true,"accept-audio-volume":false,"outfile":"\/storage\/emulated\/0\/baiduASR\/outfile.pcm"}
```

# 识别输入和输出参数

## 输入参数

场景：

- 在线识别：百度语音服务器将录音识别出文字，包括长语音
- 离线命令词：离线识别出预定义的固定短语
- 在线语义：百度语音服务器将录音识别出文字，并将服务器端的语义解析结果一起返回
- 本地语义：在识别出文字的基础上（包括离线命令词识别）， 对文字做语义分析。任意网络状况。

使用网络状况：

- 在线 ： 涵盖在线识别，在线语义及在线识别后的本地语义解析。
- 离线 ： 涵盖离线命令词，及离线命令词识别后的本地语义解析。

共支持4个语种 ，语种请在 ASR_START输入事件中的PID参数中设置

- 中文普通话 （全部场景）
- 中文四川话（离线命令词及语义不支持）
- 粤语（离线命令词及语义不支持）
- 英语（离线命令词及语义不支持）

### 识别输入事件

以下参数均为SpeechConstant类的常量，如SpeechConstant.ASR_START

| 事件名                 | 类型                       | 值                                             | 场景       | 描述                                                         |
| :--------------------- | :------------------------- | :--------------------------------------------- | :--------- | :----------------------------------------------------------- |
| ASR_START              | String (JSON结构的字符串） | json内的参数 见下文 “ASR_START 参数”           | 全部       | 开始一次识别。 注意不要连续调用ASR_START参数。下次调用需要在CALLBACK_EVENT_ASR_EXIT回调后，或者在ASR_CANCEL输入后。 |
| ASR_STOP               |                            |                                                | 全部       | 停止录音                                                     |
| ASR_CANCEL             |                            |                                                | 全部       | 取消本次识别                                                 |
| ASR_KWS_ LOAD_ENGINE   | String (JSON结构的字符串） | json内的参数 见下文 “ASR_KWS_LOAD_ENGINE 参数” |            | 离线命令词                                                   |
| ASR_KWS_ UNLOAD_ENGINE |                            |                                                | 离线命令词 | 高级                                                         |

### ASR_START 输入事件参数

| 事件参数                                | 类型/值                               | 场景       | 常用程度 | 描述                                                         |
| :-------------------------------------- | :------------------------------------ | :--------- | :------- | :----------------------------------------------------------- |
| PID                                     | int                                   | 在线       | 常用     | 根据识别语种，搜索或输入法模型及是否需要在线语义，来选择PID。默认1536，即中文搜索模型，不带在线语义。PID具体值及说明见下一个表格。 其中输入法模型是指适用于长句的输入法模型，可以带有标点符号，但没有在线语义；搜索模型适用于短语，没有标点符号，但可以使用在线语义和本地语义；如输入法模型开启标点符号时，没有本地语义；此外远场模型是指离麦克风较远的音频输入，可以有在线语义和本地语义 |
| DECODER                                 | int                                   | 全部       | 常用     | 离在线的并行策略                                             |
|                                         | 0 （默认）                            | 在线       |          | 纯在线(默认)                                                 |
|                                         | 2                                     | 离线       |          | 离在线融合(在线优先)，离线命令词功能需要开启这个选项。       |
| VAD                                     | String                                | 全部       | 高级     | 语音活动检测， 根据静音时长自动断句。注意不开启长语音的情况下，SDK只能录制60s音频。静音时长及长语音请设置VAD_ENDPOINT_TIMEOUT参数 |
|                                         | VAD_DNN（默认）                       |            | 高级     | 新一代VAD，各方面信息优秀，推荐使用。                        |
|                                         | VAD_TOUCH                             |            | 高级     | 关闭语音活动检测。注意关闭后不要开启长语音。适合用户自行控制音频结束，如按住说话松手停止的场景。功能等同于60s限制的长语音。需要手动调用ASR_STOP停止录音 |
| VAD_ENDPOINT _TIMEOUT                   | int                                   | 全部       | 高级     | 静音超时断句及长语音                                         |
|                                         | 0                                     | 在线       | 常用     | 开启长语音。即无静音超时断句。手动调用ASR_STOP停止录音。 请勿和VAD=touch联用！ |
|                                         | >0（毫秒），默认800ms                 | 在线       | 高级     | 不开启长语音。开启VAD尾点检测，即静音判断的毫秒数。建议设置800ms-3000ms |
| IN_FILE                                 | String：文件路径 资源路径或回调方法名 | 全部       | 高级     | 该参数支持设置为：文件系统路径，如：/sdcard/test/test.pcm； java资源路径，如：res:///com/baidu.test/16k_test.pcm；录音文件不要超过3分钟 数据源方法全名，格式如：”#com.test.Factory.create16KInputStream()”（解释：Factory类中存在一个返回InputStream的方法create16kInputStream()），注意：必须以井号开始；方法原型必须为：public static InputStream yourMethod()。 超过3分钟的录音文件，请在每次read中sleep，避免SDK内部缓冲不够。 |
| OUT_FILE                                | String ：文件路径                     | 全部       | 高级     | 保存识别过程产生的录音文件, 该参数需要开启ACCEPT_AUDIO_DATA后生效 |
| AUDIO_MILLS                             | int：毫秒                             | 全部       | 高级     | 录音开始的时间点。用于唤醒+识别连续说。SDK有15s的录音缓存。如设置为(System.currentTimeMillis() - 1500),表示回溯1.5s的音频。 |
| NLU                                     | String                                | 本地语义   | 高级     | 本地语义解析设置。必须设置ASR_OFFLINE_ENGINE_GRAMMER_FILE_PATH参数生效，无论网络状况，都可以有本地语义结果。并且本地语义结果会覆盖在线语义结果。本参数不控制在线语义输出，需要在线语义输出见PID参数 |
|                                         | disable（默认）                       |            | 高级     | 禁用                                                         |
|                                         | enable                                |            | 高级     | 启用                                                         |
|                                         | enable-all                            |            | 不常用   | 在enable的基础上，临时结果也会做本地语义解析                 |
| ASR_OFFLINE_ ENGINE_GRAMMER _FILE_PATH  | String：文件路径 支持assets路径       | 本地语义   | 高级     | 用于支持本地语义解析的bsg文件，离线和在线都可使用。NLU开启生效，其它说明见NLU参数。注意bsg文件同时也用于ASR_KWS_LOAD_ENGINE离线命令词功能。 |
| SLOT_DATA                               | String（JSON格式）                    | 本地语义   | 高级     | 与ASR_OFFLINE_ENGINE_GRAMMER_FILE_PATH参数一起使用后生效。 用于代码中动态扩展本地语义bsg文件的词条部分（bsg文件下载页面的左侧表格部分），具体格式参见代码示例或者demo |
| DISABLE_PUNCTUATION                     | boolean                               | 在线       | 高级     | 在选择PID为长句（输入法模式）的时候，是否禁用标点符号        |
|                                         | true                                  |            |          | 禁用标点                                                     |
|                                         | false（默认）                         |            |          | 不禁用标点，无法使用本地语义                                 |
| ACCEPT_AUDIO _DATA                      | boolean                               | 全部       | 高级     | 是否需要语音音频数据回调，开启后有CALLBACK_EVENT_ASR_AUDIO事件 |
|                                         | true                                  |            |          | 需要音频数据回调                                             |
|                                         | false （默认）                        |            |          | 不需要音频数据回调                                           |
| ACCEPT_AUDIO _VOLUME                    | boolean                               | 全部       | 高级     | 是否需要语音音量数据回调，开启后有CALLBACK_EVENT_ASR_VOLUME事件回调 |
|                                         | true （默认）                         |            |          | 需要音量数据回调                                             |
|                                         | false                                 |            |          | 不需要音量数据回调                                           |
| SOUND_START                             | int：资源ID                           | 全部       | 不常用   | 说话开始的提示音                                             |
| SOUND_END                               | int：资源ID                           | 全部       | 不常用   | 说话结束的提示音                                             |
| SOUND_SUCCESS                           | int：资源ID                           | 全部       | 不常用   | 识别成功的提示音                                             |
| SOUND_ERROR                             | int：资源ID                           | 全部       | 不常用   | 识别出错的提示音                                             |
| SOUND_CANCEL                            | int：资源ID                           | 全部       | 不常用   | 识别取消的提示音                                             |
| APP_ID                                  | String                                | 全部       | 基本不用 | 开放平台创建应用后分配，填写后会覆盖 androidManifest.xml中定义的 |
| APP_KEY                                 | String                                | 全部       | 基本不用 | 开放平台创建应用后分配，填写后会覆盖 androidManifest.xml中定义的 |
| SECRET                                  | String                                | 全部       | 基本不用 | 开放平台创建应用后分配，填写后会覆盖 androidManifest.xml中定义的 |
| SAMPLE_RATE                             | int                                   | 全部       | 基本不用 | 采样率 ，固定及默认值16000                                   |
|                                         | 16000（默认）                         |            |          |                                                              |
|                                         |                                       |            |          |                                                              |
| ASR_OFFLINE _ENGINE _LICENSE _FILE_PATH | String ：文件路径 ， 支持assets路径   | 离线命令词 | 基本不用 | 临时授权文件路径。SDK在联网时会获取自动获取离线正式授权。有特殊原因可用在官网创建应用时下载通用临时授权文件。临时授权文件测试期仅有15天，不推荐使用。 使用正式授权时请确认官网应用设置的包名与APP自身的包名相一致。目前离线命令词和唤醒词功能需要使用正式授权。 |

### ASR_KWS_LOAD_ENGINE 输入事件参数

| 事件参数                               | 类型   | 值                        | 场景     | 常用程度 | 描述                                                         |
| :------------------------------------- | :----- | :------------------------ | :------- | :------- | :----------------------------------------------------------- |
| SLOT_DATA                              | String | JSON格式                  | 本地语义 | 高级     | 与ASR_OFFLINE_ENGINE_GRAMMER_FILE_PATH参数一起使用后生效。 用于代码中动态扩展离线命令词bsg文件的词条部分（bsg文件下载页面的左侧表格部分），具体格式参见代码示例或者demo |
| DECODER                                | int    | 2                         |          |          | 固定值：2，离在线的并行策略                                  |
| ASR_OFFLINE_ ENGINE_GRAMMER _FILE_PATH | String | 文件路径， 支持assets路径 |          |          | 用于支持离线命令词（同时也是本地语义）解析的bsg文件，离线断网时可以使用。NLU开启生效，其它说明见NLU参数。注意bsg文件同时也用于ASR_KWS_LOAD_ENGINE离线命令词功能。  语义解析设置，在线使用时，会在识别结果的文本基础上同时输出语义解析的结果（该功能需要在官网的应用里设置“语义解析设置”）。 |

### PID 参数

在线参数， 请根据语言， 输入法或者搜索模型及是否需要在线语义，来选择PID。

- 语言：目前支持中文普通话，四川话，粤语，和英语四个
- 输入法模型：适用于较长的句子输入。默认有标点，不支持在线语义; 开启标点后，不支持本地语义。
- 搜索模型：适用于较短的句子输入。无标点，支持在线语义和本地语义。
- 在线语义：在线语义只支持普通话（本地语义也是只支持普通话）。在线语义详细说明请查看“语义理解协议”文档。

| PID   | 语言   | 模型       | 是否有标点                           | 在线语义             | 备注    |
| :---- | :----- | :--------- | :----------------------------------- | :------------------- | :------ |
| 1536  | 普通话 | 搜索模型   | 无标点                               | 不支持               | 默认PID |
| 15362 | 普通话 | 搜索模型   | 加强标点（逗号、句号、问号、感叹号） | 不支持               |         |
| 15363 | 普通话 | 搜索模型   | 加强标点（逗号、句号、问号、感叹号） | 支持通用场景语义解析 |         |
| 15364 | 普通话 | 搜索模型   | 加强标点（逗号、句号、问号、感叹号） | 支持百度UNIT         |         |
| 1537  | 普通话 | 输入法模型 | 有标点（逗号）                       | 不支持               |         |
| 15372 | 普通话 | 输入法模型 | 加强标点（逗号、句号、问号、感叹号） | 不支持               |         |
| 15373 | 普通话 | 输入法模型 | 加强标点（逗号、句号、问号、感叹号） | 支持通用场景语义解析 |         |
| 15374 | 普通话 | 输入法模型 | 加强标点（逗号、句号、问号、感叹号） | 支持百度UNIT         |         |
| 1737  | 英语   |            | 无标点                               | 不支持               |         |
| 17372 | 英语   |            | 加强标点（逗号、句号、问号）         | 不支持               |         |
| 1637  | 粤语   |            | 有标点（逗号）                       | 不支持               |         |
| 16372 | 粤语   |            | 加强标点（逗号、句号、问号、感叹号） | 不支持               |         |
| 1837  | 四川话 |            | 有标点（逗号）                       | 不支持               |         |
| 1936  | 普通话 | 远场模型   | 有标点（逗号）                       | 不支持               |         |
| 19362 | 普通话 | 远场模型   | 加强标点（逗号、句号、问号、感叹号） | 不支持               |         |
| 19363 | 普通话 | 远场模型   | 加强标点（逗号、句号、问号、感叹号） | 支持通用场景语义解析 |         |
| 19364 | 普通话 | 远场模型   | 加强标点（逗号、句号、问号、感叹号） | 支持百度UNIT         |         |

## 输出参数

语音回调事件统一由 public void onEvent(String name, String params, byte[] data, int offset, int length) 该方法回调。其中name是回调事件， params是回调参数。（data，offset，length）缓存临时数据，三者一起，生效部分为 data[offset] 开始，长度为length。

| 事件名（name）                   | 事件参数                    | 类型              | 值             | 描述                                                         |
| :------------------------------- | :-------------------------- | :---------------- | :------------- | :----------------------------------------------------------- |
| CALLBACK_EVENT _ASR_READY        |                             |                   |                | 引擎准备就绪，可以开始说话                                   |
| CALLBACK_EVENT _ASR_BEGIN        |                             |                   |                | 检测到说话开始                                               |
| CALLBACK_EVENT _ASR_END          |                             |                   |                | 检测到说话结束                                               |
| CALLBACK_EVENT _ASR_PARTIAL      | params                      | json              |                | 识别结果                                                     |
|                                  | params[results_recognition] | String[]          |                | 解析后的识别结果。如无特殊情况，请取第一个结果               |
|                                  | params[result_type]         | String            | partial_result | **临时识别结果**                                             |
|                                  | params[result_type]         | String            | final_result   | **最终结果**，长语音每一句都有一个最终结果                   |
|                                  | params[result_type]         | String            | nlu_result     | 语义结果，在final_result后回调。语义结果的内容在(data，offset，length中） |
|                                  | (data，offset，length）     | String            |                | 语义结果的内容 ，当 params[result_type]=nlu_result时出现。   |
| CALLBACK_EVENT _ASR_FINISH       | params                      | String(json格式） |                | 识别结束（可能含有错误信息） 。最终识别的文字结果在ASR_PARTIAL事件 中 |
|                                  | params[error]               | int               |                | 错误领域                                                     |
|                                  | params[sub_error]           | int               |                | 错误码                                                       |
|                                  | params[desc]                | String            |                | 错误描述                                                     |
| CALLBACK_EVENT _ASR_LONG _SPEECH |                             |                   |                | 长语音额外的回调，表示长语音识别结束                         |
| CALLBACK_EVENT _ASR_EXIT         |                             |                   |                | 识别结束，资源释放                                           |
| CALLBACK_EVENT _ASR_AUDIO        | (data，offset，length)      | byte[]            |                | PCM音频片段 回调。必须输入ACCEPT_AUDIO_DATA 参数激活         |
| CALLBACK_EVENT _ASR_VOLUME       | params                      | json              |                | 当前音量回调。必须输入ACCEPT_AUDIO_VOLUME参数激活            |
|                                  | params[volume]              | float             |                | 当前音量                                                     |
|                                  | params[volume-percent]      | int               |                | 当前音量的相对值（0-100）                                    |
| CALLBACK_EVENT _ASR_LOADED       |                             |                   |                | 离线模型加载成功回调                                         |
| CALLBACK_EVENT _ASR_UNLOADED     |                             |                   |                | 离线模型卸载成功回调                                         |

# 唤醒词输入和输出参数

## 输入参数

以下参数均为SpeechConstant类的常量，如SpeechConstant.WAKEUP_START

| 事件名       | 类型             | 值                                    | 描述           |
| :----------- | :--------------- | :------------------------------------ | :------------- |
| WAKEUP_START | json格式的字符串 | json内的参数见下文“WAKEUP_START 参数” | 开始识别唤醒词 |
| WAKEUP_STOP  |                  |                                       | 停止识别唤醒词 |

### WAKEUP_START 输入事件参数

| 事件参数                    | 类型    | 常用程度 | 描述                                                         |
| :-------------------------- | :------ | :------- | :----------------------------------------------------------- |
| WP_WORDS_FILE               | String  | 常用     | 唤醒词bin文件路径，支持android asset目录（如assets:///wakeUp.bin) |
| IN_FILE                     | String  | 高级     | 该参数支持设置为：文件系统路径，如：/sdcard/test/test.pcm； java资源路径，如：res:///com/baidu.test/16k_test.pcm； 数据源方法全名，格式如：”#com.test.Factory.create16KInputStream()”（解释：Factory类中存在一个返回InputStream的方法create16kInputStream()），注意：必须以井号开始；方法原型必须为：public static InputStream yourMethod()。 录音文件不要超过3分钟 |
| ACCEPT_AUDIO _DATA          | boolean | 基本不用 | 默认关闭。开启后，会有音频回调（CALLBACK_EVENT_WAKEUP_AUDIO），很占资源 |
| WP_ENGINE_LICENSE_FILE_PATH | string  | 基本不用 | 不填写，在联网时会获取自动获取离线正式授权。有特殊原因可用在官网下载临时授权文件，配置此参数，支持android asset目录（如assets:///mylicense.dat) |
| SAMPLE_RATE                 | int     | 基本不用 | 16000（默认值，且唤醒仅支持16k采样）                         |

## 输出参数

语音回调事件统一由 public void onEvent(String name, String params, byte[] data, int offset, int length) 方法回调 其中name是回调事件， params是回调参数。（data，offset，length）缓存临时数据，三者一起，生效部分为 data[offset] 开始，长度为length。

| 事件名                         | 事件参数             | 类型             | 描述                                                         |
| :----------------------------- | :------------------- | :--------------- | :----------------------------------------------------------- |
| CALLBACK_EVENT _WAKEUP_STARTED |                      |                  | 引擎开始运行                                                 |
| CALLBACK_EVENT _WAKEUP_AUDIO   | (data,offset,length) | byte[]           | PCM音频片段回调，需要输入ACCEPT_AUDIO_DATA参数激活 。保存的pcm文件的采样率是16000，16bits，单声道，小端序。 |
| CALLBACK_EVENT _WAKEUP_SUCCESS |                      |                  | 唤醒成功                                                     |
|                                | errorCode            |                  | 错误码,错误码为0表示唤醒成功，唤醒出错会在CALLBACK_EVENT_WAKEUP_ERROR 事件中 |
|                                | errorDesc            |                  | 错误描述,此处固定为 success                                  |
|                                | word                 | String           | 具体的唤醒词                                                 |
| CALLBACK_EVENT _WAKEUP_ERROR   | params               | String(json格式) | 错误描述的回调                                               |
|                                | params[error]        | int              | 错误码                                                       |
|                                | params[desc]         | int              | 错误描述                                                     |

| CALLBACK_EVENT
_WAKEUP_STOPED | | | 唤醒已关闭



# 集成指南

1. DEMO 中已经集成了 SDK。您可以参考DEMO，集成SDK。
2. 集成前，请先测通DEMO，了解调用原理。
3. 如果您自己代码过于复杂，可以使用一个helloworld项目了解集成过程。
4. DEMO目录下的doc_integration_DOCUMENT的目录中有图文集成教程。

本文以Android Studio 2.3.3作为示例

集成时请确认已经复制或者修改了一下文件，一共4步：

1. AndroidManifest.xml
2. app/libs/bdasr_V3_xxxxx_xxxxx.jar
3. app/src/main/jniLibs 下armeabi等5个目录
4. 官网申请应用时的包名与build.gradle里一致，demo的包名是"com.baidu.speech.recognizerdemo"。这步没做会导致离线命令词或者唤醒报“no licence” 错误
5. 运行时 getApplicationInfo().nativeLibraryDir 目录下查看是否有完整so文件。 特别是**系统app**需要手动push so文件到这个目录下。

## AndroidManifest.xml 文件

### 设置权限

```
<uses-permission android:name="android.permission.RECORD_AUDIO" />
<uses-permission android:name="android.permission.ACCESS_NETWORK_STATE" />
<uses-permission android:name="android.permission.INTERNET" />
<uses-permission android:name="android.permission.READ_PHONE_STATE" />
<uses-permission android:name="android.permission.WRITE_EXTERNAL_STORAGE" />
```

### 设置APP_ID, APP_KEY, APP_SECRET

```
    <meta-data android:name="com.baidu.speech.APP_ID"
        android:value="9788136" />
    <meta-data
        android:name="com.baidu.speech.API_KEY"
        android:value="0GjQNO5H4pGPf9HyA3AmZEbz" />
    <meta-data
        android:name="com.baidu.speech.SECRET_KEY"
        android:value="db981ef3ec647ba8a09b599ad7447a24" />
```

### 设置识别Service

```
<service android:name="com.baidu.speech.VoiceRecognitionService" android:exported="false" />
```

## android 6.0 以上版本权限申请

以下代码可以在demo中查找

```
/**
 * android 6.0 以上需要动态申请权限
 */
private void initPermission() {
    String permissions[] = {Manifest.permission.RECORD_AUDIO,
            Manifest.permission.ACCESS_NETWORK_STATE,
            Manifest.permission.INTERNET,
            Manifest.permission.READ_PHONE_STATE,
            Manifest.permission.WRITE_EXTERNAL_STORAGE
    };

    ArrayList<String> toApplyList = new ArrayList<String>();

    for (String perm :permissions){
        if (PackageManager.PERMISSION_GRANTED != ContextCompat.checkSelfPermission(this, perm)) {
            toApplyList.add(perm);
            //进入到这里代表没有权限.

        }
    }
    String tmpList[] = new String[toApplyList.size()];
    if (!toApplyList.isEmpty()){
        ActivityCompat.requestPermissions(this, toApplyList.toArray(tmpList), 123);
    }

}

@Override
public void onRequestPermissionsResult(int requestCode, String[] permissions, int[] grantResults) {
    // 此处为android 6.0以上动态授权的回调，用户自行实现。
```

## bdasr_V3_xxxxxxxx_xxxx.jar 库

将app/libs/bdasr_V3_xxxxx_xxxxx.jar 复制到您的项目的同名目录中。

## 复制NDK 架构目录

1. 将 app/src/main/jniLibs 下armeabi等5个目录，复制到您的项目的同名目录中。
2. 如与第三方库集成，至少要保留armeabi目录。如第三方库有7个架构目录，比语音识别SDK多出2个目录 mips和mips64，请将mips和mips64目录删除，剩下5个同名目录合并。
3. 如第三方库仅有armeabi这一个目录，请将语音识别SDK的额外4个目录如armeabi-v7a删除,合并armeabi目录下的so。 即目录取交集，so文件不可随意更改所属目录。
4. 打包成apk文件，按照zip格式解压出libs目录可以验证。
5. 运行时 getApplicationInfo().nativeLibraryDir 目录下查看是否有完整so文件。 特别是**系统app**需要手动push so文件到这个目录下。

## build.gradle 文件及包名确认

1. 根目录下build.gradle确认下gradle的版本。
2. app/build.gradle 确认下 applicationId 包名是否与官网申请应用时相一致（离线功能需要）。 demo的包名是"com.baidu.speech.recognizerdemo"。
3. 确认 compileSdkVersion buildToolsVersion 及 targetSdkVersion

## proguard文件

```
-keep class com.baidu.speech.**{*;}
```

## BEST PRACTICE

- 请先测通DEMO，了解DEMO的功能，**代码的运行原理**后再集成。DEMO有bug，请立即反馈。
- 对应任何第三方库，从一开始集成，边开发边测试，不要等所有功能都开发完再集成。否则一旦有问题，难以隔离排查。
- 有问题先与DEMO做对比。DEMO有bug，请查看错误码文档，如无法解决请立即反馈；DEMO无bug，自身代码有问题，请设置同样的输入参数后，对比两边代码及日志，自行排查问题。

# 错误码

错误码分为两类错误，错误领域和错误码，其中错误领域的值可以用于交互，错误码仅用于调试，可能会有修改。 错误码仅提示错误，缩小排查的范围， **不能确认具体出错原因**。开发时请对照集成指南文档及demo。

## 识别错误码

| 错误领域 | 描述           | 错误码 | 错误描述及可能原因                                           |
| :------- | :------------- | :----- | :----------------------------------------------------------- |
| 1        | 网络超时       |        | 出现原因可能为网络已经连接但质量比较差，建议检测网络状态     |
|          |                | 1000   | DNS连接超时                                                  |
|          |                | 1001   | 网络连接超时                                                 |
|          |                | 1002   | 网络读取超时                                                 |
|          |                | 1003   | 上行网络连接超时                                             |
|          |                | 1004   | 上行网络读取超时                                             |
|          |                | 1005   | 下行网络连接超时                                             |
|          |                | 1006   | 下行网络读取超时                                             |
| 2        | 网络连接失败   |        | 出现原因可能是网络权限被禁用，或网络确实未连接，需要开启网络或检测无法联网的原因 |
|          |                | 2000   | 网络连接失败                                                 |
|          |                | 2001   | 网络读取失败                                                 |
|          |                | 2002   | 上行网络连接失败                                             |
|          |                | 2003   | 上行网络读取失败                                             |
|          |                | 2004   | 下行网络连接失败                                             |
|          |                | 2005   | 下行网络读取失败                                             |
|          |                | 2006   | 下行数据异常                                                 |
|          |                | 2100   | 本地网络不可用                                               |
| 3        | 音频错误       |        | 出现原因可能为：未声明录音权限，或 被安全软件限制，或 录音设备被占用，需要开发者检测权限声明。 |
|          |                | 3001   | 录音机打开失败                                               |
|          |                | 3002   | 录音机参数错误                                               |
|          |                | 3003   | 录音机不可用                                                 |
|          |                | 3006   | 录音机读取失败                                               |
|          |                | 3007   | 录音机关闭失败                                               |
|          |                | 3008   | 文件打开失败                                                 |
|          |                | 3009   | 文件读取失败                                                 |
|          |                | 3010   | 文件关闭失败                                                 |
|          |                | 3100   | VAD异常，通常是VAD资源设置不正确                             |
|          |                | 3101   | 长时间未检测到人说话，请重新识别                             |
|          |                | 3102   | 检测到人说话，但语音过短                                     |
| 4        | 协议错误       |        | 出现原因可能是appid和appkey的鉴权失败                        |
|          |                | 4001   | 协议出错                                                     |
|          |                | 4002   | 协议出错                                                     |
|          |                | 4003   | 识别出错                                                     |
|          |                | 4004   | 鉴权错误 ，一般情况是pid appkey secretkey不正确              |
| 5        | 客户端调用错误 |        | 一般是开发阶段的调用错误，需要开发者检测调用逻辑或对照文档和demo进行修复。 |
|          |                | 5001   | 无法加载so库                                                 |
|          |                | 5002   | 识别参数有误                                                 |
|          |                | 5003   | 获取token失败                                                |
|          |                | 5004   | 客户端DNS解析失败                                            |
|          |                | 5005   |                                                              |
| 6        | 超时           |        | 语音过长，请配合语音识别的使用场景，如避开嘈杂的环境等       |
|          |                | 6001   | 未开启长语音时，当输入语音超过60s时，会报此错误              |
| 7        | 没有识别结果   |        | 信噪比差，请配合语音识别的使用场景，如避开嘈杂的环境等       |
|          |                | 7001   | 没有匹配的识别结果。当检测到语音结束，或手动结束时，服务端收到的音频数据质量有问题，导致没有识别结果 |
| 8        | 引擎忙         |        | 一般是开发阶段的调用错误，出现原因是上一个会话尚未结束，就让SDK开始下一次识别。SDK目前只支持单任务运行，即便创建多个实例，也只能有一个实例处于工作状态 |
|          |                | 8001   | 识别引擎繁忙 。当识别正在进行时，再次启动识别，会报busy。    |
| 9        | 缺少权限       |        | 参见demo中的权限设置                                         |
|          |                | 9001   | 没有录音权限 通常是没有配置录音权限：android.permission.RECORD_AUDIO |
| 10       | 其它错误       |        | 出现原因如：使用离线识别但未将EASR.so集成到程序中；离线授权的参数填写不正确；参数设置错误等。 |
|          |                | 10001  | 离线引擎异常                                                 |
|          |                | 10002  | 没有授权文件                                                 |
|          |                | 10003  | 授权文件不可用                                               |
|          |                | 10004  | 离线参数设置错误                                             |
|          |                | 10005  | 引擎没有被初始化                                             |
|          |                | 10006  | 模型文件不可用                                               |
|          |                | 10007  | 语法文件不可用                                               |
|          |                | 10008  | 引擎重置失败                                                 |
|          |                | 10009  | 引擎初始化失败                                               |
|          |                | 10010  | 引擎释放失败                                                 |
|          |                | 10011  | 引擎不支持                                                   |
|          |                | 10012  | 离线引擎识别失败 。离线识别引擎只能识别grammar文件中约定好的固定的话术，即使支持的话术，识别率也不如在线。请确保说的话清晰，是grammar中文件定义的，测试成功一次后，可以保存录音，便于测试。 |

## 常见识别错误信息

**no value for appid** SDK 读不到appId, 如 AndroidManifest.xml中没有填写appId

## 唤醒错误码

| 错误领域 | 描述                       | 错误码 | 错误描述         |
| :------- | :------------------------- | :----- | :--------------- |
| 10       | 录音设备出错               |        |                  |
|          |                            | 1      | 录音设备异常     |
|          |                            | 2      | 无录音权限       |
|          |                            | 3      | 录音设备不可用   |
|          |                            | 4      | 录音中断         |
| 11       | 唤醒相关错误               |        |                  |
|          | 没有授权文件               | 11002  |                  |
|          | 授权文件不可用             | 11003  |                  |
|          | 唤醒异常, 通常是唤醒词异常 | 11004  |                  |
|          | 模型文件不可用             | 11005  |                  |
|          | 引擎初始化失败             | 11006  |                  |
|          | 内存分配失败               | 11007  |                  |
|          | 引擎重置失败               | 11008  |                  |
|          | 引擎释放失败               | 11009  |                  |
|          | 引擎不支持该架构           | 11010  |                  |
| 38       | 引擎出错                   |        |                  |
|          |                            | 1      | 唤醒引擎异常     |
|          |                            | 2      | 无授权文件       |
|          |                            | 3      | 授权文件异常     |
|          |                            | 4      | 唤醒异常         |
|          |                            | 5      | 模型文件异常     |
|          |                            | 6      | 引擎初始化失败   |
|          |                            | 7      | 内存分配失败     |
|          |                            | 8      | 引擎重置失败     |
|          |                            | 9      | 引擎释放失败     |
|          |                            | 10     | 引擎不支持该架构 |
|          |                            | 11     | 无识别数据       |

## UNIT错误码

[点击查看](http://ai.baidu.com/docs#/UNIT-v2-API/4466adcf)

## **demo 及 SDK反馈**

1. SDK及DEMO BUG反馈格式：
2. 现象描述 调用我们的xxx方法之后，报错。
3. 输入参数：（DEMO中含有“反馈”两个字的日志）
4. 输出结果：
5. 音频文件: 通过OUT_FILE参数获取录音音频；
6. 用户日志:先清空日志,之后调用我们的某个方法结束。请提供给我们之中的完整日志。
7. 手机信息： 手机型号， android版本号等信息



