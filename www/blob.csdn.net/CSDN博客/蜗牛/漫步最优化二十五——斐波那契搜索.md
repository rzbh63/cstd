
# 漫步最优化二十五——斐波那契搜索 - 蜗牛 - CSDN博客


2017年10月19日 20:12:31[会敲键盘的猩猩](https://me.csdn.net/u010182633)阅读数：277



$\textbf{白天与黑夜，}$
$\textbf{希望陪你共同走过。}$
$\textbf{整夜的美梦，}$
$\textbf{希望抱你一起回味。}$
$\textbf{即便我是铁石心肠，}$
$\textbf{那也抵不过你一声哥哥，}$
$\textbf{抵不过你钻进我的胸膛。}$
$\textbf{你就是我口中的一块糖，}$
$\textbf{只想对你说：}$
$\textbf{I LOVE YOU}$
$\quad\textbf{——畅宝宝的傻逼哥哥}$
考虑不确定区间

$$
I_k=[x_{L,k,x_{U,k}}]
$$
并且假设两点$x_{a,k},x_{b,k}$均位于$I_k$中，如图1所示，对于$f(x)$在点$x_{a,k},x_{b,k}$处的值$f(x_{a,k}),f(x_{b,k})$，如果$f(x_{a,k})<f(x_{b,k})$，那么我们选择左区间

$$
I_{k+1}^{L}=[x_{L,k},x_{b,k}]
$$
如果$f(x_{a,k})>f(x_{b,k})$，那么我们选择右区间

$$
I_{k+1}^{R}=[x_{a,k},x_{U,k}]
$$
如果

$$
f(x_a,k)=f(x_b,k)
$$
那么可以选择$I_{k+1}^R,I_{k+1}^L$中的任何一个。如果右区间$I_{k+1}^R$被选中，那么它将包含最小值，另外还知道点$x_{b,k}$处的函数值。如果我们知道点$x_{b,k+1}$处的值，那么我们就有充分的信息来进一步减小不确定区域，然后不断重复此过程。这种方法每次迭代只需要估计一个函数值，计算量相对于二分搜索要小。
根据图1可知

$$
I_k=I_{k+1}^{L}+I_{k+2}^{R}
$$
为了方便，我们假设区间相等，那么

$$
\begin{align*}
I_{k+1}^L=I_{k+1}^R=I_{k+1}\\
I_{k+2}^L=I_{k+2}^R=I_{k+2}
\end{align*}
$$
由此可得

$$
I_k=I_{k+1}+I_{k+2}
$$
如果上面的过程重复多次，那么我们会得到如下的区间序列$\{I_1,I_2,\ldots,I_n\}$:

$$
\begin{align*}
I_1&=I_2+I_3\\
I_2&=I_3+I_4\\
&\vdots\\
I_n&=I_{n+1}+I_{n+2}
\end{align*}
$$

![这里写图片描述](https://img-blog.csdn.net/20171019193347594?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMDE4MjYzMw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)[ ](https://img-blog.csdn.net/20171019193347594?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMDE4MjYzMw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
图1
上面的$n$个等式中，有$n+2$个变量，如果$I_1$是给定的初始区间，那么有$n+1$个变量。所以给定的规则不同，就会生成不同的序列，我们这里讨论两个特殊的序列：斐波那契序列与黄金分割序列。本篇博文先介绍前者，下一篇介绍后者。
假设$n+2$次迭代后区间消失，即$I_{n+2}=0$，那么我们就得到斐波那契序列，如果我们令$k=n$，可以得到

$$
\begin{align*}
I_{n+1}&=I_n-I_{n+2}=I_n\equiv F_0I_n\\
I_{n}&=I_{n+1}+I_{n+2}=I_n\equiv F_1I_n\\
I_{n-1}&=I_n+I_{n+1}=2I_n\equiv F_2I_n\\
I_{n-2}&=I_{n-1}+I_{n}=3I_n\equiv F_3I_n\\
I_{n-3}&=I_{n-2}+I_{n-1}=5I_n\equiv F_4I_n\\
I_{n-4}&=I_{n-3}+I_{n-2}=8I_n\equiv F_5I_n\\
&\vdots\\
I_{k}&=I_{k+1}+I_{k+2}=F_{n-k+1}I_n\\
&\vdots\\
I_{1}&=I_{2}+I_{3}=F_nI_n
\end{align*}
$$
所生成的序列

$$
\{1,1,2,3,5,8,13,\ldots\}=\{F_0,F_1,F_2,F_3,F_4,F_5,F_6,\ldots\}
$$
就是著名的斐波那契数列，它可以由递归关系

$$
F_k=F_{k-1}+F_{k_2}\quad for\ k\geq 2
$$
得出，其中$F_0=F_1=1$。将其应用到一维优化上就得到斐波那契搜索法，当$n=6,I_1=100$时，该方法得出的结果如图2所示。
如果迭代的总数为$n$，那么斐波那契搜索将不确定区间缩小到

$$
I_n=\frac{I_1}{F_n}
$$
例如如果$n=11$，那么$F_n=144$，这样的话$I_n$将缩小到不足$I_1$的1\%，其中会有11次迭代。因为每次迭代只需要一个函数估计值，所以一共需要11个函数估计值，如果二分搜索要达到同样的精度需要14个函数估计值，故斐波那契搜索比二分搜索效率更高。事实上，相对于其他几个搜索方法，从计算效率上看它是最高效的。
如果$n$是已知的，那么我们可以得到唯一的斐波那契区间序列。如果我们的目标是在给定的误差下找到$x^*$，那么可以求出所需的$n$。然而，如果我们的目标是最小化$f(x)$，没有等式求出所需的$n$，唯一知道的信息是在解的邻域内，$f(x)$越平滑，$n$值越小，$f(x)$变化越快，$n$值越大。
我们可以用上面的原则来实现斐波那契搜索。我们假设最小值的初始边界为$x_{L,1},x_{U,1}$，并且$n$值已经给定，$f(x)$的数学形式也是已知的，那么要实现的内容就是计算区间，估计$f(x)$并选择合适的区间。

![这里写图片描述](https://img-blog.csdn.net/20171019195743411?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMDE4MjYzMw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)[ ](https://img-blog.csdn.net/20171019195743411?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMDE4MjYzMw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
图2
在$k$次迭代后，$x_{L,k},x_{a,k},x_{b,k},x_{U,k},I_{k+1},f_{a,k}=f(x_{a,k}),f_{b,k}=f(x_{b,k})$是已知的，我们需要求$x_{L,k+1},x_{a,k+1},x_{b,k+1},x_{U,k+1},I_{k+2},f_{a,k+1},f_{b,k+1}$，区间$I_{k+2}$通过下式获得

$$
I_{k+2}=\frac{F_{n-k-1}}{F_{n-k}}I_{k+1}
$$
然后依次进行。
如果$f_{a,k}>f_{b,k}$，那么$x^*$位于区间$[x_{a,k},x_{U,k}]$中，所以$x^*$的新边界更新为

$$
\begin{align*}
x_{L,k+1}=x_{a,k}\\
x_{U,k+1}=x_{U,k}
\end{align*}
$$
同样的，新区间的两个内点$x_{a,k+1},x_{b,k+1}$将会是$x_{b,k},x_{L,k+1}+I_{k+2}$，因此我们令

$$
\begin{align*}
x_{a,k+1}=x_{b,k}\\
x_{b,k+1}=x_{L,k+1}+I_{k+2}
\end{align*}
$$
如图3所示，$f_{b,k}$的值作为$f(x)$在点$x_{a,k+1}$处的值，$f(x)$在点$x_{b,k+1}$处计算如下：

$$
\begin{align*}
f_{a,k+1}=f_{b,k}\\
f_{b,k+1}=f(x_{b,k+1})
\end{align*}
$$

![这里写图片描述](https://img-blog.csdn.net/20171019195853143?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMDE4MjYzMw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)[ ](https://img-blog.csdn.net/20171019195853143?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMDE4MjYzMw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
图3
另一方面，如果$f_{a,k}<f_{b,k}$，那么$x^*$在区间$[x_{L,k},x_{b,k}]$中，这时候

$$
\begin{align*}
x_{L,k+1}&=x_{L,k}\\
x_{U,k+1}&=x_{b,k}\\
x_{a,k+1}&=x_{U,k+1}-I_{k+2}\\
x_{b,k+1}&=x_{a,k}\\
f_{b,k+1}&=f_{a,k}
\end{align*}
$$
并且计算

$$
f_{a,k+1}=f(x_{a,k+1})
$$
如图4所示。对于$f_{a,k}=f_{b,k}$，上面两种情况均可以，因为$x^*$同时包含在$[x_{L,k},x_{b,k}],[x_{a,k},x_{U,k}]$。

![这里写图片描述](https://img-blog.csdn.net/20171019195934780?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMDE4MjYzMw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)[ ](https://img-blog.csdn.net/20171019195934780?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMDE4MjYzMw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
图4
上面的过程重复执行，直到$k=n-2$，此时

$$
I_{k+2}=I_n
$$
且

$$
x^*=x_{a,k+1}=x_{b,k+1}
$$
如图5所示。显然，可以确定最小值在容忍误差$\pm1/F_n$范围内。
如果$n$足够大，那噩梦$x_{a,k},x_{b,k}$的差将会非常小，由于舍入误差，$x_{a,k}$可能超过$x_{b,k}$，如果这种情况发生的话，我们将会得到不可靠的结果。对于这样的应用，为了消除这个问题，我们需要加入一下检查措施，一种方法是终止算法，这是因为如果$x_{a,k}\approx x_{b,k}$，那么我们已经达到了足够高的精度。

![这里写图片描述](https://img-blog.csdn.net/20171019200010039?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMDE4MjYzMw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)[ ](https://img-blog.csdn.net/20171019200010039?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMDE4MjYzMw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
图5

[
						](https://img-blog.csdn.net/20171019200010039?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMDE4MjYzMw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
[
	](https://img-blog.csdn.net/20171019200010039?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMDE4MjYzMw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
