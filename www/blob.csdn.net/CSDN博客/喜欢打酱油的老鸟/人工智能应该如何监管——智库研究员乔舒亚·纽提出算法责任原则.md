
# 人工智能应该如何监管——智库研究员乔舒亚·纽提出算法责任原则 - 喜欢打酱油的老鸟 - CSDN博客


2019年04月12日 08:32:32[喜欢打酱油的老鸟](https://me.csdn.net/weixin_42137700)阅读数：66标签：[监管人工智能技术																](https://so.csdn.net/so/search/s.do?q=监管人工智能技术&t=blog)个人分类：[人工智能																](https://blog.csdn.net/weixin_42137700/article/category/7820233)


[https://www.toutiao.com/a6657037535337775623/](https://www.toutiao.com/a6657037535337775623/)
因为人工智能技术的巨大潜力，以及它可能给人类带来的巨大影响，现在，不少人都在呼吁，在发展人工智能技术的同时，也要对人工智能技术采取一些监管措施，以此来防止它的负面影响。
但是，在智库研究员乔舒亚·纽看来，这些监管措施可能是错的。乔舒亚是智库机构数据创新中心（Center for Data Innovation）的高级政策研究分析师。财富中文网发表了他的看法。
![人工智能应该如何监管——智库研究员乔舒亚·纽提出算法责任原则](http://p3.pstatp.com/large/pgc-image/a96e26d9f24d4c96ba15abffa69cd5dc)
乔舒亚分析了几种流行的监管策略。
**首先是透明性原则。**透明性原则要求人工智能技术公司公开自己的源代码，以便让包括监管机构和媒体在内的人可以查看这些代码，防止损害公共利益的技术。乔舒亚说，以人工智能技术的复杂性，这样做起到的监督效果不一定好，反而会使得竞争对手更容易偷走这些技术，损害开发者的利益。
**其次是可解释性原则。**可解释性原则指的是，技术开发者需要能够向终端用户解释他们的算法，或者只使用那些能够解释清楚决策机制的算法。欧盟就把算法可解释性作为评估人工智能技术风险的一个主要指标。欧盟的《通用数据保护条例》（GDPR）规定，一个自然人有权获得关于算法决策机制的“有意义的信息”。
在乔舒亚看来，这项原则虽然看似合理，但很难用在人工智能领域。因为，一个算法越复杂，它的准确性就越高；但是越复杂，也就意味着它越难以解释清楚。而在一些重要的人工智能技术领域，比如自动驾驶，如果要为了可解释性牺牲技术的准确性，结果就是灾难性的。
最后一个流行的策略是，**建立一个类似于食品药品监督管理局这样的人工智能监管机构。**特斯拉CEO埃隆·马斯克就是这个策略的支持者。但是，乔舒亚认为，人工智能技术不可一概而论，它的危险性其实主要取决于技术的应用场景。不能仅仅因为某个低风险的产品使用了算法，就对它监管。这样会限制公司使用人工智能技术的能力和意愿。
既然这三种策略都不合理，怎么做才是合理的呢？乔舒亚提出了一个方法：**算法责任原则**。根据算法责任原则，公司需要验证自己的人工智能系统是不是按照设计意图运行的，能不能防范有害结果。这样做的好处是，它不要求公司公布源代码；不需要解释算法的决策机制，从而减缓技术进步；而且，它可以把监管责任分散到各行业的监管机构手里。
以上就是一位智库研究人员对如何监管人工智能技术的看法。

