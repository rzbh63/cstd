
# 高斯分布 - 蜗牛 - CSDN博客


2015年05月13日 16:06:18[会敲键盘的猩猩](https://me.csdn.net/u010182633)阅读数：7145


# 数据挖掘中的高斯分布
高斯分布，无论是单变量还是多元变量，在统计数据挖掘中是非常有用的，包括一些底层数据假设是高度非高斯的数据挖掘模型。我们需要好好了解多元高斯。
## 为什么我们应该关注它
高斯像橘子汁和阳光一样是自然存在的
我们需要它来理解贝叶斯最优分类器
我们需要它来理解回归
我们需要它来理解神经网络
我们需要它来理解混合模型
……
## PDF（概率密度函数）的熵
![这里写图片描述](https://img-blog.csdn.net/20150513024426322)[ ](https://img-blog.csdn.net/20150513024426322)
分布的熵越大，预测就越困难，压缩就越困难，分布就有越少的尖。
例1、“盒子”分布
![这里写图片描述](https://img-blog.csdn.net/20150513024957717)[ ](https://img-blog.csdn.net/20150513024957717)
例2、单位方差“盒子”分布
![这里写图片描述](https://img-blog.csdn.net/20150513025256930)[ ](https://img-blog.csdn.net/20150513025256930)
例3、“尖帽”分布
![这里写图片描述](https://img-blog.csdn.net/20150513025400609)[ ](https://img-blog.csdn.net/20150513025400609)
单位方差“尖帽”分布
![这里写图片描述](https://img-blog.csdn.net/20150513025444102)[ ](https://img-blog.csdn.net/20150513025444102)
“2尖”分布
![这里写图片描述](https://img-blog.csdn.net/20150513025407704)[ ](https://img-blog.csdn.net/20150513025407704)
单位方差分布的熵：
![这里写图片描述](https://img-blog.csdn.net/20150513030109407)
## 单变量高斯分布
**单位方差高斯分布**
![这里写图片描述](https://img-blog.csdn.net/20150513030352302)
**普通高斯分布**
![这里写图片描述](https://img-blog.csdn.net/20150513030509351)[ ](https://img-blog.csdn.net/20150513030509351)
我们描述X ~ N(μ,σ2)，X是均值为μ方差为σ2的高斯分布，上图中, X ~ N(100,152)。
[
](https://img-blog.csdn.net/20150513030509351)**误差函数**：假设X ~ N(0,1)，ERF(x)等于X小于x的概率等于X的累积分布。
![这里写图片描述](https://img-blog.csdn.net/20150513031047372)[ ](https://img-blog.csdn.net/20150513031047372)
假设X ~ N(μ,σ2)，![这里写图片描述](https://img-blog.csdn.net/20150513031734499)[ ](https://img-blog.csdn.net/20150513031734499)
![这里写图片描述](https://img-blog.csdn.net/20150513031424881)
**中心极限定理**：如果(X1,X2,…Xn)是独立同分布的连续随机变量，那么定义![这里写图片描述](https://img-blog.csdn.net/20150513032105601)[，当n->∞时，p(z)->均值为E[Xi]，方差为Var[Xi]的高斯分布。](https://img-blog.csdn.net/20150513032105601)
**二维高斯分布**
![这里写图片描述](https://img-blog.csdn.net/20150513032753059)[，那么定义X~N(μ,Σ)的均值为：](https://img-blog.csdn.net/20150513032753059)![这里写图片描述](https://img-blog.csdn.net/20150513032720358)[，其中高斯参数是](https://img-blog.csdn.net/20150513032720358)![这里写图片描述](https://img-blog.csdn.net/20150513033000714)[，Σ是对称非负矩阵。可以证明E[X] = μ，Cov[X] = Σ（注意这是高斯分布的结果属性，不是定义）。 ](https://img-blog.csdn.net/20150513033000714)
估计p（x）：![这里写图片描述](https://img-blog.csdn.net/20150513110844996)
步骤一：选一个向量X
![这里写图片描述](https://img-blog.csdn.net/20150513110828364)
步骤二：定义δ = x - μ
![这里写图片描述](https://img-blog.csdn.net/20150513111128859)
步骤三：计算与椭圆相交的等高线数量，形式为Σ-1，D=sqrt(δTΣ-1δ)=x和μ的马氏距离
![这里写图片描述](https://img-blog.csdn.net/20150513111820731)
步骤四：定义w = exp(-D2/2)，在马氏距离的平方空间中，靠近μ的x有较大的权值，而远离的有较小的权值。
![这里写图片描述](https://img-blog.csdn.net/20150513123531347)
步骤五：![这里写图片描述](https://img-blog.csdn.net/20150513123702498)[乘以w确保](https://img-blog.csdn.net/20150513123702498)![这里写图片描述](https://img-blog.csdn.net/20150513123945770)[。 ](https://img-blog.csdn.net/20150513123945770)
例1：
![](https://img-blog.csdn.net/20150513130244220)[ ](https://img-blog.csdn.net/20150513130244220)
观察：均值，主轴，非对角线协方差的含义，p（x）的最大梯度区域
![](https://img-blog.csdn.net/20150513130616489)[ ](https://img-blog.csdn.net/20150513130616489)
例2：
![这里写图片描述](https://img-blog.csdn.net/20150513130921831)[ ](https://img-blog.csdn.net/20150513130921831)
![这里写图片描述](https://img-blog.csdn.net/20150513131127382)[ ](https://img-blog.csdn.net/20150513131127382)
例3：
![这里写图片描述](https://img-blog.csdn.net/20150513131340248)[ ](https://img-blog.csdn.net/20150513131340248)
![这里写图片描述](https://img-blog.csdn.net/20150513131408390)[ ](https://img-blog.csdn.net/20150513131408390)
在这个例子中，x和y几乎是独立的。
例4：
![这里写图片描述](https://img-blog.csdn.net/20150513131356765)[ ](https://img-blog.csdn.net/20150513131356765)
![这里写图片描述](https://img-blog.csdn.net/20150513131452567)[ ](https://img-blog.csdn.net/20150513131452567)
这个例子中，x和x+y明显是非独立的。
例5：
![这里写图片描述](https://img-blog.csdn.net/20150513131554764)[ ](https://img-blog.csdn.net/20150513131554764)
![这里写图片描述](https://img-blog.csdn.net/20150513131805714)[ ](https://img-blog.csdn.net/20150513131805714)
这个例子中，x和20x+y明显是非独立的。
[
](https://img-blog.csdn.net/20150513131805714)多元高斯分布
![这里写图片描述](https://img-blog.csdn.net/20150513132145066)[那么定义X ~ N(μ,Σ)的均值为： ](https://img-blog.csdn.net/20150513132145066)
![这里写图片描述](https://img-blog.csdn.net/20150513132236202)[ ](https://img-blog.csdn.net/20150513132236202)
其中高斯参数为：
![这里写图片描述](https://img-blog.csdn.net/20150513132329383)[ ](https://img-blog.csdn.net/20150513132329383)
Σ是一个非负矩阵。另外，E[X] = μ和Cov[X] = Σ。（注意他们是高斯的结果属性，不是定义）
[
](https://img-blog.csdn.net/20150513132329383)普通高斯分布
![这里写图片描述](https://img-blog.csdn.net/20150513132708155)
轴对齐高斯分布
![这里写图片描述](https://img-blog.csdn.net/20150513132912050)
球状高斯分布
![这里写图片描述](https://img-blog.csdn.net/20150513133340389)
退化的高斯分布
![这里写图片描述](https://img-blog.csdn.net/20150513133304756)[ ](https://img-blog.csdn.net/20150513133304756)
到目前为止，我们见到了高斯公式，对它的行为表现有个直观的认识，也了解了高斯协方差矩阵，接下来给一些高斯分布的技巧。
[
](https://img-blog.csdn.net/20150513133304756)变量子集
![这里写图片描述](https://img-blog.csdn.net/20150513133844103)[写作](https://img-blog.csdn.net/20150513133844103)![这里写图片描述](https://img-blog.csdn.net/20150513134118468)[其中](https://img-blog.csdn.net/20150513134118468)![这里写图片描述](https://img-blog.csdn.net/20150513134010512)[ ](https://img-blog.csdn.net/20150513134010512)
这将是我们将m维分布拆分成变量子集的标准符号。
[
](https://img-blog.csdn.net/20150513134010512)高斯边缘化依然是高斯分布
![这里写图片描述](https://img-blog.csdn.net/20150513134533217)[ ](https://img-blog.csdn.net/20150513134533217)
如果![这里写图片描述](https://img-blog.csdn.net/20150513134654103)[ ](https://img-blog.csdn.net/20150513134654103)
那么U依然是高斯分布（这个事实不是很明显）![这里写图片描述](https://img-blog.csdn.net/20150513134829450)[。](https://img-blog.csdn.net/20150513134829450)
线性变换后依然保持高斯分布
![这里写图片描述](https://img-blog.csdn.net/20150513135013188)[ ](https://img-blog.csdn.net/20150513135013188)
假设X是一个m维高斯随机变量X ~ N(μ,Σ)，定义Y是一个p维的随机变量（注意p≤m），因此Y = AX
其中A是一个p x m矩阵，那么Y ~ N(Aμ,AΣ AT )
两个独立的高斯相加依然是高斯分布
![这里写图片描述](https://img-blog.csdn.net/20150513135818364)[ ](https://img-blog.csdn.net/20150513135818364)
如果X ~ N(μ , Σ )，Y ~ N(μ , Σ )并且X ⊥ Y，那么
![这里写图片描述](https://img-blog.csdn.net/20150513140015286)[ ](https://img-blog.csdn.net/20150513140015286)
为什么X和Y不独立它就不成立呢？
下面两种说明那种对呢？
如果X和Y是非独立的，那么X+Y是高斯分布，但是协方差会改变；
如果X和Y是非独立的，那么X+Y可能是非高斯分布。
有条件的高斯是高斯分布
![这里写图片描述](https://img-blog.csdn.net/20150513141028043)[ ](https://img-blog.csdn.net/20150513141028043)
如果![这里写图片描述](https://img-blog.csdn.net/20150513140912021)[那么，](https://img-blog.csdn.net/20150513140912021)![这里写图片描述](https://img-blog.csdn.net/20150513141139382)[ ](https://img-blog.csdn.net/20150513141139382)
其中![这里写图片描述](https://img-blog.csdn.net/20150513141208476)[ ](https://img-blog.csdn.net/20150513141208476)
注意：当v的给定值是μv时，u的条件均值是μu；边缘均值是v的一个线性函数；条件方差真好等于或小于边缘方差；条件方差与v的给定值是无关的。
举例说明：
![这里写图片描述](https://img-blog.csdn.net/20150513141231920)[ ](https://img-blog.csdn.net/20150513141231920)
如果![这里写图片描述](https://img-blog.csdn.net/20150513141459280)[那么](https://img-blog.csdn.net/20150513141459280)![这里写图片描述](https://img-blog.csdn.net/20150513141532118)[，其中](https://img-blog.csdn.net/20150513141532118)![这里写图片描述](https://img-blog.csdn.net/20150513141418593)[ ](https://img-blog.csdn.net/20150513141418593)
![这里写图片描述](https://img-blog.csdn.net/20150513142438010)[ ](https://img-blog.csdn.net/20150513142438010)
同理m=82时
![这里写图片描述](https://img-blog.csdn.net/20150513142331536)[ ](https://img-blog.csdn.net/20150513142331536)
给出原高斯作对比
![这里写图片描述](https://img-blog.csdn.net/20150513142449988)
高斯和链式法则
![这里写图片描述](https://img-blog.csdn.net/20150513142749266)[ ](https://img-blog.csdn.net/20150513142749266)
让A是一个常数矩阵，如果![这里写图片描述](https://img-blog.csdn.net/20150513142711714)[那么](https://img-blog.csdn.net/20150513142711714)![这里写图片描述](https://img-blog.csdn.net/20150513142929107)[并且](https://img-blog.csdn.net/20150513142929107)![这里写图片描述](https://img-blog.csdn.net/20150513142804333)
[
](https://img-blog.csdn.net/20150513142929107)总结一下可用的高斯工具：
![这里写图片描述](https://img-blog.csdn.net/20150513142955296)
最后举一个例子。
假设有一个聪明的势利眼，且有一个孩子。整个世界中，IQ用一个高斯分布N(100,152)描绘![这里写图片描述](https://img-blog.csdn.net/20150513143527720)[ ](https://img-blog.csdn.net/20150513143527720)
另外有一个测试，是来侧IQ的分数，平均分是那个人的IQ。但是因为噪声的存在，所测的值可能比真实值IQ高或者低。
![这里写图片描述](https://img-blog.csdn.net/20150513143813514)[ ](https://img-blog.csdn.net/20150513143813514)
假设那个人非要拉着自己的孩子去做测试，孩子得到了130分，他惊喜他孩子的IQ是属于前2%。
![这里写图片描述](https://img-blog.csdn.net/20150513150034571)[ ](https://img-blog.csdn.net/20150513150034571)
某些人可能会想：这个测试肯定是不精确的，所以孩子的IQ可能是120或140，但是根据所给的结果，这个孩子很有可能是130。
[
](https://img-blog.csdn.net/20150513150034571)最大似然IQ
![这里写图片描述](https://img-blog.csdn.net/20150513150900794)[ ](https://img-blog.csdn.net/20150513150900794)
MLE是能使观测数据最有可能出现的隐藏参数的值。在本例中，![这里写图片描述](https://img-blog.csdn.net/20150513151243781)[ ](https://img-blog.csdn.net/20150513151243781)
但是这与给定观测值后最有可能的参数值不相同。
我们真正想要的是：
![这里写图片描述](https://img-blog.csdn.net/20150513151648031)[ ](https://img-blog.csdn.net/20150513151648031)
所求的是IQ的后验概率。
考虑上面说到的那么多高斯工具，我们打算这样计算：
![这里写图片描述](https://img-blog.csdn.net/20150513152136507)[ ](https://img-blog.csdn.net/20150513152136507)
如果在给定分数的情况下必须给出最有可能的IQ，那么
![这里写图片描述](https://img-blog.csdn.net/20150513152344299)[ ](https://img-blog.csdn.net/20150513152344299)
MAP是最大后验概率。
[
](https://img-blog.csdn.net/20150513152344299)to be continue……
[            ](https://img-blog.csdn.net/20150513152344299)

[
  ](https://img-blog.csdn.net/20150513152136507)