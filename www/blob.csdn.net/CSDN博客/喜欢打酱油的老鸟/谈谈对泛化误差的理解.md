
# 谈谈对泛化误差的理解 - 喜欢打酱油的老鸟 - CSDN博客


2018年08月17日 13:09:01[喜欢打酱油的老鸟](https://me.csdn.net/weixin_42137700)阅读数：214


# [https://blog.csdn.net/Cerisier/article/details/78122653](https://blog.csdn.net/Cerisier/article/details/78122653)

## 个人对泛化误差的看法

### 泛化误差与交叉验证
误差这个词我们经常会遇到，在机器学习中，我们最终想要的结果实际上就是减小学习后的估计值和真实值的误差。比如在回归中，我们的 loss function 就表示一个误差。而我们需要做的，就是最小化这个误差，也就是对 object function 的处理。
那么什么是泛化误差呢？刚刚说我们最小化了 loss function， 那是不是就一定说明我训练了一些样本后，保证求出了一组最佳的参数从而得到了一个完美的模型呢？显然不是，中国有句老话说的很好：“是骡子是马，拉出来溜溜”。怎么评价学习后得到的模型呢？实践是检验真理的唯一标准，我们再用一些数据（test data）来看看我们得到的模型在这些数据实践后，这时候的误差是多少。而这个误差，和刚刚 loss function的误差是没有关系的，也就是我们所说的泛化误差。而将数据划分为训练集（train set）和验证集（validation set）从而来求取泛化误差的方法，就是所谓的**交叉验证**。
所以交叉验证在做什么？假设我们有多种可能的模型而我们不能确定哪一种是最好的，那么我们就需要测试每一个模型训练后的泛化误差，从而选择最佳的模型。这里想多说一句，什么是模型，因为在我学习这部分时一直理解为模型就是不同参数下的同一种假设函数。实际上是完全错误的。模型指的是假设函数长什么样子，比如在回归问题中，我的假设函数可能是一个二次函数，也可能是三次甚至更高的多项式。每一个模型自然对应着一组最佳的参数，可以由最小化 loss function 来得到。交叉验证的意义在于，不是选最佳的参数，而是对每一个可能的模型，用训练集最小化 loss function 的误差从而得到最佳参数后，运用验证集来算出泛化误差。通过对泛化误差的评估来选出最优的模型。
所以我的理解就是： 训练集的作用是最小化 loss function 这样一个误差，从而能够得到最佳的参数，他不管你输入的是什么模型；验证集的作用是求取一个模型的泛化误差，它默认在测试后已经得到了该模型的最佳参数。**所以交叉验证的核心在于验证集！**

### 泛化误差的意义
泛化误差的意义，其实就是在训练后的模型，想来看一看这个模型具不具备代表性。那么这个代表性怎么去衡量呢？我们用偏差（bias）和方差（variance）来描述。偏差是什么？给了一些新的样本，我用我所得到的模型对这个样本进行估值，那这个估值和真实值的差距就是偏差；方差是什么？在不同的训练集上即使是同一模型我们可能会得到不同的参数，那么不同训练集上得到的假设函数对新样本做出的估值是不同的。我们用这些不同估值的期望作为最终这个模型对新样本的估值，那么我们想看一下这个期望的估值与不同训练集训练结果得到的估值的离散程度。
这和我们统计学上的期望与方差是相类似的，可以对比来看。我们希望最终的估值与实际值相差不大，而且所得到的模型也要相对稳定。在这种情况下我们就可以说我们的模型通用性比较强，也就是泛化。

### 泛化误差的构成
我们刚刚说偏差和方差可以来衡量这个模型是不是具有代表性，那么我们在验证集上得到了泛化误差后，怎么就能直接评估这个模型呢？我们来看一下泛化误差的构成。
先来定义几个概念：
在训练集 dd 上，我们训练后的模型为fd(x)fd(x)
那么该模型对数据 xx 的预测输出为 f(x)¯=Ed[fd(x)]f(x)¯=Ed[fd(x)]
验证集样本的真实值为 yy
由于会有噪声的存在，样本的标签值可能与真实值有出入，标签值设为 ydyd
噪声为 ϵ=y−ydϵ=y−yd，并且服从高斯分布 ϵ∼N(0,σ2)ϵ∼N(0,σ2)
根据偏差的定义，为预测输出与样本标签的差值，bias=y−f(x)¯bias=y−f(x)¯
根据方差的定义，为预测输出与不同测试集差的离散程度，var=Ed[(fd(x)−f(x)¯)2]var=Ed[(fd(x)−f(x)¯)2]
泛化误差的定义为 Ed[(yd−fd(x))2]Ed[(yd−fd(x))2]
泛化误差即每一组训练集得到结果后与验证集计算误差，误差的均值就作为衡量泛化的标准。
Ed[(yd−fd(x))2]=Ed[(yd−f(x)¯+f(x)¯−fd(x))2]
=Ed[(yd−f(x)¯)2]+Ed[(f(x)¯−fd(x))2]+0
=Ed[(yd−f(x)¯)2]+Ed[(f(x)¯−fd(x))2]
=Ed[(yd−y+y−f(x)¯)2]+Ed[(f(x)¯−fd(x))2]
=Ed[(yd−y)2]+Ed[(y−f(x)¯)2]+0+Ed[(f(x)¯−fd(x))2]
=Ed[(yd−y)2]+Ed[(y−f(x)¯)2]+Ed[(f(x)¯−fd(x))2]
=ϵ2+bias2+varEd[(yd−fd(x))2]
=Ed[(yd−f(x)¯+f(x)¯−fd(x))2]
=Ed[(yd−f(x)¯)2]+Ed[(f(x)¯−fd(x))2]+0
=Ed[(yd−f(x)¯)2]+Ed[(f(x)¯−fd(x))2]
=Ed[(yd−y+y−f(x)¯)2]+Ed[(f(x)¯−fd(x))2]
=Ed[(yd−y)2]+Ed[(y−f(x)¯)2]+0+Ed[(f(x)¯−fd(x))2]
=Ed[(yd−y)2]+Ed[(y−f(x)¯)2]+Ed[(f(x)¯−fd(x))2]
=ϵ2+bias2+var
由这个推导可以看出来，对于每一次交差验证完我们能够得到一组误差 (yd−fd(x))2(yd−fd(x))2，当我们把所有误差求均值后发现产生的误差，可以分解为偏差，方差以及噪声。也就能够体现出泛化能力。

### 总结
以上是我对泛化误差和交叉验证的理解，总结起来就是，泛化误差是衡量一个模型推广能力的标准，而交叉验证正是利用这一性质，将数据集分为训练集合验证集，对不同的模型计算泛化误差。从而帮助我们选取这个问题下的最佳模型。

